I0130 18:59:46.647845 108075 deephi_compress.cpp:236] cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/net_finetune.prototxt
I0130 18:59:46.822515 108075 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0130 18:59:46.822991 108075 gpu_memory.cpp:55] Total memory: 25620447232, Free: 14620622848, dev_info[0]: total=25620447232 free=14620622848
I0130 18:59:46.823001 108075 caffe_interface.cpp:493] Using GPUs 0
I0130 18:59:46.823254 108075 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0130 18:59:47.829386 108075 solver.cpp:51] Initializing solver from parameters: 
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 12000
snapshot_prefix: "cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/net_finetune.prototxt"
type: "Adam"
I0130 18:59:47.829493 108075 solver.cpp:99] Creating training net from net file: cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/net_finetune.prototxt
I0130 18:59:47.829711 108075 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0130 18:59:47.829726 108075 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0130 18:59:47.829866 108075 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "cats-vs-dogs/input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "scale1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "scale2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "scale7"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "scale7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0130 18:59:47.829951 108075 layer_factory.hpp:77] Creating layer data
I0130 18:59:47.830090 108075 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0130 18:59:47.830551 108075 net.cpp:94] Creating Layer data
I0130 18:59:47.830564 108075 net.cpp:409] data -> data
I0130 18:59:47.830574 108075 net.cpp:409] data -> label
I0130 18:59:47.831995 108112 db_lmdb.cpp:35] Opened lmdb cats-vs-dogs/input/lmdb/train_lmdb
I0130 18:59:47.832036 108112 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0130 18:59:47.832362 108075 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0130 18:59:47.832450 108075 data_layer.cpp:83] output data size: 256,3,227,227
I0130 18:59:48.244824 108075 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0130 18:59:48.244894 108075 net.cpp:144] Setting up data
I0130 18:59:48.244902 108075 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0130 18:59:48.244906 108075 net.cpp:151] Top shape: 256 (256)
I0130 18:59:48.244909 108075 net.cpp:159] Memory required for data: 158298112
I0130 18:59:48.244913 108075 layer_factory.hpp:77] Creating layer conv1
I0130 18:59:48.244928 108075 net.cpp:94] Creating Layer conv1
I0130 18:59:48.244931 108075 net.cpp:435] conv1 <- data
I0130 18:59:48.244947 108075 net.cpp:409] conv1 -> conv1
I0130 18:59:48.248536 108075 net.cpp:144] Setting up conv1
I0130 18:59:48.248549 108075 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0130 18:59:48.248551 108075 net.cpp:159] Memory required for data: 455667712
I0130 18:59:48.248582 108075 layer_factory.hpp:77] Creating layer bn1
I0130 18:59:48.248591 108075 net.cpp:94] Creating Layer bn1
I0130 18:59:48.248594 108075 net.cpp:435] bn1 <- conv1
I0130 18:59:48.248600 108075 net.cpp:409] bn1 -> scale1
I0130 18:59:48.249827 108075 net.cpp:144] Setting up bn1
I0130 18:59:48.249835 108075 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0130 18:59:48.249836 108075 net.cpp:159] Memory required for data: 753037312
I0130 18:59:48.249846 108075 layer_factory.hpp:77] Creating layer relu1
I0130 18:59:48.249867 108075 net.cpp:94] Creating Layer relu1
I0130 18:59:48.249871 108075 net.cpp:435] relu1 <- scale1
I0130 18:59:48.249874 108075 net.cpp:409] relu1 -> relu1
I0130 18:59:48.249943 108075 net.cpp:144] Setting up relu1
I0130 18:59:48.249951 108075 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0130 18:59:48.249955 108075 net.cpp:159] Memory required for data: 1050406912
I0130 18:59:48.249958 108075 layer_factory.hpp:77] Creating layer pool1
I0130 18:59:48.249966 108075 net.cpp:94] Creating Layer pool1
I0130 18:59:48.249969 108075 net.cpp:435] pool1 <- relu1
I0130 18:59:48.249975 108075 net.cpp:409] pool1 -> pool1
I0130 18:59:48.250044 108075 net.cpp:144] Setting up pool1
I0130 18:59:48.250049 108075 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0130 18:59:48.250051 108075 net.cpp:159] Memory required for data: 1122070528
I0130 18:59:48.250054 108075 layer_factory.hpp:77] Creating layer conv2
I0130 18:59:48.250061 108075 net.cpp:94] Creating Layer conv2
I0130 18:59:48.250064 108075 net.cpp:435] conv2 <- pool1
I0130 18:59:48.250071 108075 net.cpp:409] conv2 -> conv2
I0130 18:59:48.267201 108075 net.cpp:144] Setting up conv2
I0130 18:59:48.267220 108075 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0130 18:59:48.267223 108075 net.cpp:159] Memory required for data: 1313173504
I0130 18:59:48.267235 108075 layer_factory.hpp:77] Creating layer bn2
I0130 18:59:48.267244 108075 net.cpp:94] Creating Layer bn2
I0130 18:59:48.267248 108075 net.cpp:435] bn2 <- conv2
I0130 18:59:48.267257 108075 net.cpp:409] bn2 -> scale2
I0130 18:59:48.267838 108075 net.cpp:144] Setting up bn2
I0130 18:59:48.267846 108075 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0130 18:59:48.267849 108075 net.cpp:159] Memory required for data: 1504276480
I0130 18:59:48.267858 108075 layer_factory.hpp:77] Creating layer relu2
I0130 18:59:48.267863 108075 net.cpp:94] Creating Layer relu2
I0130 18:59:48.267868 108075 net.cpp:435] relu2 <- scale2
I0130 18:59:48.267875 108075 net.cpp:409] relu2 -> relu2
I0130 18:59:48.267902 108075 net.cpp:144] Setting up relu2
I0130 18:59:48.267911 108075 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0130 18:59:48.267915 108075 net.cpp:159] Memory required for data: 1695379456
I0130 18:59:48.267918 108075 layer_factory.hpp:77] Creating layer pool2
I0130 18:59:48.267926 108075 net.cpp:94] Creating Layer pool2
I0130 18:59:48.267931 108075 net.cpp:435] pool2 <- relu2
I0130 18:59:48.267958 108075 net.cpp:409] pool2 -> pool2
I0130 18:59:48.268007 108075 net.cpp:144] Setting up pool2
I0130 18:59:48.268013 108075 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0130 18:59:48.268018 108075 net.cpp:159] Memory required for data: 1739681792
I0130 18:59:48.268021 108075 layer_factory.hpp:77] Creating layer conv3
I0130 18:59:48.268029 108075 net.cpp:94] Creating Layer conv3
I0130 18:59:48.268033 108075 net.cpp:435] conv3 <- pool2
I0130 18:59:48.268038 108075 net.cpp:409] conv3 -> conv3
I0130 18:59:48.283574 108075 net.cpp:144] Setting up conv3
I0130 18:59:48.283605 108075 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0130 18:59:48.283608 108075 net.cpp:159] Memory required for data: 1806135296
I0130 18:59:48.283619 108075 layer_factory.hpp:77] Creating layer relu3
I0130 18:59:48.283632 108075 net.cpp:94] Creating Layer relu3
I0130 18:59:48.283637 108075 net.cpp:435] relu3 <- conv3
I0130 18:59:48.283644 108075 net.cpp:409] relu3 -> relu3
I0130 18:59:48.283668 108075 net.cpp:144] Setting up relu3
I0130 18:59:48.283674 108075 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0130 18:59:48.283676 108075 net.cpp:159] Memory required for data: 1872588800
I0130 18:59:48.283679 108075 layer_factory.hpp:77] Creating layer conv4
I0130 18:59:48.283689 108075 net.cpp:94] Creating Layer conv4
I0130 18:59:48.283691 108075 net.cpp:435] conv4 <- relu3
I0130 18:59:48.283696 108075 net.cpp:409] conv4 -> conv4
I0130 18:59:48.298846 108075 net.cpp:144] Setting up conv4
I0130 18:59:48.298867 108075 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0130 18:59:48.298871 108075 net.cpp:159] Memory required for data: 1939042304
I0130 18:59:48.298882 108075 layer_factory.hpp:77] Creating layer relu4
I0130 18:59:48.298890 108075 net.cpp:94] Creating Layer relu4
I0130 18:59:48.298894 108075 net.cpp:435] relu4 <- conv4
I0130 18:59:48.298900 108075 net.cpp:409] relu4 -> relu4
I0130 18:59:48.298933 108075 net.cpp:144] Setting up relu4
I0130 18:59:48.298939 108075 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0130 18:59:48.298941 108075 net.cpp:159] Memory required for data: 2005495808
I0130 18:59:48.298945 108075 layer_factory.hpp:77] Creating layer conv5
I0130 18:59:48.298954 108075 net.cpp:94] Creating Layer conv5
I0130 18:59:48.298957 108075 net.cpp:435] conv5 <- relu4
I0130 18:59:48.298962 108075 net.cpp:409] conv5 -> conv5
I0130 18:59:48.315780 108075 net.cpp:144] Setting up conv5
I0130 18:59:48.315805 108075 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0130 18:59:48.315809 108075 net.cpp:159] Memory required for data: 2049798144
I0130 18:59:48.315819 108075 layer_factory.hpp:77] Creating layer relu5
I0130 18:59:48.315831 108075 net.cpp:94] Creating Layer relu5
I0130 18:59:48.315835 108075 net.cpp:435] relu5 <- conv5
I0130 18:59:48.315842 108075 net.cpp:409] relu5 -> relu5
I0130 18:59:48.315874 108075 net.cpp:144] Setting up relu5
I0130 18:59:48.315907 108075 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0130 18:59:48.315922 108075 net.cpp:159] Memory required for data: 2094100480
I0130 18:59:48.315938 108075 layer_factory.hpp:77] Creating layer pool5
I0130 18:59:48.315959 108075 net.cpp:94] Creating Layer pool5
I0130 18:59:48.315975 108075 net.cpp:435] pool5 <- relu5
I0130 18:59:48.315994 108075 net.cpp:409] pool5 -> pool5
I0130 18:59:48.316048 108075 net.cpp:144] Setting up pool5
I0130 18:59:48.316057 108075 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0130 18:59:48.316062 108075 net.cpp:159] Memory required for data: 2103537664
I0130 18:59:48.316066 108075 layer_factory.hpp:77] Creating layer fc6
I0130 18:59:48.316077 108075 net.cpp:94] Creating Layer fc6
I0130 18:59:48.316082 108075 net.cpp:435] fc6 <- pool5
I0130 18:59:48.316092 108075 net.cpp:409] fc6 -> fc6
I0130 18:59:48.679991 108075 net.cpp:144] Setting up fc6
I0130 18:59:48.680018 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.680022 108075 net.cpp:159] Memory required for data: 2107731968
I0130 18:59:48.680032 108075 layer_factory.hpp:77] Creating layer relu6
I0130 18:59:48.680040 108075 net.cpp:94] Creating Layer relu6
I0130 18:59:48.680061 108075 net.cpp:435] relu6 <- fc6
I0130 18:59:48.680069 108075 net.cpp:409] relu6 -> relu6
I0130 18:59:48.680089 108075 net.cpp:144] Setting up relu6
I0130 18:59:48.680109 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.680112 108075 net.cpp:159] Memory required for data: 2111926272
I0130 18:59:48.680115 108075 layer_factory.hpp:77] Creating layer drop6
I0130 18:59:48.680121 108075 net.cpp:94] Creating Layer drop6
I0130 18:59:48.680130 108075 net.cpp:435] drop6 <- relu6
I0130 18:59:48.680135 108075 net.cpp:409] drop6 -> drop6
I0130 18:59:48.680171 108075 net.cpp:144] Setting up drop6
I0130 18:59:48.680176 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.680178 108075 net.cpp:159] Memory required for data: 2116120576
I0130 18:59:48.680181 108075 layer_factory.hpp:77] Creating layer fc7
I0130 18:59:48.680189 108075 net.cpp:94] Creating Layer fc7
I0130 18:59:48.680194 108075 net.cpp:435] fc7 <- drop6
I0130 18:59:48.680200 108075 net.cpp:409] fc7 -> fc7
I0130 18:59:48.827535 108075 net.cpp:144] Setting up fc7
I0130 18:59:48.827560 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.827564 108075 net.cpp:159] Memory required for data: 2120314880
I0130 18:59:48.827574 108075 layer_factory.hpp:77] Creating layer bn7
I0130 18:59:48.827585 108075 net.cpp:94] Creating Layer bn7
I0130 18:59:48.827590 108075 net.cpp:435] bn7 <- fc7
I0130 18:59:48.827600 108075 net.cpp:409] bn7 -> scale7
I0130 18:59:48.828112 108075 net.cpp:144] Setting up bn7
I0130 18:59:48.828119 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.828124 108075 net.cpp:159] Memory required for data: 2124509184
I0130 18:59:48.828135 108075 layer_factory.hpp:77] Creating layer relu7
I0130 18:59:48.828142 108075 net.cpp:94] Creating Layer relu7
I0130 18:59:48.828145 108075 net.cpp:435] relu7 <- scale7
I0130 18:59:48.828151 108075 net.cpp:409] relu7 -> relu7
I0130 18:59:48.828171 108075 net.cpp:144] Setting up relu7
I0130 18:59:48.828176 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.828181 108075 net.cpp:159] Memory required for data: 2128703488
I0130 18:59:48.828183 108075 layer_factory.hpp:77] Creating layer drop7
I0130 18:59:48.828191 108075 net.cpp:94] Creating Layer drop7
I0130 18:59:48.828193 108075 net.cpp:435] drop7 <- relu7
I0130 18:59:48.828199 108075 net.cpp:409] drop7 -> drop7
I0130 18:59:48.828225 108075 net.cpp:144] Setting up drop7
I0130 18:59:48.828230 108075 net.cpp:151] Top shape: 256 4096 (1048576)
I0130 18:59:48.828233 108075 net.cpp:159] Memory required for data: 2132897792
I0130 18:59:48.828236 108075 layer_factory.hpp:77] Creating layer fc8
I0130 18:59:48.828244 108075 net.cpp:94] Creating Layer fc8
I0130 18:59:48.828249 108075 net.cpp:435] fc8 <- drop7
I0130 18:59:48.828254 108075 net.cpp:409] fc8 -> fc8
I0130 18:59:48.829144 108075 net.cpp:144] Setting up fc8
I0130 18:59:48.829157 108075 net.cpp:151] Top shape: 256 2 (512)
I0130 18:59:48.829161 108075 net.cpp:159] Memory required for data: 2132899840
I0130 18:59:48.829169 108075 layer_factory.hpp:77] Creating layer loss
I0130 18:59:48.829176 108075 net.cpp:94] Creating Layer loss
I0130 18:59:48.829180 108075 net.cpp:435] loss <- fc8
I0130 18:59:48.829186 108075 net.cpp:435] loss <- label
I0130 18:59:48.829192 108075 net.cpp:409] loss -> loss
I0130 18:59:48.829202 108075 layer_factory.hpp:77] Creating layer loss
I0130 18:59:48.829268 108075 net.cpp:144] Setting up loss
I0130 18:59:48.829274 108075 net.cpp:151] Top shape: (1)
I0130 18:59:48.829277 108075 net.cpp:154]     with loss weight 1
I0130 18:59:48.829288 108075 net.cpp:159] Memory required for data: 2132899844
I0130 18:59:48.829291 108075 net.cpp:220] loss needs backward computation.
I0130 18:59:48.829309 108075 net.cpp:220] fc8 needs backward computation.
I0130 18:59:48.829313 108075 net.cpp:220] drop7 needs backward computation.
I0130 18:59:48.829316 108075 net.cpp:220] relu7 needs backward computation.
I0130 18:59:48.829320 108075 net.cpp:220] bn7 needs backward computation.
I0130 18:59:48.829324 108075 net.cpp:220] fc7 needs backward computation.
I0130 18:59:48.829340 108075 net.cpp:220] drop6 needs backward computation.
I0130 18:59:48.829344 108075 net.cpp:220] relu6 needs backward computation.
I0130 18:59:48.829349 108075 net.cpp:220] fc6 needs backward computation.
I0130 18:59:48.829352 108075 net.cpp:220] pool5 needs backward computation.
I0130 18:59:48.829356 108075 net.cpp:220] relu5 needs backward computation.
I0130 18:59:48.829360 108075 net.cpp:220] conv5 needs backward computation.
I0130 18:59:48.829363 108075 net.cpp:220] relu4 needs backward computation.
I0130 18:59:48.829367 108075 net.cpp:220] conv4 needs backward computation.
I0130 18:59:48.829370 108075 net.cpp:220] relu3 needs backward computation.
I0130 18:59:48.829375 108075 net.cpp:220] conv3 needs backward computation.
I0130 18:59:48.829378 108075 net.cpp:220] pool2 needs backward computation.
I0130 18:59:48.829381 108075 net.cpp:220] relu2 needs backward computation.
I0130 18:59:48.829385 108075 net.cpp:220] bn2 needs backward computation.
I0130 18:59:48.829390 108075 net.cpp:220] conv2 needs backward computation.
I0130 18:59:48.829392 108075 net.cpp:220] pool1 needs backward computation.
I0130 18:59:48.829396 108075 net.cpp:220] relu1 needs backward computation.
I0130 18:59:48.829401 108075 net.cpp:220] bn1 needs backward computation.
I0130 18:59:48.829403 108075 net.cpp:220] conv1 needs backward computation.
I0130 18:59:48.829407 108075 net.cpp:222] data does not need backward computation.
I0130 18:59:48.829411 108075 net.cpp:264] This network produces output loss
I0130 18:59:48.829432 108075 net.cpp:284] Network initialization done.
I0130 18:59:48.829707 108075 solver.cpp:189] Creating test net (#0) specified by net file: cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/net_finetune.prototxt
I0130 18:59:48.829740 108075 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0130 18:59:48.829906 108075 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "cats-vs-dogs/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "scale1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "scale2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "scale7"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "scale7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0130 18:59:48.830015 108075 layer_factory.hpp:77] Creating layer data
I0130 18:59:48.830060 108075 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0130 18:59:48.830891 108075 net.cpp:94] Creating Layer data
I0130 18:59:48.830904 108075 net.cpp:409] data -> data
I0130 18:59:48.830915 108075 net.cpp:409] data -> label
I0130 18:59:48.832006 108142 db_lmdb.cpp:35] Opened lmdb cats-vs-dogs/input/lmdb/valid_lmdb
I0130 18:59:48.832044 108142 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0130 18:59:48.832298 108075 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0130 18:59:48.832365 108075 data_layer.cpp:83] output data size: 50,3,227,227
I0130 18:59:48.934118 108075 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0130 18:59:48.934170 108075 net.cpp:144] Setting up data
I0130 18:59:48.934178 108075 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0130 18:59:48.934181 108075 net.cpp:151] Top shape: 50 (50)
I0130 18:59:48.934183 108075 net.cpp:159] Memory required for data: 30917600
I0130 18:59:48.934206 108075 layer_factory.hpp:77] Creating layer label_data_1_split
I0130 18:59:48.934216 108075 net.cpp:94] Creating Layer label_data_1_split
I0130 18:59:48.934218 108075 net.cpp:435] label_data_1_split <- label
I0130 18:59:48.934234 108075 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0130 18:59:48.934243 108075 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0130 18:59:48.934298 108075 net.cpp:144] Setting up label_data_1_split
I0130 18:59:48.934303 108075 net.cpp:151] Top shape: 50 (50)
I0130 18:59:48.934306 108075 net.cpp:151] Top shape: 50 (50)
I0130 18:59:48.934309 108075 net.cpp:159] Memory required for data: 30918000
I0130 18:59:48.934311 108075 layer_factory.hpp:77] Creating layer conv1
I0130 18:59:48.934321 108075 net.cpp:94] Creating Layer conv1
I0130 18:59:48.934324 108075 net.cpp:435] conv1 <- data
I0130 18:59:48.934329 108075 net.cpp:409] conv1 -> conv1
I0130 18:59:48.934938 108075 net.cpp:144] Setting up conv1
I0130 18:59:48.934945 108075 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0130 18:59:48.934948 108075 net.cpp:159] Memory required for data: 88998000
I0130 18:59:48.934957 108075 layer_factory.hpp:77] Creating layer bn1
I0130 18:59:48.934965 108075 net.cpp:94] Creating Layer bn1
I0130 18:59:48.934967 108075 net.cpp:435] bn1 <- conv1
I0130 18:59:48.934972 108075 net.cpp:409] bn1 -> scale1
I0130 18:59:48.936836 108075 net.cpp:144] Setting up bn1
I0130 18:59:48.936842 108075 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0130 18:59:48.936844 108075 net.cpp:159] Memory required for data: 147078000
I0130 18:59:48.936853 108075 layer_factory.hpp:77] Creating layer relu1
I0130 18:59:48.936874 108075 net.cpp:94] Creating Layer relu1
I0130 18:59:48.936877 108075 net.cpp:435] relu1 <- scale1
I0130 18:59:48.936882 108075 net.cpp:409] relu1 -> relu1
I0130 18:59:48.937147 108075 net.cpp:144] Setting up relu1
I0130 18:59:48.937153 108075 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0130 18:59:48.937156 108075 net.cpp:159] Memory required for data: 205158000
I0130 18:59:48.937160 108075 layer_factory.hpp:77] Creating layer pool1
I0130 18:59:48.937163 108075 net.cpp:94] Creating Layer pool1
I0130 18:59:48.937166 108075 net.cpp:435] pool1 <- relu1
I0130 18:59:48.937170 108075 net.cpp:409] pool1 -> pool1
I0130 18:59:48.937202 108075 net.cpp:144] Setting up pool1
I0130 18:59:48.937206 108075 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0130 18:59:48.937208 108075 net.cpp:159] Memory required for data: 219154800
I0130 18:59:48.937211 108075 layer_factory.hpp:77] Creating layer conv2
I0130 18:59:48.937217 108075 net.cpp:94] Creating Layer conv2
I0130 18:59:48.937237 108075 net.cpp:435] conv2 <- pool1
I0130 18:59:48.937242 108075 net.cpp:409] conv2 -> conv2
I0130 18:59:48.944272 108075 net.cpp:144] Setting up conv2
I0130 18:59:48.944294 108075 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0130 18:59:48.944298 108075 net.cpp:159] Memory required for data: 256479600
I0130 18:59:48.944314 108075 layer_factory.hpp:77] Creating layer bn2
I0130 18:59:48.944337 108075 net.cpp:94] Creating Layer bn2
I0130 18:59:48.944347 108075 net.cpp:435] bn2 <- conv2
I0130 18:59:48.944357 108075 net.cpp:409] bn2 -> scale2
I0130 18:59:48.944994 108075 net.cpp:144] Setting up bn2
I0130 18:59:48.945003 108075 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0130 18:59:48.945008 108075 net.cpp:159] Memory required for data: 293804400
I0130 18:59:48.945026 108075 layer_factory.hpp:77] Creating layer relu2
I0130 18:59:48.945035 108075 net.cpp:94] Creating Layer relu2
I0130 18:59:48.945041 108075 net.cpp:435] relu2 <- scale2
I0130 18:59:48.945047 108075 net.cpp:409] relu2 -> relu2
I0130 18:59:48.945072 108075 net.cpp:144] Setting up relu2
I0130 18:59:48.945078 108075 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0130 18:59:48.945083 108075 net.cpp:159] Memory required for data: 331129200
I0130 18:59:48.945086 108075 layer_factory.hpp:77] Creating layer pool2
I0130 18:59:48.945094 108075 net.cpp:94] Creating Layer pool2
I0130 18:59:48.945098 108075 net.cpp:435] pool2 <- relu2
I0130 18:59:48.945106 108075 net.cpp:409] pool2 -> pool2
I0130 18:59:48.945142 108075 net.cpp:144] Setting up pool2
I0130 18:59:48.945147 108075 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0130 18:59:48.945150 108075 net.cpp:159] Memory required for data: 339782000
I0130 18:59:48.945155 108075 layer_factory.hpp:77] Creating layer conv3
I0130 18:59:48.945168 108075 net.cpp:94] Creating Layer conv3
I0130 18:59:48.945174 108075 net.cpp:435] conv3 <- pool2
I0130 18:59:48.945183 108075 net.cpp:409] conv3 -> conv3
I0130 18:59:48.957515 108075 net.cpp:144] Setting up conv3
I0130 18:59:48.957538 108075 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0130 18:59:48.957542 108075 net.cpp:159] Memory required for data: 352761200
I0130 18:59:48.957552 108075 layer_factory.hpp:77] Creating layer relu3
I0130 18:59:48.957563 108075 net.cpp:94] Creating Layer relu3
I0130 18:59:48.957568 108075 net.cpp:435] relu3 <- conv3
I0130 18:59:48.957577 108075 net.cpp:409] relu3 -> relu3
I0130 18:59:48.957612 108075 net.cpp:144] Setting up relu3
I0130 18:59:48.957617 108075 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0130 18:59:48.957621 108075 net.cpp:159] Memory required for data: 365740400
I0130 18:59:48.957625 108075 layer_factory.hpp:77] Creating layer conv4
I0130 18:59:48.957638 108075 net.cpp:94] Creating Layer conv4
I0130 18:59:48.957643 108075 net.cpp:435] conv4 <- relu3
I0130 18:59:48.957649 108075 net.cpp:409] conv4 -> conv4
I0130 18:59:48.975203 108075 net.cpp:144] Setting up conv4
I0130 18:59:48.975230 108075 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0130 18:59:48.975234 108075 net.cpp:159] Memory required for data: 378719600
I0130 18:59:48.975251 108075 layer_factory.hpp:77] Creating layer relu4
I0130 18:59:48.975262 108075 net.cpp:94] Creating Layer relu4
I0130 18:59:48.975273 108075 net.cpp:435] relu4 <- conv4
I0130 18:59:48.975283 108075 net.cpp:409] relu4 -> relu4
I0130 18:59:48.975324 108075 net.cpp:144] Setting up relu4
I0130 18:59:48.975330 108075 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0130 18:59:48.975334 108075 net.cpp:159] Memory required for data: 391698800
I0130 18:59:48.975339 108075 layer_factory.hpp:77] Creating layer conv5
I0130 18:59:48.975352 108075 net.cpp:94] Creating Layer conv5
I0130 18:59:48.975354 108075 net.cpp:435] conv5 <- relu4
I0130 18:59:48.975361 108075 net.cpp:409] conv5 -> conv5
I0130 18:59:48.985707 108075 net.cpp:144] Setting up conv5
I0130 18:59:48.985736 108075 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0130 18:59:48.985741 108075 net.cpp:159] Memory required for data: 400351600
I0130 18:59:48.985752 108075 layer_factory.hpp:77] Creating layer relu5
I0130 18:59:48.985764 108075 net.cpp:94] Creating Layer relu5
I0130 18:59:48.985791 108075 net.cpp:435] relu5 <- conv5
I0130 18:59:48.985800 108075 net.cpp:409] relu5 -> relu5
I0130 18:59:48.985838 108075 net.cpp:144] Setting up relu5
I0130 18:59:48.985847 108075 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0130 18:59:48.985852 108075 net.cpp:159] Memory required for data: 409004400
I0130 18:59:48.985855 108075 layer_factory.hpp:77] Creating layer pool5
I0130 18:59:48.985865 108075 net.cpp:94] Creating Layer pool5
I0130 18:59:48.985870 108075 net.cpp:435] pool5 <- relu5
I0130 18:59:48.985874 108075 net.cpp:409] pool5 -> pool5
I0130 18:59:48.985908 108075 net.cpp:144] Setting up pool5
I0130 18:59:48.985913 108075 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0130 18:59:48.985916 108075 net.cpp:159] Memory required for data: 410847600
I0130 18:59:48.985918 108075 layer_factory.hpp:77] Creating layer fc6
I0130 18:59:48.985925 108075 net.cpp:94] Creating Layer fc6
I0130 18:59:48.985929 108075 net.cpp:435] fc6 <- pool5
I0130 18:59:48.985934 108075 net.cpp:409] fc6 -> fc6
I0130 18:59:49.325064 108075 net.cpp:144] Setting up fc6
I0130 18:59:49.325088 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.325090 108075 net.cpp:159] Memory required for data: 411666800
I0130 18:59:49.325114 108075 layer_factory.hpp:77] Creating layer relu6
I0130 18:59:49.325121 108075 net.cpp:94] Creating Layer relu6
I0130 18:59:49.325124 108075 net.cpp:435] relu6 <- fc6
I0130 18:59:49.325139 108075 net.cpp:409] relu6 -> relu6
I0130 18:59:49.325165 108075 net.cpp:144] Setting up relu6
I0130 18:59:49.325167 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.325170 108075 net.cpp:159] Memory required for data: 412486000
I0130 18:59:49.325172 108075 layer_factory.hpp:77] Creating layer drop6
I0130 18:59:49.325177 108075 net.cpp:94] Creating Layer drop6
I0130 18:59:49.325179 108075 net.cpp:435] drop6 <- relu6
I0130 18:59:49.325183 108075 net.cpp:409] drop6 -> drop6
I0130 18:59:49.325206 108075 net.cpp:144] Setting up drop6
I0130 18:59:49.325211 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.325212 108075 net.cpp:159] Memory required for data: 413305200
I0130 18:59:49.325230 108075 layer_factory.hpp:77] Creating layer fc7
I0130 18:59:49.325237 108075 net.cpp:94] Creating Layer fc7
I0130 18:59:49.325238 108075 net.cpp:435] fc7 <- drop6
I0130 18:59:49.325242 108075 net.cpp:409] fc7 -> fc7
I0130 18:59:49.476948 108075 net.cpp:144] Setting up fc7
I0130 18:59:49.476970 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.476974 108075 net.cpp:159] Memory required for data: 414124400
I0130 18:59:49.476981 108075 layer_factory.hpp:77] Creating layer bn7
I0130 18:59:49.476989 108075 net.cpp:94] Creating Layer bn7
I0130 18:59:49.476994 108075 net.cpp:435] bn7 <- fc7
I0130 18:59:49.477000 108075 net.cpp:409] bn7 -> scale7
I0130 18:59:49.477571 108075 net.cpp:144] Setting up bn7
I0130 18:59:49.477577 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.477581 108075 net.cpp:159] Memory required for data: 414943600
I0130 18:59:49.477589 108075 layer_factory.hpp:77] Creating layer relu7
I0130 18:59:49.477594 108075 net.cpp:94] Creating Layer relu7
I0130 18:59:49.477596 108075 net.cpp:435] relu7 <- scale7
I0130 18:59:49.477600 108075 net.cpp:409] relu7 -> relu7
I0130 18:59:49.477619 108075 net.cpp:144] Setting up relu7
I0130 18:59:49.477624 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.477627 108075 net.cpp:159] Memory required for data: 415762800
I0130 18:59:49.477628 108075 layer_factory.hpp:77] Creating layer drop7
I0130 18:59:49.477633 108075 net.cpp:94] Creating Layer drop7
I0130 18:59:49.477636 108075 net.cpp:435] drop7 <- relu7
I0130 18:59:49.477640 108075 net.cpp:409] drop7 -> drop7
I0130 18:59:49.477663 108075 net.cpp:144] Setting up drop7
I0130 18:59:49.477669 108075 net.cpp:151] Top shape: 50 4096 (204800)
I0130 18:59:49.477671 108075 net.cpp:159] Memory required for data: 416582000
I0130 18:59:49.477674 108075 layer_factory.hpp:77] Creating layer fc8
I0130 18:59:49.477679 108075 net.cpp:94] Creating Layer fc8
I0130 18:59:49.477702 108075 net.cpp:435] fc8 <- drop7
I0130 18:59:49.477706 108075 net.cpp:409] fc8 -> fc8
I0130 18:59:49.477870 108075 net.cpp:144] Setting up fc8
I0130 18:59:49.477875 108075 net.cpp:151] Top shape: 50 2 (100)
I0130 18:59:49.477880 108075 net.cpp:159] Memory required for data: 416582400
I0130 18:59:49.477883 108075 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0130 18:59:49.477887 108075 net.cpp:94] Creating Layer fc8_fc8_0_split
I0130 18:59:49.477890 108075 net.cpp:435] fc8_fc8_0_split <- fc8
I0130 18:59:49.477895 108075 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0130 18:59:49.477900 108075 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0130 18:59:49.477923 108075 net.cpp:144] Setting up fc8_fc8_0_split
I0130 18:59:49.477928 108075 net.cpp:151] Top shape: 50 2 (100)
I0130 18:59:49.477931 108075 net.cpp:151] Top shape: 50 2 (100)
I0130 18:59:49.477933 108075 net.cpp:159] Memory required for data: 416583200
I0130 18:59:49.477936 108075 layer_factory.hpp:77] Creating layer loss
I0130 18:59:49.477939 108075 net.cpp:94] Creating Layer loss
I0130 18:59:49.477942 108075 net.cpp:435] loss <- fc8_fc8_0_split_0
I0130 18:59:49.477946 108075 net.cpp:435] loss <- label_data_1_split_0
I0130 18:59:49.477950 108075 net.cpp:409] loss -> loss
I0130 18:59:49.477957 108075 layer_factory.hpp:77] Creating layer loss
I0130 18:59:49.478027 108075 net.cpp:144] Setting up loss
I0130 18:59:49.478031 108075 net.cpp:151] Top shape: (1)
I0130 18:59:49.478034 108075 net.cpp:154]     with loss weight 1
I0130 18:59:49.478044 108075 net.cpp:159] Memory required for data: 416583204
I0130 18:59:49.478046 108075 layer_factory.hpp:77] Creating layer accuracy-top1
I0130 18:59:49.478051 108075 net.cpp:94] Creating Layer accuracy-top1
I0130 18:59:49.478054 108075 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_1
I0130 18:59:49.478056 108075 net.cpp:435] accuracy-top1 <- label_data_1_split_1
I0130 18:59:49.478060 108075 net.cpp:409] accuracy-top1 -> top-1
I0130 18:59:49.478066 108075 net.cpp:144] Setting up accuracy-top1
I0130 18:59:49.478070 108075 net.cpp:151] Top shape: (1)
I0130 18:59:49.478072 108075 net.cpp:159] Memory required for data: 416583208
I0130 18:59:49.478075 108075 net.cpp:222] accuracy-top1 does not need backward computation.
I0130 18:59:49.478078 108075 net.cpp:220] loss needs backward computation.
I0130 18:59:49.478081 108075 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0130 18:59:49.478083 108075 net.cpp:220] fc8 needs backward computation.
I0130 18:59:49.478086 108075 net.cpp:220] drop7 needs backward computation.
I0130 18:59:49.478090 108075 net.cpp:220] relu7 needs backward computation.
I0130 18:59:49.478091 108075 net.cpp:220] bn7 needs backward computation.
I0130 18:59:49.478094 108075 net.cpp:220] fc7 needs backward computation.
I0130 18:59:49.478097 108075 net.cpp:220] drop6 needs backward computation.
I0130 18:59:49.478101 108075 net.cpp:220] relu6 needs backward computation.
I0130 18:59:49.478102 108075 net.cpp:220] fc6 needs backward computation.
I0130 18:59:49.478104 108075 net.cpp:220] pool5 needs backward computation.
I0130 18:59:49.478107 108075 net.cpp:220] relu5 needs backward computation.
I0130 18:59:49.478111 108075 net.cpp:220] conv5 needs backward computation.
I0130 18:59:49.478112 108075 net.cpp:220] relu4 needs backward computation.
I0130 18:59:49.478116 108075 net.cpp:220] conv4 needs backward computation.
I0130 18:59:49.478118 108075 net.cpp:220] relu3 needs backward computation.
I0130 18:59:49.478121 108075 net.cpp:220] conv3 needs backward computation.
I0130 18:59:49.478123 108075 net.cpp:220] pool2 needs backward computation.
I0130 18:59:49.478126 108075 net.cpp:220] relu2 needs backward computation.
I0130 18:59:49.478128 108075 net.cpp:220] bn2 needs backward computation.
I0130 18:59:49.478130 108075 net.cpp:220] conv2 needs backward computation.
I0130 18:59:49.478133 108075 net.cpp:220] pool1 needs backward computation.
I0130 18:59:49.478135 108075 net.cpp:220] relu1 needs backward computation.
I0130 18:59:49.478138 108075 net.cpp:220] bn1 needs backward computation.
I0130 18:59:49.478149 108075 net.cpp:220] conv1 needs backward computation.
I0130 18:59:49.478152 108075 net.cpp:222] label_data_1_split does not need backward computation.
I0130 18:59:49.478155 108075 net.cpp:222] data does not need backward computation.
I0130 18:59:49.478158 108075 net.cpp:264] This network produces output loss
I0130 18:59:49.478160 108075 net.cpp:264] This network produces output top-1
I0130 18:59:49.478178 108075 net.cpp:284] Network initialization done.
I0130 18:59:49.478283 108075 solver.cpp:63] Solver scaffolding done.
I0130 18:59:49.479521 108075 caffe_interface.cpp:93] Finetuning from cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/sparse.caffemodel
I0130 18:59:51.127720 108075 caffe_interface.cpp:527] Starting Optimization
I0130 18:59:51.127740 108075 solver.cpp:335] Solving 
I0130 18:59:51.127743 108075 solver.cpp:336] Learning Rate Policy: step
I0130 18:59:51.129959 108075 solver.cpp:418] Iteration 0, Testing net (#0)
I0130 18:59:54.675580 108075 solver.cpp:517]     Test net output #0: loss = 0.202857 (* 1 = 0.202857 loss)
I0130 18:59:54.675602 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95675
I0130 18:59:55.269644 108075 solver.cpp:266] Iteration 0 (0 iter/s, 4.14172s/50 iter), loss = 0.000794127
I0130 18:59:55.269675 108075 solver.cpp:285]     Train net output #0: loss = 0.000794127 (* 1 = 0.000794127 loss)
I0130 18:59:55.271958 108075 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0130 19:00:19.535966 108075 solver.cpp:266] Iteration 50 (2.06074 iter/s, 24.2631s/50 iter), loss = 0.123971
I0130 19:00:19.536036 108075 solver.cpp:285]     Train net output #0: loss = 0.123971 (* 1 = 0.123971 loss)
I0130 19:00:19.538220 108075 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0130 19:00:44.011445 108075 solver.cpp:266] Iteration 100 (2.04312 iter/s, 24.4723s/50 iter), loss = 0.0231088
I0130 19:00:44.011485 108075 solver.cpp:285]     Train net output #0: loss = 0.0231088 (* 1 = 0.0231088 loss)
I0130 19:00:44.013695 108075 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0130 19:01:08.664554 108075 solver.cpp:266] Iteration 150 (2.0284 iter/s, 24.65s/50 iter), loss = 0.0475764
I0130 19:01:08.664608 108075 solver.cpp:285]     Train net output #0: loss = 0.0475764 (* 1 = 0.0475764 loss)
I0130 19:01:08.666801 108075 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0130 19:01:33.326845 108075 solver.cpp:266] Iteration 200 (2.02765 iter/s, 24.6591s/50 iter), loss = 0.0509651
I0130 19:01:33.326889 108075 solver.cpp:285]     Train net output #0: loss = 0.0509651 (* 1 = 0.0509651 loss)
I0130 19:01:33.326931 108075 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0130 19:01:57.783998 108075 solver.cpp:266] Iteration 250 (2.04447 iter/s, 24.4562s/50 iter), loss = 0.0401931
I0130 19:01:57.784132 108075 solver.cpp:285]     Train net output #0: loss = 0.0401931 (* 1 = 0.0401931 loss)
I0130 19:01:57.784281 108075 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0130 19:02:22.364248 108075 solver.cpp:266] Iteration 300 (2.03425 iter/s, 24.5791s/50 iter), loss = 0.0557585
I0130 19:02:22.364281 108075 solver.cpp:285]     Train net output #0: loss = 0.0557585 (* 1 = 0.0557585 loss)
I0130 19:02:22.366506 108075 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0130 19:02:46.919731 108075 solver.cpp:266] Iteration 350 (2.03647 iter/s, 24.5523s/50 iter), loss = 0.0796052
I0130 19:02:46.919853 108075 solver.cpp:285]     Train net output #0: loss = 0.0796052 (* 1 = 0.0796052 loss)
I0130 19:02:46.921985 108075 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0130 19:03:11.398427 108075 solver.cpp:266] Iteration 400 (2.04286 iter/s, 24.4755s/50 iter), loss = 0.0328728
I0130 19:03:11.398459 108075 solver.cpp:285]     Train net output #0: loss = 0.0328728 (* 1 = 0.0328728 loss)
I0130 19:03:11.400673 108075 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0130 19:03:35.915886 108075 solver.cpp:266] Iteration 450 (2.03963 iter/s, 24.5143s/50 iter), loss = 0.0400809
I0130 19:03:35.915976 108075 solver.cpp:285]     Train net output #0: loss = 0.0400809 (* 1 = 0.0400809 loss)
I0130 19:03:35.915982 108075 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0130 19:04:00.626391 108075 solver.cpp:266] Iteration 500 (2.02351 iter/s, 24.7095s/50 iter), loss = 0.0383771
I0130 19:04:00.626425 108075 solver.cpp:285]     Train net output #0: loss = 0.0383771 (* 1 = 0.0383771 loss)
I0130 19:04:00.626477 108075 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0130 19:04:25.262701 108075 solver.cpp:266] Iteration 550 (2.02961 iter/s, 24.6353s/50 iter), loss = 0.0538273
I0130 19:04:25.262837 108075 solver.cpp:285]     Train net output #0: loss = 0.0538273 (* 1 = 0.0538273 loss)
I0130 19:04:25.262845 108075 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0130 19:04:49.888976 108075 solver.cpp:266] Iteration 600 (2.03044 iter/s, 24.6252s/50 iter), loss = 0.0613805
I0130 19:04:49.889012 108075 solver.cpp:285]     Train net output #0: loss = 0.0613805 (* 1 = 0.0613805 loss)
I0130 19:04:49.891227 108075 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0130 19:05:14.281620 108075 solver.cpp:266] Iteration 650 (2.05006 iter/s, 24.3895s/50 iter), loss = 0.0580838
I0130 19:05:14.281739 108075 solver.cpp:285]     Train net output #0: loss = 0.0580838 (* 1 = 0.0580838 loss)
I0130 19:05:14.281882 108075 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0130 19:05:38.893723 108075 solver.cpp:266] Iteration 700 (2.03162 iter/s, 24.6109s/50 iter), loss = 0.0566552
I0130 19:05:38.893754 108075 solver.cpp:285]     Train net output #0: loss = 0.0566552 (* 1 = 0.0566552 loss)
I0130 19:05:38.895970 108075 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0130 19:06:03.273370 108075 solver.cpp:266] Iteration 750 (2.05116 iter/s, 24.3765s/50 iter), loss = 0.0558305
I0130 19:06:03.273474 108075 solver.cpp:285]     Train net output #0: loss = 0.0558305 (* 1 = 0.0558305 loss)
I0130 19:06:03.275624 108075 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0130 19:06:27.697963 108075 solver.cpp:266] Iteration 800 (2.04738 iter/s, 24.4214s/50 iter), loss = 0.0300854
I0130 19:06:27.697996 108075 solver.cpp:285]     Train net output #0: loss = 0.0300854 (* 1 = 0.0300854 loss)
I0130 19:06:27.698050 108075 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0130 19:06:52.268931 108075 solver.cpp:266] Iteration 850 (2.035 iter/s, 24.57s/50 iter), loss = 0.0788683
I0130 19:06:52.269053 108075 solver.cpp:285]     Train net output #0: loss = 0.0788683 (* 1 = 0.0788683 loss)
I0130 19:06:52.271191 108075 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0130 19:07:16.702970 108075 solver.cpp:266] Iteration 900 (2.04659 iter/s, 24.4309s/50 iter), loss = 0.0741501
I0130 19:07:16.702999 108075 solver.cpp:285]     Train net output #0: loss = 0.0741501 (* 1 = 0.0741501 loss)
I0130 19:07:16.703047 108075 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0130 19:07:41.128649 108075 solver.cpp:266] Iteration 950 (2.04711 iter/s, 24.4247s/50 iter), loss = 0.0493385
I0130 19:07:41.128756 108075 solver.cpp:285]     Train net output #0: loss = 0.0493385 (* 1 = 0.0493385 loss)
I0130 19:07:41.130906 108075 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0130 19:08:05.234223 108075 solver.cpp:418] Iteration 1000, Testing net (#0)
I0130 19:08:08.635457 108075 solver.cpp:517]     Test net output #0: loss = 0.216264 (* 1 = 0.216264 loss)
I0130 19:08:08.635473 108075 solver.cpp:517]     Test net output #1: top-1 = 0.941
I0130 19:08:09.171789 108075 solver.cpp:266] Iteration 1000 (1.78318 iter/s, 28.0398s/50 iter), loss = 0.0620158
I0130 19:08:09.171814 108075 solver.cpp:285]     Train net output #0: loss = 0.0620158 (* 1 = 0.0620158 loss)
I0130 19:08:09.171893 108075 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0130 19:08:33.811460 108075 solver.cpp:266] Iteration 1050 (2.02933 iter/s, 24.6387s/50 iter), loss = 0.0560807
I0130 19:08:33.811580 108075 solver.cpp:285]     Train net output #0: loss = 0.0560807 (* 1 = 0.0560807 loss)
I0130 19:08:33.813714 108075 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0130 19:08:58.417125 108075 solver.cpp:266] Iteration 1100 (2.03231 iter/s, 24.6025s/50 iter), loss = 0.0332372
I0130 19:08:58.417156 108075 solver.cpp:285]     Train net output #0: loss = 0.0332372 (* 1 = 0.0332372 loss)
I0130 19:08:58.419381 108075 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0130 19:09:22.906060 108075 solver.cpp:266] Iteration 1150 (2.042 iter/s, 24.4858s/50 iter), loss = 0.0615296
I0130 19:09:22.906231 108075 solver.cpp:285]     Train net output #0: loss = 0.0615296 (* 1 = 0.0615296 loss)
I0130 19:09:22.908290 108075 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0130 19:09:47.527355 108075 solver.cpp:266] Iteration 1200 (2.03102 iter/s, 24.6182s/50 iter), loss = 0.0470543
I0130 19:09:47.527390 108075 solver.cpp:285]     Train net output #0: loss = 0.0470543 (* 1 = 0.0470543 loss)
I0130 19:09:47.529606 108075 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0130 19:10:12.139307 108075 solver.cpp:266] Iteration 1250 (2.03179 iter/s, 24.6088s/50 iter), loss = 0.0803854
I0130 19:10:12.139438 108075 solver.cpp:285]     Train net output #0: loss = 0.0803854 (* 1 = 0.0803854 loss)
I0130 19:10:12.139482 108075 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0130 19:10:36.649363 108075 solver.cpp:266] Iteration 1300 (2.04007 iter/s, 24.509s/50 iter), loss = 0.0738293
I0130 19:10:36.649399 108075 solver.cpp:285]     Train net output #0: loss = 0.0738293 (* 1 = 0.0738293 loss)
I0130 19:10:36.651624 108075 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0130 19:11:01.230866 108075 solver.cpp:266] Iteration 1350 (2.03431 iter/s, 24.5783s/50 iter), loss = 0.0490635
I0130 19:11:01.230981 108075 solver.cpp:285]     Train net output #0: loss = 0.0490635 (* 1 = 0.0490635 loss)
I0130 19:11:01.233193 108075 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0130 19:11:25.812485 108075 solver.cpp:266] Iteration 1400 (2.03431 iter/s, 24.5784s/50 iter), loss = 0.0726925
I0130 19:11:25.812515 108075 solver.cpp:285]     Train net output #0: loss = 0.0726925 (* 1 = 0.0726925 loss)
I0130 19:11:25.814740 108075 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0130 19:11:50.286746 108075 solver.cpp:266] Iteration 1450 (2.04323 iter/s, 24.4711s/50 iter), loss = 0.0809641
I0130 19:11:50.286856 108075 solver.cpp:285]     Train net output #0: loss = 0.0809641 (* 1 = 0.0809641 loss)
I0130 19:11:50.288997 108075 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0130 19:12:14.814386 108075 solver.cpp:266] Iteration 1500 (2.03878 iter/s, 24.5245s/50 iter), loss = 0.0761479
I0130 19:12:14.814416 108075 solver.cpp:285]     Train net output #0: loss = 0.0761479 (* 1 = 0.0761479 loss)
I0130 19:12:14.816625 108075 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0130 19:12:39.431771 108075 solver.cpp:266] Iteration 1550 (2.03134 iter/s, 24.6142s/50 iter), loss = 0.0599435
I0130 19:12:39.431897 108075 solver.cpp:285]     Train net output #0: loss = 0.0599435 (* 1 = 0.0599435 loss)
I0130 19:12:39.431905 108075 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0130 19:13:03.925927 108075 solver.cpp:266] Iteration 1600 (2.04139 iter/s, 24.4931s/50 iter), loss = 0.0799105
I0130 19:13:03.925969 108075 solver.cpp:285]     Train net output #0: loss = 0.0799105 (* 1 = 0.0799105 loss)
I0130 19:13:03.928179 108075 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0130 19:13:28.545038 108075 solver.cpp:266] Iteration 1650 (2.0312 iter/s, 24.6159s/50 iter), loss = 0.0519055
I0130 19:13:28.545163 108075 solver.cpp:285]     Train net output #0: loss = 0.0519055 (* 1 = 0.0519055 loss)
I0130 19:13:28.547297 108075 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0130 19:13:53.016695 108075 solver.cpp:266] Iteration 1700 (2.04344 iter/s, 24.4685s/50 iter), loss = 0.0345315
I0130 19:13:53.016727 108075 solver.cpp:285]     Train net output #0: loss = 0.0345315 (* 1 = 0.0345315 loss)
I0130 19:13:53.018955 108075 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0130 19:14:17.382282 108075 solver.cpp:266] Iteration 1750 (2.05234 iter/s, 24.3624s/50 iter), loss = 0.0602607
I0130 19:14:17.382390 108075 solver.cpp:285]     Train net output #0: loss = 0.0602607 (* 1 = 0.0602607 loss)
I0130 19:14:17.384541 108075 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0130 19:14:41.940434 108075 solver.cpp:266] Iteration 1800 (2.03625 iter/s, 24.555s/50 iter), loss = 0.0551041
I0130 19:14:41.940469 108075 solver.cpp:285]     Train net output #0: loss = 0.0551041 (* 1 = 0.0551041 loss)
I0130 19:14:41.940474 108075 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0130 19:15:06.392992 108075 solver.cpp:266] Iteration 1850 (2.04485 iter/s, 24.4516s/50 iter), loss = 0.0527309
I0130 19:15:06.393121 108075 solver.cpp:285]     Train net output #0: loss = 0.0527309 (* 1 = 0.0527309 loss)
I0130 19:15:06.395234 108075 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0130 19:15:30.985369 108075 solver.cpp:266] Iteration 1900 (2.03341 iter/s, 24.5892s/50 iter), loss = 0.0511365
I0130 19:15:30.985399 108075 solver.cpp:285]     Train net output #0: loss = 0.0511364 (* 1 = 0.0511364 loss)
I0130 19:15:30.985452 108075 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0130 19:15:55.321259 108075 solver.cpp:266] Iteration 1950 (2.05466 iter/s, 24.3349s/50 iter), loss = 0.0641422
I0130 19:15:55.321310 108075 solver.cpp:285]     Train net output #0: loss = 0.0641422 (* 1 = 0.0641422 loss)
I0130 19:15:55.323510 108075 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0130 19:16:19.426164 108075 solver.cpp:418] Iteration 2000, Testing net (#0)
I0130 19:16:22.955549 108075 solver.cpp:517]     Test net output #0: loss = 0.239001 (* 1 = 0.239001 loss)
I0130 19:16:22.955566 108075 solver.cpp:517]     Test net output #1: top-1 = 0.921
I0130 19:16:23.426808 108075 solver.cpp:266] Iteration 2000 (1.77922 iter/s, 28.1023s/50 iter), loss = 0.0495876
I0130 19:16:23.426836 108075 solver.cpp:285]     Train net output #0: loss = 0.0495876 (* 1 = 0.0495876 loss)
I0130 19:16:23.429061 108075 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0130 19:16:47.992096 108075 solver.cpp:266] Iteration 2050 (2.03565 iter/s, 24.5621s/50 iter), loss = 0.0695679
I0130 19:16:47.992200 108075 solver.cpp:285]     Train net output #0: loss = 0.0695678 (* 1 = 0.0695678 loss)
I0130 19:16:47.992244 108075 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0130 19:17:12.477581 108075 solver.cpp:266] Iteration 2100 (2.04211 iter/s, 24.4844s/50 iter), loss = 0.0200402
I0130 19:17:12.477610 108075 solver.cpp:285]     Train net output #0: loss = 0.0200402 (* 1 = 0.0200402 loss)
I0130 19:17:12.479832 108075 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0130 19:17:36.985895 108075 solver.cpp:266] Iteration 2150 (2.04039 iter/s, 24.5052s/50 iter), loss = 0.0747418
I0130 19:17:36.986023 108075 solver.cpp:285]     Train net output #0: loss = 0.0747418 (* 1 = 0.0747418 loss)
I0130 19:17:36.988148 108075 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0130 19:18:01.438376 108075 solver.cpp:266] Iteration 2200 (2.04505 iter/s, 24.4493s/50 iter), loss = 0.0367172
I0130 19:18:01.438410 108075 solver.cpp:285]     Train net output #0: loss = 0.0367172 (* 1 = 0.0367172 loss)
I0130 19:18:01.438432 108075 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0130 19:18:26.103477 108075 solver.cpp:266] Iteration 2250 (2.02723 iter/s, 24.6642s/50 iter), loss = 0.0458151
I0130 19:18:26.103582 108075 solver.cpp:285]     Train net output #0: loss = 0.0458151 (* 1 = 0.0458151 loss)
I0130 19:18:26.103794 108075 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0130 19:18:50.544364 108075 solver.cpp:266] Iteration 2300 (2.04585 iter/s, 24.4397s/50 iter), loss = 0.0203554
I0130 19:18:50.544395 108075 solver.cpp:285]     Train net output #0: loss = 0.0203554 (* 1 = 0.0203554 loss)
I0130 19:18:50.546627 108075 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0130 19:19:15.163293 108075 solver.cpp:266] Iteration 2350 (2.03122 iter/s, 24.6158s/50 iter), loss = 0.0462179
I0130 19:19:15.163391 108075 solver.cpp:285]     Train net output #0: loss = 0.0462179 (* 1 = 0.0462179 loss)
I0130 19:19:15.165555 108075 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0130 19:19:39.675117 108075 solver.cpp:266] Iteration 2400 (2.0401 iter/s, 24.5087s/50 iter), loss = 0.0854423
I0130 19:19:39.675145 108075 solver.cpp:285]     Train net output #0: loss = 0.0854423 (* 1 = 0.0854423 loss)
I0130 19:19:39.677376 108075 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0130 19:20:04.061463 108075 solver.cpp:266] Iteration 2450 (2.05059 iter/s, 24.3832s/50 iter), loss = 0.0317398
I0130 19:20:04.061553 108075 solver.cpp:285]     Train net output #0: loss = 0.0317398 (* 1 = 0.0317398 loss)
I0130 19:20:04.063707 108075 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0130 19:20:28.674608 108075 solver.cpp:266] Iteration 2500 (2.0317 iter/s, 24.61s/50 iter), loss = 0.0363859
I0130 19:20:28.674652 108075 solver.cpp:285]     Train net output #0: loss = 0.0363859 (* 1 = 0.0363859 loss)
I0130 19:20:28.674659 108075 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0130 19:20:53.241792 108075 solver.cpp:266] Iteration 2550 (2.03531 iter/s, 24.5662s/50 iter), loss = 0.0182896
I0130 19:20:53.241916 108075 solver.cpp:285]     Train net output #0: loss = 0.0182896 (* 1 = 0.0182896 loss)
I0130 19:20:53.242158 108075 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0130 19:21:17.669884 108075 solver.cpp:266] Iteration 2600 (2.04693 iter/s, 24.4268s/50 iter), loss = 0.0190868
I0130 19:21:17.669916 108075 solver.cpp:285]     Train net output #0: loss = 0.0190868 (* 1 = 0.0190868 loss)
I0130 19:21:17.669922 108075 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0130 19:21:42.258353 108075 solver.cpp:266] Iteration 2650 (2.03355 iter/s, 24.5875s/50 iter), loss = 0.00362732
I0130 19:21:42.258476 108075 solver.cpp:285]     Train net output #0: loss = 0.00362731 (* 1 = 0.00362731 loss)
I0130 19:21:42.260607 108075 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0130 19:22:06.767812 108075 solver.cpp:266] Iteration 2700 (2.04029 iter/s, 24.5063s/50 iter), loss = 0.0232841
I0130 19:22:06.767844 108075 solver.cpp:285]     Train net output #0: loss = 0.0232841 (* 1 = 0.0232841 loss)
I0130 19:22:06.770069 108075 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0130 19:22:31.116160 108075 solver.cpp:266] Iteration 2750 (2.05379 iter/s, 24.3452s/50 iter), loss = 0.011664
I0130 19:22:31.116286 108075 solver.cpp:285]     Train net output #0: loss = 0.011664 (* 1 = 0.011664 loss)
I0130 19:22:31.116293 108075 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0130 19:22:55.640161 108075 solver.cpp:266] Iteration 2800 (2.03891 iter/s, 24.523s/50 iter), loss = 0.0223089
I0130 19:22:55.640193 108075 solver.cpp:285]     Train net output #0: loss = 0.0223089 (* 1 = 0.0223089 loss)
I0130 19:22:55.642397 108075 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0130 19:23:20.207525 108075 solver.cpp:266] Iteration 2850 (2.03548 iter/s, 24.5642s/50 iter), loss = 0.0408196
I0130 19:23:20.207623 108075 solver.cpp:285]     Train net output #0: loss = 0.0408196 (* 1 = 0.0408196 loss)
I0130 19:23:20.207686 108075 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0130 19:23:44.620620 108075 solver.cpp:266] Iteration 2900 (2.04817 iter/s, 24.412s/50 iter), loss = 0.0127327
I0130 19:23:44.620652 108075 solver.cpp:285]     Train net output #0: loss = 0.0127327 (* 1 = 0.0127327 loss)
I0130 19:23:44.622872 108075 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0130 19:24:09.006145 108075 solver.cpp:266] Iteration 2950 (2.05066 iter/s, 24.3824s/50 iter), loss = 0.00722162
I0130 19:24:09.006268 108075 solver.cpp:285]     Train net output #0: loss = 0.00722162 (* 1 = 0.00722162 loss)
I0130 19:24:09.008389 108075 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0130 19:24:33.071291 108075 solver.cpp:418] Iteration 3000, Testing net (#0)
I0130 19:24:36.721338 108075 solver.cpp:517]     Test net output #0: loss = 0.154178 (* 1 = 0.154178 loss)
I0130 19:24:36.721356 108075 solver.cpp:517]     Test net output #1: top-1 = 0.944
I0130 19:24:37.193233 108075 solver.cpp:266] Iteration 3000 (1.77407 iter/s, 28.1838s/50 iter), loss = 0.0276492
I0130 19:24:37.193259 108075 solver.cpp:285]     Train net output #0: loss = 0.0276492 (* 1 = 0.0276492 loss)
I0130 19:24:37.195494 108075 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0130 19:25:01.647572 108075 solver.cpp:266] Iteration 3050 (2.04489 iter/s, 24.4512s/50 iter), loss = 0.0174256
I0130 19:25:01.647712 108075 solver.cpp:285]     Train net output #0: loss = 0.0174256 (* 1 = 0.0174256 loss)
I0130 19:25:01.649837 108075 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0130 19:25:26.080662 108075 solver.cpp:266] Iteration 3100 (2.04667 iter/s, 24.4299s/50 iter), loss = 0.0216754
I0130 19:25:26.080694 108075 solver.cpp:285]     Train net output #0: loss = 0.0216754 (* 1 = 0.0216754 loss)
I0130 19:25:26.082908 108075 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0130 19:25:50.556466 108075 solver.cpp:266] Iteration 3150 (2.0431 iter/s, 24.4727s/50 iter), loss = 0.00424145
I0130 19:25:50.556594 108075 solver.cpp:285]     Train net output #0: loss = 0.00424145 (* 1 = 0.00424145 loss)
I0130 19:25:50.558713 108075 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0130 19:26:15.175647 108075 solver.cpp:266] Iteration 3200 (2.0312 iter/s, 24.616s/50 iter), loss = 0.0276334
I0130 19:26:15.175683 108075 solver.cpp:285]     Train net output #0: loss = 0.0276334 (* 1 = 0.0276334 loss)
I0130 19:26:15.175689 108075 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0130 19:26:39.654405 108075 solver.cpp:266] Iteration 3250 (2.04267 iter/s, 24.4778s/50 iter), loss = 0.00900114
I0130 19:26:39.654464 108075 solver.cpp:285]     Train net output #0: loss = 0.00900113 (* 1 = 0.00900113 loss)
I0130 19:26:39.656669 108075 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0130 19:27:04.213675 108075 solver.cpp:266] Iteration 3300 (2.03615 iter/s, 24.5561s/50 iter), loss = 0.0132078
I0130 19:27:04.213704 108075 solver.cpp:285]     Train net output #0: loss = 0.0132078 (* 1 = 0.0132078 loss)
I0130 19:27:04.215940 108075 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0130 19:27:28.651502 108075 solver.cpp:266] Iteration 3350 (2.04627 iter/s, 24.4347s/50 iter), loss = 0.0192293
I0130 19:27:28.651604 108075 solver.cpp:285]     Train net output #0: loss = 0.0192293 (* 1 = 0.0192293 loss)
I0130 19:27:28.653745 108075 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0130 19:27:53.148948 108075 solver.cpp:266] Iteration 3400 (2.04129 iter/s, 24.4943s/50 iter), loss = 0.0133135
I0130 19:27:53.148982 108075 solver.cpp:285]     Train net output #0: loss = 0.0133135 (* 1 = 0.0133135 loss)
I0130 19:27:53.151196 108075 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0130 19:28:17.617022 108075 solver.cpp:266] Iteration 3450 (2.04374 iter/s, 24.4649s/50 iter), loss = 0.00621353
I0130 19:28:17.617154 108075 solver.cpp:285]     Train net output #0: loss = 0.00621352 (* 1 = 0.00621352 loss)
I0130 19:28:17.617194 108075 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0130 19:28:42.086881 108075 solver.cpp:266] Iteration 3500 (2.04342 iter/s, 24.4688s/50 iter), loss = 0.0120578
I0130 19:28:42.086916 108075 solver.cpp:285]     Train net output #0: loss = 0.0120578 (* 1 = 0.0120578 loss)
I0130 19:28:42.089135 108075 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0130 19:29:06.625668 108075 solver.cpp:266] Iteration 3550 (2.03785 iter/s, 24.5356s/50 iter), loss = 0.00556678
I0130 19:29:06.625773 108075 solver.cpp:285]     Train net output #0: loss = 0.00556678 (* 1 = 0.00556678 loss)
I0130 19:29:06.627918 108075 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0130 19:29:31.213902 108075 solver.cpp:266] Iteration 3600 (2.03375 iter/s, 24.5851s/50 iter), loss = 0.00753283
I0130 19:29:31.213932 108075 solver.cpp:285]     Train net output #0: loss = 0.00753282 (* 1 = 0.00753282 loss)
I0130 19:29:31.216156 108075 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0130 19:29:55.445170 108075 solver.cpp:266] Iteration 3650 (2.06372 iter/s, 24.2281s/50 iter), loss = 0.0168028
I0130 19:29:55.445287 108075 solver.cpp:285]     Train net output #0: loss = 0.0168028 (* 1 = 0.0168028 loss)
I0130 19:29:55.447417 108075 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0130 19:30:19.996062 108075 solver.cpp:266] Iteration 3700 (2.03685 iter/s, 24.5477s/50 iter), loss = 0.00153896
I0130 19:30:19.996106 108075 solver.cpp:285]     Train net output #0: loss = 0.00153895 (* 1 = 0.00153895 loss)
I0130 19:30:19.996129 108075 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0130 19:30:44.582484 108075 solver.cpp:266] Iteration 3750 (2.03372 iter/s, 24.5855s/50 iter), loss = 0.013215
I0130 19:30:44.582621 108075 solver.cpp:285]     Train net output #0: loss = 0.013215 (* 1 = 0.013215 loss)
I0130 19:30:44.584693 108075 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0130 19:31:08.980690 108075 solver.cpp:266] Iteration 3800 (2.04959 iter/s, 24.3951s/50 iter), loss = 0.00900626
I0130 19:31:08.980731 108075 solver.cpp:285]     Train net output #0: loss = 0.00900625 (* 1 = 0.00900625 loss)
I0130 19:31:08.980777 108075 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0130 19:31:33.462489 108075 solver.cpp:266] Iteration 3850 (2.04242 iter/s, 24.4808s/50 iter), loss = 0.00381409
I0130 19:31:33.462621 108075 solver.cpp:285]     Train net output #0: loss = 0.00381408 (* 1 = 0.00381408 loss)
I0130 19:31:33.464743 108075 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0130 19:31:57.780824 108075 solver.cpp:266] Iteration 3900 (2.05633 iter/s, 24.3152s/50 iter), loss = 0.0022673
I0130 19:31:57.780856 108075 solver.cpp:285]     Train net output #0: loss = 0.00226729 (* 1 = 0.00226729 loss)
I0130 19:31:57.783049 108075 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0130 19:32:22.369024 108075 solver.cpp:266] Iteration 3950 (2.03376 iter/s, 24.5851s/50 iter), loss = 0.0147449
I0130 19:32:22.369143 108075 solver.cpp:285]     Train net output #0: loss = 0.0147448 (* 1 = 0.0147448 loss)
I0130 19:32:22.369462 108075 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0130 19:32:46.277441 108075 solver.cpp:418] Iteration 4000, Testing net (#0)
I0130 19:32:49.896072 108075 solver.cpp:517]     Test net output #0: loss = 0.143191 (* 1 = 0.143191 loss)
I0130 19:32:49.896090 108075 solver.cpp:517]     Test net output #1: top-1 = 0.9485
I0130 19:32:50.386359 108075 solver.cpp:266] Iteration 4000 (1.7847 iter/s, 28.0159s/50 iter), loss = 0.00457117
I0130 19:32:50.386389 108075 solver.cpp:285]     Train net output #0: loss = 0.00457115 (* 1 = 0.00457115 loss)
I0130 19:32:50.388610 108075 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0130 19:33:14.787497 108075 solver.cpp:266] Iteration 4050 (2.04935 iter/s, 24.398s/50 iter), loss = 0.0109061
I0130 19:33:14.787606 108075 solver.cpp:285]     Train net output #0: loss = 0.0109061 (* 1 = 0.0109061 loss)
I0130 19:33:14.787612 108075 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0130 19:33:39.241350 108075 solver.cpp:266] Iteration 4100 (2.04475 iter/s, 24.4528s/50 iter), loss = 0.00583307
I0130 19:33:39.241382 108075 solver.cpp:285]     Train net output #0: loss = 0.00583305 (* 1 = 0.00583305 loss)
I0130 19:33:39.243607 108075 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0130 19:34:03.871201 108075 solver.cpp:266] Iteration 4150 (2.03032 iter/s, 24.6267s/50 iter), loss = 0.00334841
I0130 19:34:03.871325 108075 solver.cpp:285]     Train net output #0: loss = 0.0033484 (* 1 = 0.0033484 loss)
I0130 19:34:03.871387 108075 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0130 19:34:28.406527 108075 solver.cpp:266] Iteration 4200 (2.03797 iter/s, 24.5342s/50 iter), loss = 0.00653789
I0130 19:34:28.406559 108075 solver.cpp:285]     Train net output #0: loss = 0.00653788 (* 1 = 0.00653788 loss)
I0130 19:34:28.408768 108075 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0130 19:34:52.919631 108075 solver.cpp:266] Iteration 4250 (2.03999 iter/s, 24.51s/50 iter), loss = 0.0138645
I0130 19:34:52.919737 108075 solver.cpp:285]     Train net output #0: loss = 0.0138645 (* 1 = 0.0138645 loss)
I0130 19:34:52.921881 108075 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0130 19:35:17.241665 108075 solver.cpp:266] Iteration 4300 (2.05602 iter/s, 24.3189s/50 iter), loss = 0.00722508
I0130 19:35:17.241699 108075 solver.cpp:285]     Train net output #0: loss = 0.00722507 (* 1 = 0.00722507 loss)
I0130 19:35:17.243912 108075 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0130 19:35:41.765456 108075 solver.cpp:266] Iteration 4350 (2.0391 iter/s, 24.5206s/50 iter), loss = 0.00129821
I0130 19:35:41.765584 108075 solver.cpp:285]     Train net output #0: loss = 0.00129819 (* 1 = 0.00129819 loss)
I0130 19:35:41.765591 108075 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0130 19:36:06.342991 108075 solver.cpp:266] Iteration 4400 (2.03446 iter/s, 24.5765s/50 iter), loss = 0.0177787
I0130 19:36:06.343025 108075 solver.cpp:285]     Train net output #0: loss = 0.0177787 (* 1 = 0.0177787 loss)
I0130 19:36:06.345255 108075 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0130 19:36:30.772199 108075 solver.cpp:266] Iteration 4450 (2.047 iter/s, 24.426s/50 iter), loss = 0.036301
I0130 19:36:30.772351 108075 solver.cpp:285]     Train net output #0: loss = 0.0363009 (* 1 = 0.0363009 loss)
I0130 19:36:30.772392 108075 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0130 19:36:55.211469 108075 solver.cpp:266] Iteration 4500 (2.04598 iter/s, 24.4382s/50 iter), loss = 0.0092373
I0130 19:36:55.211499 108075 solver.cpp:285]     Train net output #0: loss = 0.00923729 (* 1 = 0.00923729 loss)
I0130 19:36:55.213721 108075 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0130 19:37:19.485473 108075 solver.cpp:266] Iteration 4550 (2.06008 iter/s, 24.2709s/50 iter), loss = 0.0183773
I0130 19:37:19.485594 108075 solver.cpp:285]     Train net output #0: loss = 0.0183773 (* 1 = 0.0183773 loss)
I0130 19:37:19.487725 108075 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0130 19:37:43.914568 108075 solver.cpp:266] Iteration 4600 (2.047 iter/s, 24.4259s/50 iter), loss = 0.00386744
I0130 19:37:43.914600 108075 solver.cpp:285]     Train net output #0: loss = 0.00386743 (* 1 = 0.00386743 loss)
I0130 19:37:43.914607 108075 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0130 19:38:08.438730 108075 solver.cpp:266] Iteration 4650 (2.03888 iter/s, 24.5232s/50 iter), loss = 0.00625017
I0130 19:38:08.438838 108075 solver.cpp:285]     Train net output #0: loss = 0.00625016 (* 1 = 0.00625016 loss)
I0130 19:38:08.440985 108075 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0130 19:38:32.899129 108075 solver.cpp:266] Iteration 4700 (2.04438 iter/s, 24.4572s/50 iter), loss = 0.00152539
I0130 19:38:32.899158 108075 solver.cpp:285]     Train net output #0: loss = 0.00152537 (* 1 = 0.00152537 loss)
I0130 19:38:32.899384 108075 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0130 19:38:57.323189 108075 solver.cpp:266] Iteration 4750 (2.04726 iter/s, 24.4229s/50 iter), loss = 0.0079554
I0130 19:38:57.323240 108075 solver.cpp:285]     Train net output #0: loss = 0.00795539 (* 1 = 0.00795539 loss)
I0130 19:38:57.325449 108075 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0130 19:39:21.709420 108075 solver.cpp:266] Iteration 4800 (2.0506 iter/s, 24.3831s/50 iter), loss = 0.00912289
I0130 19:39:21.709453 108075 solver.cpp:285]     Train net output #0: loss = 0.00912287 (* 1 = 0.00912287 loss)
I0130 19:39:21.711673 108075 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0130 19:39:46.201520 108075 solver.cpp:266] Iteration 4850 (2.04174 iter/s, 24.4889s/50 iter), loss = 0.00504549
I0130 19:39:46.201630 108075 solver.cpp:285]     Train net output #0: loss = 0.00504547 (* 1 = 0.00504547 loss)
I0130 19:39:46.201653 108075 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0130 19:40:10.720173 108075 solver.cpp:266] Iteration 4900 (2.03935 iter/s, 24.5176s/50 iter), loss = 0.00483148
I0130 19:40:10.720208 108075 solver.cpp:285]     Train net output #0: loss = 0.00483146 (* 1 = 0.00483146 loss)
I0130 19:40:10.722429 108075 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0130 19:40:35.083732 108075 solver.cpp:266] Iteration 4950 (2.05251 iter/s, 24.3604s/50 iter), loss = 0.00666517
I0130 19:40:35.083861 108075 solver.cpp:285]     Train net output #0: loss = 0.00666515 (* 1 = 0.00666515 loss)
I0130 19:40:35.083902 108075 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0130 19:40:58.952486 108075 solver.cpp:418] Iteration 5000, Testing net (#0)
I0130 19:41:02.746223 108075 solver.cpp:517]     Test net output #0: loss = 0.158569 (* 1 = 0.158569 loss)
I0130 19:41:02.746242 108075 solver.cpp:517]     Test net output #1: top-1 = 0.94875
I0130 19:41:03.057071 108075 solver.cpp:266] Iteration 5000 (1.78749 iter/s, 27.9721s/50 iter), loss = 0.017395
I0130 19:41:03.057101 108075 solver.cpp:285]     Train net output #0: loss = 0.017395 (* 1 = 0.017395 loss)
I0130 19:41:03.059324 108075 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0130 19:41:27.579547 108075 solver.cpp:266] Iteration 5050 (2.03921 iter/s, 24.5193s/50 iter), loss = 0.00493465
I0130 19:41:27.579663 108075 solver.cpp:285]     Train net output #0: loss = 0.00493463 (* 1 = 0.00493463 loss)
I0130 19:41:27.580806 108075 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0130 19:41:51.991217 108075 solver.cpp:266] Iteration 5100 (2.04838 iter/s, 24.4095s/50 iter), loss = 0.00179092
I0130 19:41:51.991246 108075 solver.cpp:285]     Train net output #0: loss = 0.0017909 (* 1 = 0.0017909 loss)
I0130 19:41:51.993471 108075 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0130 19:42:16.562474 108075 solver.cpp:266] Iteration 5150 (2.03516 iter/s, 24.5681s/50 iter), loss = 0.00981228
I0130 19:42:16.562541 108075 solver.cpp:285]     Train net output #0: loss = 0.00981226 (* 1 = 0.00981226 loss)
I0130 19:42:16.562611 108075 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0130 19:42:40.853919 108075 solver.cpp:266] Iteration 5200 (2.05843 iter/s, 24.2904s/50 iter), loss = 0.00158059
I0130 19:42:40.853950 108075 solver.cpp:285]     Train net output #0: loss = 0.00158057 (* 1 = 0.00158057 loss)
I0130 19:42:40.856163 108075 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0130 19:43:05.315623 108075 solver.cpp:266] Iteration 5250 (2.04427 iter/s, 24.4586s/50 iter), loss = 0.0020719
I0130 19:43:05.315677 108075 solver.cpp:285]     Train net output #0: loss = 0.00207188 (* 1 = 0.00207188 loss)
I0130 19:43:05.317867 108075 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0130 19:43:29.718560 108075 solver.cpp:266] Iteration 5300 (2.0492 iter/s, 24.3998s/50 iter), loss = 0.00569158
I0130 19:43:29.718616 108075 solver.cpp:285]     Train net output #0: loss = 0.00569156 (* 1 = 0.00569156 loss)
I0130 19:43:29.718624 108075 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0130 19:43:54.213805 108075 solver.cpp:266] Iteration 5350 (2.04129 iter/s, 24.4943s/50 iter), loss = 0.00380419
I0130 19:43:54.213929 108075 solver.cpp:285]     Train net output #0: loss = 0.00380418 (* 1 = 0.00380418 loss)
I0130 19:43:54.216063 108075 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0130 19:44:18.635823 108075 solver.cpp:266] Iteration 5400 (2.0476 iter/s, 24.4189s/50 iter), loss = 0.000697649
I0130 19:44:18.635854 108075 solver.cpp:285]     Train net output #0: loss = 0.000697638 (* 1 = 0.000697638 loss)
I0130 19:44:18.638079 108075 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0130 19:44:42.968734 108075 solver.cpp:266] Iteration 5450 (2.0551 iter/s, 24.3298s/50 iter), loss = 0.00223126
I0130 19:44:42.968868 108075 solver.cpp:285]     Train net output #0: loss = 0.00223125 (* 1 = 0.00223125 loss)
I0130 19:44:42.970985 108075 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0130 19:45:07.343339 108075 solver.cpp:266] Iteration 5500 (2.05158 iter/s, 24.3715s/50 iter), loss = 0.00549768
I0130 19:45:07.343382 108075 solver.cpp:285]     Train net output #0: loss = 0.00549767 (* 1 = 0.00549767 loss)
I0130 19:45:07.343405 108075 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0130 19:45:31.822182 108075 solver.cpp:266] Iteration 5550 (2.04266 iter/s, 24.4779s/50 iter), loss = 0.00117123
I0130 19:45:31.822268 108075 solver.cpp:285]     Train net output #0: loss = 0.00117122 (* 1 = 0.00117122 loss)
I0130 19:45:31.824440 108075 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0130 19:45:56.240439 108075 solver.cpp:266] Iteration 5600 (2.04791 iter/s, 24.4151s/50 iter), loss = 0.00359016
I0130 19:45:56.240479 108075 solver.cpp:285]     Train net output #0: loss = 0.00359015 (* 1 = 0.00359015 loss)
I0130 19:45:56.240540 108075 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0130 19:46:20.592084 108075 solver.cpp:266] Iteration 5650 (2.05333 iter/s, 24.3506s/50 iter), loss = 0.00266306
I0130 19:46:20.592219 108075 solver.cpp:285]     Train net output #0: loss = 0.00266305 (* 1 = 0.00266305 loss)
I0130 19:46:20.594343 108075 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0130 19:46:44.855114 108075 solver.cpp:266] Iteration 5700 (2.06102 iter/s, 24.2599s/50 iter), loss = 0.00155281
I0130 19:46:44.855149 108075 solver.cpp:285]     Train net output #0: loss = 0.0015528 (* 1 = 0.0015528 loss)
I0130 19:46:44.857360 108075 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0130 19:47:09.394676 108075 solver.cpp:266] Iteration 5750 (2.03779 iter/s, 24.5364s/50 iter), loss = 0.00305936
I0130 19:47:09.394794 108075 solver.cpp:285]     Train net output #0: loss = 0.00305935 (* 1 = 0.00305935 loss)
I0130 19:47:09.396909 108075 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0130 19:47:33.863013 108075 solver.cpp:266] Iteration 5800 (2.04372 iter/s, 24.4652s/50 iter), loss = 0.00237559
I0130 19:47:33.863044 108075 solver.cpp:285]     Train net output #0: loss = 0.00237559 (* 1 = 0.00237559 loss)
I0130 19:47:33.865272 108075 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0130 19:47:58.359930 108075 solver.cpp:266] Iteration 5850 (2.04134 iter/s, 24.4937s/50 iter), loss = 0.00390417
I0130 19:47:58.360057 108075 solver.cpp:285]     Train net output #0: loss = 0.00390416 (* 1 = 0.00390416 loss)
I0130 19:47:58.362195 108075 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0130 19:48:22.727643 108075 solver.cpp:266] Iteration 5900 (2.05216 iter/s, 24.3645s/50 iter), loss = 0.00808172
I0130 19:48:22.727674 108075 solver.cpp:285]     Train net output #0: loss = 0.00808172 (* 1 = 0.00808172 loss)
I0130 19:48:22.729895 108075 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0130 19:48:47.157619 108075 solver.cpp:266] Iteration 5950 (2.04693 iter/s, 24.4268s/50 iter), loss = 0.00544804
I0130 19:48:47.157735 108075 solver.cpp:285]     Train net output #0: loss = 0.00544803 (* 1 = 0.00544803 loss)
I0130 19:48:47.159874 108075 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0130 19:49:11.250548 108075 solver.cpp:418] Iteration 6000, Testing net (#0)
I0130 19:49:14.727843 108075 solver.cpp:517]     Test net output #0: loss = 0.169566 (* 1 = 0.169566 loss)
I0130 19:49:14.727874 108075 solver.cpp:517]     Test net output #1: top-1 = 0.954
I0130 19:49:15.286088 108075 solver.cpp:266] Iteration 6000 (1.77777 iter/s, 28.1252s/50 iter), loss = 0.000566902
I0130 19:49:15.286114 108075 solver.cpp:285]     Train net output #0: loss = 0.000566901 (* 1 = 0.000566901 loss)
I0130 19:49:15.288343 108075 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0130 19:49:39.687842 108075 solver.cpp:266] Iteration 6050 (2.0493 iter/s, 24.3986s/50 iter), loss = 0.0109698
I0130 19:49:39.687904 108075 solver.cpp:285]     Train net output #0: loss = 0.0109698 (* 1 = 0.0109698 loss)
I0130 19:49:39.690095 108075 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0130 19:50:04.111362 108075 solver.cpp:266] Iteration 6100 (2.04747 iter/s, 24.4204s/50 iter), loss = 0.0109298
I0130 19:50:04.111393 108075 solver.cpp:285]     Train net output #0: loss = 0.0109298 (* 1 = 0.0109298 loss)
I0130 19:50:04.113605 108075 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0130 19:50:28.747316 108075 solver.cpp:266] Iteration 6150 (2.02981 iter/s, 24.6328s/50 iter), loss = 0.00164413
I0130 19:50:28.747459 108075 solver.cpp:285]     Train net output #0: loss = 0.00164412 (* 1 = 0.00164412 loss)
I0130 19:50:28.747483 108075 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0130 19:50:53.262926 108075 solver.cpp:266] Iteration 6200 (2.0396 iter/s, 24.5146s/50 iter), loss = 0.00213613
I0130 19:50:53.262957 108075 solver.cpp:285]     Train net output #0: loss = 0.00213612 (* 1 = 0.00213612 loss)
I0130 19:50:53.265193 108075 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0130 19:51:17.660187 108075 solver.cpp:266] Iteration 6250 (2.04968 iter/s, 24.3941s/50 iter), loss = 0.00146663
I0130 19:51:17.660240 108075 solver.cpp:285]     Train net output #0: loss = 0.00146662 (* 1 = 0.00146662 loss)
I0130 19:51:17.660284 108075 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0130 19:51:42.185895 108075 solver.cpp:266] Iteration 6300 (2.03876 iter/s, 24.5247s/50 iter), loss = 0.00641933
I0130 19:51:42.185926 108075 solver.cpp:285]     Train net output #0: loss = 0.00641932 (* 1 = 0.00641932 loss)
I0130 19:51:42.188148 108075 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0130 19:52:06.553567 108075 solver.cpp:266] Iteration 6350 (2.05216 iter/s, 24.3645s/50 iter), loss = 0.00126017
I0130 19:52:06.553704 108075 solver.cpp:285]     Train net output #0: loss = 0.00126017 (* 1 = 0.00126017 loss)
I0130 19:52:06.555817 108075 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0130 19:52:30.942157 108075 solver.cpp:266] Iteration 6400 (2.0504 iter/s, 24.3854s/50 iter), loss = 0.0120511
I0130 19:52:30.942193 108075 solver.cpp:285]     Train net output #0: loss = 0.0120511 (* 1 = 0.0120511 loss)
I0130 19:52:30.942199 108075 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0130 19:52:55.463943 108075 solver.cpp:266] Iteration 6450 (2.03908 iter/s, 24.5208s/50 iter), loss = 0.00259399
I0130 19:52:55.464087 108075 solver.cpp:285]     Train net output #0: loss = 0.00259397 (* 1 = 0.00259397 loss)
I0130 19:52:55.466202 108075 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0130 19:53:19.872556 108075 solver.cpp:266] Iteration 6500 (2.04872 iter/s, 24.4055s/50 iter), loss = 0.00411449
I0130 19:53:19.872587 108075 solver.cpp:285]     Train net output #0: loss = 0.00411448 (* 1 = 0.00411448 loss)
I0130 19:53:19.872640 108075 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0130 19:53:44.243911 108075 solver.cpp:266] Iteration 6550 (2.05167 iter/s, 24.3704s/50 iter), loss = 0.00112948
I0130 19:53:44.244009 108075 solver.cpp:285]     Train net output #0: loss = 0.00112947 (* 1 = 0.00112947 loss)
I0130 19:53:44.246168 108075 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0130 19:54:08.576268 108075 solver.cpp:266] Iteration 6600 (2.05514 iter/s, 24.3292s/50 iter), loss = 0.00162844
I0130 19:54:08.576301 108075 solver.cpp:285]     Train net output #0: loss = 0.00162843 (* 1 = 0.00162843 loss)
I0130 19:54:08.578470 108075 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0130 19:54:33.175213 108075 solver.cpp:266] Iteration 6650 (2.03286 iter/s, 24.5958s/50 iter), loss = 0.00209818
I0130 19:54:33.175343 108075 solver.cpp:285]     Train net output #0: loss = 0.00209817 (* 1 = 0.00209817 loss)
I0130 19:54:33.175351 108075 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0130 19:54:57.539127 108075 solver.cpp:266] Iteration 6700 (2.0523 iter/s, 24.3629s/50 iter), loss = 0.0077553
I0130 19:54:57.539160 108075 solver.cpp:285]     Train net output #0: loss = 0.00775529 (* 1 = 0.00775529 loss)
I0130 19:54:57.541380 108075 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0130 19:55:21.992291 108075 solver.cpp:266] Iteration 6750 (2.04499 iter/s, 24.45s/50 iter), loss = 0.0051613
I0130 19:55:21.992414 108075 solver.cpp:285]     Train net output #0: loss = 0.00516129 (* 1 = 0.00516129 loss)
I0130 19:55:21.994546 108075 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0130 19:55:46.196780 108075 solver.cpp:266] Iteration 6800 (2.066 iter/s, 24.2013s/50 iter), loss = 0.00139522
I0130 19:55:46.196815 108075 solver.cpp:285]     Train net output #0: loss = 0.0013952 (* 1 = 0.0013952 loss)
I0130 19:55:46.199030 108075 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0130 19:56:10.714646 108075 solver.cpp:266] Iteration 6850 (2.03959 iter/s, 24.5147s/50 iter), loss = 0.00355202
I0130 19:56:10.714761 108075 solver.cpp:285]     Train net output #0: loss = 0.00355201 (* 1 = 0.00355201 loss)
I0130 19:56:10.716902 108075 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0130 19:56:35.247588 108075 solver.cpp:266] Iteration 6900 (2.03834 iter/s, 24.5298s/50 iter), loss = 0.00370675
I0130 19:56:35.247622 108075 solver.cpp:285]     Train net output #0: loss = 0.00370673 (* 1 = 0.00370673 loss)
I0130 19:56:35.248101 108075 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0130 19:56:59.631299 108075 solver.cpp:266] Iteration 6950 (2.05067 iter/s, 24.3823s/50 iter), loss = 0.00983472
I0130 19:56:59.631397 108075 solver.cpp:285]     Train net output #0: loss = 0.0098347 (* 1 = 0.0098347 loss)
I0130 19:56:59.633555 108075 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0130 19:57:23.555508 108075 solver.cpp:418] Iteration 7000, Testing net (#0)
I0130 19:57:27.382673 108075 solver.cpp:517]     Test net output #0: loss = 0.184737 (* 1 = 0.184737 loss)
I0130 19:57:27.382690 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95575
I0130 19:57:27.689261 108075 solver.cpp:266] Iteration 7000 (1.78223 iter/s, 28.0547s/50 iter), loss = 0.00490579
I0130 19:57:27.689287 108075 solver.cpp:285]     Train net output #0: loss = 0.00490577 (* 1 = 0.00490577 loss)
I0130 19:57:27.691517 108075 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0130 19:57:52.269776 108075 solver.cpp:266] Iteration 7050 (2.03439 iter/s, 24.5774s/50 iter), loss = 0.000982586
I0130 19:57:52.269927 108075 solver.cpp:285]     Train net output #0: loss = 0.000982566 (* 1 = 0.000982566 loss)
I0130 19:57:52.269933 108075 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0130 19:58:16.752743 108075 solver.cpp:266] Iteration 7100 (2.04232 iter/s, 24.4819s/50 iter), loss = 0.0139705
I0130 19:58:16.752773 108075 solver.cpp:285]     Train net output #0: loss = 0.0139705 (* 1 = 0.0139705 loss)
I0130 19:58:16.754998 108075 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0130 19:58:41.242934 108075 solver.cpp:266] Iteration 7150 (2.0419 iter/s, 24.487s/50 iter), loss = 0.00604935
I0130 19:58:41.243041 108075 solver.cpp:285]     Train net output #0: loss = 0.00604933 (* 1 = 0.00604933 loss)
I0130 19:58:41.245196 108075 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0130 19:59:05.714294 108075 solver.cpp:266] Iteration 7200 (2.04347 iter/s, 24.4682s/50 iter), loss = 0.00150135
I0130 19:59:05.714334 108075 solver.cpp:285]     Train net output #0: loss = 0.00150133 (* 1 = 0.00150133 loss)
I0130 19:59:05.716547 108075 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0130 19:59:30.053720 108075 solver.cpp:266] Iteration 7250 (2.05455 iter/s, 24.3363s/50 iter), loss = 0.0016647
I0130 19:59:30.053875 108075 solver.cpp:285]     Train net output #0: loss = 0.00166467 (* 1 = 0.00166467 loss)
I0130 19:59:30.055965 108075 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0130 19:59:54.442667 108075 solver.cpp:266] Iteration 7300 (2.05037 iter/s, 24.3858s/50 iter), loss = 0.00618558
I0130 19:59:54.442710 108075 solver.cpp:285]     Train net output #0: loss = 0.00618556 (* 1 = 0.00618556 loss)
I0130 19:59:54.442718 108075 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0130 20:00:19.050287 108075 solver.cpp:266] Iteration 7350 (2.03197 iter/s, 24.6067s/50 iter), loss = 0.000471993
I0130 20:00:19.050390 108075 solver.cpp:285]     Train net output #0: loss = 0.000471969 (* 1 = 0.000471969 loss)
I0130 20:00:19.052522 108075 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0130 20:00:43.356545 108075 solver.cpp:266] Iteration 7400 (2.05735 iter/s, 24.3031s/50 iter), loss = 0.00272901
I0130 20:00:43.356585 108075 solver.cpp:285]     Train net output #0: loss = 0.00272898 (* 1 = 0.00272898 loss)
I0130 20:00:43.356621 108075 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0130 20:01:07.895805 108075 solver.cpp:266] Iteration 7450 (2.03763 iter/s, 24.5383s/50 iter), loss = 0.00084938
I0130 20:01:07.895938 108075 solver.cpp:285]     Train net output #0: loss = 0.000849353 (* 1 = 0.000849353 loss)
I0130 20:01:07.898059 108075 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0130 20:01:32.270366 108075 solver.cpp:266] Iteration 7500 (2.05158 iter/s, 24.3714s/50 iter), loss = 0.00103733
I0130 20:01:32.270406 108075 solver.cpp:285]     Train net output #0: loss = 0.0010373 (* 1 = 0.0010373 loss)
I0130 20:01:32.272621 108075 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0130 20:01:56.669167 108075 solver.cpp:266] Iteration 7550 (2.04955 iter/s, 24.3956s/50 iter), loss = 0.00453597
I0130 20:01:56.669221 108075 solver.cpp:285]     Train net output #0: loss = 0.00453594 (* 1 = 0.00453594 loss)
I0130 20:01:56.671417 108075 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0130 20:02:21.129166 108075 solver.cpp:266] Iteration 7600 (2.04442 iter/s, 24.4568s/50 iter), loss = 0.00127092
I0130 20:02:21.129215 108075 solver.cpp:285]     Train net output #0: loss = 0.00127089 (* 1 = 0.00127089 loss)
I0130 20:02:21.131412 108075 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0130 20:02:45.685499 108075 solver.cpp:266] Iteration 7650 (2.0364 iter/s, 24.5532s/50 iter), loss = 0.00489511
I0130 20:02:45.685663 108075 solver.cpp:285]     Train net output #0: loss = 0.00489508 (* 1 = 0.00489508 loss)
I0130 20:02:45.687121 108075 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0130 20:03:10.015228 108075 solver.cpp:266] Iteration 7700 (2.05531 iter/s, 24.3272s/50 iter), loss = 0.00190662
I0130 20:03:10.015269 108075 solver.cpp:285]     Train net output #0: loss = 0.00190659 (* 1 = 0.00190659 loss)
I0130 20:03:10.015316 108075 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0130 20:03:34.458472 108075 solver.cpp:266] Iteration 7750 (2.04564 iter/s, 24.4423s/50 iter), loss = 0.00126034
I0130 20:03:34.458611 108075 solver.cpp:285]     Train net output #0: loss = 0.00126032 (* 1 = 0.00126032 loss)
I0130 20:03:34.460731 108075 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0130 20:03:58.756675 108075 solver.cpp:266] Iteration 7800 (2.05803 iter/s, 24.295s/50 iter), loss = 0.0031578
I0130 20:03:58.756709 108075 solver.cpp:285]     Train net output #0: loss = 0.00315777 (* 1 = 0.00315777 loss)
I0130 20:03:58.758919 108075 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0130 20:04:23.326902 108075 solver.cpp:266] Iteration 7850 (2.03524 iter/s, 24.5671s/50 iter), loss = 0.00585136
I0130 20:04:23.327020 108075 solver.cpp:285]     Train net output #0: loss = 0.00585133 (* 1 = 0.00585133 loss)
I0130 20:04:23.327028 108075 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0130 20:04:47.934960 108075 solver.cpp:266] Iteration 7900 (2.03194 iter/s, 24.607s/50 iter), loss = 0.00752474
I0130 20:04:47.935003 108075 solver.cpp:285]     Train net output #0: loss = 0.0075247 (* 1 = 0.0075247 loss)
I0130 20:04:47.937217 108075 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0130 20:05:12.395836 108075 solver.cpp:266] Iteration 7950 (2.04434 iter/s, 24.4577s/50 iter), loss = 0.0010659
I0130 20:05:12.395969 108075 solver.cpp:285]     Train net output #0: loss = 0.00106586 (* 1 = 0.00106586 loss)
I0130 20:05:12.398089 108075 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0130 20:05:36.396441 108075 solver.cpp:418] Iteration 8000, Testing net (#0)
I0130 20:05:40.081311 108075 solver.cpp:517]     Test net output #0: loss = 0.196591 (* 1 = 0.196591 loss)
I0130 20:05:40.081329 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95625
I0130 20:05:40.433974 108075 solver.cpp:266] Iteration 8000 (1.78349 iter/s, 28.0348s/50 iter), loss = 0.000935885
I0130 20:05:40.434017 108075 solver.cpp:285]     Train net output #0: loss = 0.000935851 (* 1 = 0.000935851 loss)
I0130 20:05:40.434059 108075 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0130 20:06:04.996968 108075 solver.cpp:266] Iteration 8050 (2.03566 iter/s, 24.562s/50 iter), loss = 0.00470514
I0130 20:06:04.997035 108075 solver.cpp:285]     Train net output #0: loss = 0.00470511 (* 1 = 0.00470511 loss)
I0130 20:06:04.999227 108075 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0130 20:06:29.418934 108075 solver.cpp:266] Iteration 8100 (2.0476 iter/s, 24.4188s/50 iter), loss = 0.00346562
I0130 20:06:29.418978 108075 solver.cpp:285]     Train net output #0: loss = 0.00346559 (* 1 = 0.00346559 loss)
I0130 20:06:29.421190 108075 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0130 20:06:53.968272 108075 solver.cpp:266] Iteration 8150 (2.03698 iter/s, 24.5462s/50 iter), loss = 0.0042642
I0130 20:06:53.968374 108075 solver.cpp:285]     Train net output #0: loss = 0.00426417 (* 1 = 0.00426417 loss)
I0130 20:06:53.968425 108075 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0130 20:07:18.322129 108075 solver.cpp:266] Iteration 8200 (2.05315 iter/s, 24.3528s/50 iter), loss = 0.0126051
I0130 20:07:18.322160 108075 solver.cpp:285]     Train net output #0: loss = 0.0126051 (* 1 = 0.0126051 loss)
I0130 20:07:18.324383 108075 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0130 20:07:42.696429 108075 solver.cpp:266] Iteration 8250 (2.05161 iter/s, 24.3711s/50 iter), loss = 0.0036781
I0130 20:07:42.696583 108075 solver.cpp:285]     Train net output #0: loss = 0.00367807 (* 1 = 0.00367807 loss)
I0130 20:07:42.698671 108075 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0130 20:08:07.300701 108075 solver.cpp:266] Iteration 8300 (2.03243 iter/s, 24.6011s/50 iter), loss = 0.00116343
I0130 20:08:07.300735 108075 solver.cpp:285]     Train net output #0: loss = 0.00116339 (* 1 = 0.00116339 loss)
I0130 20:08:07.300742 108075 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0130 20:08:31.737720 108075 solver.cpp:266] Iteration 8350 (2.04615 iter/s, 24.4361s/50 iter), loss = 0.0052863
I0130 20:08:31.737849 108075 solver.cpp:285]     Train net output #0: loss = 0.00528627 (* 1 = 0.00528627 loss)
I0130 20:08:31.739974 108075 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0130 20:08:56.019379 108075 solver.cpp:266] Iteration 8400 (2.05943 iter/s, 24.2785s/50 iter), loss = 0.0019499
I0130 20:08:56.019409 108075 solver.cpp:285]     Train net output #0: loss = 0.00194987 (* 1 = 0.00194987 loss)
I0130 20:08:56.021637 108075 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0130 20:09:20.299234 108075 solver.cpp:266] Iteration 8450 (2.05959 iter/s, 24.2767s/50 iter), loss = 0.00123651
I0130 20:09:20.299381 108075 solver.cpp:285]     Train net output #0: loss = 0.00123648 (* 1 = 0.00123648 loss)
I0130 20:09:20.301488 108075 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0130 20:09:44.720367 108075 solver.cpp:266] Iteration 8500 (2.04767 iter/s, 24.418s/50 iter), loss = 0.00678909
I0130 20:09:44.720401 108075 solver.cpp:285]     Train net output #0: loss = 0.00678906 (* 1 = 0.00678906 loss)
I0130 20:09:44.720407 108075 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0130 20:10:09.192991 108075 solver.cpp:266] Iteration 8550 (2.04318 iter/s, 24.4717s/50 iter), loss = 0.00265001
I0130 20:10:09.193053 108075 solver.cpp:285]     Train net output #0: loss = 0.00264998 (* 1 = 0.00264998 loss)
I0130 20:10:09.195245 108075 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0130 20:10:33.643144 108075 solver.cpp:266] Iteration 8600 (2.04524 iter/s, 24.447s/50 iter), loss = 0.000665247
I0130 20:10:33.643188 108075 solver.cpp:285]     Train net output #0: loss = 0.00066521 (* 1 = 0.00066521 loss)
I0130 20:10:33.645404 108075 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0130 20:10:58.045660 108075 solver.cpp:266] Iteration 8650 (2.04923 iter/s, 24.3994s/50 iter), loss = 0.00938998
I0130 20:10:58.045783 108075 solver.cpp:285]     Train net output #0: loss = 0.00938994 (* 1 = 0.00938994 loss)
I0130 20:10:58.047919 108075 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0130 20:11:22.283324 108075 solver.cpp:266] Iteration 8700 (2.06317 iter/s, 24.2345s/50 iter), loss = 0.00494704
I0130 20:11:22.283368 108075 solver.cpp:285]     Train net output #0: loss = 0.00494701 (* 1 = 0.00494701 loss)
I0130 20:11:22.285571 108075 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0130 20:11:46.811544 108075 solver.cpp:266] Iteration 8750 (2.03873 iter/s, 24.5251s/50 iter), loss = 0.0103857
I0130 20:11:46.811689 108075 solver.cpp:285]     Train net output #0: loss = 0.0103857 (* 1 = 0.0103857 loss)
I0130 20:11:46.813877 108075 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0130 20:12:11.123572 108075 solver.cpp:266] Iteration 8800 (2.05687 iter/s, 24.3088s/50 iter), loss = 0.00469767
I0130 20:12:11.123615 108075 solver.cpp:285]     Train net output #0: loss = 0.00469762 (* 1 = 0.00469762 loss)
I0130 20:12:11.123661 108075 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0130 20:12:35.597187 108075 solver.cpp:266] Iteration 8850 (2.0431 iter/s, 24.4726s/50 iter), loss = 0.00667212
I0130 20:12:35.597296 108075 solver.cpp:285]     Train net output #0: loss = 0.00667207 (* 1 = 0.00667207 loss)
I0130 20:12:35.599442 108075 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0130 20:12:59.943894 108075 solver.cpp:266] Iteration 8900 (2.05393 iter/s, 24.3436s/50 iter), loss = 0.00036323
I0130 20:12:59.943928 108075 solver.cpp:285]     Train net output #0: loss = 0.000363188 (* 1 = 0.000363188 loss)
I0130 20:12:59.946146 108075 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0130 20:13:24.453636 108075 solver.cpp:266] Iteration 8950 (2.04027 iter/s, 24.5066s/50 iter), loss = 0.00318929
I0130 20:13:24.453781 108075 solver.cpp:285]     Train net output #0: loss = 0.00318925 (* 1 = 0.00318925 loss)
I0130 20:13:24.455883 108075 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0130 20:13:48.479146 108075 solver.cpp:418] Iteration 9000, Testing net (#0)
I0130 20:13:52.014715 108075 solver.cpp:517]     Test net output #0: loss = 0.202658 (* 1 = 0.202658 loss)
I0130 20:13:52.014734 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95475
I0130 20:13:52.526791 108075 solver.cpp:266] Iteration 9000 (1.78127 iter/s, 28.0699s/50 iter), loss = 0.000535359
I0130 20:13:52.526847 108075 solver.cpp:285]     Train net output #0: loss = 0.000535311 (* 1 = 0.000535311 loss)
I0130 20:13:52.526875 108075 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0130 20:14:16.913105 108075 solver.cpp:266] Iteration 9050 (2.05041 iter/s, 24.3853s/50 iter), loss = 0.00466202
I0130 20:14:16.913178 108075 solver.cpp:285]     Train net output #0: loss = 0.00466198 (* 1 = 0.00466198 loss)
I0130 20:14:16.915359 108075 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0130 20:14:41.338908 108075 solver.cpp:266] Iteration 9100 (2.04728 iter/s, 24.4226s/50 iter), loss = 0.00265611
I0130 20:14:41.338938 108075 solver.cpp:285]     Train net output #0: loss = 0.00265606 (* 1 = 0.00265606 loss)
I0130 20:14:41.341154 108075 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0130 20:15:05.691262 108075 solver.cpp:266] Iteration 9150 (2.05346 iter/s, 24.3492s/50 iter), loss = 0.00125538
I0130 20:15:05.691401 108075 solver.cpp:285]     Train net output #0: loss = 0.00125533 (* 1 = 0.00125533 loss)
I0130 20:15:05.691408 108075 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0130 20:15:30.162008 108075 solver.cpp:266] Iteration 9200 (2.04334 iter/s, 24.4697s/50 iter), loss = 0.000630896
I0130 20:15:30.162050 108075 solver.cpp:285]     Train net output #0: loss = 0.000630852 (* 1 = 0.000630852 loss)
I0130 20:15:30.164273 108075 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0130 20:15:54.549440 108075 solver.cpp:266] Iteration 9250 (2.0505 iter/s, 24.3843s/50 iter), loss = 0.00971223
I0130 20:15:54.549580 108075 solver.cpp:285]     Train net output #0: loss = 0.00971218 (* 1 = 0.00971218 loss)
I0130 20:15:54.549621 108075 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0130 20:16:18.939488 108075 solver.cpp:266] Iteration 9300 (2.05011 iter/s, 24.389s/50 iter), loss = 0.00912686
I0130 20:16:18.939527 108075 solver.cpp:285]     Train net output #0: loss = 0.00912682 (* 1 = 0.00912682 loss)
I0130 20:16:18.941748 108075 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0130 20:16:43.194769 108075 solver.cpp:266] Iteration 9350 (2.06168 iter/s, 24.2521s/50 iter), loss = 0.00673868
I0130 20:16:43.194870 108075 solver.cpp:285]     Train net output #0: loss = 0.00673863 (* 1 = 0.00673863 loss)
I0130 20:16:43.197038 108075 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0130 20:17:07.740890 108075 solver.cpp:266] Iteration 9400 (2.03725 iter/s, 24.5429s/50 iter), loss = 0.00520916
I0130 20:17:07.740926 108075 solver.cpp:285]     Train net output #0: loss = 0.00520911 (* 1 = 0.00520911 loss)
I0130 20:17:07.743134 108075 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0130 20:17:32.309793 108075 solver.cpp:266] Iteration 9450 (2.03535 iter/s, 24.5658s/50 iter), loss = 0.00731155
I0130 20:17:32.309902 108075 solver.cpp:285]     Train net output #0: loss = 0.0073115 (* 1 = 0.0073115 loss)
I0130 20:17:32.310045 108075 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0130 20:17:56.790863 108075 solver.cpp:266] Iteration 9500 (2.04249 iter/s, 24.4799s/50 iter), loss = 0.0141564
I0130 20:17:56.790896 108075 solver.cpp:285]     Train net output #0: loss = 0.0141563 (* 1 = 0.0141563 loss)
I0130 20:17:56.793123 108075 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0130 20:18:21.089639 108075 solver.cpp:266] Iteration 9550 (2.05798 iter/s, 24.2956s/50 iter), loss = 0.00184295
I0130 20:18:21.089762 108075 solver.cpp:285]     Train net output #0: loss = 0.0018429 (* 1 = 0.0018429 loss)
I0130 20:18:21.091895 108075 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0130 20:18:45.443071 108075 solver.cpp:266] Iteration 9600 (2.05336 iter/s, 24.3503s/50 iter), loss = 0.000840532
I0130 20:18:45.443105 108075 solver.cpp:285]     Train net output #0: loss = 0.000840477 (* 1 = 0.000840477 loss)
I0130 20:18:45.445325 108075 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0130 20:19:09.893312 108075 solver.cpp:266] Iteration 9650 (2.04523 iter/s, 24.4471s/50 iter), loss = 0.00349679
I0130 20:19:09.893462 108075 solver.cpp:285]     Train net output #0: loss = 0.00349674 (* 1 = 0.00349674 loss)
I0130 20:19:09.895557 108075 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0130 20:19:34.436817 108075 solver.cpp:266] Iteration 9700 (2.03746 iter/s, 24.5404s/50 iter), loss = 0.000839339
I0130 20:19:34.436854 108075 solver.cpp:285]     Train net output #0: loss = 0.00083928 (* 1 = 0.00083928 loss)
I0130 20:19:34.436863 108075 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0130 20:19:58.984007 108075 solver.cpp:266] Iteration 9750 (2.03697 iter/s, 24.5462s/50 iter), loss = 0.00192623
I0130 20:19:58.984308 108075 solver.cpp:285]     Train net output #0: loss = 0.00192617 (* 1 = 0.00192617 loss)
I0130 20:19:58.984341 108075 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0130 20:20:23.417157 108075 solver.cpp:266] Iteration 9800 (2.0465 iter/s, 24.4319s/50 iter), loss = 0.00175542
I0130 20:20:23.417191 108075 solver.cpp:285]     Train net output #0: loss = 0.00175536 (* 1 = 0.00175536 loss)
I0130 20:20:23.419404 108075 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0130 20:20:47.803824 108075 solver.cpp:266] Iteration 9850 (2.05057 iter/s, 24.3835s/50 iter), loss = 0.00165255
I0130 20:20:47.803876 108075 solver.cpp:285]     Train net output #0: loss = 0.00165249 (* 1 = 0.00165249 loss)
I0130 20:20:47.806067 108075 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0130 20:21:12.147855 108075 solver.cpp:266] Iteration 9900 (2.05416 iter/s, 24.3409s/50 iter), loss = 0.0065013
I0130 20:21:12.147894 108075 solver.cpp:285]     Train net output #0: loss = 0.00650124 (* 1 = 0.00650124 loss)
I0130 20:21:12.150117 108075 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0130 20:21:36.505561 108075 solver.cpp:266] Iteration 9950 (2.053 iter/s, 24.3545s/50 iter), loss = 0.00183489
I0130 20:21:36.505681 108075 solver.cpp:285]     Train net output #0: loss = 0.00183483 (* 1 = 0.00183483 loss)
I0130 20:21:36.507803 108075 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0130 20:22:00.674018 108075 solver.cpp:418] Iteration 10000, Testing net (#0)
I0130 20:22:04.165673 108075 solver.cpp:517]     Test net output #0: loss = 0.205225 (* 1 = 0.205225 loss)
I0130 20:22:04.165688 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95525
I0130 20:22:04.711702 108075 solver.cpp:266] Iteration 10000 (1.77287 iter/s, 28.2029s/50 iter), loss = 0.00271825
I0130 20:22:04.711731 108075 solver.cpp:285]     Train net output #0: loss = 0.00271819 (* 1 = 0.00271819 loss)
I0130 20:22:04.713954 108075 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0130 20:22:28.968057 108075 solver.cpp:266] Iteration 10050 (2.06158 iter/s, 24.2532s/50 iter), loss = 0.000622985
I0130 20:22:28.968111 108075 solver.cpp:285]     Train net output #0: loss = 0.000622924 (* 1 = 0.000622924 loss)
I0130 20:22:28.970304 108075 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0130 20:22:53.352555 108075 solver.cpp:266] Iteration 10100 (2.05075 iter/s, 24.3814s/50 iter), loss = 0.0131765
I0130 20:22:53.352591 108075 solver.cpp:285]     Train net output #0: loss = 0.0131764 (* 1 = 0.0131764 loss)
I0130 20:22:53.352598 108075 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0130 20:23:17.951989 108075 solver.cpp:266] Iteration 10150 (2.03265 iter/s, 24.5985s/50 iter), loss = 0.00260277
I0130 20:23:17.952105 108075 solver.cpp:285]     Train net output #0: loss = 0.00260272 (* 1 = 0.00260272 loss)
I0130 20:23:17.952440 108075 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0130 20:23:42.323846 108075 solver.cpp:266] Iteration 10200 (2.05166 iter/s, 24.3705s/50 iter), loss = 0.0050119
I0130 20:23:42.323889 108075 solver.cpp:285]     Train net output #0: loss = 0.00501184 (* 1 = 0.00501184 loss)
I0130 20:23:42.326099 108075 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0130 20:24:06.757861 108075 solver.cpp:266] Iteration 10250 (2.04659 iter/s, 24.4309s/50 iter), loss = 0.00315185
I0130 20:24:06.758019 108075 solver.cpp:285]     Train net output #0: loss = 0.00315179 (* 1 = 0.00315179 loss)
I0130 20:24:06.760119 108075 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0130 20:24:31.015214 108075 solver.cpp:266] Iteration 10300 (2.0615 iter/s, 24.2542s/50 iter), loss = 0.00166696
I0130 20:24:31.015247 108075 solver.cpp:285]     Train net output #0: loss = 0.0016669 (* 1 = 0.0016669 loss)
I0130 20:24:31.017465 108075 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0130 20:24:55.475217 108075 solver.cpp:266] Iteration 10350 (2.04442 iter/s, 24.4568s/50 iter), loss = 0.0229131
I0130 20:24:55.475340 108075 solver.cpp:285]     Train net output #0: loss = 0.022913 (* 1 = 0.022913 loss)
I0130 20:24:55.475348 108075 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0130 20:25:19.955803 108075 solver.cpp:266] Iteration 10400 (2.04252 iter/s, 24.4796s/50 iter), loss = 0.00296928
I0130 20:25:19.955848 108075 solver.cpp:285]     Train net output #0: loss = 0.00296923 (* 1 = 0.00296923 loss)
I0130 20:25:19.958061 108075 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0130 20:25:44.455258 108075 solver.cpp:266] Iteration 10450 (2.04113 iter/s, 24.4963s/50 iter), loss = 0.00152892
I0130 20:25:44.455376 108075 solver.cpp:285]     Train net output #0: loss = 0.00152886 (* 1 = 0.00152886 loss)
I0130 20:25:44.457506 108075 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0130 20:26:08.783697 108075 solver.cpp:266] Iteration 10500 (2.05547 iter/s, 24.3253s/50 iter), loss = 0.0178687
I0130 20:26:08.783736 108075 solver.cpp:285]     Train net output #0: loss = 0.0178686 (* 1 = 0.0178686 loss)
I0130 20:26:08.785959 108075 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0130 20:26:33.158568 108075 solver.cpp:266] Iteration 10550 (2.05156 iter/s, 24.3717s/50 iter), loss = 0.000708015
I0130 20:26:33.158690 108075 solver.cpp:285]     Train net output #0: loss = 0.000707962 (* 1 = 0.000707962 loss)
I0130 20:26:33.160815 108075 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0130 20:26:57.651885 108075 solver.cpp:266] Iteration 10600 (2.04164 iter/s, 24.4902s/50 iter), loss = 0.00323947
I0130 20:26:57.651929 108075 solver.cpp:285]     Train net output #0: loss = 0.00323942 (* 1 = 0.00323942 loss)
I0130 20:26:57.654127 108075 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0130 20:27:22.174720 108075 solver.cpp:266] Iteration 10650 (2.03918 iter/s, 24.5197s/50 iter), loss = 0.0256958
I0130 20:27:22.174859 108075 solver.cpp:285]     Train net output #0: loss = 0.0256957 (* 1 = 0.0256957 loss)
I0130 20:27:22.176931 108075 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0130 20:27:46.526528 108075 solver.cpp:266] Iteration 10700 (2.0535 iter/s, 24.3487s/50 iter), loss = 0.00731941
I0130 20:27:46.526568 108075 solver.cpp:285]     Train net output #0: loss = 0.00731936 (* 1 = 0.00731936 loss)
I0130 20:27:46.528744 108075 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0130 20:28:10.847471 108075 solver.cpp:266] Iteration 10750 (2.0561 iter/s, 24.3178s/50 iter), loss = 0.0190157
I0130 20:28:10.847548 108075 solver.cpp:285]     Train net output #0: loss = 0.0190157 (* 1 = 0.0190157 loss)
I0130 20:28:10.849720 108075 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0130 20:28:35.158046 108075 solver.cpp:266] Iteration 10800 (2.05698 iter/s, 24.3074s/50 iter), loss = 0.00893878
I0130 20:28:35.158092 108075 solver.cpp:285]     Train net output #0: loss = 0.00893873 (* 1 = 0.00893873 loss)
I0130 20:28:35.160291 108075 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0130 20:28:59.648741 108075 solver.cpp:266] Iteration 10850 (2.04185 iter/s, 24.4875s/50 iter), loss = 0.00319947
I0130 20:28:59.648828 108075 solver.cpp:285]     Train net output #0: loss = 0.00319942 (* 1 = 0.00319942 loss)
I0130 20:28:59.648867 108075 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0130 20:29:24.160676 108075 solver.cpp:266] Iteration 10900 (2.03991 iter/s, 24.5109s/50 iter), loss = 0.0107936
I0130 20:29:24.160720 108075 solver.cpp:285]     Train net output #0: loss = 0.0107936 (* 1 = 0.0107936 loss)
I0130 20:29:24.162911 108075 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0130 20:29:48.428681 108075 solver.cpp:266] Iteration 10950 (2.06059 iter/s, 24.2649s/50 iter), loss = 0.00104806
I0130 20:29:48.428840 108075 solver.cpp:285]     Train net output #0: loss = 0.00104801 (* 1 = 0.00104801 loss)
I0130 20:29:48.430933 108075 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0130 20:30:12.313174 108075 solver.cpp:418] Iteration 11000, Testing net (#0)
I0130 20:30:15.796603 108075 solver.cpp:517]     Test net output #0: loss = 0.207177 (* 1 = 0.207177 loss)
I0130 20:30:15.796622 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95525
I0130 20:30:16.263911 108075 solver.cpp:266] Iteration 11000 (1.7965 iter/s, 27.832s/50 iter), loss = 0.010336
I0130 20:30:16.263934 108075 solver.cpp:285]     Train net output #0: loss = 0.010336 (* 1 = 0.010336 loss)
I0130 20:30:16.266170 108075 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0130 20:30:40.792858 108075 solver.cpp:266] Iteration 11050 (2.03867 iter/s, 24.5258s/50 iter), loss = 0.00107306
I0130 20:30:40.792984 108075 solver.cpp:285]     Train net output #0: loss = 0.001073 (* 1 = 0.001073 loss)
I0130 20:30:40.793047 108075 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0130 20:31:05.193106 108075 solver.cpp:266] Iteration 11100 (2.04925 iter/s, 24.3992s/50 iter), loss = 0.00463679
I0130 20:31:05.193135 108075 solver.cpp:285]     Train net output #0: loss = 0.00463673 (* 1 = 0.00463673 loss)
I0130 20:31:05.195353 108075 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0130 20:31:29.644505 108075 solver.cpp:266] Iteration 11150 (2.04514 iter/s, 24.4482s/50 iter), loss = 0.00201902
I0130 20:31:29.644610 108075 solver.cpp:285]     Train net output #0: loss = 0.00201896 (* 1 = 0.00201896 loss)
I0130 20:31:29.646755 108075 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0130 20:31:54.027154 108075 solver.cpp:266] Iteration 11200 (2.0509 iter/s, 24.3795s/50 iter), loss = 0.00556205
I0130 20:31:54.027184 108075 solver.cpp:285]     Train net output #0: loss = 0.00556199 (* 1 = 0.00556199 loss)
I0130 20:31:54.029403 108075 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0130 20:32:18.494259 108075 solver.cpp:266] Iteration 11250 (2.04382 iter/s, 24.464s/50 iter), loss = 0.00146526
I0130 20:32:18.494334 108075 solver.cpp:285]     Train net output #0: loss = 0.0014652 (* 1 = 0.0014652 loss)
I0130 20:32:18.494343 108075 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0130 20:32:42.873003 108075 solver.cpp:266] Iteration 11300 (2.05105 iter/s, 24.3778s/50 iter), loss = 0.0209533
I0130 20:32:42.873039 108075 solver.cpp:285]     Train net output #0: loss = 0.0209533 (* 1 = 0.0209533 loss)
I0130 20:32:42.875262 108075 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0130 20:33:07.207188 108075 solver.cpp:266] Iteration 11350 (2.05499 iter/s, 24.331s/50 iter), loss = 0.00176925
I0130 20:33:07.207239 108075 solver.cpp:285]     Train net output #0: loss = 0.0017692 (* 1 = 0.0017692 loss)
I0130 20:33:07.209444 108075 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0130 20:33:31.593134 108075 solver.cpp:266] Iteration 11400 (2.05063 iter/s, 24.3828s/50 iter), loss = 0.00310873
I0130 20:33:31.593165 108075 solver.cpp:285]     Train net output #0: loss = 0.00310868 (* 1 = 0.00310868 loss)
I0130 20:33:31.595383 108075 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0130 20:33:56.061599 108075 solver.cpp:266] Iteration 11450 (2.04371 iter/s, 24.4653s/50 iter), loss = 0.000950579
I0130 20:33:56.061731 108075 solver.cpp:285]     Train net output #0: loss = 0.000950524 (* 1 = 0.000950524 loss)
I0130 20:33:56.063832 108075 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0130 20:34:20.521378 108075 solver.cpp:266] Iteration 11500 (2.04443 iter/s, 24.4566s/50 iter), loss = 0.0010902
I0130 20:34:20.521410 108075 solver.cpp:285]     Train net output #0: loss = 0.00109014 (* 1 = 0.00109014 loss)
I0130 20:34:20.521417 108075 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0130 20:34:44.946509 108075 solver.cpp:266] Iteration 11550 (2.04715 iter/s, 24.4242s/50 iter), loss = 0.00622484
I0130 20:34:44.946665 108075 solver.cpp:285]     Train net output #0: loss = 0.00622478 (* 1 = 0.00622478 loss)
I0130 20:34:44.948756 108075 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0130 20:35:09.379173 108075 solver.cpp:266] Iteration 11600 (2.0467 iter/s, 24.4295s/50 iter), loss = 0.00390021
I0130 20:35:09.379204 108075 solver.cpp:285]     Train net output #0: loss = 0.00390015 (* 1 = 0.00390015 loss)
I0130 20:35:09.379251 108075 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0130 20:35:33.845940 108075 solver.cpp:266] Iteration 11650 (2.04367 iter/s, 24.4658s/50 iter), loss = 0.00177404
I0130 20:35:33.846053 108075 solver.cpp:285]     Train net output #0: loss = 0.00177398 (* 1 = 0.00177398 loss)
I0130 20:35:33.848189 108075 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0130 20:35:58.209190 108075 solver.cpp:266] Iteration 11700 (2.05254 iter/s, 24.3601s/50 iter), loss = 0.00154144
I0130 20:35:58.209233 108075 solver.cpp:285]     Train net output #0: loss = 0.00154137 (* 1 = 0.00154137 loss)
I0130 20:35:58.211441 108075 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0130 20:36:22.529708 108075 solver.cpp:266] Iteration 11750 (2.05614 iter/s, 24.3174s/50 iter), loss = 0.0123155
I0130 20:36:22.529788 108075 solver.cpp:285]     Train net output #0: loss = 0.0123154 (* 1 = 0.0123154 loss)
I0130 20:36:22.529795 108075 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0130 20:36:47.061061 108075 solver.cpp:266] Iteration 11800 (2.03829 iter/s, 24.5304s/50 iter), loss = 0.00761097
I0130 20:36:47.061096 108075 solver.cpp:285]     Train net output #0: loss = 0.0076109 (* 1 = 0.0076109 loss)
I0130 20:36:47.061102 108075 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0130 20:37:11.580435 108075 solver.cpp:266] Iteration 11850 (2.03928 iter/s, 24.5184s/50 iter), loss = 0.000940835
I0130 20:37:11.580556 108075 solver.cpp:285]     Train net output #0: loss = 0.000940774 (* 1 = 0.000940774 loss)
I0130 20:37:11.580965 108075 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0130 20:37:35.985307 108075 solver.cpp:266] Iteration 11900 (2.04889 iter/s, 24.4034s/50 iter), loss = 0.0202657
I0130 20:37:35.985342 108075 solver.cpp:285]     Train net output #0: loss = 0.0202656 (* 1 = 0.0202656 loss)
I0130 20:37:35.987556 108075 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0130 20:38:00.423892 108075 solver.cpp:266] Iteration 11950 (2.04621 iter/s, 24.4354s/50 iter), loss = 0.00183411
I0130 20:38:00.423959 108075 solver.cpp:285]     Train net output #0: loss = 0.00183405 (* 1 = 0.00183405 loss)
I0130 20:38:00.426604 108075 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0130 20:38:24.158326 108075 solver.cpp:929] Snapshotting to binary proto file cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/snapshots/_iter_12000.caffemodel
I0130 20:38:26.637879 108075 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cats-vs-dogs/deephi/alexnetBNnoLRN/pruning/regular_rate_0.3/snapshots/_iter_12000.solverstate
I0130 20:38:27.357877 108075 solver.cpp:378] Iteration 12000, loss = 0.0035702
I0130 20:38:27.357903 108075 solver.cpp:418] Iteration 12000, Testing net (#0)
I0130 20:38:30.830286 108075 solver.cpp:517]     Test net output #0: loss = 0.208346 (* 1 = 0.208346 loss)
I0130 20:38:30.830390 108075 solver.cpp:517]     Test net output #1: top-1 = 0.95575
I0130 20:38:30.830395 108075 solver.cpp:386] Optimization Done (2.0378 iter/s).
I0130 20:38:30.830397 108075 caffe_interface.cpp:530] Optimization Done.
