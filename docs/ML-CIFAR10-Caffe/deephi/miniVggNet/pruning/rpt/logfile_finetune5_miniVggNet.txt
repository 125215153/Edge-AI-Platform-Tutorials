I0122 16:38:49.565065 56358 deephi_compress.cpp:236] cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/net_finetune.prototxt
I0122 16:38:49.746558 56358 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 16:38:49.747069 56358 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24887558144, dev_info[0]: total=25620447232 free=24887558144
I0122 16:38:49.747081 56358 caffe_interface.cpp:493] Using GPUs 0
I0122 16:38:49.747332 56358 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 16:38:50.330523 56358 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 20000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0005
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/net_finetune.prototxt"
type: "SGD"
I0122 16:38:50.330972 56358 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/net_finetune.prototxt
I0122 16:38:50.331451 56358 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 16:38:50.331481 56358 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 16:38:50.331488 56358 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 16:38:50.331861 56358 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 125
    mean_value: 123
    mean_value: 114
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "scale1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "scale2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "drop1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "scale3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "scale4"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu4"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "drop2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "drop2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "fc1"
  top: "scale5"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "scale5"
  top: "relu5"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "relu5"
  top: "drop3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop3"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
I0122 16:38:50.331996 56358 layer_factory.hpp:77] Creating layer data
I0122 16:38:50.332164 56358 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:38:50.332998 56358 net.cpp:94] Creating Layer data
I0122 16:38:50.333016 56358 net.cpp:409] data -> data
I0122 16:38:50.333050 56358 net.cpp:409] data -> label
I0122 16:38:50.334228 56397 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 16:38:50.334273 56397 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 16:38:50.334406 56358 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 16:38:50.334558 56358 data_layer.cpp:83] output data size: 128,3,32,32
I0122 16:38:50.346828 56358 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:38:50.346886 56358 net.cpp:144] Setting up data
I0122 16:38:50.346896 56358 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 16:38:50.346902 56358 net.cpp:151] Top shape: 128 (128)
I0122 16:38:50.346907 56358 net.cpp:159] Memory required for data: 1573376
I0122 16:38:50.346913 56358 layer_factory.hpp:77] Creating layer conv1
I0122 16:38:50.346931 56358 net.cpp:94] Creating Layer conv1
I0122 16:38:50.346938 56358 net.cpp:435] conv1 <- data
I0122 16:38:50.346957 56358 net.cpp:409] conv1 -> conv1
I0122 16:38:50.348379 56358 net.cpp:144] Setting up conv1
I0122 16:38:50.348394 56358 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:38:50.348398 56358 net.cpp:159] Memory required for data: 18350592
I0122 16:38:50.348419 56358 layer_factory.hpp:77] Creating layer bn1
I0122 16:38:50.348431 56358 net.cpp:94] Creating Layer bn1
I0122 16:38:50.348436 56358 net.cpp:435] bn1 <- conv1
I0122 16:38:50.348443 56358 net.cpp:409] bn1 -> scale1
I0122 16:38:50.349334 56358 net.cpp:144] Setting up bn1
I0122 16:38:50.349344 56358 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:38:50.349347 56358 net.cpp:159] Memory required for data: 35127808
I0122 16:38:50.349364 56358 layer_factory.hpp:77] Creating layer relu1
I0122 16:38:50.349372 56358 net.cpp:94] Creating Layer relu1
I0122 16:38:50.349381 56358 net.cpp:435] relu1 <- scale1
I0122 16:38:50.349387 56358 net.cpp:409] relu1 -> relu1
I0122 16:38:50.349954 56358 net.cpp:144] Setting up relu1
I0122 16:38:50.349964 56358 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:38:50.349968 56358 net.cpp:159] Memory required for data: 51905024
I0122 16:38:50.349972 56358 layer_factory.hpp:77] Creating layer conv2
I0122 16:38:50.349984 56358 net.cpp:94] Creating Layer conv2
I0122 16:38:50.349989 56358 net.cpp:435] conv2 <- relu1
I0122 16:38:50.349997 56358 net.cpp:409] conv2 -> conv2
I0122 16:38:50.351444 56358 net.cpp:144] Setting up conv2
I0122 16:38:50.351459 56358 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:38:50.351464 56358 net.cpp:159] Memory required for data: 68682240
I0122 16:38:50.351475 56358 layer_factory.hpp:77] Creating layer bn2
I0122 16:38:50.351486 56358 net.cpp:94] Creating Layer bn2
I0122 16:38:50.351490 56358 net.cpp:435] bn2 <- conv2
I0122 16:38:50.351500 56358 net.cpp:409] bn2 -> scale2
I0122 16:38:50.352522 56358 net.cpp:144] Setting up bn2
I0122 16:38:50.352533 56358 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:38:50.352537 56358 net.cpp:159] Memory required for data: 85459456
I0122 16:38:50.352551 56358 layer_factory.hpp:77] Creating layer relu2
I0122 16:38:50.352560 56358 net.cpp:94] Creating Layer relu2
I0122 16:38:50.352566 56358 net.cpp:435] relu2 <- scale2
I0122 16:38:50.352572 56358 net.cpp:409] relu2 -> relu2
I0122 16:38:50.352598 56358 net.cpp:144] Setting up relu2
I0122 16:38:50.352607 56358 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:38:50.352610 56358 net.cpp:159] Memory required for data: 102236672
I0122 16:38:50.352614 56358 layer_factory.hpp:77] Creating layer pool1
I0122 16:38:50.352623 56358 net.cpp:94] Creating Layer pool1
I0122 16:38:50.352628 56358 net.cpp:435] pool1 <- relu2
I0122 16:38:50.352634 56358 net.cpp:409] pool1 -> pool1
I0122 16:38:50.352679 56358 net.cpp:144] Setting up pool1
I0122 16:38:50.352694 56358 net.cpp:151] Top shape: 128 32 16 16 (1048576)
I0122 16:38:50.352699 56358 net.cpp:159] Memory required for data: 106430976
I0122 16:38:50.352702 56358 layer_factory.hpp:77] Creating layer drop1
I0122 16:38:50.352710 56358 net.cpp:94] Creating Layer drop1
I0122 16:38:50.352715 56358 net.cpp:435] drop1 <- pool1
I0122 16:38:50.352739 56358 net.cpp:409] drop1 -> drop1
I0122 16:38:50.352784 56358 net.cpp:144] Setting up drop1
I0122 16:38:50.352792 56358 net.cpp:151] Top shape: 128 32 16 16 (1048576)
I0122 16:38:50.352797 56358 net.cpp:159] Memory required for data: 110625280
I0122 16:38:50.352802 56358 layer_factory.hpp:77] Creating layer conv3
I0122 16:38:50.352813 56358 net.cpp:94] Creating Layer conv3
I0122 16:38:50.352819 56358 net.cpp:435] conv3 <- drop1
I0122 16:38:50.352828 56358 net.cpp:409] conv3 -> conv3
I0122 16:38:50.354102 56358 net.cpp:144] Setting up conv3
I0122 16:38:50.354115 56358 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:38:50.354117 56358 net.cpp:159] Memory required for data: 119013888
I0122 16:38:50.354125 56358 layer_factory.hpp:77] Creating layer bn3
I0122 16:38:50.354131 56358 net.cpp:94] Creating Layer bn3
I0122 16:38:50.354137 56358 net.cpp:435] bn3 <- conv3
I0122 16:38:50.354143 56358 net.cpp:409] bn3 -> scale3
I0122 16:38:50.354840 56358 net.cpp:144] Setting up bn3
I0122 16:38:50.354847 56358 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:38:50.354851 56358 net.cpp:159] Memory required for data: 127402496
I0122 16:38:50.354861 56358 layer_factory.hpp:77] Creating layer relu3
I0122 16:38:50.354868 56358 net.cpp:94] Creating Layer relu3
I0122 16:38:50.354872 56358 net.cpp:435] relu3 <- scale3
I0122 16:38:50.354876 56358 net.cpp:409] relu3 -> relu3
I0122 16:38:50.354894 56358 net.cpp:144] Setting up relu3
I0122 16:38:50.354902 56358 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:38:50.354905 56358 net.cpp:159] Memory required for data: 135791104
I0122 16:38:50.354907 56358 layer_factory.hpp:77] Creating layer conv4
I0122 16:38:50.354916 56358 net.cpp:94] Creating Layer conv4
I0122 16:38:50.354921 56358 net.cpp:435] conv4 <- relu3
I0122 16:38:50.354926 56358 net.cpp:409] conv4 -> conv4
I0122 16:38:50.355394 56358 net.cpp:144] Setting up conv4
I0122 16:38:50.355402 56358 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:38:50.355406 56358 net.cpp:159] Memory required for data: 144179712
I0122 16:38:50.355412 56358 layer_factory.hpp:77] Creating layer bn4
I0122 16:38:50.355418 56358 net.cpp:94] Creating Layer bn4
I0122 16:38:50.355422 56358 net.cpp:435] bn4 <- conv4
I0122 16:38:50.355427 56358 net.cpp:409] bn4 -> scale4
I0122 16:38:50.356070 56358 net.cpp:144] Setting up bn4
I0122 16:38:50.356076 56358 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:38:50.356079 56358 net.cpp:159] Memory required for data: 152568320
I0122 16:38:50.356088 56358 layer_factory.hpp:77] Creating layer relu4
I0122 16:38:50.356093 56358 net.cpp:94] Creating Layer relu4
I0122 16:38:50.356096 56358 net.cpp:435] relu4 <- scale4
I0122 16:38:50.356101 56358 net.cpp:409] relu4 -> relu4
I0122 16:38:50.356119 56358 net.cpp:144] Setting up relu4
I0122 16:38:50.356127 56358 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:38:50.356130 56358 net.cpp:159] Memory required for data: 160956928
I0122 16:38:50.356133 56358 layer_factory.hpp:77] Creating layer pool2
I0122 16:38:50.356139 56358 net.cpp:94] Creating Layer pool2
I0122 16:38:50.356142 56358 net.cpp:435] pool2 <- relu4
I0122 16:38:50.356146 56358 net.cpp:409] pool2 -> pool2
I0122 16:38:50.356178 56358 net.cpp:144] Setting up pool2
I0122 16:38:50.356184 56358 net.cpp:151] Top shape: 128 64 8 8 (524288)
I0122 16:38:50.356186 56358 net.cpp:159] Memory required for data: 163054080
I0122 16:38:50.356189 56358 layer_factory.hpp:77] Creating layer drop2
I0122 16:38:50.356195 56358 net.cpp:94] Creating Layer drop2
I0122 16:38:50.356201 56358 net.cpp:435] drop2 <- pool2
I0122 16:38:50.356205 56358 net.cpp:409] drop2 -> drop2
I0122 16:38:50.356232 56358 net.cpp:144] Setting up drop2
I0122 16:38:50.356238 56358 net.cpp:151] Top shape: 128 64 8 8 (524288)
I0122 16:38:50.356242 56358 net.cpp:159] Memory required for data: 165151232
I0122 16:38:50.356245 56358 layer_factory.hpp:77] Creating layer fc1
I0122 16:38:50.356251 56358 net.cpp:94] Creating Layer fc1
I0122 16:38:50.356253 56358 net.cpp:435] fc1 <- drop2
I0122 16:38:50.356258 56358 net.cpp:409] fc1 -> fc1
I0122 16:38:50.371639 56358 net.cpp:144] Setting up fc1
I0122 16:38:50.371655 56358 net.cpp:151] Top shape: 128 512 (65536)
I0122 16:38:50.371657 56358 net.cpp:159] Memory required for data: 165413376
I0122 16:38:50.371665 56358 layer_factory.hpp:77] Creating layer bn5
I0122 16:38:50.371675 56358 net.cpp:94] Creating Layer bn5
I0122 16:38:50.371678 56358 net.cpp:435] bn5 <- fc1
I0122 16:38:50.371685 56358 net.cpp:409] bn5 -> scale5
I0122 16:38:50.372210 56358 net.cpp:144] Setting up bn5
I0122 16:38:50.372217 56358 net.cpp:151] Top shape: 128 512 (65536)
I0122 16:38:50.372220 56358 net.cpp:159] Memory required for data: 165675520
I0122 16:38:50.372231 56358 layer_factory.hpp:77] Creating layer relu5
I0122 16:38:50.372238 56358 net.cpp:94] Creating Layer relu5
I0122 16:38:50.372241 56358 net.cpp:435] relu5 <- scale5
I0122 16:38:50.372246 56358 net.cpp:409] relu5 -> relu5
I0122 16:38:50.372263 56358 net.cpp:144] Setting up relu5
I0122 16:38:50.372269 56358 net.cpp:151] Top shape: 128 512 (65536)
I0122 16:38:50.372272 56358 net.cpp:159] Memory required for data: 165937664
I0122 16:38:50.372274 56358 layer_factory.hpp:77] Creating layer drop3
I0122 16:38:50.372279 56358 net.cpp:94] Creating Layer drop3
I0122 16:38:50.372283 56358 net.cpp:435] drop3 <- relu5
I0122 16:38:50.372287 56358 net.cpp:409] drop3 -> drop3
I0122 16:38:50.372313 56358 net.cpp:144] Setting up drop3
I0122 16:38:50.372318 56358 net.cpp:151] Top shape: 128 512 (65536)
I0122 16:38:50.372321 56358 net.cpp:159] Memory required for data: 166199808
I0122 16:38:50.372323 56358 layer_factory.hpp:77] Creating layer fc2
I0122 16:38:50.372330 56358 net.cpp:94] Creating Layer fc2
I0122 16:38:50.372334 56358 net.cpp:435] fc2 <- drop3
I0122 16:38:50.372340 56358 net.cpp:409] fc2 -> fc2
I0122 16:38:50.372470 56358 net.cpp:144] Setting up fc2
I0122 16:38:50.372475 56358 net.cpp:151] Top shape: 128 10 (1280)
I0122 16:38:50.372478 56358 net.cpp:159] Memory required for data: 166204928
I0122 16:38:50.372483 56358 layer_factory.hpp:77] Creating layer loss
I0122 16:38:50.372488 56358 net.cpp:94] Creating Layer loss
I0122 16:38:50.372490 56358 net.cpp:435] loss <- fc2
I0122 16:38:50.372494 56358 net.cpp:435] loss <- label
I0122 16:38:50.372500 56358 net.cpp:409] loss -> loss
I0122 16:38:50.372506 56358 layer_factory.hpp:77] Creating layer loss
I0122 16:38:50.373229 56358 net.cpp:144] Setting up loss
I0122 16:38:50.373239 56358 net.cpp:151] Top shape: (1)
I0122 16:38:50.373242 56358 net.cpp:154]     with loss weight 1
I0122 16:38:50.373251 56358 net.cpp:159] Memory required for data: 166204932
I0122 16:38:50.373255 56358 net.cpp:220] loss needs backward computation.
I0122 16:38:50.373268 56358 net.cpp:220] fc2 needs backward computation.
I0122 16:38:50.373272 56358 net.cpp:220] drop3 needs backward computation.
I0122 16:38:50.373275 56358 net.cpp:220] relu5 needs backward computation.
I0122 16:38:50.373278 56358 net.cpp:220] bn5 needs backward computation.
I0122 16:38:50.373281 56358 net.cpp:220] fc1 needs backward computation.
I0122 16:38:50.373284 56358 net.cpp:220] drop2 needs backward computation.
I0122 16:38:50.373287 56358 net.cpp:220] pool2 needs backward computation.
I0122 16:38:50.373291 56358 net.cpp:220] relu4 needs backward computation.
I0122 16:38:50.373293 56358 net.cpp:220] bn4 needs backward computation.
I0122 16:38:50.373297 56358 net.cpp:220] conv4 needs backward computation.
I0122 16:38:50.373301 56358 net.cpp:220] relu3 needs backward computation.
I0122 16:38:50.373303 56358 net.cpp:220] bn3 needs backward computation.
I0122 16:38:50.373306 56358 net.cpp:220] conv3 needs backward computation.
I0122 16:38:50.373309 56358 net.cpp:220] drop1 needs backward computation.
I0122 16:38:50.373312 56358 net.cpp:220] pool1 needs backward computation.
I0122 16:38:50.373315 56358 net.cpp:220] relu2 needs backward computation.
I0122 16:38:50.373318 56358 net.cpp:220] bn2 needs backward computation.
I0122 16:38:50.373322 56358 net.cpp:220] conv2 needs backward computation.
I0122 16:38:50.373324 56358 net.cpp:220] relu1 needs backward computation.
I0122 16:38:50.373340 56358 net.cpp:220] bn1 needs backward computation.
I0122 16:38:50.373344 56358 net.cpp:220] conv1 needs backward computation.
I0122 16:38:50.373348 56358 net.cpp:222] data does not need backward computation.
I0122 16:38:50.373351 56358 net.cpp:264] This network produces output loss
I0122 16:38:50.373371 56358 net.cpp:284] Network initialization done.
I0122 16:38:50.373677 56358 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/net_finetune.prototxt
I0122 16:38:50.373709 56358 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 16:38:50.373898 56358 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 125
    mean_value: 123
    mean_value: 114
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "scale1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "scale2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "drop1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "scale3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "scale4"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu4"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "drop2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "drop2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "fc1"
  top: "scale5"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "scale5"
  top: "relu5"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "relu5"
  top: "drop3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop3"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 16:38:50.374002 56358 layer_factory.hpp:77] Creating layer data
I0122 16:38:50.374042 56358 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:38:50.374891 56358 net.cpp:94] Creating Layer data
I0122 16:38:50.374902 56358 net.cpp:409] data -> data
I0122 16:38:50.374910 56358 net.cpp:409] data -> label
I0122 16:38:50.376050 56427 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 16:38:50.376085 56427 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 16:38:50.376188 56358 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 16:38:50.376274 56358 data_layer.cpp:83] output data size: 50,3,32,32
I0122 16:38:50.379904 56358 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:38:50.379956 56358 net.cpp:144] Setting up data
I0122 16:38:50.379963 56358 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 16:38:50.379967 56358 net.cpp:151] Top shape: 50 (50)
I0122 16:38:50.379971 56358 net.cpp:159] Memory required for data: 614600
I0122 16:38:50.379974 56358 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 16:38:50.379986 56358 net.cpp:94] Creating Layer label_data_1_split
I0122 16:38:50.379990 56358 net.cpp:435] label_data_1_split <- label
I0122 16:38:50.379995 56358 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 16:38:50.380022 56358 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 16:38:50.380028 56358 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 16:38:50.380173 56358 net.cpp:144] Setting up label_data_1_split
I0122 16:38:50.380178 56358 net.cpp:151] Top shape: 50 (50)
I0122 16:38:50.380182 56358 net.cpp:151] Top shape: 50 (50)
I0122 16:38:50.380187 56358 net.cpp:151] Top shape: 50 (50)
I0122 16:38:50.380188 56358 net.cpp:159] Memory required for data: 615200
I0122 16:38:50.380192 56358 layer_factory.hpp:77] Creating layer conv1
I0122 16:38:50.380201 56358 net.cpp:94] Creating Layer conv1
I0122 16:38:50.380205 56358 net.cpp:435] conv1 <- data
I0122 16:38:50.380210 56358 net.cpp:409] conv1 -> conv1
I0122 16:38:50.380525 56358 net.cpp:144] Setting up conv1
I0122 16:38:50.380532 56358 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:38:50.380535 56358 net.cpp:159] Memory required for data: 7168800
I0122 16:38:50.380544 56358 layer_factory.hpp:77] Creating layer bn1
I0122 16:38:50.380553 56358 net.cpp:94] Creating Layer bn1
I0122 16:38:50.380556 56358 net.cpp:435] bn1 <- conv1
I0122 16:38:50.380561 56358 net.cpp:409] bn1 -> scale1
I0122 16:38:50.381202 56358 net.cpp:144] Setting up bn1
I0122 16:38:50.381209 56358 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:38:50.381212 56358 net.cpp:159] Memory required for data: 13722400
I0122 16:38:50.381223 56358 layer_factory.hpp:77] Creating layer relu1
I0122 16:38:50.381230 56358 net.cpp:94] Creating Layer relu1
I0122 16:38:50.381233 56358 net.cpp:435] relu1 <- scale1
I0122 16:38:50.381238 56358 net.cpp:409] relu1 -> relu1
I0122 16:38:50.381255 56358 net.cpp:144] Setting up relu1
I0122 16:38:50.381261 56358 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:38:50.381264 56358 net.cpp:159] Memory required for data: 20276000
I0122 16:38:50.381268 56358 layer_factory.hpp:77] Creating layer conv2
I0122 16:38:50.381275 56358 net.cpp:94] Creating Layer conv2
I0122 16:38:50.381279 56358 net.cpp:435] conv2 <- relu1
I0122 16:38:50.381283 56358 net.cpp:409] conv2 -> conv2
I0122 16:38:50.381862 56358 net.cpp:144] Setting up conv2
I0122 16:38:50.381868 56358 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:38:50.381871 56358 net.cpp:159] Memory required for data: 26829600
I0122 16:38:50.381878 56358 layer_factory.hpp:77] Creating layer bn2
I0122 16:38:50.381884 56358 net.cpp:94] Creating Layer bn2
I0122 16:38:50.381888 56358 net.cpp:435] bn2 <- conv2
I0122 16:38:50.381893 56358 net.cpp:409] bn2 -> scale2
I0122 16:38:50.382683 56358 net.cpp:144] Setting up bn2
I0122 16:38:50.382691 56358 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:38:50.382694 56358 net.cpp:159] Memory required for data: 33383200
I0122 16:38:50.382702 56358 layer_factory.hpp:77] Creating layer relu2
I0122 16:38:50.382706 56358 net.cpp:94] Creating Layer relu2
I0122 16:38:50.382710 56358 net.cpp:435] relu2 <- scale2
I0122 16:38:50.382714 56358 net.cpp:409] relu2 -> relu2
I0122 16:38:50.382737 56358 net.cpp:144] Setting up relu2
I0122 16:38:50.382742 56358 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:38:50.382745 56358 net.cpp:159] Memory required for data: 39936800
I0122 16:38:50.382748 56358 layer_factory.hpp:77] Creating layer pool1
I0122 16:38:50.382755 56358 net.cpp:94] Creating Layer pool1
I0122 16:38:50.382760 56358 net.cpp:435] pool1 <- relu2
I0122 16:38:50.382764 56358 net.cpp:409] pool1 -> pool1
I0122 16:38:50.382798 56358 net.cpp:144] Setting up pool1
I0122 16:38:50.382814 56358 net.cpp:151] Top shape: 50 32 16 16 (409600)
I0122 16:38:50.382817 56358 net.cpp:159] Memory required for data: 41575200
I0122 16:38:50.382820 56358 layer_factory.hpp:77] Creating layer drop1
I0122 16:38:50.382825 56358 net.cpp:94] Creating Layer drop1
I0122 16:38:50.382827 56358 net.cpp:435] drop1 <- pool1
I0122 16:38:50.382836 56358 net.cpp:409] drop1 -> drop1
I0122 16:38:50.382874 56358 net.cpp:144] Setting up drop1
I0122 16:38:50.382879 56358 net.cpp:151] Top shape: 50 32 16 16 (409600)
I0122 16:38:50.382881 56358 net.cpp:159] Memory required for data: 43213600
I0122 16:38:50.382884 56358 layer_factory.hpp:77] Creating layer conv3
I0122 16:38:50.382894 56358 net.cpp:94] Creating Layer conv3
I0122 16:38:50.382895 56358 net.cpp:435] conv3 <- drop1
I0122 16:38:50.382900 56358 net.cpp:409] conv3 -> conv3
I0122 16:38:50.383316 56358 net.cpp:144] Setting up conv3
I0122 16:38:50.383323 56358 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:38:50.383327 56358 net.cpp:159] Memory required for data: 46490400
I0122 16:38:50.383332 56358 layer_factory.hpp:77] Creating layer bn3
I0122 16:38:50.383344 56358 net.cpp:94] Creating Layer bn3
I0122 16:38:50.383350 56358 net.cpp:435] bn3 <- conv3
I0122 16:38:50.383357 56358 net.cpp:409] bn3 -> scale3
I0122 16:38:50.384027 56358 net.cpp:144] Setting up bn3
I0122 16:38:50.384034 56358 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:38:50.384038 56358 net.cpp:159] Memory required for data: 49767200
I0122 16:38:50.384052 56358 layer_factory.hpp:77] Creating layer relu3
I0122 16:38:50.384057 56358 net.cpp:94] Creating Layer relu3
I0122 16:38:50.384061 56358 net.cpp:435] relu3 <- scale3
I0122 16:38:50.384066 56358 net.cpp:409] relu3 -> relu3
I0122 16:38:50.384085 56358 net.cpp:144] Setting up relu3
I0122 16:38:50.384091 56358 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:38:50.384094 56358 net.cpp:159] Memory required for data: 53044000
I0122 16:38:50.384097 56358 layer_factory.hpp:77] Creating layer conv4
I0122 16:38:50.384105 56358 net.cpp:94] Creating Layer conv4
I0122 16:38:50.384110 56358 net.cpp:435] conv4 <- relu3
I0122 16:38:50.384116 56358 net.cpp:409] conv4 -> conv4
I0122 16:38:50.384609 56358 net.cpp:144] Setting up conv4
I0122 16:38:50.384616 56358 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:38:50.384619 56358 net.cpp:159] Memory required for data: 56320800
I0122 16:38:50.384624 56358 layer_factory.hpp:77] Creating layer bn4
I0122 16:38:50.384632 56358 net.cpp:94] Creating Layer bn4
I0122 16:38:50.384635 56358 net.cpp:435] bn4 <- conv4
I0122 16:38:50.384649 56358 net.cpp:409] bn4 -> scale4
I0122 16:38:50.385354 56358 net.cpp:144] Setting up bn4
I0122 16:38:50.385361 56358 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:38:50.385365 56358 net.cpp:159] Memory required for data: 59597600
I0122 16:38:50.385371 56358 layer_factory.hpp:77] Creating layer relu4
I0122 16:38:50.385380 56358 net.cpp:94] Creating Layer relu4
I0122 16:38:50.385383 56358 net.cpp:435] relu4 <- scale4
I0122 16:38:50.385387 56358 net.cpp:409] relu4 -> relu4
I0122 16:38:50.385416 56358 net.cpp:144] Setting up relu4
I0122 16:38:50.385422 56358 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:38:50.385426 56358 net.cpp:159] Memory required for data: 62874400
I0122 16:38:50.385427 56358 layer_factory.hpp:77] Creating layer pool2
I0122 16:38:50.385435 56358 net.cpp:94] Creating Layer pool2
I0122 16:38:50.385439 56358 net.cpp:435] pool2 <- relu4
I0122 16:38:50.385445 56358 net.cpp:409] pool2 -> pool2
I0122 16:38:50.385479 56358 net.cpp:144] Setting up pool2
I0122 16:38:50.385484 56358 net.cpp:151] Top shape: 50 64 8 8 (204800)
I0122 16:38:50.385486 56358 net.cpp:159] Memory required for data: 63693600
I0122 16:38:50.385489 56358 layer_factory.hpp:77] Creating layer drop2
I0122 16:38:50.385495 56358 net.cpp:94] Creating Layer drop2
I0122 16:38:50.385498 56358 net.cpp:435] drop2 <- pool2
I0122 16:38:50.385501 56358 net.cpp:409] drop2 -> drop2
I0122 16:38:50.385573 56358 net.cpp:144] Setting up drop2
I0122 16:38:50.385579 56358 net.cpp:151] Top shape: 50 64 8 8 (204800)
I0122 16:38:50.385592 56358 net.cpp:159] Memory required for data: 64512800
I0122 16:38:50.385596 56358 layer_factory.hpp:77] Creating layer fc1
I0122 16:38:50.385603 56358 net.cpp:94] Creating Layer fc1
I0122 16:38:50.385607 56358 net.cpp:435] fc1 <- drop2
I0122 16:38:50.385612 56358 net.cpp:409] fc1 -> fc1
I0122 16:38:50.399791 56358 net.cpp:144] Setting up fc1
I0122 16:38:50.399809 56358 net.cpp:151] Top shape: 50 512 (25600)
I0122 16:38:50.399811 56358 net.cpp:159] Memory required for data: 64615200
I0122 16:38:50.399818 56358 layer_factory.hpp:77] Creating layer bn5
I0122 16:38:50.399827 56358 net.cpp:94] Creating Layer bn5
I0122 16:38:50.399832 56358 net.cpp:435] bn5 <- fc1
I0122 16:38:50.399838 56358 net.cpp:409] bn5 -> scale5
I0122 16:38:50.400457 56358 net.cpp:144] Setting up bn5
I0122 16:38:50.400463 56358 net.cpp:151] Top shape: 50 512 (25600)
I0122 16:38:50.400466 56358 net.cpp:159] Memory required for data: 64717600
I0122 16:38:50.400480 56358 layer_factory.hpp:77] Creating layer relu5
I0122 16:38:50.400496 56358 net.cpp:94] Creating Layer relu5
I0122 16:38:50.400499 56358 net.cpp:435] relu5 <- scale5
I0122 16:38:50.400506 56358 net.cpp:409] relu5 -> relu5
I0122 16:38:50.400524 56358 net.cpp:144] Setting up relu5
I0122 16:38:50.400530 56358 net.cpp:151] Top shape: 50 512 (25600)
I0122 16:38:50.400532 56358 net.cpp:159] Memory required for data: 64820000
I0122 16:38:50.400535 56358 layer_factory.hpp:77] Creating layer drop3
I0122 16:38:50.400540 56358 net.cpp:94] Creating Layer drop3
I0122 16:38:50.400543 56358 net.cpp:435] drop3 <- relu5
I0122 16:38:50.400547 56358 net.cpp:409] drop3 -> drop3
I0122 16:38:50.400576 56358 net.cpp:144] Setting up drop3
I0122 16:38:50.400581 56358 net.cpp:151] Top shape: 50 512 (25600)
I0122 16:38:50.400584 56358 net.cpp:159] Memory required for data: 64922400
I0122 16:38:50.400586 56358 layer_factory.hpp:77] Creating layer fc2
I0122 16:38:50.400594 56358 net.cpp:94] Creating Layer fc2
I0122 16:38:50.400599 56358 net.cpp:435] fc2 <- drop3
I0122 16:38:50.400604 56358 net.cpp:409] fc2 -> fc2
I0122 16:38:50.400743 56358 net.cpp:144] Setting up fc2
I0122 16:38:50.400749 56358 net.cpp:151] Top shape: 50 10 (500)
I0122 16:38:50.400753 56358 net.cpp:159] Memory required for data: 64924400
I0122 16:38:50.400756 56358 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0122 16:38:50.400763 56358 net.cpp:94] Creating Layer fc2_fc2_0_split
I0122 16:38:50.400766 56358 net.cpp:435] fc2_fc2_0_split <- fc2
I0122 16:38:50.400770 56358 net.cpp:409] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0122 16:38:50.400776 56358 net.cpp:409] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0122 16:38:50.400784 56358 net.cpp:409] fc2_fc2_0_split -> fc2_fc2_0_split_2
I0122 16:38:50.400825 56358 net.cpp:144] Setting up fc2_fc2_0_split
I0122 16:38:50.400830 56358 net.cpp:151] Top shape: 50 10 (500)
I0122 16:38:50.400833 56358 net.cpp:151] Top shape: 50 10 (500)
I0122 16:38:50.400836 56358 net.cpp:151] Top shape: 50 10 (500)
I0122 16:38:50.400840 56358 net.cpp:159] Memory required for data: 64930400
I0122 16:38:50.400842 56358 layer_factory.hpp:77] Creating layer loss
I0122 16:38:50.400846 56358 net.cpp:94] Creating Layer loss
I0122 16:38:50.400849 56358 net.cpp:435] loss <- fc2_fc2_0_split_0
I0122 16:38:50.400853 56358 net.cpp:435] loss <- label_data_1_split_0
I0122 16:38:50.400858 56358 net.cpp:409] loss -> loss
I0122 16:38:50.400866 56358 layer_factory.hpp:77] Creating layer loss
I0122 16:38:50.400938 56358 net.cpp:144] Setting up loss
I0122 16:38:50.400944 56358 net.cpp:151] Top shape: (1)
I0122 16:38:50.400946 56358 net.cpp:154]     with loss weight 1
I0122 16:38:50.400955 56358 net.cpp:159] Memory required for data: 64930404
I0122 16:38:50.400959 56358 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 16:38:50.400964 56358 net.cpp:94] Creating Layer accuracy-top1
I0122 16:38:50.400967 56358 net.cpp:435] accuracy-top1 <- fc2_fc2_0_split_1
I0122 16:38:50.400971 56358 net.cpp:435] accuracy-top1 <- label_data_1_split_1
I0122 16:38:50.400976 56358 net.cpp:409] accuracy-top1 -> top-1
I0122 16:38:50.400995 56358 net.cpp:144] Setting up accuracy-top1
I0122 16:38:50.401000 56358 net.cpp:151] Top shape: (1)
I0122 16:38:50.401001 56358 net.cpp:159] Memory required for data: 64930408
I0122 16:38:50.401003 56358 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 16:38:50.401008 56358 net.cpp:94] Creating Layer accuracy-top5
I0122 16:38:50.401011 56358 net.cpp:435] accuracy-top5 <- fc2_fc2_0_split_2
I0122 16:38:50.401015 56358 net.cpp:435] accuracy-top5 <- label_data_1_split_2
I0122 16:38:50.401019 56358 net.cpp:409] accuracy-top5 -> top-5
I0122 16:38:50.401026 56358 net.cpp:144] Setting up accuracy-top5
I0122 16:38:50.401031 56358 net.cpp:151] Top shape: (1)
I0122 16:38:50.401032 56358 net.cpp:159] Memory required for data: 64930412
I0122 16:38:50.401036 56358 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 16:38:50.401039 56358 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 16:38:50.401043 56358 net.cpp:220] loss needs backward computation.
I0122 16:38:50.401046 56358 net.cpp:220] fc2_fc2_0_split needs backward computation.
I0122 16:38:50.401049 56358 net.cpp:220] fc2 needs backward computation.
I0122 16:38:50.401053 56358 net.cpp:220] drop3 needs backward computation.
I0122 16:38:50.401055 56358 net.cpp:220] relu5 needs backward computation.
I0122 16:38:50.401062 56358 net.cpp:220] bn5 needs backward computation.
I0122 16:38:50.401065 56358 net.cpp:220] fc1 needs backward computation.
I0122 16:38:50.401069 56358 net.cpp:220] drop2 needs backward computation.
I0122 16:38:50.401072 56358 net.cpp:220] pool2 needs backward computation.
I0122 16:38:50.401075 56358 net.cpp:220] relu4 needs backward computation.
I0122 16:38:50.401077 56358 net.cpp:220] bn4 needs backward computation.
I0122 16:38:50.401082 56358 net.cpp:220] conv4 needs backward computation.
I0122 16:38:50.401084 56358 net.cpp:220] relu3 needs backward computation.
I0122 16:38:50.401087 56358 net.cpp:220] bn3 needs backward computation.
I0122 16:38:50.401090 56358 net.cpp:220] conv3 needs backward computation.
I0122 16:38:50.401093 56358 net.cpp:220] drop1 needs backward computation.
I0122 16:38:50.401096 56358 net.cpp:220] pool1 needs backward computation.
I0122 16:38:50.401099 56358 net.cpp:220] relu2 needs backward computation.
I0122 16:38:50.401103 56358 net.cpp:220] bn2 needs backward computation.
I0122 16:38:50.401105 56358 net.cpp:220] conv2 needs backward computation.
I0122 16:38:50.401108 56358 net.cpp:220] relu1 needs backward computation.
I0122 16:38:50.401111 56358 net.cpp:220] bn1 needs backward computation.
I0122 16:38:50.401114 56358 net.cpp:220] conv1 needs backward computation.
I0122 16:38:50.401118 56358 net.cpp:222] label_data_1_split does not need backward computation.
I0122 16:38:50.401121 56358 net.cpp:222] data does not need backward computation.
I0122 16:38:50.401124 56358 net.cpp:264] This network produces output loss
I0122 16:38:50.401127 56358 net.cpp:264] This network produces output top-1
I0122 16:38:50.401130 56358 net.cpp:264] This network produces output top-5
I0122 16:38:50.401154 56358 net.cpp:284] Network initialization done.
I0122 16:38:50.401257 56358 solver.cpp:63] Solver scaffolding done.
I0122 16:38:50.402413 56358 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/sparse.caffemodel
I0122 16:38:50.461673 56358 caffe_interface.cpp:527] Starting Optimization
I0122 16:38:50.461693 56358 solver.cpp:335] Solving 
I0122 16:38:50.461694 56358 solver.cpp:336] Learning Rate Policy: poly
I0122 16:38:50.462932 56358 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 16:38:50.689474 56358 solver.cpp:517]     Test net output #0: loss = 1.29264 (* 1 = 1.29264 loss)
I0122 16:38:50.689498 56358 solver.cpp:517]     Test net output #1: top-1 = 0.663556
I0122 16:38:50.689503 56358 solver.cpp:517]     Test net output #2: top-5 = 0.972
I0122 16:38:50.706653 56358 solver.cpp:266] Iteration 0 (0 iter/s, 0.244919s/100 iter), loss = 0.187225
I0122 16:38:50.706683 56358 solver.cpp:285]     Train net output #0: loss = 0.187225 (* 1 = 0.187225 loss)
I0122 16:38:50.706722 56358 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0122 16:38:51.572247 56358 solver.cpp:266] Iteration 100 (115.537 iter/s, 0.865526s/100 iter), loss = 0.275855
I0122 16:38:51.572273 56358 solver.cpp:285]     Train net output #0: loss = 0.275855 (* 1 = 0.275855 loss)
I0122 16:38:51.572280 56358 sgd_solver.cpp:106] Iteration 100, lr = 0.00995
I0122 16:38:52.436559 56358 solver.cpp:266] Iteration 200 (115.708 iter/s, 0.864248s/100 iter), loss = 0.236721
I0122 16:38:52.436599 56358 solver.cpp:285]     Train net output #0: loss = 0.236721 (* 1 = 0.236721 loss)
I0122 16:38:52.436604 56358 sgd_solver.cpp:106] Iteration 200, lr = 0.0099
I0122 16:38:53.301424 56358 solver.cpp:266] Iteration 300 (115.635 iter/s, 0.864787s/100 iter), loss = 0.245984
I0122 16:38:53.301463 56358 solver.cpp:285]     Train net output #0: loss = 0.245984 (* 1 = 0.245984 loss)
I0122 16:38:53.301470 56358 sgd_solver.cpp:106] Iteration 300, lr = 0.00985
I0122 16:38:54.163635 56358 solver.cpp:266] Iteration 400 (115.991 iter/s, 0.862133s/100 iter), loss = 0.183398
I0122 16:38:54.163661 56358 solver.cpp:285]     Train net output #0: loss = 0.183398 (* 1 = 0.183398 loss)
I0122 16:38:54.163667 56358 sgd_solver.cpp:106] Iteration 400, lr = 0.0098
I0122 16:38:55.025578 56358 solver.cpp:266] Iteration 500 (116.026 iter/s, 0.861878s/100 iter), loss = 0.308119
I0122 16:38:55.025605 56358 solver.cpp:285]     Train net output #0: loss = 0.308119 (* 1 = 0.308119 loss)
I0122 16:38:55.025611 56358 sgd_solver.cpp:106] Iteration 500, lr = 0.00975
I0122 16:38:55.887598 56358 solver.cpp:266] Iteration 600 (116.016 iter/s, 0.861953s/100 iter), loss = 0.292541
I0122 16:38:55.887624 56358 solver.cpp:285]     Train net output #0: loss = 0.292541 (* 1 = 0.292541 loss)
I0122 16:38:55.887630 56358 sgd_solver.cpp:106] Iteration 600, lr = 0.0097
I0122 16:38:56.755240 56358 solver.cpp:266] Iteration 700 (115.264 iter/s, 0.867577s/100 iter), loss = 0.472931
I0122 16:38:56.755267 56358 solver.cpp:285]     Train net output #0: loss = 0.472931 (* 1 = 0.472931 loss)
I0122 16:38:56.755273 56358 sgd_solver.cpp:106] Iteration 700, lr = 0.00965
I0122 16:38:57.616762 56358 solver.cpp:266] Iteration 800 (116.083 iter/s, 0.861456s/100 iter), loss = 0.394181
I0122 16:38:57.616791 56358 solver.cpp:285]     Train net output #0: loss = 0.394181 (* 1 = 0.394181 loss)
I0122 16:38:57.616796 56358 sgd_solver.cpp:106] Iteration 800, lr = 0.0096
I0122 16:38:58.480615 56358 solver.cpp:266] Iteration 900 (115.769 iter/s, 0.863787s/100 iter), loss = 0.199125
I0122 16:38:58.480643 56358 solver.cpp:285]     Train net output #0: loss = 0.199125 (* 1 = 0.199125 loss)
I0122 16:38:58.480648 56358 sgd_solver.cpp:106] Iteration 900, lr = 0.00955
I0122 16:38:59.341756 56358 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 16:38:59.563309 56358 solver.cpp:517]     Test net output #0: loss = 0.868949 (* 1 = 0.868949 loss)
I0122 16:38:59.563324 56358 solver.cpp:517]     Test net output #1: top-1 = 0.774889
I0122 16:38:59.563329 56358 solver.cpp:517]     Test net output #2: top-5 = 0.981112
I0122 16:38:59.571394 56358 solver.cpp:266] Iteration 1000 (91.6834 iter/s, 1.09071s/100 iter), loss = 0.244894
I0122 16:38:59.571411 56358 solver.cpp:285]     Train net output #0: loss = 0.244894 (* 1 = 0.244894 loss)
I0122 16:38:59.571418 56358 sgd_solver.cpp:106] Iteration 1000, lr = 0.0095
I0122 16:39:00.437387 56358 solver.cpp:266] Iteration 1100 (115.482 iter/s, 0.865937s/100 iter), loss = 0.25375
I0122 16:39:00.437414 56358 solver.cpp:285]     Train net output #0: loss = 0.25375 (* 1 = 0.25375 loss)
I0122 16:39:00.437419 56358 sgd_solver.cpp:106] Iteration 1100, lr = 0.00945
I0122 16:39:01.301543 56358 solver.cpp:266] Iteration 1200 (115.729 iter/s, 0.864091s/100 iter), loss = 0.371845
I0122 16:39:01.301570 56358 solver.cpp:285]     Train net output #0: loss = 0.371845 (* 1 = 0.371845 loss)
I0122 16:39:01.301575 56358 sgd_solver.cpp:106] Iteration 1200, lr = 0.0094
I0122 16:39:02.165213 56358 solver.cpp:266] Iteration 1300 (115.794 iter/s, 0.863604s/100 iter), loss = 0.334344
I0122 16:39:02.165241 56358 solver.cpp:285]     Train net output #0: loss = 0.334344 (* 1 = 0.334344 loss)
I0122 16:39:02.165264 56358 sgd_solver.cpp:106] Iteration 1300, lr = 0.00935
I0122 16:39:03.027678 56358 solver.cpp:266] Iteration 1400 (115.956 iter/s, 0.862397s/100 iter), loss = 0.208302
I0122 16:39:03.027705 56358 solver.cpp:285]     Train net output #0: loss = 0.208302 (* 1 = 0.208302 loss)
I0122 16:39:03.027711 56358 sgd_solver.cpp:106] Iteration 1400, lr = 0.0093
I0122 16:39:03.890936 56358 solver.cpp:266] Iteration 1500 (115.849 iter/s, 0.863192s/100 iter), loss = 0.161811
I0122 16:39:03.890964 56358 solver.cpp:285]     Train net output #0: loss = 0.161811 (* 1 = 0.161811 loss)
I0122 16:39:03.890969 56358 sgd_solver.cpp:106] Iteration 1500, lr = 0.00925
I0122 16:39:04.753965 56358 solver.cpp:266] Iteration 1600 (115.88 iter/s, 0.862963s/100 iter), loss = 0.337869
I0122 16:39:04.753993 56358 solver.cpp:285]     Train net output #0: loss = 0.337869 (* 1 = 0.337869 loss)
I0122 16:39:04.753998 56358 sgd_solver.cpp:106] Iteration 1600, lr = 0.0092
I0122 16:39:05.617162 56358 solver.cpp:266] Iteration 1700 (115.857 iter/s, 0.863132s/100 iter), loss = 0.263484
I0122 16:39:05.617189 56358 solver.cpp:285]     Train net output #0: loss = 0.263484 (* 1 = 0.263484 loss)
I0122 16:39:05.617195 56358 sgd_solver.cpp:106] Iteration 1700, lr = 0.00915
I0122 16:39:06.479921 56358 solver.cpp:266] Iteration 1800 (115.916 iter/s, 0.862694s/100 iter), loss = 0.231168
I0122 16:39:06.479948 56358 solver.cpp:285]     Train net output #0: loss = 0.231168 (* 1 = 0.231168 loss)
I0122 16:39:06.479954 56358 sgd_solver.cpp:106] Iteration 1800, lr = 0.0091
I0122 16:39:07.343329 56358 solver.cpp:266] Iteration 1900 (115.829 iter/s, 0.863343s/100 iter), loss = 0.19005
I0122 16:39:07.343355 56358 solver.cpp:285]     Train net output #0: loss = 0.19005 (* 1 = 0.19005 loss)
I0122 16:39:07.343360 56358 sgd_solver.cpp:106] Iteration 1900, lr = 0.00905
I0122 16:39:08.197926 56358 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 16:39:08.417404 56358 solver.cpp:517]     Test net output #0: loss = 0.770257 (* 1 = 0.770257 loss)
I0122 16:39:08.417419 56358 solver.cpp:517]     Test net output #1: top-1 = 0.797333
I0122 16:39:08.417423 56358 solver.cpp:517]     Test net output #2: top-5 = 0.983334
I0122 16:39:08.425510 56358 solver.cpp:266] Iteration 2000 (92.4119 iter/s, 1.08211s/100 iter), loss = 0.227372
I0122 16:39:08.425527 56358 solver.cpp:285]     Train net output #0: loss = 0.227372 (* 1 = 0.227372 loss)
I0122 16:39:08.425532 56358 sgd_solver.cpp:106] Iteration 2000, lr = 0.009
I0122 16:39:09.291072 56358 solver.cpp:266] Iteration 2100 (115.539 iter/s, 0.865506s/100 iter), loss = 0.251298
I0122 16:39:09.291097 56358 solver.cpp:285]     Train net output #0: loss = 0.251298 (* 1 = 0.251298 loss)
I0122 16:39:09.291103 56358 sgd_solver.cpp:106] Iteration 2100, lr = 0.00895
I0122 16:39:10.152398 56358 solver.cpp:266] Iteration 2200 (116.108 iter/s, 0.861264s/100 iter), loss = 0.239137
I0122 16:39:10.152426 56358 solver.cpp:285]     Train net output #0: loss = 0.239137 (* 1 = 0.239137 loss)
I0122 16:39:10.152431 56358 sgd_solver.cpp:106] Iteration 2200, lr = 0.0089
I0122 16:39:11.015380 56358 solver.cpp:266] Iteration 2300 (115.886 iter/s, 0.862918s/100 iter), loss = 0.346102
I0122 16:39:11.015408 56358 solver.cpp:285]     Train net output #0: loss = 0.346102 (* 1 = 0.346102 loss)
I0122 16:39:11.015413 56358 sgd_solver.cpp:106] Iteration 2300, lr = 0.00885
I0122 16:39:11.878247 56358 solver.cpp:266] Iteration 2400 (115.901 iter/s, 0.862802s/100 iter), loss = 0.21026
I0122 16:39:11.878285 56358 solver.cpp:285]     Train net output #0: loss = 0.21026 (* 1 = 0.21026 loss)
I0122 16:39:11.878291 56358 sgd_solver.cpp:106] Iteration 2400, lr = 0.0088
I0122 16:39:12.741438 56358 solver.cpp:266] Iteration 2500 (115.86 iter/s, 0.863114s/100 iter), loss = 0.20698
I0122 16:39:12.741466 56358 solver.cpp:285]     Train net output #0: loss = 0.20698 (* 1 = 0.20698 loss)
I0122 16:39:12.741472 56358 sgd_solver.cpp:106] Iteration 2500, lr = 0.00875
I0122 16:39:13.605206 56358 solver.cpp:266] Iteration 2600 (115.781 iter/s, 0.863701s/100 iter), loss = 0.221458
I0122 16:39:13.605250 56358 solver.cpp:285]     Train net output #0: loss = 0.221458 (* 1 = 0.221458 loss)
I0122 16:39:13.605257 56358 sgd_solver.cpp:106] Iteration 2600, lr = 0.0087
I0122 16:39:14.468376 56358 solver.cpp:266] Iteration 2700 (115.863 iter/s, 0.863089s/100 iter), loss = 0.275625
I0122 16:39:14.468405 56358 solver.cpp:285]     Train net output #0: loss = 0.275625 (* 1 = 0.275625 loss)
I0122 16:39:14.468410 56358 sgd_solver.cpp:106] Iteration 2700, lr = 0.00865
I0122 16:39:15.332212 56358 solver.cpp:266] Iteration 2800 (115.771 iter/s, 0.863771s/100 iter), loss = 0.244255
I0122 16:39:15.332242 56358 solver.cpp:285]     Train net output #0: loss = 0.244255 (* 1 = 0.244255 loss)
I0122 16:39:15.332247 56358 sgd_solver.cpp:106] Iteration 2800, lr = 0.0086
I0122 16:39:16.194941 56358 solver.cpp:266] Iteration 2900 (115.92 iter/s, 0.862661s/100 iter), loss = 0.226373
I0122 16:39:16.194968 56358 solver.cpp:285]     Train net output #0: loss = 0.226373 (* 1 = 0.226373 loss)
I0122 16:39:16.194974 56358 sgd_solver.cpp:106] Iteration 2900, lr = 0.00855
I0122 16:39:17.049672 56358 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 16:39:17.269393 56358 solver.cpp:517]     Test net output #0: loss = 0.668943 (* 1 = 0.668943 loss)
I0122 16:39:17.269407 56358 solver.cpp:517]     Test net output #1: top-1 = 0.799222
I0122 16:39:17.269412 56358 solver.cpp:517]     Test net output #2: top-5 = 0.986334
I0122 16:39:17.277467 56358 solver.cpp:266] Iteration 3000 (92.3826 iter/s, 1.08246s/100 iter), loss = 0.192249
I0122 16:39:17.277493 56358 solver.cpp:285]     Train net output #0: loss = 0.192249 (* 1 = 0.192249 loss)
I0122 16:39:17.277500 56358 sgd_solver.cpp:106] Iteration 3000, lr = 0.0085
I0122 16:39:18.144027 56358 solver.cpp:266] Iteration 3100 (115.406 iter/s, 0.866505s/100 iter), loss = 0.19544
I0122 16:39:18.144053 56358 solver.cpp:285]     Train net output #0: loss = 0.19544 (* 1 = 0.19544 loss)
I0122 16:39:18.144058 56358 sgd_solver.cpp:106] Iteration 3100, lr = 0.00845
I0122 16:39:19.006961 56358 solver.cpp:266] Iteration 3200 (115.892 iter/s, 0.862871s/100 iter), loss = 0.284749
I0122 16:39:19.006989 56358 solver.cpp:285]     Train net output #0: loss = 0.284749 (* 1 = 0.284749 loss)
I0122 16:39:19.006994 56358 sgd_solver.cpp:106] Iteration 3200, lr = 0.0084
I0122 16:39:19.870378 56358 solver.cpp:266] Iteration 3300 (115.828 iter/s, 0.863351s/100 iter), loss = 0.132221
I0122 16:39:19.870522 56358 solver.cpp:285]     Train net output #0: loss = 0.132221 (* 1 = 0.132221 loss)
I0122 16:39:19.870529 56358 sgd_solver.cpp:106] Iteration 3300, lr = 0.00835
I0122 16:39:20.736526 56358 solver.cpp:266] Iteration 3400 (115.477 iter/s, 0.86597s/100 iter), loss = 0.253273
I0122 16:39:20.736553 56358 solver.cpp:285]     Train net output #0: loss = 0.253273 (* 1 = 0.253273 loss)
I0122 16:39:20.736559 56358 sgd_solver.cpp:106] Iteration 3400, lr = 0.0083
I0122 16:39:21.608160 56358 solver.cpp:266] Iteration 3500 (114.736 iter/s, 0.871567s/100 iter), loss = 0.266053
I0122 16:39:21.608186 56358 solver.cpp:285]     Train net output #0: loss = 0.266053 (* 1 = 0.266053 loss)
I0122 16:39:21.608191 56358 sgd_solver.cpp:106] Iteration 3500, lr = 0.00825
I0122 16:39:22.477016 56358 solver.cpp:266] Iteration 3600 (115.102 iter/s, 0.868792s/100 iter), loss = 0.287669
I0122 16:39:22.477042 56358 solver.cpp:285]     Train net output #0: loss = 0.287669 (* 1 = 0.287669 loss)
I0122 16:39:22.477047 56358 sgd_solver.cpp:106] Iteration 3600, lr = 0.0082
I0122 16:39:23.342468 56358 solver.cpp:266] Iteration 3700 (115.555 iter/s, 0.865387s/100 iter), loss = 0.193523
I0122 16:39:23.342495 56358 solver.cpp:285]     Train net output #0: loss = 0.193523 (* 1 = 0.193523 loss)
I0122 16:39:23.342502 56358 sgd_solver.cpp:106] Iteration 3700, lr = 0.00815
I0122 16:39:24.208081 56358 solver.cpp:266] Iteration 3800 (115.534 iter/s, 0.865546s/100 iter), loss = 0.216373
I0122 16:39:24.208111 56358 solver.cpp:285]     Train net output #0: loss = 0.216373 (* 1 = 0.216373 loss)
I0122 16:39:24.208115 56358 sgd_solver.cpp:106] Iteration 3800, lr = 0.0081
I0122 16:39:25.070724 56358 solver.cpp:266] Iteration 3900 (115.932 iter/s, 0.862578s/100 iter), loss = 0.159415
I0122 16:39:25.070751 56358 solver.cpp:285]     Train net output #0: loss = 0.159415 (* 1 = 0.159415 loss)
I0122 16:39:25.070756 56358 sgd_solver.cpp:106] Iteration 3900, lr = 0.00805
I0122 16:39:25.923995 56358 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 16:39:26.144367 56358 solver.cpp:517]     Test net output #0: loss = 0.590049 (* 1 = 0.590049 loss)
I0122 16:39:26.144381 56358 solver.cpp:517]     Test net output #1: top-1 = 0.822556
I0122 16:39:26.144385 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990333
I0122 16:39:26.152503 56358 solver.cpp:266] Iteration 4000 (92.4463 iter/s, 1.08171s/100 iter), loss = 0.219252
I0122 16:39:26.152520 56358 solver.cpp:285]     Train net output #0: loss = 0.219252 (* 1 = 0.219252 loss)
I0122 16:39:26.152525 56358 sgd_solver.cpp:106] Iteration 4000, lr = 0.008
I0122 16:39:27.015589 56358 solver.cpp:266] Iteration 4100 (115.871 iter/s, 0.86303s/100 iter), loss = 0.235417
I0122 16:39:27.015614 56358 solver.cpp:285]     Train net output #0: loss = 0.235417 (* 1 = 0.235417 loss)
I0122 16:39:27.015620 56358 sgd_solver.cpp:106] Iteration 4100, lr = 0.00795
I0122 16:39:27.879992 56358 solver.cpp:266] Iteration 4200 (115.695 iter/s, 0.864339s/100 iter), loss = 0.297365
I0122 16:39:27.880017 56358 solver.cpp:285]     Train net output #0: loss = 0.297365 (* 1 = 0.297365 loss)
I0122 16:39:27.880023 56358 sgd_solver.cpp:106] Iteration 4200, lr = 0.0079
I0122 16:39:28.743436 56358 solver.cpp:266] Iteration 4300 (115.824 iter/s, 0.863381s/100 iter), loss = 0.246826
I0122 16:39:28.743463 56358 solver.cpp:285]     Train net output #0: loss = 0.246826 (* 1 = 0.246826 loss)
I0122 16:39:28.743468 56358 sgd_solver.cpp:106] Iteration 4300, lr = 0.00785
I0122 16:39:29.615756 56358 solver.cpp:266] Iteration 4400 (114.646 iter/s, 0.872253s/100 iter), loss = 0.247167
I0122 16:39:29.615783 56358 solver.cpp:285]     Train net output #0: loss = 0.247168 (* 1 = 0.247168 loss)
I0122 16:39:29.615789 56358 sgd_solver.cpp:106] Iteration 4400, lr = 0.0078
I0122 16:39:30.485623 56358 solver.cpp:266] Iteration 4500 (114.969 iter/s, 0.869802s/100 iter), loss = 0.226204
I0122 16:39:30.485651 56358 solver.cpp:285]     Train net output #0: loss = 0.226204 (* 1 = 0.226204 loss)
I0122 16:39:30.485656 56358 sgd_solver.cpp:106] Iteration 4500, lr = 0.00775
I0122 16:39:31.350811 56358 solver.cpp:266] Iteration 4600 (115.591 iter/s, 0.865122s/100 iter), loss = 0.169253
I0122 16:39:31.350870 56358 solver.cpp:285]     Train net output #0: loss = 0.169253 (* 1 = 0.169253 loss)
I0122 16:39:31.350878 56358 sgd_solver.cpp:106] Iteration 4600, lr = 0.0077
I0122 16:39:32.217686 56358 solver.cpp:266] Iteration 4700 (115.37 iter/s, 0.866777s/100 iter), loss = 0.208356
I0122 16:39:32.217713 56358 solver.cpp:285]     Train net output #0: loss = 0.208356 (* 1 = 0.208356 loss)
I0122 16:39:32.217718 56358 sgd_solver.cpp:106] Iteration 4700, lr = 0.00765
I0122 16:39:33.084478 56358 solver.cpp:266] Iteration 4800 (115.377 iter/s, 0.866727s/100 iter), loss = 0.21154
I0122 16:39:33.084506 56358 solver.cpp:285]     Train net output #0: loss = 0.21154 (* 1 = 0.21154 loss)
I0122 16:39:33.084511 56358 sgd_solver.cpp:106] Iteration 4800, lr = 0.0076
I0122 16:39:33.950562 56358 solver.cpp:266] Iteration 4900 (115.471 iter/s, 0.866018s/100 iter), loss = 0.355379
I0122 16:39:33.950590 56358 solver.cpp:285]     Train net output #0: loss = 0.355379 (* 1 = 0.355379 loss)
I0122 16:39:33.950597 56358 sgd_solver.cpp:106] Iteration 4900, lr = 0.00755
I0122 16:39:34.807580 56358 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 16:39:35.036131 56358 solver.cpp:517]     Test net output #0: loss = 0.512399 (* 1 = 0.512399 loss)
I0122 16:39:35.036149 56358 solver.cpp:517]     Test net output #1: top-1 = 0.836556
I0122 16:39:35.036154 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990222
I0122 16:39:35.044328 56358 solver.cpp:266] Iteration 5000 (91.4332 iter/s, 1.09369s/100 iter), loss = 0.248553
I0122 16:39:35.044347 56358 solver.cpp:285]     Train net output #0: loss = 0.248553 (* 1 = 0.248553 loss)
I0122 16:39:35.044353 56358 sgd_solver.cpp:106] Iteration 5000, lr = 0.0075
I0122 16:39:35.909921 56358 solver.cpp:266] Iteration 5100 (115.536 iter/s, 0.865535s/100 iter), loss = 0.253116
I0122 16:39:35.909947 56358 solver.cpp:285]     Train net output #0: loss = 0.253116 (* 1 = 0.253116 loss)
I0122 16:39:35.909953 56358 sgd_solver.cpp:106] Iteration 5100, lr = 0.00745
I0122 16:39:36.777719 56358 solver.cpp:266] Iteration 5200 (115.243 iter/s, 0.867734s/100 iter), loss = 0.233294
I0122 16:39:36.777746 56358 solver.cpp:285]     Train net output #0: loss = 0.233294 (* 1 = 0.233294 loss)
I0122 16:39:36.777751 56358 sgd_solver.cpp:106] Iteration 5200, lr = 0.0074
I0122 16:39:37.650826 56358 solver.cpp:266] Iteration 5300 (114.542 iter/s, 0.873041s/100 iter), loss = 0.26883
I0122 16:39:37.650852 56358 solver.cpp:285]     Train net output #0: loss = 0.26883 (* 1 = 0.26883 loss)
I0122 16:39:37.650874 56358 sgd_solver.cpp:106] Iteration 5300, lr = 0.00735
I0122 16:39:38.521621 56358 solver.cpp:266] Iteration 5400 (114.846 iter/s, 0.870731s/100 iter), loss = 0.192107
I0122 16:39:38.521648 56358 solver.cpp:285]     Train net output #0: loss = 0.192107 (* 1 = 0.192107 loss)
I0122 16:39:38.521654 56358 sgd_solver.cpp:106] Iteration 5400, lr = 0.0073
I0122 16:39:39.384289 56358 solver.cpp:266] Iteration 5500 (115.928 iter/s, 0.862601s/100 iter), loss = 0.173617
I0122 16:39:39.384315 56358 solver.cpp:285]     Train net output #0: loss = 0.173617 (* 1 = 0.173617 loss)
I0122 16:39:39.384320 56358 sgd_solver.cpp:106] Iteration 5500, lr = 0.00725
I0122 16:39:40.251325 56358 solver.cpp:266] Iteration 5600 (115.344 iter/s, 0.866972s/100 iter), loss = 0.214834
I0122 16:39:40.251351 56358 solver.cpp:285]     Train net output #0: loss = 0.214834 (* 1 = 0.214834 loss)
I0122 16:39:40.251356 56358 sgd_solver.cpp:106] Iteration 5600, lr = 0.0072
I0122 16:39:41.114099 56358 solver.cpp:266] Iteration 5700 (115.914 iter/s, 0.862708s/100 iter), loss = 0.233871
I0122 16:39:41.114126 56358 solver.cpp:285]     Train net output #0: loss = 0.233871 (* 1 = 0.233871 loss)
I0122 16:39:41.114131 56358 sgd_solver.cpp:106] Iteration 5700, lr = 0.00715
I0122 16:39:41.990056 56358 solver.cpp:266] Iteration 5800 (114.17 iter/s, 0.875891s/100 iter), loss = 0.227502
I0122 16:39:41.990084 56358 solver.cpp:285]     Train net output #0: loss = 0.227502 (* 1 = 0.227502 loss)
I0122 16:39:41.990108 56358 sgd_solver.cpp:106] Iteration 5800, lr = 0.0071
I0122 16:39:42.859736 56358 solver.cpp:266] Iteration 5900 (114.994 iter/s, 0.869613s/100 iter), loss = 0.239008
I0122 16:39:42.859763 56358 solver.cpp:285]     Train net output #0: loss = 0.239008 (* 1 = 0.239008 loss)
I0122 16:39:42.859768 56358 sgd_solver.cpp:106] Iteration 5900, lr = 0.00705
I0122 16:39:43.717051 56358 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 16:39:43.936792 56358 solver.cpp:517]     Test net output #0: loss = 0.557302 (* 1 = 0.557302 loss)
I0122 16:39:43.936807 56358 solver.cpp:517]     Test net output #1: top-1 = 0.837111
I0122 16:39:43.936811 56358 solver.cpp:517]     Test net output #2: top-5 = 0.99
I0122 16:39:43.944916 56358 solver.cpp:266] Iteration 6000 (92.1565 iter/s, 1.08511s/100 iter), loss = 0.248403
I0122 16:39:43.944933 56358 solver.cpp:285]     Train net output #0: loss = 0.248403 (* 1 = 0.248403 loss)
I0122 16:39:43.944938 56358 sgd_solver.cpp:106] Iteration 6000, lr = 0.007
I0122 16:39:44.808531 56358 solver.cpp:266] Iteration 6100 (115.8 iter/s, 0.86356s/100 iter), loss = 0.222723
I0122 16:39:44.808557 56358 solver.cpp:285]     Train net output #0: loss = 0.222723 (* 1 = 0.222723 loss)
I0122 16:39:44.808562 56358 sgd_solver.cpp:106] Iteration 6100, lr = 0.00695
I0122 16:39:45.673879 56358 solver.cpp:266] Iteration 6200 (115.569 iter/s, 0.865283s/100 iter), loss = 0.227622
I0122 16:39:45.673907 56358 solver.cpp:285]     Train net output #0: loss = 0.227622 (* 1 = 0.227622 loss)
I0122 16:39:45.673915 56358 sgd_solver.cpp:106] Iteration 6200, lr = 0.0069
I0122 16:39:46.541980 56358 solver.cpp:266] Iteration 6300 (115.202 iter/s, 0.868037s/100 iter), loss = 0.146399
I0122 16:39:46.542007 56358 solver.cpp:285]     Train net output #0: loss = 0.146399 (* 1 = 0.146399 loss)
I0122 16:39:46.542012 56358 sgd_solver.cpp:106] Iteration 6300, lr = 0.00685
I0122 16:39:47.414607 56358 solver.cpp:266] Iteration 6400 (114.605 iter/s, 0.872559s/100 iter), loss = 0.130591
I0122 16:39:47.414645 56358 solver.cpp:285]     Train net output #0: loss = 0.130591 (* 1 = 0.130591 loss)
I0122 16:39:47.414651 56358 sgd_solver.cpp:106] Iteration 6400, lr = 0.0068
I0122 16:39:48.285969 56358 solver.cpp:266] Iteration 6500 (114.773 iter/s, 0.871284s/100 iter), loss = 0.231326
I0122 16:39:48.285996 56358 solver.cpp:285]     Train net output #0: loss = 0.231326 (* 1 = 0.231326 loss)
I0122 16:39:48.286002 56358 sgd_solver.cpp:106] Iteration 6500, lr = 0.00675
I0122 16:39:49.149631 56358 solver.cpp:266] Iteration 6600 (115.795 iter/s, 0.863598s/100 iter), loss = 0.245378
I0122 16:39:49.149657 56358 solver.cpp:285]     Train net output #0: loss = 0.245378 (* 1 = 0.245378 loss)
I0122 16:39:49.149663 56358 sgd_solver.cpp:106] Iteration 6600, lr = 0.0067
I0122 16:39:50.026733 56358 solver.cpp:266] Iteration 6700 (114.02 iter/s, 0.877036s/100 iter), loss = 0.221438
I0122 16:39:50.026911 56358 solver.cpp:285]     Train net output #0: loss = 0.221438 (* 1 = 0.221438 loss)
I0122 16:39:50.026919 56358 sgd_solver.cpp:106] Iteration 6700, lr = 0.00665
I0122 16:39:50.896739 56358 solver.cpp:266] Iteration 6800 (114.97 iter/s, 0.869792s/100 iter), loss = 0.299731
I0122 16:39:50.896766 56358 solver.cpp:285]     Train net output #0: loss = 0.299731 (* 1 = 0.299731 loss)
I0122 16:39:50.896772 56358 sgd_solver.cpp:106] Iteration 6800, lr = 0.0066
I0122 16:39:51.760782 56358 solver.cpp:266] Iteration 6900 (115.744 iter/s, 0.863976s/100 iter), loss = 0.207094
I0122 16:39:51.760808 56358 solver.cpp:285]     Train net output #0: loss = 0.207094 (* 1 = 0.207094 loss)
I0122 16:39:51.760814 56358 sgd_solver.cpp:106] Iteration 6900, lr = 0.00655
I0122 16:39:52.618552 56358 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 16:39:52.839859 56358 solver.cpp:517]     Test net output #0: loss = 0.507769 (* 1 = 0.507769 loss)
I0122 16:39:52.839874 56358 solver.cpp:517]     Test net output #1: top-1 = 0.843666
I0122 16:39:52.839879 56358 solver.cpp:517]     Test net output #2: top-5 = 0.989778
I0122 16:39:52.847950 56358 solver.cpp:266] Iteration 7000 (91.9879 iter/s, 1.0871s/100 iter), loss = 0.269685
I0122 16:39:52.847968 56358 solver.cpp:285]     Train net output #0: loss = 0.269685 (* 1 = 0.269685 loss)
I0122 16:39:52.847975 56358 sgd_solver.cpp:106] Iteration 7000, lr = 0.0065
I0122 16:39:53.710907 56358 solver.cpp:266] Iteration 7100 (115.888 iter/s, 0.8629s/100 iter), loss = 0.238185
I0122 16:39:53.710932 56358 solver.cpp:285]     Train net output #0: loss = 0.238185 (* 1 = 0.238185 loss)
I0122 16:39:53.710938 56358 sgd_solver.cpp:106] Iteration 7100, lr = 0.00645
I0122 16:39:54.578660 56358 solver.cpp:266] Iteration 7200 (115.249 iter/s, 0.867687s/100 iter), loss = 0.372838
I0122 16:39:54.578685 56358 solver.cpp:285]     Train net output #0: loss = 0.372838 (* 1 = 0.372838 loss)
I0122 16:39:54.578691 56358 sgd_solver.cpp:106] Iteration 7200, lr = 0.0064
I0122 16:39:55.450206 56358 solver.cpp:266] Iteration 7300 (114.747 iter/s, 0.871481s/100 iter), loss = 0.276045
I0122 16:39:55.450232 56358 solver.cpp:285]     Train net output #0: loss = 0.276045 (* 1 = 0.276045 loss)
I0122 16:39:55.450238 56358 sgd_solver.cpp:106] Iteration 7300, lr = 0.00635
I0122 16:39:56.316293 56358 solver.cpp:266] Iteration 7400 (115.47 iter/s, 0.866023s/100 iter), loss = 0.208802
I0122 16:39:56.316318 56358 solver.cpp:285]     Train net output #0: loss = 0.208802 (* 1 = 0.208802 loss)
I0122 16:39:56.316324 56358 sgd_solver.cpp:106] Iteration 7400, lr = 0.0063
I0122 16:39:57.179309 56358 solver.cpp:266] Iteration 7500 (115.881 iter/s, 0.862951s/100 iter), loss = 0.262486
I0122 16:39:57.179334 56358 solver.cpp:285]     Train net output #0: loss = 0.262486 (* 1 = 0.262486 loss)
I0122 16:39:57.179340 56358 sgd_solver.cpp:106] Iteration 7500, lr = 0.00625
I0122 16:39:58.042434 56358 solver.cpp:266] Iteration 7600 (115.867 iter/s, 0.863062s/100 iter), loss = 0.218856
I0122 16:39:58.042460 56358 solver.cpp:285]     Train net output #0: loss = 0.218856 (* 1 = 0.218856 loss)
I0122 16:39:58.042465 56358 sgd_solver.cpp:106] Iteration 7600, lr = 0.0062
I0122 16:39:58.905459 56358 solver.cpp:266] Iteration 7700 (115.88 iter/s, 0.862961s/100 iter), loss = 0.151931
I0122 16:39:58.905485 56358 solver.cpp:285]     Train net output #0: loss = 0.151931 (* 1 = 0.151931 loss)
I0122 16:39:58.905491 56358 sgd_solver.cpp:106] Iteration 7700, lr = 0.00615
I0122 16:39:59.772233 56358 solver.cpp:266] Iteration 7800 (115.379 iter/s, 0.86671s/100 iter), loss = 0.174728
I0122 16:39:59.772258 56358 solver.cpp:285]     Train net output #0: loss = 0.174728 (* 1 = 0.174728 loss)
I0122 16:39:59.772264 56358 sgd_solver.cpp:106] Iteration 7800, lr = 0.0061
I0122 16:40:00.639921 56358 solver.cpp:266] Iteration 7900 (115.257 iter/s, 0.867625s/100 iter), loss = 0.183744
I0122 16:40:00.639948 56358 solver.cpp:285]     Train net output #0: loss = 0.183744 (* 1 = 0.183744 loss)
I0122 16:40:00.639953 56358 sgd_solver.cpp:106] Iteration 7900, lr = 0.00605
I0122 16:40:01.496666 56358 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 16:40:01.716265 56358 solver.cpp:517]     Test net output #0: loss = 0.551618 (* 1 = 0.551618 loss)
I0122 16:40:01.716280 56358 solver.cpp:517]     Test net output #1: top-1 = 0.829222
I0122 16:40:01.716284 56358 solver.cpp:517]     Test net output #2: top-5 = 0.991
I0122 16:40:01.724334 56358 solver.cpp:266] Iteration 8000 (92.2218 iter/s, 1.08434s/100 iter), loss = 0.185087
I0122 16:40:01.724350 56358 solver.cpp:285]     Train net output #0: loss = 0.185087 (* 1 = 0.185087 loss)
I0122 16:40:01.724356 56358 sgd_solver.cpp:106] Iteration 8000, lr = 0.006
I0122 16:40:02.587471 56358 solver.cpp:266] Iteration 8100 (115.864 iter/s, 0.863082s/100 iter), loss = 0.224262
I0122 16:40:02.587496 56358 solver.cpp:285]     Train net output #0: loss = 0.224262 (* 1 = 0.224262 loss)
I0122 16:40:02.587502 56358 sgd_solver.cpp:106] Iteration 8100, lr = 0.00595
I0122 16:40:03.454341 56358 solver.cpp:266] Iteration 8200 (115.366 iter/s, 0.866807s/100 iter), loss = 0.161389
I0122 16:40:03.454370 56358 solver.cpp:285]     Train net output #0: loss = 0.161389 (* 1 = 0.161389 loss)
I0122 16:40:03.454376 56358 sgd_solver.cpp:106] Iteration 8200, lr = 0.0059
I0122 16:40:04.353070 56358 solver.cpp:266] Iteration 8300 (111.277 iter/s, 0.898657s/100 iter), loss = 0.20406
I0122 16:40:04.353097 56358 solver.cpp:285]     Train net output #0: loss = 0.20406 (* 1 = 0.20406 loss)
I0122 16:40:04.353103 56358 sgd_solver.cpp:106] Iteration 8300, lr = 0.00585
I0122 16:40:05.245889 56358 solver.cpp:266] Iteration 8400 (112.013 iter/s, 0.892752s/100 iter), loss = 0.134937
I0122 16:40:05.245921 56358 solver.cpp:285]     Train net output #0: loss = 0.134937 (* 1 = 0.134937 loss)
I0122 16:40:05.245926 56358 sgd_solver.cpp:106] Iteration 8400, lr = 0.0058
I0122 16:40:06.116338 56358 solver.cpp:266] Iteration 8500 (114.893 iter/s, 0.870378s/100 iter), loss = 0.247626
I0122 16:40:06.116365 56358 solver.cpp:285]     Train net output #0: loss = 0.247626 (* 1 = 0.247626 loss)
I0122 16:40:06.116371 56358 sgd_solver.cpp:106] Iteration 8500, lr = 0.00575
I0122 16:40:07.010193 56358 solver.cpp:266] Iteration 8600 (111.883 iter/s, 0.893788s/100 iter), loss = 0.163042
I0122 16:40:07.010221 56358 solver.cpp:285]     Train net output #0: loss = 0.163042 (* 1 = 0.163042 loss)
I0122 16:40:07.010226 56358 sgd_solver.cpp:106] Iteration 8600, lr = 0.0057
I0122 16:40:07.873512 56358 solver.cpp:266] Iteration 8700 (115.841 iter/s, 0.863251s/100 iter), loss = 0.167646
I0122 16:40:07.873549 56358 solver.cpp:285]     Train net output #0: loss = 0.167646 (* 1 = 0.167646 loss)
I0122 16:40:07.873555 56358 sgd_solver.cpp:106] Iteration 8700, lr = 0.00565
I0122 16:40:08.759862 56358 solver.cpp:266] Iteration 8800 (112.832 iter/s, 0.886274s/100 iter), loss = 0.24476
I0122 16:40:08.759889 56358 solver.cpp:285]     Train net output #0: loss = 0.24476 (* 1 = 0.24476 loss)
I0122 16:40:08.759896 56358 sgd_solver.cpp:106] Iteration 8800, lr = 0.0056
I0122 16:40:09.625655 56358 solver.cpp:266] Iteration 8900 (115.51 iter/s, 0.865727s/100 iter), loss = 0.134373
I0122 16:40:09.625694 56358 solver.cpp:285]     Train net output #0: loss = 0.134373 (* 1 = 0.134373 loss)
I0122 16:40:09.625701 56358 sgd_solver.cpp:106] Iteration 8900, lr = 0.00555
I0122 16:40:10.481906 56358 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 16:40:10.704524 56358 solver.cpp:517]     Test net output #0: loss = 0.506887 (* 1 = 0.506887 loss)
I0122 16:40:10.704538 56358 solver.cpp:517]     Test net output #1: top-1 = 0.840444
I0122 16:40:10.704543 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990667
I0122 16:40:10.712636 56358 solver.cpp:266] Iteration 9000 (92.0048 iter/s, 1.0869s/100 iter), loss = 0.198678
I0122 16:40:10.712652 56358 solver.cpp:285]     Train net output #0: loss = 0.198678 (* 1 = 0.198678 loss)
I0122 16:40:10.712658 56358 sgd_solver.cpp:106] Iteration 9000, lr = 0.0055
I0122 16:40:11.575709 56358 solver.cpp:266] Iteration 9100 (115.872 iter/s, 0.863018s/100 iter), loss = 0.115772
I0122 16:40:11.575734 56358 solver.cpp:285]     Train net output #0: loss = 0.115772 (* 1 = 0.115772 loss)
I0122 16:40:11.575768 56358 sgd_solver.cpp:106] Iteration 9100, lr = 0.00545
I0122 16:40:12.450681 56358 solver.cpp:266] Iteration 9200 (114.298 iter/s, 0.874908s/100 iter), loss = 0.21927
I0122 16:40:12.450711 56358 solver.cpp:285]     Train net output #0: loss = 0.21927 (* 1 = 0.21927 loss)
I0122 16:40:12.450716 56358 sgd_solver.cpp:106] Iteration 9200, lr = 0.0054
I0122 16:40:13.316885 56358 solver.cpp:266] Iteration 9300 (115.455 iter/s, 0.866137s/100 iter), loss = 0.162757
I0122 16:40:13.316911 56358 solver.cpp:285]     Train net output #0: loss = 0.162757 (* 1 = 0.162757 loss)
I0122 16:40:13.316917 56358 sgd_solver.cpp:106] Iteration 9300, lr = 0.00535
I0122 16:40:14.184279 56358 solver.cpp:266] Iteration 9400 (115.296 iter/s, 0.867329s/100 iter), loss = 0.204865
I0122 16:40:14.184305 56358 solver.cpp:285]     Train net output #0: loss = 0.204865 (* 1 = 0.204865 loss)
I0122 16:40:14.184310 56358 sgd_solver.cpp:106] Iteration 9400, lr = 0.0053
I0122 16:40:15.046594 56358 solver.cpp:266] Iteration 9500 (115.975 iter/s, 0.862251s/100 iter), loss = 0.148123
I0122 16:40:15.046622 56358 solver.cpp:285]     Train net output #0: loss = 0.148123 (* 1 = 0.148123 loss)
I0122 16:40:15.046627 56358 sgd_solver.cpp:106] Iteration 9500, lr = 0.00525
I0122 16:40:15.917695 56358 solver.cpp:266] Iteration 9600 (114.806 iter/s, 0.871033s/100 iter), loss = 0.215157
I0122 16:40:15.917721 56358 solver.cpp:285]     Train net output #0: loss = 0.215157 (* 1 = 0.215157 loss)
I0122 16:40:15.917726 56358 sgd_solver.cpp:106] Iteration 9600, lr = 0.0052
I0122 16:40:16.781949 56358 solver.cpp:266] Iteration 9700 (115.715 iter/s, 0.86419s/100 iter), loss = 0.154885
I0122 16:40:16.781975 56358 solver.cpp:285]     Train net output #0: loss = 0.154885 (* 1 = 0.154885 loss)
I0122 16:40:16.781980 56358 sgd_solver.cpp:106] Iteration 9700, lr = 0.00515
I0122 16:40:17.644497 56358 solver.cpp:266] Iteration 9800 (115.944 iter/s, 0.862486s/100 iter), loss = 0.326336
I0122 16:40:17.644536 56358 solver.cpp:285]     Train net output #0: loss = 0.326336 (* 1 = 0.326336 loss)
I0122 16:40:17.644542 56358 sgd_solver.cpp:106] Iteration 9800, lr = 0.0051
I0122 16:40:18.511914 56358 solver.cpp:266] Iteration 9900 (115.295 iter/s, 0.86734s/100 iter), loss = 0.25909
I0122 16:40:18.511940 56358 solver.cpp:285]     Train net output #0: loss = 0.25909 (* 1 = 0.25909 loss)
I0122 16:40:18.511945 56358 sgd_solver.cpp:106] Iteration 9900, lr = 0.00505
I0122 16:40:19.373044 56358 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 16:40:19.593742 56358 solver.cpp:517]     Test net output #0: loss = 0.497428 (* 1 = 0.497428 loss)
I0122 16:40:19.593757 56358 solver.cpp:517]     Test net output #1: top-1 = 0.846333
I0122 16:40:19.593761 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990778
I0122 16:40:19.602634 56358 solver.cpp:266] Iteration 10000 (91.6883 iter/s, 1.09065s/100 iter), loss = 0.25102
I0122 16:40:19.602653 56358 solver.cpp:285]     Train net output #0: loss = 0.25102 (* 1 = 0.25102 loss)
I0122 16:40:19.602658 56358 sgd_solver.cpp:106] Iteration 10000, lr = 0.005
I0122 16:40:20.466027 56358 solver.cpp:266] Iteration 10100 (115.83 iter/s, 0.863335s/100 iter), loss = 0.144585
I0122 16:40:20.466166 56358 solver.cpp:285]     Train net output #0: loss = 0.144585 (* 1 = 0.144585 loss)
I0122 16:40:20.466173 56358 sgd_solver.cpp:106] Iteration 10100, lr = 0.00495
I0122 16:40:21.334406 56358 solver.cpp:266] Iteration 10200 (115.18 iter/s, 0.868205s/100 iter), loss = 0.205947
I0122 16:40:21.334434 56358 solver.cpp:285]     Train net output #0: loss = 0.205947 (* 1 = 0.205947 loss)
I0122 16:40:21.334439 56358 sgd_solver.cpp:106] Iteration 10200, lr = 0.0049
I0122 16:40:22.242857 56358 solver.cpp:266] Iteration 10300 (110.086 iter/s, 0.908382s/100 iter), loss = 0.170186
I0122 16:40:22.242887 56358 solver.cpp:285]     Train net output #0: loss = 0.170186 (* 1 = 0.170186 loss)
I0122 16:40:22.242892 56358 sgd_solver.cpp:106] Iteration 10300, lr = 0.00485
I0122 16:40:23.127945 56358 solver.cpp:266] Iteration 10400 (112.992 iter/s, 0.88502s/100 iter), loss = 0.191921
I0122 16:40:23.127974 56358 solver.cpp:285]     Train net output #0: loss = 0.191921 (* 1 = 0.191921 loss)
I0122 16:40:23.127979 56358 sgd_solver.cpp:106] Iteration 10400, lr = 0.0048
I0122 16:40:23.999495 56358 solver.cpp:266] Iteration 10500 (114.747 iter/s, 0.871482s/100 iter), loss = 0.122154
I0122 16:40:23.999521 56358 solver.cpp:285]     Train net output #0: loss = 0.122154 (* 1 = 0.122154 loss)
I0122 16:40:23.999527 56358 sgd_solver.cpp:106] Iteration 10500, lr = 0.00475
I0122 16:40:24.894804 56358 solver.cpp:266] Iteration 10600 (111.701 iter/s, 0.895243s/100 iter), loss = 0.158028
I0122 16:40:24.894831 56358 solver.cpp:285]     Train net output #0: loss = 0.158028 (* 1 = 0.158028 loss)
I0122 16:40:24.894837 56358 sgd_solver.cpp:106] Iteration 10600, lr = 0.0047
I0122 16:40:25.759634 56358 solver.cpp:266] Iteration 10700 (115.639 iter/s, 0.864763s/100 iter), loss = 0.203774
I0122 16:40:25.759660 56358 solver.cpp:285]     Train net output #0: loss = 0.203774 (* 1 = 0.203774 loss)
I0122 16:40:25.759666 56358 sgd_solver.cpp:106] Iteration 10700, lr = 0.00465
I0122 16:40:26.634130 56358 solver.cpp:266] Iteration 10800 (114.36 iter/s, 0.874433s/100 iter), loss = 0.163711
I0122 16:40:26.634157 56358 solver.cpp:285]     Train net output #0: loss = 0.163711 (* 1 = 0.163711 loss)
I0122 16:40:26.634162 56358 sgd_solver.cpp:106] Iteration 10800, lr = 0.0046
I0122 16:40:27.516993 56358 solver.cpp:266] Iteration 10900 (113.276 iter/s, 0.882797s/100 iter), loss = 0.195547
I0122 16:40:27.517020 56358 solver.cpp:285]     Train net output #0: loss = 0.195547 (* 1 = 0.195547 loss)
I0122 16:40:27.517026 56358 sgd_solver.cpp:106] Iteration 10900, lr = 0.00455
I0122 16:40:28.372331 56358 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 16:40:28.592420 56358 solver.cpp:517]     Test net output #0: loss = 0.608123 (* 1 = 0.608123 loss)
I0122 16:40:28.592435 56358 solver.cpp:517]     Test net output #1: top-1 = 0.816
I0122 16:40:28.592439 56358 solver.cpp:517]     Test net output #2: top-5 = 0.986667
I0122 16:40:28.600499 56358 solver.cpp:266] Iteration 11000 (92.2989 iter/s, 1.08344s/100 iter), loss = 0.214699
I0122 16:40:28.600517 56358 solver.cpp:285]     Train net output #0: loss = 0.214699 (* 1 = 0.214699 loss)
I0122 16:40:28.600522 56358 sgd_solver.cpp:106] Iteration 11000, lr = 0.0045
I0122 16:40:29.486333 56358 solver.cpp:266] Iteration 11100 (112.895 iter/s, 0.885778s/100 iter), loss = 0.113131
I0122 16:40:29.486359 56358 solver.cpp:285]     Train net output #0: loss = 0.113131 (* 1 = 0.113131 loss)
I0122 16:40:29.486366 56358 sgd_solver.cpp:106] Iteration 11100, lr = 0.00445
I0122 16:40:30.364805 56358 solver.cpp:266] Iteration 11200 (113.842 iter/s, 0.878408s/100 iter), loss = 0.155673
I0122 16:40:30.364832 56358 solver.cpp:285]     Train net output #0: loss = 0.155673 (* 1 = 0.155673 loss)
I0122 16:40:30.364837 56358 sgd_solver.cpp:106] Iteration 11200, lr = 0.0044
I0122 16:40:31.240711 56358 solver.cpp:266] Iteration 11300 (114.176 iter/s, 0.875839s/100 iter), loss = 0.242291
I0122 16:40:31.240737 56358 solver.cpp:285]     Train net output #0: loss = 0.242291 (* 1 = 0.242291 loss)
I0122 16:40:31.240743 56358 sgd_solver.cpp:106] Iteration 11300, lr = 0.00435
I0122 16:40:32.140324 56358 solver.cpp:266] Iteration 11400 (111.167 iter/s, 0.899548s/100 iter), loss = 0.289464
I0122 16:40:32.140352 56358 solver.cpp:285]     Train net output #0: loss = 0.289464 (* 1 = 0.289464 loss)
I0122 16:40:32.140357 56358 sgd_solver.cpp:106] Iteration 11400, lr = 0.0043
I0122 16:40:33.010416 56358 solver.cpp:266] Iteration 11500 (114.939 iter/s, 0.870024s/100 iter), loss = 0.17182
I0122 16:40:33.010442 56358 solver.cpp:285]     Train net output #0: loss = 0.17182 (* 1 = 0.17182 loss)
I0122 16:40:33.010448 56358 sgd_solver.cpp:106] Iteration 11500, lr = 0.00425
I0122 16:40:33.879307 56358 solver.cpp:266] Iteration 11600 (115.098 iter/s, 0.868824s/100 iter), loss = 0.214879
I0122 16:40:33.879333 56358 solver.cpp:285]     Train net output #0: loss = 0.214879 (* 1 = 0.214879 loss)
I0122 16:40:33.879338 56358 sgd_solver.cpp:106] Iteration 11600, lr = 0.0042
I0122 16:40:34.741264 56358 solver.cpp:266] Iteration 11700 (116.024 iter/s, 0.861893s/100 iter), loss = 0.216148
I0122 16:40:34.741291 56358 solver.cpp:285]     Train net output #0: loss = 0.216148 (* 1 = 0.216148 loss)
I0122 16:40:34.741297 56358 sgd_solver.cpp:106] Iteration 11700, lr = 0.00415
I0122 16:40:35.604091 56358 solver.cpp:266] Iteration 11800 (115.907 iter/s, 0.86276s/100 iter), loss = 0.149312
I0122 16:40:35.604118 56358 solver.cpp:285]     Train net output #0: loss = 0.149312 (* 1 = 0.149312 loss)
I0122 16:40:35.604123 56358 sgd_solver.cpp:106] Iteration 11800, lr = 0.0041
I0122 16:40:36.466786 56358 solver.cpp:266] Iteration 11900 (115.924 iter/s, 0.862631s/100 iter), loss = 0.15686
I0122 16:40:36.466825 56358 solver.cpp:285]     Train net output #0: loss = 0.15686 (* 1 = 0.15686 loss)
I0122 16:40:36.466830 56358 sgd_solver.cpp:106] Iteration 11900, lr = 0.00405
I0122 16:40:37.320751 56358 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 16:40:37.541707 56358 solver.cpp:517]     Test net output #0: loss = 0.499224 (* 1 = 0.499224 loss)
I0122 16:40:37.541720 56358 solver.cpp:517]     Test net output #1: top-1 = 0.848667
I0122 16:40:37.541724 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990333
I0122 16:40:37.549784 56358 solver.cpp:266] Iteration 12000 (92.343 iter/s, 1.08292s/100 iter), loss = 0.207918
I0122 16:40:37.549801 56358 solver.cpp:285]     Train net output #0: loss = 0.207918 (* 1 = 0.207918 loss)
I0122 16:40:37.549806 56358 sgd_solver.cpp:106] Iteration 12000, lr = 0.004
I0122 16:40:38.413285 56358 solver.cpp:266] Iteration 12100 (115.815 iter/s, 0.863446s/100 iter), loss = 0.153007
I0122 16:40:38.413311 56358 solver.cpp:285]     Train net output #0: loss = 0.153007 (* 1 = 0.153007 loss)
I0122 16:40:38.413317 56358 sgd_solver.cpp:106] Iteration 12100, lr = 0.00395
I0122 16:40:39.275025 56358 solver.cpp:266] Iteration 12200 (116.053 iter/s, 0.861676s/100 iter), loss = 0.40102
I0122 16:40:39.275049 56358 solver.cpp:285]     Train net output #0: loss = 0.40102 (* 1 = 0.40102 loss)
I0122 16:40:39.275054 56358 sgd_solver.cpp:106] Iteration 12200, lr = 0.0039
I0122 16:40:40.138288 56358 solver.cpp:266] Iteration 12300 (115.848 iter/s, 0.8632s/100 iter), loss = 0.187594
I0122 16:40:40.138314 56358 solver.cpp:285]     Train net output #0: loss = 0.187594 (* 1 = 0.187594 loss)
I0122 16:40:40.138319 56358 sgd_solver.cpp:106] Iteration 12300, lr = 0.00385
I0122 16:40:41.006512 56358 solver.cpp:266] Iteration 12400 (115.186 iter/s, 0.86816s/100 iter), loss = 0.180739
I0122 16:40:41.006539 56358 solver.cpp:285]     Train net output #0: loss = 0.180739 (* 1 = 0.180739 loss)
I0122 16:40:41.006546 56358 sgd_solver.cpp:106] Iteration 12400, lr = 0.0038
I0122 16:40:41.868959 56358 solver.cpp:266] Iteration 12500 (115.958 iter/s, 0.862382s/100 iter), loss = 0.116752
I0122 16:40:41.868988 56358 solver.cpp:285]     Train net output #0: loss = 0.116752 (* 1 = 0.116752 loss)
I0122 16:40:41.868993 56358 sgd_solver.cpp:106] Iteration 12500, lr = 0.00375
I0122 16:40:42.732007 56358 solver.cpp:266] Iteration 12600 (115.878 iter/s, 0.86298s/100 iter), loss = 0.175929
I0122 16:40:42.732034 56358 solver.cpp:285]     Train net output #0: loss = 0.175929 (* 1 = 0.175929 loss)
I0122 16:40:42.732058 56358 sgd_solver.cpp:106] Iteration 12600, lr = 0.0037
I0122 16:40:43.594584 56358 solver.cpp:266] Iteration 12700 (115.94 iter/s, 0.862511s/100 iter), loss = 0.197073
I0122 16:40:43.594611 56358 solver.cpp:285]     Train net output #0: loss = 0.197073 (* 1 = 0.197073 loss)
I0122 16:40:43.594616 56358 sgd_solver.cpp:106] Iteration 12700, lr = 0.00365
I0122 16:40:44.461181 56358 solver.cpp:266] Iteration 12800 (115.403 iter/s, 0.866531s/100 iter), loss = 0.206288
I0122 16:40:44.461210 56358 solver.cpp:285]     Train net output #0: loss = 0.206288 (* 1 = 0.206288 loss)
I0122 16:40:44.461215 56358 sgd_solver.cpp:106] Iteration 12800, lr = 0.0036
I0122 16:40:45.329157 56358 solver.cpp:266] Iteration 12900 (115.219 iter/s, 0.867909s/100 iter), loss = 0.138023
I0122 16:40:45.329183 56358 solver.cpp:285]     Train net output #0: loss = 0.138023 (* 1 = 0.138023 loss)
I0122 16:40:45.329190 56358 sgd_solver.cpp:106] Iteration 12900, lr = 0.00355
I0122 16:40:46.202891 56358 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 16:40:46.428483 56358 solver.cpp:517]     Test net output #0: loss = 0.47976 (* 1 = 0.47976 loss)
I0122 16:40:46.428498 56358 solver.cpp:517]     Test net output #1: top-1 = 0.850778
I0122 16:40:46.428503 56358 solver.cpp:517]     Test net output #2: top-5 = 0.992667
I0122 16:40:46.436545 56358 solver.cpp:266] Iteration 13000 (90.3082 iter/s, 1.10732s/100 iter), loss = 0.262727
I0122 16:40:46.436563 56358 solver.cpp:285]     Train net output #0: loss = 0.262727 (* 1 = 0.262727 loss)
I0122 16:40:46.436569 56358 sgd_solver.cpp:106] Iteration 13000, lr = 0.0035
I0122 16:40:47.316171 56358 solver.cpp:266] Iteration 13100 (113.692 iter/s, 0.879569s/100 iter), loss = 0.163221
I0122 16:40:47.316198 56358 solver.cpp:285]     Train net output #0: loss = 0.163221 (* 1 = 0.163221 loss)
I0122 16:40:47.316205 56358 sgd_solver.cpp:106] Iteration 13100, lr = 0.00345
I0122 16:40:48.177773 56358 solver.cpp:266] Iteration 13200 (116.072 iter/s, 0.861537s/100 iter), loss = 0.329066
I0122 16:40:48.177801 56358 solver.cpp:285]     Train net output #0: loss = 0.329066 (* 1 = 0.329066 loss)
I0122 16:40:48.177806 56358 sgd_solver.cpp:106] Iteration 13200, lr = 0.0034
I0122 16:40:49.068063 56358 solver.cpp:266] Iteration 13300 (112.332 iter/s, 0.890222s/100 iter), loss = 0.178849
I0122 16:40:49.068089 56358 solver.cpp:285]     Train net output #0: loss = 0.178849 (* 1 = 0.178849 loss)
I0122 16:40:49.068095 56358 sgd_solver.cpp:106] Iteration 13300, lr = 0.00335
I0122 16:40:49.952428 56358 solver.cpp:266] Iteration 13400 (113.084 iter/s, 0.8843s/100 iter), loss = 0.145544
I0122 16:40:49.952455 56358 solver.cpp:285]     Train net output #0: loss = 0.145544 (* 1 = 0.145544 loss)
I0122 16:40:49.952461 56358 sgd_solver.cpp:106] Iteration 13400, lr = 0.0033
I0122 16:40:50.819974 56358 solver.cpp:266] Iteration 13500 (115.276 iter/s, 0.867481s/100 iter), loss = 0.125595
I0122 16:40:50.820082 56358 solver.cpp:285]     Train net output #0: loss = 0.125595 (* 1 = 0.125595 loss)
I0122 16:40:50.820088 56358 sgd_solver.cpp:106] Iteration 13500, lr = 0.00325
I0122 16:40:51.694248 56358 solver.cpp:266] Iteration 13600 (114.4 iter/s, 0.874129s/100 iter), loss = 0.176674
I0122 16:40:51.694275 56358 solver.cpp:285]     Train net output #0: loss = 0.176674 (* 1 = 0.176674 loss)
I0122 16:40:51.694280 56358 sgd_solver.cpp:106] Iteration 13600, lr = 0.0032
I0122 16:40:52.610179 56358 solver.cpp:266] Iteration 13700 (109.187 iter/s, 0.915863s/100 iter), loss = 0.150129
I0122 16:40:52.610218 56358 solver.cpp:285]     Train net output #0: loss = 0.150129 (* 1 = 0.150129 loss)
I0122 16:40:52.610224 56358 sgd_solver.cpp:106] Iteration 13700, lr = 0.00315
I0122 16:40:53.476239 56358 solver.cpp:266] Iteration 13800 (115.476 iter/s, 0.865982s/100 iter), loss = 0.174633
I0122 16:40:53.476267 56358 solver.cpp:285]     Train net output #0: loss = 0.174633 (* 1 = 0.174633 loss)
I0122 16:40:53.476274 56358 sgd_solver.cpp:106] Iteration 13800, lr = 0.0031
I0122 16:40:54.337461 56358 solver.cpp:266] Iteration 13900 (116.123 iter/s, 0.861156s/100 iter), loss = 0.144366
I0122 16:40:54.337487 56358 solver.cpp:285]     Train net output #0: loss = 0.144366 (* 1 = 0.144366 loss)
I0122 16:40:54.337492 56358 sgd_solver.cpp:106] Iteration 13900, lr = 0.00305
I0122 16:40:55.192530 56358 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 16:40:55.415419 56358 solver.cpp:517]     Test net output #0: loss = 0.478237 (* 1 = 0.478237 loss)
I0122 16:40:55.415433 56358 solver.cpp:517]     Test net output #1: top-1 = 0.851444
I0122 16:40:55.415437 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990778
I0122 16:40:55.423561 56358 solver.cpp:266] Iteration 14000 (92.0784 iter/s, 1.08603s/100 iter), loss = 0.10762
I0122 16:40:55.423578 56358 solver.cpp:285]     Train net output #0: loss = 0.10762 (* 1 = 0.10762 loss)
I0122 16:40:55.423584 56358 sgd_solver.cpp:106] Iteration 14000, lr = 0.003
I0122 16:40:56.311094 56358 solver.cpp:266] Iteration 14100 (112.679 iter/s, 0.887474s/100 iter), loss = 0.124198
I0122 16:40:56.311120 56358 solver.cpp:285]     Train net output #0: loss = 0.124198 (* 1 = 0.124198 loss)
I0122 16:40:56.311126 56358 sgd_solver.cpp:106] Iteration 14100, lr = 0.00295
I0122 16:40:57.186972 56358 solver.cpp:266] Iteration 14200 (114.18 iter/s, 0.875813s/100 iter), loss = 0.12877
I0122 16:40:57.187000 56358 solver.cpp:285]     Train net output #0: loss = 0.12877 (* 1 = 0.12877 loss)
I0122 16:40:57.187005 56358 sgd_solver.cpp:106] Iteration 14200, lr = 0.0029
I0122 16:40:58.048964 56358 solver.cpp:266] Iteration 14300 (116.019 iter/s, 0.861925s/100 iter), loss = 0.178183
I0122 16:40:58.048991 56358 solver.cpp:285]     Train net output #0: loss = 0.178183 (* 1 = 0.178183 loss)
I0122 16:40:58.048997 56358 sgd_solver.cpp:106] Iteration 14300, lr = 0.00285
I0122 16:40:58.918201 56358 solver.cpp:266] Iteration 14400 (115.052 iter/s, 0.869171s/100 iter), loss = 0.122136
I0122 16:40:58.918229 56358 solver.cpp:285]     Train net output #0: loss = 0.122136 (* 1 = 0.122136 loss)
I0122 16:40:58.918236 56358 sgd_solver.cpp:106] Iteration 14400, lr = 0.0028
I0122 16:40:59.797286 56358 solver.cpp:266] Iteration 14500 (113.763 iter/s, 0.879017s/100 iter), loss = 0.0918108
I0122 16:40:59.797313 56358 solver.cpp:285]     Train net output #0: loss = 0.0918108 (* 1 = 0.0918108 loss)
I0122 16:40:59.797319 56358 sgd_solver.cpp:106] Iteration 14500, lr = 0.00275
I0122 16:41:00.663060 56358 solver.cpp:266] Iteration 14600 (115.512 iter/s, 0.865708s/100 iter), loss = 0.103151
I0122 16:41:00.663087 56358 solver.cpp:285]     Train net output #0: loss = 0.103151 (* 1 = 0.103151 loss)
I0122 16:41:00.663094 56358 sgd_solver.cpp:106] Iteration 14600, lr = 0.0027
I0122 16:41:01.528515 56358 solver.cpp:266] Iteration 14700 (115.555 iter/s, 0.865389s/100 iter), loss = 0.0582767
I0122 16:41:01.528543 56358 solver.cpp:285]     Train net output #0: loss = 0.0582767 (* 1 = 0.0582767 loss)
I0122 16:41:01.528549 56358 sgd_solver.cpp:106] Iteration 14700, lr = 0.00265
I0122 16:41:02.393410 56358 solver.cpp:266] Iteration 14800 (115.63 iter/s, 0.864829s/100 iter), loss = 0.142753
I0122 16:41:02.393436 56358 solver.cpp:285]     Train net output #0: loss = 0.142753 (* 1 = 0.142753 loss)
I0122 16:41:02.393442 56358 sgd_solver.cpp:106] Iteration 14800, lr = 0.0026
I0122 16:41:03.255591 56358 solver.cpp:266] Iteration 14900 (115.994 iter/s, 0.862116s/100 iter), loss = 0.134496
I0122 16:41:03.255620 56358 solver.cpp:285]     Train net output #0: loss = 0.134496 (* 1 = 0.134496 loss)
I0122 16:41:03.255625 56358 sgd_solver.cpp:106] Iteration 14900, lr = 0.00255
I0122 16:41:04.161459 56358 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 16:41:04.381582 56358 solver.cpp:517]     Test net output #0: loss = 0.490479 (* 1 = 0.490479 loss)
I0122 16:41:04.381603 56358 solver.cpp:517]     Test net output #1: top-1 = 0.851333
I0122 16:41:04.381608 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990111
I0122 16:41:04.389672 56358 solver.cpp:266] Iteration 15000 (88.1828 iter/s, 1.13401s/100 iter), loss = 0.20817
I0122 16:41:04.389688 56358 solver.cpp:285]     Train net output #0: loss = 0.20817 (* 1 = 0.20817 loss)
I0122 16:41:04.389694 56358 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0122 16:41:05.265817 56358 solver.cpp:266] Iteration 15100 (114.144 iter/s, 0.876089s/100 iter), loss = 0.0869578
I0122 16:41:05.265844 56358 solver.cpp:285]     Train net output #0: loss = 0.0869578 (* 1 = 0.0869578 loss)
I0122 16:41:05.265851 56358 sgd_solver.cpp:106] Iteration 15100, lr = 0.00245
I0122 16:41:06.135257 56358 solver.cpp:266] Iteration 15200 (115.025 iter/s, 0.869373s/100 iter), loss = 0.218636
I0122 16:41:06.135285 56358 solver.cpp:285]     Train net output #0: loss = 0.218636 (* 1 = 0.218636 loss)
I0122 16:41:06.135290 56358 sgd_solver.cpp:106] Iteration 15200, lr = 0.0024
I0122 16:41:07.010794 56358 solver.cpp:266] Iteration 15300 (114.224 iter/s, 0.875471s/100 iter), loss = 0.193568
I0122 16:41:07.010821 56358 solver.cpp:285]     Train net output #0: loss = 0.193568 (* 1 = 0.193568 loss)
I0122 16:41:07.010828 56358 sgd_solver.cpp:106] Iteration 15300, lr = 0.00235
I0122 16:41:07.883733 56358 solver.cpp:266] Iteration 15400 (114.564 iter/s, 0.872871s/100 iter), loss = 0.179632
I0122 16:41:07.883760 56358 solver.cpp:285]     Train net output #0: loss = 0.179632 (* 1 = 0.179632 loss)
I0122 16:41:07.883766 56358 sgd_solver.cpp:106] Iteration 15400, lr = 0.0023
I0122 16:41:08.755970 56358 solver.cpp:266] Iteration 15500 (114.657 iter/s, 0.87217s/100 iter), loss = 0.165628
I0122 16:41:08.755997 56358 solver.cpp:285]     Train net output #0: loss = 0.165628 (* 1 = 0.165628 loss)
I0122 16:41:08.756003 56358 sgd_solver.cpp:106] Iteration 15500, lr = 0.00225
I0122 16:41:09.620128 56358 solver.cpp:266] Iteration 15600 (115.728 iter/s, 0.864092s/100 iter), loss = 0.161383
I0122 16:41:09.620157 56358 solver.cpp:285]     Train net output #0: loss = 0.161383 (* 1 = 0.161383 loss)
I0122 16:41:09.620162 56358 sgd_solver.cpp:106] Iteration 15600, lr = 0.0022
I0122 16:41:10.484211 56358 solver.cpp:266] Iteration 15700 (115.739 iter/s, 0.864016s/100 iter), loss = 0.10945
I0122 16:41:10.484239 56358 solver.cpp:285]     Train net output #0: loss = 0.10945 (* 1 = 0.10945 loss)
I0122 16:41:10.484246 56358 sgd_solver.cpp:106] Iteration 15700, lr = 0.00215
I0122 16:41:11.346891 56358 solver.cpp:266] Iteration 15800 (115.927 iter/s, 0.862613s/100 iter), loss = 0.137631
I0122 16:41:11.346918 56358 solver.cpp:285]     Train net output #0: loss = 0.137631 (* 1 = 0.137631 loss)
I0122 16:41:11.346925 56358 sgd_solver.cpp:106] Iteration 15800, lr = 0.0021
I0122 16:41:12.208968 56358 solver.cpp:266] Iteration 15900 (116.008 iter/s, 0.862011s/100 iter), loss = 0.232173
I0122 16:41:12.208998 56358 solver.cpp:285]     Train net output #0: loss = 0.232173 (* 1 = 0.232173 loss)
I0122 16:41:12.209003 56358 sgd_solver.cpp:106] Iteration 15900, lr = 0.00205
I0122 16:41:13.063845 56358 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 16:41:13.284840 56358 solver.cpp:517]     Test net output #0: loss = 0.470084 (* 1 = 0.470084 loss)
I0122 16:41:13.284873 56358 solver.cpp:517]     Test net output #1: top-1 = 0.856778
I0122 16:41:13.284878 56358 solver.cpp:517]     Test net output #2: top-5 = 0.990889
I0122 16:41:13.293084 56358 solver.cpp:266] Iteration 16000 (92.2472 iter/s, 1.08404s/100 iter), loss = 0.169693
I0122 16:41:13.293102 56358 solver.cpp:285]     Train net output #0: loss = 0.169693 (* 1 = 0.169693 loss)
I0122 16:41:13.293107 56358 sgd_solver.cpp:106] Iteration 16000, lr = 0.002
I0122 16:41:14.156107 56358 solver.cpp:266] Iteration 16100 (115.879 iter/s, 0.862967s/100 iter), loss = 0.199058
I0122 16:41:14.156144 56358 solver.cpp:285]     Train net output #0: loss = 0.199058 (* 1 = 0.199058 loss)
I0122 16:41:14.156152 56358 sgd_solver.cpp:106] Iteration 16100, lr = 0.00195
I0122 16:41:15.019872 56358 solver.cpp:266] Iteration 16200 (115.782 iter/s, 0.86369s/100 iter), loss = 0.147623
I0122 16:41:15.019897 56358 solver.cpp:285]     Train net output #0: loss = 0.147623 (* 1 = 0.147623 loss)
I0122 16:41:15.019903 56358 sgd_solver.cpp:106] Iteration 16200, lr = 0.0019
I0122 16:41:15.885440 56358 solver.cpp:266] Iteration 16300 (115.54 iter/s, 0.865504s/100 iter), loss = 0.163395
I0122 16:41:15.885468 56358 solver.cpp:285]     Train net output #0: loss = 0.163395 (* 1 = 0.163395 loss)
I0122 16:41:15.885473 56358 sgd_solver.cpp:106] Iteration 16300, lr = 0.00185
I0122 16:41:16.748720 56358 solver.cpp:266] Iteration 16400 (115.846 iter/s, 0.863215s/100 iter), loss = 0.134782
I0122 16:41:16.748747 56358 solver.cpp:285]     Train net output #0: loss = 0.134782 (* 1 = 0.134782 loss)
I0122 16:41:16.748752 56358 sgd_solver.cpp:106] Iteration 16400, lr = 0.0018
I0122 16:41:17.614356 56358 solver.cpp:266] Iteration 16500 (115.531 iter/s, 0.86557s/100 iter), loss = 0.161537
I0122 16:41:17.614387 56358 solver.cpp:285]     Train net output #0: loss = 0.161537 (* 1 = 0.161537 loss)
I0122 16:41:17.614392 56358 sgd_solver.cpp:106] Iteration 16500, lr = 0.00175
I0122 16:41:18.479460 56358 solver.cpp:266] Iteration 16600 (115.602 iter/s, 0.865035s/100 iter), loss = 0.200338
I0122 16:41:18.479486 56358 solver.cpp:285]     Train net output #0: loss = 0.200338 (* 1 = 0.200338 loss)
I0122 16:41:18.479492 56358 sgd_solver.cpp:106] Iteration 16600, lr = 0.0017
I0122 16:41:19.342610 56358 solver.cpp:266] Iteration 16700 (115.863 iter/s, 0.863086s/100 iter), loss = 0.117915
I0122 16:41:19.342638 56358 solver.cpp:285]     Train net output #0: loss = 0.117915 (* 1 = 0.117915 loss)
I0122 16:41:19.342643 56358 sgd_solver.cpp:106] Iteration 16700, lr = 0.00165
I0122 16:41:20.280894 56358 solver.cpp:266] Iteration 16800 (106.585 iter/s, 0.938214s/100 iter), loss = 0.157756
I0122 16:41:20.280920 56358 solver.cpp:285]     Train net output #0: loss = 0.157756 (* 1 = 0.157756 loss)
I0122 16:41:20.280925 56358 sgd_solver.cpp:106] Iteration 16800, lr = 0.0016
I0122 16:41:21.154065 56358 solver.cpp:266] Iteration 16900 (114.534 iter/s, 0.873106s/100 iter), loss = 0.215282
I0122 16:41:21.154179 56358 solver.cpp:285]     Train net output #0: loss = 0.215282 (* 1 = 0.215282 loss)
I0122 16:41:21.154187 56358 sgd_solver.cpp:106] Iteration 16900, lr = 0.00155
I0122 16:41:22.009171 56358 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 16:41:22.239665 56358 solver.cpp:517]     Test net output #0: loss = 0.468133 (* 1 = 0.468133 loss)
I0122 16:41:22.239682 56358 solver.cpp:517]     Test net output #1: top-1 = 0.855667
I0122 16:41:22.239686 56358 solver.cpp:517]     Test net output #2: top-5 = 0.991889
I0122 16:41:22.248088 56358 solver.cpp:266] Iteration 17000 (91.4187 iter/s, 1.09387s/100 iter), loss = 0.189364
I0122 16:41:22.248106 56358 solver.cpp:285]     Train net output #0: loss = 0.189364 (* 1 = 0.189364 loss)
I0122 16:41:22.248113 56358 sgd_solver.cpp:106] Iteration 17000, lr = 0.0015
I0122 16:41:23.112552 56358 solver.cpp:266] Iteration 17100 (115.686 iter/s, 0.864406s/100 iter), loss = 0.161264
I0122 16:41:23.112579 56358 solver.cpp:285]     Train net output #0: loss = 0.161264 (* 1 = 0.161264 loss)
I0122 16:41:23.112584 56358 sgd_solver.cpp:106] Iteration 17100, lr = 0.00145
I0122 16:41:23.999634 56358 solver.cpp:266] Iteration 17200 (112.738 iter/s, 0.887016s/100 iter), loss = 0.206895
I0122 16:41:23.999662 56358 solver.cpp:285]     Train net output #0: loss = 0.206895 (* 1 = 0.206895 loss)
I0122 16:41:23.999668 56358 sgd_solver.cpp:106] Iteration 17200, lr = 0.0014
I0122 16:41:24.862287 56358 solver.cpp:266] Iteration 17300 (115.931 iter/s, 0.862586s/100 iter), loss = 0.261465
I0122 16:41:24.862314 56358 solver.cpp:285]     Train net output #0: loss = 0.261465 (* 1 = 0.261465 loss)
I0122 16:41:24.862320 56358 sgd_solver.cpp:106] Iteration 17300, lr = 0.00135
I0122 16:41:25.747434 56358 solver.cpp:266] Iteration 17400 (112.984 iter/s, 0.88508s/100 iter), loss = 0.159458
I0122 16:41:25.747463 56358 solver.cpp:285]     Train net output #0: loss = 0.159458 (* 1 = 0.159458 loss)
I0122 16:41:25.747468 56358 sgd_solver.cpp:106] Iteration 17400, lr = 0.0013
I0122 16:41:26.613247 56358 solver.cpp:266] Iteration 17500 (115.507 iter/s, 0.865746s/100 iter), loss = 0.148827
I0122 16:41:26.613274 56358 solver.cpp:285]     Train net output #0: loss = 0.148827 (* 1 = 0.148827 loss)
I0122 16:41:26.613281 56358 sgd_solver.cpp:106] Iteration 17500, lr = 0.00125
I0122 16:41:27.475894 56358 solver.cpp:266] Iteration 17600 (115.931 iter/s, 0.862581s/100 iter), loss = 0.192074
I0122 16:41:27.475922 56358 solver.cpp:285]     Train net output #0: loss = 0.192074 (* 1 = 0.192074 loss)
I0122 16:41:27.475929 56358 sgd_solver.cpp:106] Iteration 17600, lr = 0.0012
I0122 16:41:28.338361 56358 solver.cpp:266] Iteration 17700 (115.955 iter/s, 0.8624s/100 iter), loss = 0.200234
I0122 16:41:28.338388 56358 solver.cpp:285]     Train net output #0: loss = 0.200234 (* 1 = 0.200234 loss)
I0122 16:41:28.338394 56358 sgd_solver.cpp:106] Iteration 17700, lr = 0.00115
I0122 16:41:29.202088 56358 solver.cpp:266] Iteration 17800 (115.786 iter/s, 0.863662s/100 iter), loss = 0.193523
I0122 16:41:29.202114 56358 solver.cpp:285]     Train net output #0: loss = 0.193523 (* 1 = 0.193523 loss)
I0122 16:41:29.202121 56358 sgd_solver.cpp:106] Iteration 17800, lr = 0.0011
I0122 16:41:30.065737 56358 solver.cpp:266] Iteration 17900 (115.797 iter/s, 0.863583s/100 iter), loss = 0.223768
I0122 16:41:30.065763 56358 solver.cpp:285]     Train net output #0: loss = 0.223768 (* 1 = 0.223768 loss)
I0122 16:41:30.065769 56358 sgd_solver.cpp:106] Iteration 17900, lr = 0.00105
I0122 16:41:30.919059 56358 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 16:41:31.140036 56358 solver.cpp:517]     Test net output #0: loss = 0.445225 (* 1 = 0.445225 loss)
I0122 16:41:31.140051 56358 solver.cpp:517]     Test net output #1: top-1 = 0.860111
I0122 16:41:31.140055 56358 solver.cpp:517]     Test net output #2: top-5 = 0.991889
I0122 16:41:31.148167 56358 solver.cpp:266] Iteration 18000 (92.3906 iter/s, 1.08236s/100 iter), loss = 0.150569
I0122 16:41:31.148183 56358 solver.cpp:285]     Train net output #0: loss = 0.150569 (* 1 = 0.150569 loss)
I0122 16:41:31.148188 56358 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0122 16:41:32.010272 56358 solver.cpp:266] Iteration 18100 (116.003 iter/s, 0.862049s/100 iter), loss = 0.161548
I0122 16:41:32.010298 56358 solver.cpp:285]     Train net output #0: loss = 0.161548 (* 1 = 0.161548 loss)
I0122 16:41:32.010304 56358 sgd_solver.cpp:106] Iteration 18100, lr = 0.00095
I0122 16:41:32.872977 56358 solver.cpp:266] Iteration 18200 (115.923 iter/s, 0.862642s/100 iter), loss = 0.178229
I0122 16:41:32.873004 56358 solver.cpp:285]     Train net output #0: loss = 0.178229 (* 1 = 0.178229 loss)
I0122 16:41:32.873009 56358 sgd_solver.cpp:106] Iteration 18200, lr = 0.0009
I0122 16:41:33.734499 56358 solver.cpp:266] Iteration 18300 (116.082 iter/s, 0.861457s/100 iter), loss = 0.179794
I0122 16:41:33.734524 56358 solver.cpp:285]     Train net output #0: loss = 0.179794 (* 1 = 0.179794 loss)
I0122 16:41:33.734529 56358 sgd_solver.cpp:106] Iteration 18300, lr = 0.00085
I0122 16:41:34.597285 56358 solver.cpp:266] Iteration 18400 (115.912 iter/s, 0.862722s/100 iter), loss = 0.168931
I0122 16:41:34.597311 56358 solver.cpp:285]     Train net output #0: loss = 0.168931 (* 1 = 0.168931 loss)
I0122 16:41:34.597316 56358 sgd_solver.cpp:106] Iteration 18400, lr = 0.0008
I0122 16:41:35.461895 56358 solver.cpp:266] Iteration 18500 (115.668 iter/s, 0.864546s/100 iter), loss = 0.241565
I0122 16:41:35.461923 56358 solver.cpp:285]     Train net output #0: loss = 0.241565 (* 1 = 0.241565 loss)
I0122 16:41:35.461930 56358 sgd_solver.cpp:106] Iteration 18500, lr = 0.00075
I0122 16:41:36.324481 56358 solver.cpp:266] Iteration 18600 (115.94 iter/s, 0.862518s/100 iter), loss = 0.160278
I0122 16:41:36.324506 56358 solver.cpp:285]     Train net output #0: loss = 0.160278 (* 1 = 0.160278 loss)
I0122 16:41:36.324512 56358 sgd_solver.cpp:106] Iteration 18600, lr = 0.0007
I0122 16:41:37.189597 56358 solver.cpp:266] Iteration 18700 (115.6 iter/s, 0.865052s/100 iter), loss = 0.158366
I0122 16:41:37.189620 56358 solver.cpp:285]     Train net output #0: loss = 0.158366 (* 1 = 0.158366 loss)
I0122 16:41:37.189625 56358 sgd_solver.cpp:106] Iteration 18700, lr = 0.00065
I0122 16:41:38.051679 56358 solver.cpp:266] Iteration 18800 (116.007 iter/s, 0.86202s/100 iter), loss = 0.103973
I0122 16:41:38.051707 56358 solver.cpp:285]     Train net output #0: loss = 0.103973 (* 1 = 0.103973 loss)
I0122 16:41:38.051712 56358 sgd_solver.cpp:106] Iteration 18800, lr = 0.0006
I0122 16:41:38.914188 56358 solver.cpp:266] Iteration 18900 (115.95 iter/s, 0.862442s/100 iter), loss = 0.140709
I0122 16:41:38.914216 56358 solver.cpp:285]     Train net output #0: loss = 0.140709 (* 1 = 0.140709 loss)
I0122 16:41:38.914222 56358 sgd_solver.cpp:106] Iteration 18900, lr = 0.00055
I0122 16:41:39.769454 56358 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 16:41:39.989310 56358 solver.cpp:517]     Test net output #0: loss = 0.447801 (* 1 = 0.447801 loss)
I0122 16:41:39.989323 56358 solver.cpp:517]     Test net output #1: top-1 = 0.860778
I0122 16:41:39.989328 56358 solver.cpp:517]     Test net output #2: top-5 = 0.991667
I0122 16:41:39.997455 56358 solver.cpp:266] Iteration 19000 (92.3194 iter/s, 1.0832s/100 iter), loss = 0.310725
I0122 16:41:39.997473 56358 solver.cpp:285]     Train net output #0: loss = 0.310725 (* 1 = 0.310725 loss)
I0122 16:41:39.997478 56358 sgd_solver.cpp:106] Iteration 19000, lr = 0.0005
I0122 16:41:40.859714 56358 solver.cpp:266] Iteration 19100 (115.982 iter/s, 0.862202s/100 iter), loss = 0.131359
I0122 16:41:40.859738 56358 solver.cpp:285]     Train net output #0: loss = 0.131359 (* 1 = 0.131359 loss)
I0122 16:41:40.859743 56358 sgd_solver.cpp:106] Iteration 19100, lr = 0.00045
I0122 16:41:41.722190 56358 solver.cpp:266] Iteration 19200 (115.954 iter/s, 0.862414s/100 iter), loss = 0.178168
I0122 16:41:41.722218 56358 solver.cpp:285]     Train net output #0: loss = 0.178168 (* 1 = 0.178168 loss)
I0122 16:41:41.722223 56358 sgd_solver.cpp:106] Iteration 19200, lr = 0.0004
I0122 16:41:42.586732 56358 solver.cpp:266] Iteration 19300 (115.677 iter/s, 0.864477s/100 iter), loss = 0.12426
I0122 16:41:42.586777 56358 solver.cpp:285]     Train net output #0: loss = 0.12426 (* 1 = 0.12426 loss)
I0122 16:41:42.586784 56358 sgd_solver.cpp:106] Iteration 19300, lr = 0.00035
I0122 16:41:43.450242 56358 solver.cpp:266] Iteration 19400 (115.818 iter/s, 0.863426s/100 iter), loss = 0.167845
I0122 16:41:43.450268 56358 solver.cpp:285]     Train net output #0: loss = 0.167845 (* 1 = 0.167845 loss)
I0122 16:41:43.450273 56358 sgd_solver.cpp:106] Iteration 19400, lr = 0.0003
I0122 16:41:44.315016 56358 solver.cpp:266] Iteration 19500 (115.646 iter/s, 0.86471s/100 iter), loss = 0.0847646
I0122 16:41:44.315042 56358 solver.cpp:285]     Train net output #0: loss = 0.0847646 (* 1 = 0.0847646 loss)
I0122 16:41:44.315047 56358 sgd_solver.cpp:106] Iteration 19500, lr = 0.00025
I0122 16:41:45.176795 56358 solver.cpp:266] Iteration 19600 (116.048 iter/s, 0.861714s/100 iter), loss = 0.241344
I0122 16:41:45.176821 56358 solver.cpp:285]     Train net output #0: loss = 0.241344 (* 1 = 0.241344 loss)
I0122 16:41:45.176826 56358 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I0122 16:41:46.039110 56358 solver.cpp:266] Iteration 19700 (115.976 iter/s, 0.86225s/100 iter), loss = 0.147473
I0122 16:41:46.039139 56358 solver.cpp:285]     Train net output #0: loss = 0.147473 (* 1 = 0.147473 loss)
I0122 16:41:46.039144 56358 sgd_solver.cpp:106] Iteration 19700, lr = 0.00015
I0122 16:41:46.903443 56358 solver.cpp:266] Iteration 19800 (115.705 iter/s, 0.864267s/100 iter), loss = 0.127007
I0122 16:41:46.903470 56358 solver.cpp:285]     Train net output #0: loss = 0.127007 (* 1 = 0.127007 loss)
I0122 16:41:46.903475 56358 sgd_solver.cpp:106] Iteration 19800, lr = 9.99999e-05
I0122 16:41:47.765820 56358 solver.cpp:266] Iteration 19900 (115.967 iter/s, 0.862311s/100 iter), loss = 0.136626
I0122 16:41:47.765846 56358 solver.cpp:285]     Train net output #0: loss = 0.136626 (* 1 = 0.136626 loss)
I0122 16:41:47.765851 56358 sgd_solver.cpp:106] Iteration 19900, lr = 5e-05
I0122 16:41:48.621839 56358 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/snapshots/_iter_20000.caffemodel
I0122 16:41:48.695271 56358 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniVggNet/pruning/regular_rate_0.5/snapshots/_iter_20000.solverstate
I0122 16:41:48.707917 56358 solver.cpp:378] Iteration 20000, loss = 0.0227214
I0122 16:41:48.707939 56358 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 16:41:48.928603 56358 solver.cpp:517]     Test net output #0: loss = 0.448445 (* 1 = 0.448445 loss)
I0122 16:41:48.928619 56358 solver.cpp:517]     Test net output #1: top-1 = 0.861222
I0122 16:41:48.928623 56358 solver.cpp:517]     Test net output #2: top-5 = 0.991889
I0122 16:41:48.928627 56358 solver.cpp:386] Optimization Done (112.809 iter/s).
I0122 16:41:48.928632 56358 caffe_interface.cpp:530] Optimization Done.
