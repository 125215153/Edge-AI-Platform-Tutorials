net:  "deephi/pruning/train_val.prototxt"
#
#
test_iter: 180          # test_iter = test dataset size / test batch size
#
test_interval: 1000       # amount of iterations after which the NN will test the performance on the test dataset
#
base_lr: 0.1            # the beginning of learning rate
#
lr_policy: "step"         # it could be "step", "fixed", "exp", "poly", "sigmoid"
#power: 1
#
gamma: 0.1               # how much the learning rate should be changed every time we reach the next step
#
stepsize: 10000

display:  100
max_iter: 40000          # end of NN training. Note that max_iter  = num_epochs * training set size / test batch size
# max_iter: 1000         # end of NN training. Note that max_iter  = num_epochs * training set size / test batch size
#
momentum: 0.9
weight_decay: 0.001
snapshot: 20000
#snapshot_format: HDF5
snapshot_prefix: "deephi/pruning/snapshot_3_miniGoogleNet_"
#
#solver_mode: CPU
solver_mode: GPU
#
#type: "Nesterov"
type: "SGD"
