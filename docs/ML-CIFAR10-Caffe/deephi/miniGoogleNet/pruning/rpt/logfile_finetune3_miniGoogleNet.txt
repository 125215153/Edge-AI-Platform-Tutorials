I0122 19:14:41.375304 70150 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt
I0122 19:14:41.551424 70150 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 19:14:41.551930 70150 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24778440704, dev_info[0]: total=25620447232 free=24778440704
I0122 19:14:41.551941 70150 caffe_interface.cpp:493] Using GPUs 0
I0122 19:14:41.552222 70150 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 19:14:42.139788 70150 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt"
type: "SGD"
I0122 19:14:42.139899 70150 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt
I0122 19:14:42.140473 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 19:14:42.140502 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 19:14:42.140506 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 19:14:42.140508 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 19:14:42.141005 70150 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 19:14:42.141247 70150 layer_factory.hpp:77] Creating layer data
I0122 19:14:42.141350 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.142292 70150 net.cpp:94] Creating Layer data
I0122 19:14:42.142309 70150 net.cpp:409] data -> data
I0122 19:14:42.142320 70150 net.cpp:409] data -> label
I0122 19:14:42.143688 70189 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 19:14:42.143739 70189 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 19:14:42.143823 70150 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 19:14:42.143903 70150 data_layer.cpp:83] output data size: 128,3,32,32
I0122 19:14:42.151445 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.151490 70150 net.cpp:144] Setting up data
I0122 19:14:42.151497 70150 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 19:14:42.151501 70150 net.cpp:151] Top shape: 128 (128)
I0122 19:14:42.151504 70150 net.cpp:159] Memory required for data: 1573376
I0122 19:14:42.151509 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:14:42.151520 70150 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:14:42.151525 70150 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:14:42.151537 70150 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:14:42.153069 70150 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:14:42.153080 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153084 70150 net.cpp:159] Memory required for data: 51905024
I0122 19:14:42.153096 70150 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:14:42.153103 70150 net.cpp:94] Creating Layer conv1/bn1
I0122 19:14:42.153106 70150 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:14:42.153111 70150 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.153709 70150 net.cpp:144] Setting up conv1/bn1
I0122 19:14:42.153717 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153719 70150 net.cpp:159] Memory required for data: 102236672
I0122 19:14:42.153730 70150 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:14:42.153738 70150 net.cpp:94] Creating Layer conv1/relu1
I0122 19:14:42.153740 70150 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:14:42.153744 70150 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.153754 70150 net.cpp:144] Setting up conv1/relu1
I0122 19:14:42.153771 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153774 70150 net.cpp:159] Memory required for data: 152568320
I0122 19:14:42.153777 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.153784 70150 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.153785 70150 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:14:42.153790 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.153796 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.153823 70150 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.153828 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153832 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153836 70150 net.cpp:159] Memory required for data: 253231616
I0122 19:14:42.153838 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:14:42.153846 70150 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:14:42.153848 70150 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.153852 70150 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:14:42.154078 70150 net.cpp:144] Setting up inception_2a/1x1
I0122 19:14:42.154085 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.154088 70150 net.cpp:159] Memory required for data: 270008832
I0122 19:14:42.154094 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:14:42.154100 70150 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:14:42.154105 70150 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:14:42.154110 70150 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.155262 70150 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:14:42.155268 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.155270 70150 net.cpp:159] Memory required for data: 286786048
I0122 19:14:42.155277 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:14:42.155282 70150 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:14:42.155284 70150 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:14:42.155287 70150 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.155292 70150 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:14:42.155295 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.155297 70150 net.cpp:159] Memory required for data: 303563264
I0122 19:14:42.155299 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:14:42.155306 70150 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:14:42.155309 70150 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.155314 70150 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:14:42.156498 70150 net.cpp:144] Setting up inception_2a/3x3
I0122 19:14:42.156508 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.156512 70150 net.cpp:159] Memory required for data: 320340480
I0122 19:14:42.156518 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:14:42.156525 70150 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:14:42.156529 70150 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:14:42.156534 70150 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.157393 70150 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:14:42.157399 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.157403 70150 net.cpp:159] Memory required for data: 337117696
I0122 19:14:42.157414 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:14:42.157421 70150 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:14:42.157424 70150 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:14:42.157428 70150 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.157446 70150 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:14:42.157451 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.157470 70150 net.cpp:159] Memory required for data: 353894912
I0122 19:14:42.157472 70150 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:14:42.157477 70150 net.cpp:94] Creating Layer inception_2a/output
I0122 19:14:42.157480 70150 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:14:42.157485 70150 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:14:42.157488 70150 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:14:42.157507 70150 net.cpp:144] Setting up inception_2a/output
I0122 19:14:42.157513 70150 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:14:42.157516 70150 net.cpp:159] Memory required for data: 387449344
I0122 19:14:42.157518 70150 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.157522 70150 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.157526 70150 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:14:42.157531 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.157537 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.157565 70150 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.157570 70150 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:14:42.157575 70150 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:14:42.157577 70150 net.cpp:159] Memory required for data: 454558208
I0122 19:14:42.157580 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:14:42.157588 70150 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:14:42.157590 70150 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.157595 70150 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:14:42.157825 70150 net.cpp:144] Setting up inception_3a/1x1
I0122 19:14:42.157832 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.157835 70150 net.cpp:159] Memory required for data: 471335424
I0122 19:14:42.157840 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:14:42.157846 70150 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:14:42.157850 70150 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:14:42.157855 70150 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.158495 70150 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:14:42.158502 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.158506 70150 net.cpp:159] Memory required for data: 488112640
I0122 19:14:42.158514 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:14:42.158519 70150 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:14:42.158522 70150 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:14:42.158527 70150 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.158533 70150 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:14:42.158538 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.158541 70150 net.cpp:159] Memory required for data: 504889856
I0122 19:14:42.158545 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:14:42.158553 70150 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:14:42.158556 70150 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.158562 70150 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:14:42.158939 70150 net.cpp:144] Setting up inception_3a/3x3
I0122 19:14:42.158946 70150 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:14:42.158949 70150 net.cpp:159] Memory required for data: 530055680
I0122 19:14:42.158963 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:14:42.158970 70150 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:14:42.158973 70150 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:14:42.158978 70150 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.159631 70150 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:14:42.159637 70150 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:14:42.159641 70150 net.cpp:159] Memory required for data: 555221504
I0122 19:14:42.159651 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:14:42.159657 70150 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:14:42.159662 70150 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:14:42.159665 70150 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.159672 70150 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:14:42.159677 70150 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:14:42.159680 70150 net.cpp:159] Memory required for data: 580387328
I0122 19:14:42.159682 70150 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:14:42.159687 70150 net.cpp:94] Creating Layer inception_3a/output
I0122 19:14:42.159689 70150 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:14:42.159694 70150 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:14:42.159699 70150 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:14:42.159718 70150 net.cpp:144] Setting up inception_3a/output
I0122 19:14:42.159724 70150 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:14:42.159727 70150 net.cpp:159] Memory required for data: 622330368
I0122 19:14:42.159730 70150 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.159735 70150 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.159739 70150 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:14:42.159744 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.159750 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.159778 70150 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.159785 70150 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:14:42.159788 70150 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:14:42.159790 70150 net.cpp:159] Memory required for data: 706216448
I0122 19:14:42.159793 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:14:42.159801 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:14:42.159806 70150 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.159811 70150 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:14:42.160526 70150 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:14:42.160533 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.160537 70150 net.cpp:159] Memory required for data: 716702208
I0122 19:14:42.160543 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:14:42.160552 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:14:42.160557 70150 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:14:42.160563 70150 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.161218 70150 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:14:42.161224 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.161228 70150 net.cpp:159] Memory required for data: 727187968
I0122 19:14:42.161237 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:14:42.161240 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:14:42.161243 70150 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:14:42.161258 70150 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.161265 70150 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:14:42.161269 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.161272 70150 net.cpp:159] Memory required for data: 737673728
I0122 19:14:42.161274 70150 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:14:42.161281 70150 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:14:42.161284 70150 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.161290 70150 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:14:42.161331 70150 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:14:42.161339 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.161340 70150 net.cpp:159] Memory required for data: 748159488
I0122 19:14:42.161343 70150 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:14:42.161348 70150 net.cpp:94] Creating Layer downsample_4/output
I0122 19:14:42.161352 70150 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:14:42.161355 70150 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:14:42.161365 70150 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:14:42.161383 70150 net.cpp:144] Setting up downsample_4/output
I0122 19:14:42.161389 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.161392 70150 net.cpp:159] Memory required for data: 769131008
I0122 19:14:42.161396 70150 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.161399 70150 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.161402 70150 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:14:42.161408 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.161414 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.161443 70150 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.161450 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.161453 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.161458 70150 net.cpp:159] Memory required for data: 811074048
I0122 19:14:42.161460 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:14:42.161469 70150 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:14:42.161473 70150 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.161478 70150 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:14:42.161831 70150 net.cpp:144] Setting up inception_5a/1x1
I0122 19:14:42.161839 70150 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:14:42.161841 70150 net.cpp:159] Memory required for data: 825754112
I0122 19:14:42.161847 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:14:42.161855 70150 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:14:42.161861 70150 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:14:42.161866 70150 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.162623 70150 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:14:42.162631 70150 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:14:42.162634 70150 net.cpp:159] Memory required for data: 840434176
I0122 19:14:42.162642 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:14:42.162648 70150 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:14:42.162653 70150 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:14:42.162658 70150 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.162664 70150 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:14:42.162668 70150 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:14:42.162679 70150 net.cpp:159] Memory required for data: 855114240
I0122 19:14:42.162683 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:14:42.162691 70150 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:14:42.162696 70150 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.162703 70150 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:14:42.163427 70150 net.cpp:144] Setting up inception_5a/3x3
I0122 19:14:42.163435 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.163437 70150 net.cpp:159] Memory required for data: 861405696
I0122 19:14:42.163444 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:14:42.163453 70150 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:14:42.163460 70150 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:14:42.163465 70150 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.164132 70150 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:14:42.164140 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.164144 70150 net.cpp:159] Memory required for data: 867697152
I0122 19:14:42.164151 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:14:42.164160 70150 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:14:42.164165 70150 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:14:42.164170 70150 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.164175 70150 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:14:42.164180 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.164182 70150 net.cpp:159] Memory required for data: 873988608
I0122 19:14:42.164186 70150 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:14:42.164191 70150 net.cpp:94] Creating Layer inception_5a/output
I0122 19:14:42.164196 70150 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:14:42.164199 70150 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:14:42.164204 70150 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:14:42.164227 70150 net.cpp:144] Setting up inception_5a/output
I0122 19:14:42.164232 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.164235 70150 net.cpp:159] Memory required for data: 894960128
I0122 19:14:42.164237 70150 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.164242 70150 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.164245 70150 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:14:42.164252 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.164258 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.164288 70150 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.164294 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.164299 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.164301 70150 net.cpp:159] Memory required for data: 936903168
I0122 19:14:42.164304 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:14:42.164311 70150 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:14:42.164317 70150 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.164324 70150 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:14:42.165309 70150 net.cpp:144] Setting up inception_6a/1x1
I0122 19:14:42.165319 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.165323 70150 net.cpp:159] Memory required for data: 949486080
I0122 19:14:42.165328 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:14:42.165336 70150 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:14:42.165350 70150 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:14:42.165359 70150 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.166234 70150 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:14:42.166241 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.166244 70150 net.cpp:159] Memory required for data: 962068992
I0122 19:14:42.166254 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:14:42.166262 70150 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:14:42.166265 70150 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:14:42.166270 70150 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.166280 70150 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:14:42.166285 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.166288 70150 net.cpp:159] Memory required for data: 974651904
I0122 19:14:42.166290 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:14:42.166302 70150 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:14:42.166307 70150 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.166313 70150 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:14:42.167083 70150 net.cpp:144] Setting up inception_6a/3x3
I0122 19:14:42.167093 70150 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:14:42.167094 70150 net.cpp:159] Memory required for data: 983040512
I0122 19:14:42.167106 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:14:42.167117 70150 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:14:42.167122 70150 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:14:42.167130 70150 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.167791 70150 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:14:42.167798 70150 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:14:42.167801 70150 net.cpp:159] Memory required for data: 991429120
I0122 19:14:42.167809 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:14:42.167815 70150 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:14:42.167819 70150 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:14:42.167824 70150 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.167829 70150 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:14:42.167834 70150 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:14:42.167837 70150 net.cpp:159] Memory required for data: 999817728
I0122 19:14:42.167840 70150 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:14:42.167846 70150 net.cpp:94] Creating Layer inception_6a/output
I0122 19:14:42.167851 70150 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:14:42.167855 70150 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:14:42.167860 70150 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:14:42.167879 70150 net.cpp:144] Setting up inception_6a/output
I0122 19:14:42.167886 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.167887 70150 net.cpp:159] Memory required for data: 1020789248
I0122 19:14:42.167891 70150 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.167897 70150 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.167901 70150 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:14:42.167906 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.167912 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.167942 70150 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.167948 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.167960 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.167963 70150 net.cpp:159] Memory required for data: 1062732288
I0122 19:14:42.167965 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:14:42.167976 70150 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:14:42.167981 70150 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.167986 70150 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:14:42.168411 70150 net.cpp:144] Setting up inception_7a/1x1
I0122 19:14:42.168419 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.168423 70150 net.cpp:159] Memory required for data: 1073218048
I0122 19:14:42.168428 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:14:42.168437 70150 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:14:42.168439 70150 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:14:42.168445 70150 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.169121 70150 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:14:42.169127 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.169131 70150 net.cpp:159] Memory required for data: 1083703808
I0122 19:14:42.169138 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:14:42.169144 70150 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:14:42.169147 70150 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:14:42.169152 70150 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.169157 70150 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:14:42.169162 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.169164 70150 net.cpp:159] Memory required for data: 1094189568
I0122 19:14:42.169167 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:14:42.169178 70150 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:14:42.169185 70150 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.169193 70150 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:14:42.170140 70150 net.cpp:144] Setting up inception_7a/3x3
I0122 19:14:42.170148 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.170151 70150 net.cpp:159] Memory required for data: 1104675328
I0122 19:14:42.170156 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:14:42.170166 70150 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:14:42.170168 70150 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:14:42.170176 70150 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.171054 70150 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:14:42.171061 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.171063 70150 net.cpp:159] Memory required for data: 1115161088
I0122 19:14:42.171072 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:14:42.171077 70150 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:14:42.171080 70150 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:14:42.171087 70150 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.171092 70150 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:14:42.171098 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.171100 70150 net.cpp:159] Memory required for data: 1125646848
I0122 19:14:42.171103 70150 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:14:42.171108 70150 net.cpp:94] Creating Layer inception_7a/output
I0122 19:14:42.171111 70150 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:14:42.171115 70150 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:14:42.171120 70150 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:14:42.171144 70150 net.cpp:144] Setting up inception_7a/output
I0122 19:14:42.171150 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.171162 70150 net.cpp:159] Memory required for data: 1146618368
I0122 19:14:42.171165 70150 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.171172 70150 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.171175 70150 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:14:42.171191 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.171209 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.171241 70150 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.171245 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.171249 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.171252 70150 net.cpp:159] Memory required for data: 1188561408
I0122 19:14:42.171254 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:14:42.171264 70150 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:14:42.171268 70150 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.171274 70150 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:14:42.171552 70150 net.cpp:144] Setting up inception_8a/1x1
I0122 19:14:42.171560 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.171561 70150 net.cpp:159] Memory required for data: 1194852864
I0122 19:14:42.171566 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:14:42.171574 70150 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:14:42.171577 70150 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:14:42.171583 70150 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.172258 70150 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:14:42.172267 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.172269 70150 net.cpp:159] Memory required for data: 1201144320
I0122 19:14:42.172277 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:14:42.172281 70150 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:14:42.172286 70150 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:14:42.172291 70150 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.172297 70150 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:14:42.172300 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.172303 70150 net.cpp:159] Memory required for data: 1207435776
I0122 19:14:42.172307 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:14:42.172314 70150 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:14:42.172319 70150 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.172327 70150 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:14:42.174026 70150 net.cpp:144] Setting up inception_8a/3x3
I0122 19:14:42.174037 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.174041 70150 net.cpp:159] Memory required for data: 1220018688
I0122 19:14:42.174047 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:14:42.174057 70150 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:14:42.174062 70150 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:14:42.174070 70150 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.174759 70150 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:14:42.174767 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.174769 70150 net.cpp:159] Memory required for data: 1232601600
I0122 19:14:42.174777 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:14:42.174784 70150 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:14:42.174787 70150 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:14:42.174803 70150 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.174811 70150 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:14:42.174816 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.174819 70150 net.cpp:159] Memory required for data: 1245184512
I0122 19:14:42.174821 70150 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:14:42.174826 70150 net.cpp:94] Creating Layer inception_8a/output
I0122 19:14:42.174829 70150 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:14:42.174834 70150 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:14:42.174840 70150 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:14:42.174860 70150 net.cpp:144] Setting up inception_8a/output
I0122 19:14:42.174865 70150 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:14:42.174868 70150 net.cpp:159] Memory required for data: 1264058880
I0122 19:14:42.174870 70150 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.174875 70150 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.174880 70150 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:14:42.174887 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.174896 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.174926 70150 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.174932 70150 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:14:42.174935 70150 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:14:42.174938 70150 net.cpp:159] Memory required for data: 1301807616
I0122 19:14:42.174940 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:14:42.174950 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:14:42.174955 70150 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.174962 70150 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:14:42.175921 70150 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:14:42.175930 70150 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:14:42.175933 70150 net.cpp:159] Memory required for data: 1304953344
I0122 19:14:42.175938 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:14:42.175947 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:14:42.175953 70150 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:14:42.175961 70150 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.176642 70150 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:14:42.176650 70150 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:14:42.176652 70150 net.cpp:159] Memory required for data: 1308099072
I0122 19:14:42.176661 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:14:42.176666 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:14:42.176668 70150 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:14:42.176676 70150 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.176683 70150 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:14:42.176687 70150 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:14:42.176690 70150 net.cpp:159] Memory required for data: 1311244800
I0122 19:14:42.176693 70150 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:14:42.176698 70150 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:14:42.176702 70150 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.176708 70150 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:14:42.176740 70150 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:14:42.176757 70150 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 19:14:42.176760 70150 net.cpp:159] Memory required for data: 1315963392
I0122 19:14:42.176764 70150 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:14:42.176769 70150 net.cpp:94] Creating Layer downsample_9/output
I0122 19:14:42.176771 70150 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:14:42.176775 70150 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:14:42.176781 70150 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:14:42.176800 70150 net.cpp:144] Setting up downsample_9/output
I0122 19:14:42.176805 70150 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:14:42.176807 70150 net.cpp:159] Memory required for data: 1323827712
I0122 19:14:42.176810 70150 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.176821 70150 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.176826 70150 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:14:42.176831 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.176837 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.176868 70150 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.176874 70150 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:14:42.176877 70150 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:14:42.176880 70150 net.cpp:159] Memory required for data: 1339556352
I0122 19:14:42.176884 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:14:42.176893 70150 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:14:42.176898 70150 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.176905 70150 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:14:42.177371 70150 net.cpp:144] Setting up inception_10a/1x1
I0122 19:14:42.177378 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.177381 70150 net.cpp:159] Memory required for data: 1345323520
I0122 19:14:42.177386 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:14:42.177393 70150 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:14:42.177398 70150 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:14:42.177405 70150 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.178077 70150 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:14:42.178086 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.178088 70150 net.cpp:159] Memory required for data: 1351090688
I0122 19:14:42.178095 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:14:42.178102 70150 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:14:42.178104 70150 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:14:42.178109 70150 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.178115 70150 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:14:42.178120 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.178124 70150 net.cpp:159] Memory required for data: 1356857856
I0122 19:14:42.178126 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:14:42.178134 70150 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:14:42.178138 70150 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.178144 70150 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:14:42.181342 70150 net.cpp:144] Setting up inception_10a/3x3
I0122 19:14:42.181354 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.181357 70150 net.cpp:159] Memory required for data: 1362100736
I0122 19:14:42.181362 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:14:42.181381 70150 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:14:42.181385 70150 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:14:42.181391 70150 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.182055 70150 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:14:42.182063 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.182066 70150 net.cpp:159] Memory required for data: 1367343616
I0122 19:14:42.182075 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:14:42.182081 70150 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:14:42.182086 70150 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:14:42.182091 70150 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.182098 70150 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:14:42.182104 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.182107 70150 net.cpp:159] Memory required for data: 1372586496
I0122 19:14:42.182109 70150 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:14:42.182116 70150 net.cpp:94] Creating Layer inception_10a/output
I0122 19:14:42.182119 70150 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:14:42.182122 70150 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:14:42.182127 70150 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:14:42.182147 70150 net.cpp:144] Setting up inception_10a/output
I0122 19:14:42.182152 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.182155 70150 net.cpp:159] Memory required for data: 1383596544
I0122 19:14:42.182158 70150 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.182163 70150 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.182168 70150 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:14:42.182173 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.182178 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.182206 70150 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.182212 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.182216 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.182219 70150 net.cpp:159] Memory required for data: 1405616640
I0122 19:14:42.182221 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:14:42.182231 70150 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:14:42.182236 70150 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.182241 70150 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:14:42.182804 70150 net.cpp:144] Setting up inception_11a/1x1
I0122 19:14:42.182811 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.182814 70150 net.cpp:159] Memory required for data: 1411383808
I0122 19:14:42.182821 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:14:42.182828 70150 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:14:42.182833 70150 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:14:42.182840 70150 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.183512 70150 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:14:42.183519 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.183522 70150 net.cpp:159] Memory required for data: 1417150976
I0122 19:14:42.183531 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:14:42.183534 70150 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:14:42.183537 70150 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:14:42.183553 70150 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.183560 70150 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:14:42.183564 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.183568 70150 net.cpp:159] Memory required for data: 1422918144
I0122 19:14:42.183570 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:14:42.183579 70150 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:14:42.183584 70150 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.183590 70150 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:14:42.187325 70150 net.cpp:144] Setting up inception_11a/3x3
I0122 19:14:42.187336 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.187340 70150 net.cpp:159] Memory required for data: 1428161024
I0122 19:14:42.187345 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:14:42.187368 70150 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:14:42.187371 70150 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:14:42.187378 70150 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.188063 70150 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:14:42.188072 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.188076 70150 net.cpp:159] Memory required for data: 1433403904
I0122 19:14:42.188096 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:14:42.188102 70150 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:14:42.188107 70150 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:14:42.188110 70150 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.188117 70150 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:14:42.188120 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.188123 70150 net.cpp:159] Memory required for data: 1438646784
I0122 19:14:42.188127 70150 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:14:42.188133 70150 net.cpp:94] Creating Layer inception_11a/output
I0122 19:14:42.188138 70150 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:14:42.188141 70150 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:14:42.188146 70150 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:14:42.188165 70150 net.cpp:144] Setting up inception_11a/output
I0122 19:14:42.188170 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.188174 70150 net.cpp:159] Memory required for data: 1449656832
I0122 19:14:42.188175 70150 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:14:42.188181 70150 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:14:42.188184 70150 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:14:42.188191 70150 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:14:42.188215 70150 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:14:42.188220 70150 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:14:42.188223 70150 net.cpp:159] Memory required for data: 1449828864
I0122 19:14:42.188226 70150 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:14:42.188231 70150 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:14:42.188235 70150 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:14:42.188239 70150 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:14:42.188257 70150 net.cpp:144] Setting up drop_8x8_s1
I0122 19:14:42.188264 70150 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:14:42.188266 70150 net.cpp:159] Memory required for data: 1450000896
I0122 19:14:42.188269 70150 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:14:42.188275 70150 net.cpp:94] Creating Layer loss/classifier
I0122 19:14:42.188280 70150 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:14:42.188287 70150 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:14:42.188424 70150 net.cpp:144] Setting up loss/classifier
I0122 19:14:42.188439 70150 net.cpp:151] Top shape: 128 10 (1280)
I0122 19:14:42.188442 70150 net.cpp:159] Memory required for data: 1450006016
I0122 19:14:42.188447 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.188453 70150 net.cpp:94] Creating Layer loss
I0122 19:14:42.188459 70150 net.cpp:435] loss <- loss/classifier
I0122 19:14:42.188462 70150 net.cpp:435] loss <- label
I0122 19:14:42.188467 70150 net.cpp:409] loss -> loss
I0122 19:14:42.188474 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.188550 70150 net.cpp:144] Setting up loss
I0122 19:14:42.188556 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.188560 70150 net.cpp:154]     with loss weight 1
I0122 19:14:42.188568 70150 net.cpp:159] Memory required for data: 1450006020
I0122 19:14:42.188572 70150 net.cpp:220] loss needs backward computation.
I0122 19:14:42.188580 70150 net.cpp:220] loss/classifier needs backward computation.
I0122 19:14:42.188583 70150 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:14:42.188586 70150 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:14:42.188591 70150 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:14:42.188593 70150 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:14:42.188596 70150 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:14:42.188598 70150 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:14:42.188602 70150 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:14:42.188604 70150 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:14:42.188607 70150 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:14:42.188611 70150 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:14:42.188614 70150 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:14:42.188617 70150 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:14:42.188621 70150 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:14:42.188623 70150 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:14:42.188627 70150 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:14:42.188629 70150 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:14:42.188632 70150 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:14:42.188635 70150 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:14:42.188639 70150 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:14:42.188642 70150 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:14:42.188645 70150 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.188648 70150 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.188652 70150 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:14:42.188654 70150 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:14:42.188657 70150 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:14:42.188661 70150 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:14:42.188664 70150 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:14:42.188668 70150 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:14:42.188670 70150 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:14:42.188673 70150 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:14:42.188678 70150 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:14:42.188680 70150 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:14:42.188683 70150 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:14:42.188688 70150 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:14:42.188697 70150 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:14:42.188700 70150 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:14:42.188704 70150 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:14:42.188706 70150 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:14:42.188710 70150 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:14:42.188714 70150 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:14:42.188717 70150 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:14:42.188721 70150 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:14:42.188724 70150 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:14:42.188729 70150 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:14:42.188730 70150 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:14:42.188733 70150 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:14:42.188737 70150 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:14:42.188740 70150 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:14:42.188743 70150 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:14:42.188747 70150 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:14:42.188750 70150 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:14:42.188753 70150 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:14:42.188756 70150 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:14:42.188760 70150 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:14:42.188762 70150 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:14:42.188766 70150 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:14:42.188769 70150 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:14:42.188773 70150 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:14:42.188777 70150 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.188779 70150 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.188782 70150 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:14:42.188787 70150 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:14:42.188791 70150 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:14:42.188796 70150 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:14:42.188798 70150 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:14:42.188800 70150 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:14:42.188804 70150 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:14:42.188807 70150 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:14:42.188810 70150 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:14:42.188813 70150 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:14:42.188817 70150 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:14:42.188820 70150 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:14:42.188823 70150 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:14:42.188827 70150 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:14:42.188829 70150 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:14:42.188832 70150 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:14:42.188835 70150 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:14:42.188838 70150 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:14:42.188848 70150 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:14:42.188851 70150 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:14:42.188853 70150 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:14:42.188858 70150 net.cpp:222] data does not need backward computation.
I0122 19:14:42.188861 70150 net.cpp:264] This network produces output loss
I0122 19:14:42.188923 70150 net.cpp:284] Network initialization done.
I0122 19:14:42.189815 70150 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt
I0122 19:14:42.189896 70150 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 19:14:42.190554 70150 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 19:14:42.190876 70150 layer_factory.hpp:77] Creating layer data
I0122 19:14:42.190917 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.191743 70150 net.cpp:94] Creating Layer data
I0122 19:14:42.191753 70150 net.cpp:409] data -> data
I0122 19:14:42.191761 70150 net.cpp:409] data -> label
I0122 19:14:42.192740 70219 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 19:14:42.192773 70219 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 19:14:42.192869 70150 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 19:14:42.192966 70150 data_layer.cpp:83] output data size: 50,3,32,32
I0122 19:14:42.195981 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.196034 70150 net.cpp:144] Setting up data
I0122 19:14:42.196043 70150 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 19:14:42.196045 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196048 70150 net.cpp:159] Memory required for data: 614600
I0122 19:14:42.196051 70150 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 19:14:42.196059 70150 net.cpp:94] Creating Layer label_data_1_split
I0122 19:14:42.196066 70150 net.cpp:435] label_data_1_split <- label
I0122 19:14:42.196074 70150 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 19:14:42.196081 70150 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 19:14:42.196090 70150 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 19:14:42.196096 70150 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 19:14:42.196207 70150 net.cpp:144] Setting up label_data_1_split
I0122 19:14:42.196213 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196216 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196219 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196223 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196224 70150 net.cpp:159] Memory required for data: 615400
I0122 19:14:42.196228 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:14:42.196238 70150 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:14:42.196243 70150 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:14:42.196249 70150 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:14:42.196609 70150 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:14:42.196614 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.196617 70150 net.cpp:159] Memory required for data: 20276200
I0122 19:14:42.196625 70150 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:14:42.196633 70150 net.cpp:94] Creating Layer conv1/bn1
I0122 19:14:42.196636 70150 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:14:42.196651 70150 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.197336 70150 net.cpp:144] Setting up conv1/bn1
I0122 19:14:42.197346 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197348 70150 net.cpp:159] Memory required for data: 39937000
I0122 19:14:42.197360 70150 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:14:42.197366 70150 net.cpp:94] Creating Layer conv1/relu1
I0122 19:14:42.197371 70150 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:14:42.197376 70150 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.197381 70150 net.cpp:144] Setting up conv1/relu1
I0122 19:14:42.197384 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197387 70150 net.cpp:159] Memory required for data: 59597800
I0122 19:14:42.197389 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.197394 70150 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.197397 70150 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:14:42.197402 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.197408 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.197439 70150 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.197444 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197449 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197451 70150 net.cpp:159] Memory required for data: 98919400
I0122 19:14:42.197453 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:14:42.197461 70150 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:14:42.197468 70150 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.197474 70150 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:14:42.198083 70150 net.cpp:144] Setting up inception_2a/1x1
I0122 19:14:42.198091 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.198094 70150 net.cpp:159] Memory required for data: 105473000
I0122 19:14:42.198102 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:14:42.198109 70150 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:14:42.198114 70150 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:14:42.198122 70150 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.198987 70150 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:14:42.198994 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.198997 70150 net.cpp:159] Memory required for data: 112026600
I0122 19:14:42.199005 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:14:42.199012 70150 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:14:42.199017 70150 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:14:42.199023 70150 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.199029 70150 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:14:42.199035 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.199038 70150 net.cpp:159] Memory required for data: 118580200
I0122 19:14:42.199040 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:14:42.199049 70150 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:14:42.199054 70150 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.199061 70150 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:14:42.199514 70150 net.cpp:144] Setting up inception_2a/3x3
I0122 19:14:42.199522 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.199525 70150 net.cpp:159] Memory required for data: 125133800
I0122 19:14:42.199530 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:14:42.199537 70150 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:14:42.199542 70150 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:14:42.199558 70150 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.200270 70150 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:14:42.200278 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.200282 70150 net.cpp:159] Memory required for data: 131687400
I0122 19:14:42.200294 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:14:42.200306 70150 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:14:42.200312 70150 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:14:42.200317 70150 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.200323 70150 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:14:42.200326 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.200330 70150 net.cpp:159] Memory required for data: 138241000
I0122 19:14:42.200332 70150 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:14:42.200337 70150 net.cpp:94] Creating Layer inception_2a/output
I0122 19:14:42.200340 70150 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:14:42.200343 70150 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:14:42.200350 70150 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:14:42.200371 70150 net.cpp:144] Setting up inception_2a/output
I0122 19:14:42.200376 70150 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:42.200378 70150 net.cpp:159] Memory required for data: 151348200
I0122 19:14:42.200381 70150 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.200387 70150 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.200389 70150 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:14:42.200395 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.200402 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.200438 70150 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.200443 70150 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:42.200448 70150 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:42.200450 70150 net.cpp:159] Memory required for data: 177562600
I0122 19:14:42.200454 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:14:42.200464 70150 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:14:42.200467 70150 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.200476 70150 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:14:42.200803 70150 net.cpp:144] Setting up inception_3a/1x1
I0122 19:14:42.200810 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.200814 70150 net.cpp:159] Memory required for data: 184116200
I0122 19:14:42.200819 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:14:42.200827 70150 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:14:42.200830 70150 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:14:42.200837 70150 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.201571 70150 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:14:42.201577 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.201581 70150 net.cpp:159] Memory required for data: 190669800
I0122 19:14:42.201587 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:14:42.201596 70150 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:14:42.201601 70150 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:14:42.201607 70150 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.201613 70150 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:14:42.201622 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.201625 70150 net.cpp:159] Memory required for data: 197223400
I0122 19:14:42.201637 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:14:42.201647 70150 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:14:42.201651 70150 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.201658 70150 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:14:42.202730 70150 net.cpp:144] Setting up inception_3a/3x3
I0122 19:14:42.202744 70150 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:42.202747 70150 net.cpp:159] Memory required for data: 207053800
I0122 19:14:42.202754 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:14:42.202761 70150 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:14:42.202767 70150 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:14:42.202776 70150 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.203550 70150 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:14:42.203557 70150 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:42.203559 70150 net.cpp:159] Memory required for data: 216884200
I0122 19:14:42.203573 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:14:42.203583 70150 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:14:42.203585 70150 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:14:42.203591 70150 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.203598 70150 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:14:42.203606 70150 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:42.203609 70150 net.cpp:159] Memory required for data: 226714600
I0122 19:14:42.203613 70150 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:14:42.203629 70150 net.cpp:94] Creating Layer inception_3a/output
I0122 19:14:42.203634 70150 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:14:42.203637 70150 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:14:42.203641 70150 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:14:42.203716 70150 net.cpp:144] Setting up inception_3a/output
I0122 19:14:42.203722 70150 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:42.203724 70150 net.cpp:159] Memory required for data: 243098600
I0122 19:14:42.203727 70150 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.203733 70150 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.203737 70150 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:14:42.203742 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.203748 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.203780 70150 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.203785 70150 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:42.203789 70150 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:42.203791 70150 net.cpp:159] Memory required for data: 275866600
I0122 19:14:42.203794 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:14:42.203804 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:14:42.203807 70150 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.203814 70150 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:14:42.204380 70150 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:14:42.204387 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.204390 70150 net.cpp:159] Memory required for data: 279962600
I0122 19:14:42.204394 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:14:42.204402 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:14:42.204406 70150 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:14:42.204425 70150 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.205252 70150 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:14:42.205260 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.205262 70150 net.cpp:159] Memory required for data: 284058600
I0122 19:14:42.205271 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:14:42.205279 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:14:42.205283 70150 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:14:42.205287 70150 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.205293 70150 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:14:42.205299 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.205303 70150 net.cpp:159] Memory required for data: 288154600
I0122 19:14:42.205305 70150 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:14:42.205312 70150 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:14:42.205315 70150 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.205320 70150 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:14:42.205360 70150 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:14:42.205365 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.205368 70150 net.cpp:159] Memory required for data: 292250600
I0122 19:14:42.205371 70150 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:14:42.205379 70150 net.cpp:94] Creating Layer downsample_4/output
I0122 19:14:42.205382 70150 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:14:42.205385 70150 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:14:42.205391 70150 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:14:42.205422 70150 net.cpp:144] Setting up downsample_4/output
I0122 19:14:42.205427 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.205430 70150 net.cpp:159] Memory required for data: 300442600
I0122 19:14:42.205433 70150 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.205440 70150 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.205443 70150 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:14:42.205447 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.205454 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.205484 70150 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.205489 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.205493 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.205497 70150 net.cpp:159] Memory required for data: 316826600
I0122 19:14:42.205498 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:14:42.205508 70150 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:14:42.205513 70150 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.205518 70150 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:14:42.205868 70150 net.cpp:144] Setting up inception_5a/1x1
I0122 19:14:42.205874 70150 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:42.205878 70150 net.cpp:159] Memory required for data: 322561000
I0122 19:14:42.205883 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:14:42.205890 70150 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:14:42.205893 70150 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:14:42.205899 70150 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.206701 70150 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:14:42.206717 70150 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:42.206718 70150 net.cpp:159] Memory required for data: 328295400
I0122 19:14:42.206727 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:14:42.206733 70150 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:14:42.206745 70150 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:14:42.206753 70150 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.206758 70150 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:14:42.206768 70150 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:42.206769 70150 net.cpp:159] Memory required for data: 334029800
I0122 19:14:42.206773 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:14:42.206781 70150 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:14:42.206787 70150 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.206794 70150 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:14:42.207470 70150 net.cpp:144] Setting up inception_5a/3x3
I0122 19:14:42.207478 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.207481 70150 net.cpp:159] Memory required for data: 336487400
I0122 19:14:42.207486 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:14:42.207499 70150 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:14:42.207505 70150 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:14:42.207514 70150 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.208293 70150 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:14:42.208299 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.208302 70150 net.cpp:159] Memory required for data: 338945000
I0122 19:14:42.208310 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:14:42.208315 70150 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:14:42.208318 70150 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:14:42.208334 70150 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.208340 70150 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:14:42.208354 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.208357 70150 net.cpp:159] Memory required for data: 341402600
I0122 19:14:42.208359 70150 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:14:42.208364 70150 net.cpp:94] Creating Layer inception_5a/output
I0122 19:14:42.208367 70150 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:14:42.208370 70150 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:14:42.208377 70150 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:14:42.208401 70150 net.cpp:144] Setting up inception_5a/output
I0122 19:14:42.208406 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.208410 70150 net.cpp:159] Memory required for data: 349594600
I0122 19:14:42.208411 70150 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.208417 70150 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.208421 70150 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:14:42.208426 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.208436 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.208508 70150 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.208514 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.208518 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.208520 70150 net.cpp:159] Memory required for data: 365978600
I0122 19:14:42.208523 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:14:42.208541 70150 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:14:42.208544 70150 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.208551 70150 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:14:42.208897 70150 net.cpp:144] Setting up inception_6a/1x1
I0122 19:14:42.208904 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.208906 70150 net.cpp:159] Memory required for data: 370893800
I0122 19:14:42.208911 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:14:42.208921 70150 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:14:42.208925 70150 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:14:42.208930 70150 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.209705 70150 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:14:42.209713 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.209715 70150 net.cpp:159] Memory required for data: 375809000
I0122 19:14:42.209723 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:14:42.209729 70150 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:14:42.209733 70150 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:14:42.209738 70150 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.209744 70150 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:14:42.209748 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.209751 70150 net.cpp:159] Memory required for data: 380724200
I0122 19:14:42.209753 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:14:42.209762 70150 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:14:42.209769 70150 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.209774 70150 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:14:42.211207 70150 net.cpp:144] Setting up inception_6a/3x3
I0122 19:14:42.211220 70150 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:42.211223 70150 net.cpp:159] Memory required for data: 384001000
I0122 19:14:42.211236 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:14:42.211246 70150 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:14:42.211256 70150 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:14:42.211262 70150 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.212087 70150 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:14:42.212095 70150 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:42.212098 70150 net.cpp:159] Memory required for data: 387277800
I0122 19:14:42.212106 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:14:42.212112 70150 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:14:42.212116 70150 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:14:42.212121 70150 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.212128 70150 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:14:42.212134 70150 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:42.212137 70150 net.cpp:159] Memory required for data: 390554600
I0122 19:14:42.212141 70150 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:14:42.212146 70150 net.cpp:94] Creating Layer inception_6a/output
I0122 19:14:42.212148 70150 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:14:42.212152 70150 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:14:42.212158 70150 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:14:42.212177 70150 net.cpp:144] Setting up inception_6a/output
I0122 19:14:42.212183 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.212186 70150 net.cpp:159] Memory required for data: 398746600
I0122 19:14:42.212189 70150 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.212193 70150 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.212206 70150 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:14:42.212213 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.212220 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.212251 70150 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.212258 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.212262 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.212265 70150 net.cpp:159] Memory required for data: 415130600
I0122 19:14:42.212267 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:14:42.212276 70150 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:14:42.212280 70150 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.212285 70150 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:14:42.212599 70150 net.cpp:144] Setting up inception_7a/1x1
I0122 19:14:42.212605 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.212607 70150 net.cpp:159] Memory required for data: 419226600
I0122 19:14:42.212612 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:14:42.212620 70150 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:14:42.212625 70150 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:14:42.212632 70150 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.213335 70150 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:14:42.213342 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.213346 70150 net.cpp:159] Memory required for data: 423322600
I0122 19:14:42.213353 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:14:42.213361 70150 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:14:42.213364 70150 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:14:42.213369 70150 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.213376 70150 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:14:42.213378 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.213382 70150 net.cpp:159] Memory required for data: 427418600
I0122 19:14:42.213384 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:14:42.213392 70150 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:14:42.213397 70150 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.213403 70150 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:14:42.214288 70150 net.cpp:144] Setting up inception_7a/3x3
I0122 19:14:42.214298 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.214300 70150 net.cpp:159] Memory required for data: 431514600
I0122 19:14:42.214305 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:14:42.214313 70150 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:14:42.214316 70150 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:14:42.214323 70150 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.215016 70150 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:14:42.215025 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.215029 70150 net.cpp:159] Memory required for data: 435610600
I0122 19:14:42.215036 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:14:42.215040 70150 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:14:42.215044 70150 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:14:42.215049 70150 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.215054 70150 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:14:42.215059 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.215061 70150 net.cpp:159] Memory required for data: 439706600
I0122 19:14:42.215073 70150 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:14:42.215080 70150 net.cpp:94] Creating Layer inception_7a/output
I0122 19:14:42.215081 70150 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:14:42.215086 70150 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:14:42.215090 70150 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:14:42.215114 70150 net.cpp:144] Setting up inception_7a/output
I0122 19:14:42.215119 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.215123 70150 net.cpp:159] Memory required for data: 447898600
I0122 19:14:42.215126 70150 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.215131 70150 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.215134 70150 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:14:42.215139 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.215147 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.215178 70150 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.215184 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.215188 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.215190 70150 net.cpp:159] Memory required for data: 464282600
I0122 19:14:42.215193 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:14:42.215201 70150 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:14:42.215206 70150 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.215212 70150 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:14:42.215497 70150 net.cpp:144] Setting up inception_8a/1x1
I0122 19:14:42.215502 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.215507 70150 net.cpp:159] Memory required for data: 466740200
I0122 19:14:42.215510 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:14:42.215518 70150 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:14:42.215521 70150 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:14:42.215528 70150 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.216217 70150 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:14:42.216223 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.216226 70150 net.cpp:159] Memory required for data: 469197800
I0122 19:14:42.216234 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:14:42.216238 70150 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:14:42.216241 70150 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:14:42.216248 70150 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.216258 70150 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:14:42.216260 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.216264 70150 net.cpp:159] Memory required for data: 471655400
I0122 19:14:42.216265 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:14:42.216274 70150 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:14:42.216277 70150 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.216284 70150 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:14:42.217921 70150 net.cpp:144] Setting up inception_8a/3x3
I0122 19:14:42.217931 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.217934 70150 net.cpp:159] Memory required for data: 476570600
I0122 19:14:42.217939 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:14:42.217948 70150 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:14:42.217952 70150 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:14:42.217968 70150 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.218691 70150 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:14:42.218698 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.218703 70150 net.cpp:159] Memory required for data: 481485800
I0122 19:14:42.218709 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:14:42.218716 70150 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:14:42.218719 70150 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:14:42.218725 70150 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.218732 70150 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:14:42.218737 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.218740 70150 net.cpp:159] Memory required for data: 486401000
I0122 19:14:42.218744 70150 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:14:42.218749 70150 net.cpp:94] Creating Layer inception_8a/output
I0122 19:14:42.218750 70150 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:14:42.218755 70150 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:14:42.218761 70150 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:14:42.218780 70150 net.cpp:144] Setting up inception_8a/output
I0122 19:14:42.218786 70150 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:42.218788 70150 net.cpp:159] Memory required for data: 493773800
I0122 19:14:42.218792 70150 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.218796 70150 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.218799 70150 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:14:42.218806 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.218812 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.218842 70150 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.218847 70150 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:42.218852 70150 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:42.218855 70150 net.cpp:159] Memory required for data: 508519400
I0122 19:14:42.218858 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:14:42.218866 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:14:42.218871 70150 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.218878 70150 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:14:42.220443 70150 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:14:42.220453 70150 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:42.220455 70150 net.cpp:159] Memory required for data: 509748200
I0122 19:14:42.220461 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:14:42.220469 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:14:42.220474 70150 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:14:42.220479 70150 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.221211 70150 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:14:42.221218 70150 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:42.221222 70150 net.cpp:159] Memory required for data: 510977000
I0122 19:14:42.221230 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:14:42.221235 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:14:42.221238 70150 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:14:42.221244 70150 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.221251 70150 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:14:42.221264 70150 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:42.221266 70150 net.cpp:159] Memory required for data: 512205800
I0122 19:14:42.221269 70150 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:14:42.221276 70150 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:14:42.221282 70150 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.221287 70150 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:14:42.221320 70150 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:14:42.221326 70150 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 19:14:42.221329 70150 net.cpp:159] Memory required for data: 514049000
I0122 19:14:42.221333 70150 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:14:42.221341 70150 net.cpp:94] Creating Layer downsample_9/output
I0122 19:14:42.221345 70150 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:14:42.221350 70150 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:14:42.221355 70150 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:14:42.221372 70150 net.cpp:144] Setting up downsample_9/output
I0122 19:14:42.221377 70150 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:42.221381 70150 net.cpp:159] Memory required for data: 517121000
I0122 19:14:42.221385 70150 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.221390 70150 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.221392 70150 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:14:42.221398 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.221405 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.221436 70150 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.221442 70150 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:42.221446 70150 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:42.221448 70150 net.cpp:159] Memory required for data: 523265000
I0122 19:14:42.221451 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:14:42.221460 70150 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:14:42.221465 70150 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.221472 70150 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:14:42.221956 70150 net.cpp:144] Setting up inception_10a/1x1
I0122 19:14:42.221963 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.221967 70150 net.cpp:159] Memory required for data: 525517800
I0122 19:14:42.221972 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:14:42.221981 70150 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:14:42.221984 70150 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:14:42.221992 70150 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.222699 70150 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:14:42.222707 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.222709 70150 net.cpp:159] Memory required for data: 527770600
I0122 19:14:42.222718 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:14:42.222723 70150 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:14:42.222729 70150 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:14:42.222734 70150 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.222743 70150 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:14:42.222748 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.222750 70150 net.cpp:159] Memory required for data: 530023400
I0122 19:14:42.222754 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:14:42.222770 70150 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:14:42.222775 70150 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.222782 70150 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:14:42.225301 70150 net.cpp:144] Setting up inception_10a/3x3
I0122 19:14:42.225311 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.225313 70150 net.cpp:159] Memory required for data: 532071400
I0122 19:14:42.225318 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:14:42.225325 70150 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:14:42.225329 70150 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:14:42.225335 70150 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.226068 70150 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:14:42.226075 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.226079 70150 net.cpp:159] Memory required for data: 534119400
I0122 19:14:42.226088 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:14:42.226092 70150 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:14:42.226095 70150 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:14:42.226101 70150 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.226109 70150 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:14:42.226114 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.226116 70150 net.cpp:159] Memory required for data: 536167400
I0122 19:14:42.226119 70150 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:14:42.226125 70150 net.cpp:94] Creating Layer inception_10a/output
I0122 19:14:42.226127 70150 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:14:42.226130 70150 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:14:42.226138 70150 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:14:42.226161 70150 net.cpp:144] Setting up inception_10a/output
I0122 19:14:42.226166 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.226171 70150 net.cpp:159] Memory required for data: 540468200
I0122 19:14:42.226173 70150 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.226178 70150 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.226181 70150 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:14:42.226186 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.226193 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.226225 70150 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.226231 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.226234 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.226238 70150 net.cpp:159] Memory required for data: 549069800
I0122 19:14:42.226240 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:14:42.226248 70150 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:14:42.226251 70150 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.226258 70150 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:14:42.226835 70150 net.cpp:144] Setting up inception_11a/1x1
I0122 19:14:42.226842 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.226845 70150 net.cpp:159] Memory required for data: 551322600
I0122 19:14:42.226851 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:14:42.226860 70150 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:14:42.226864 70150 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:14:42.226871 70150 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.227596 70150 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:14:42.227602 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.227605 70150 net.cpp:159] Memory required for data: 553575400
I0122 19:14:42.227613 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:14:42.227619 70150 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:14:42.227622 70150 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:14:42.227628 70150 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.227634 70150 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:14:42.227640 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.227643 70150 net.cpp:159] Memory required for data: 555828200
I0122 19:14:42.227645 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:14:42.227654 70150 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:14:42.227659 70150 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.227666 70150 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:14:42.231405 70150 net.cpp:144] Setting up inception_11a/3x3
I0122 19:14:42.231416 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.231420 70150 net.cpp:159] Memory required for data: 557876200
I0122 19:14:42.231425 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:14:42.231432 70150 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:14:42.231436 70150 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:14:42.231441 70150 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.232162 70150 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:14:42.232169 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.232173 70150 net.cpp:159] Memory required for data: 559924200
I0122 19:14:42.232197 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:14:42.232204 70150 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:14:42.232208 70150 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:14:42.232213 70150 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.232219 70150 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:14:42.232223 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.232225 70150 net.cpp:159] Memory required for data: 561972200
I0122 19:14:42.232228 70150 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:14:42.232234 70150 net.cpp:94] Creating Layer inception_11a/output
I0122 19:14:42.232235 70150 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:14:42.232239 70150 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:14:42.232246 70150 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:14:42.232265 70150 net.cpp:144] Setting up inception_11a/output
I0122 19:14:42.232271 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.232273 70150 net.cpp:159] Memory required for data: 566273000
I0122 19:14:42.232276 70150 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:14:42.232283 70150 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:14:42.232286 70150 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:14:42.232292 70150 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:14:42.232311 70150 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:14:42.232317 70150 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:14:42.232319 70150 net.cpp:159] Memory required for data: 566340200
I0122 19:14:42.232322 70150 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:14:42.232328 70150 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:14:42.232332 70150 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:14:42.232338 70150 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:14:42.232359 70150 net.cpp:144] Setting up drop_8x8_s1
I0122 19:14:42.232363 70150 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:14:42.232376 70150 net.cpp:159] Memory required for data: 566407400
I0122 19:14:42.232379 70150 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:14:42.232386 70150 net.cpp:94] Creating Layer loss/classifier
I0122 19:14:42.232389 70150 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:14:42.232395 70150 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:14:42.232544 70150 net.cpp:144] Setting up loss/classifier
I0122 19:14:42.232550 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232553 70150 net.cpp:159] Memory required for data: 566409400
I0122 19:14:42.232558 70150 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 19:14:42.232564 70150 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 19:14:42.232568 70150 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 19:14:42.232573 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 19:14:42.232579 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 19:14:42.232586 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 19:14:42.232592 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 19:14:42.232646 70150 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 19:14:42.232651 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232655 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232657 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232661 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232663 70150 net.cpp:159] Memory required for data: 566417400
I0122 19:14:42.232666 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.232671 70150 net.cpp:94] Creating Layer loss
I0122 19:14:42.232673 70150 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 19:14:42.232677 70150 net.cpp:435] loss <- label_data_1_split_0
I0122 19:14:42.232683 70150 net.cpp:409] loss -> loss
I0122 19:14:42.232690 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.232772 70150 net.cpp:144] Setting up loss
I0122 19:14:42.232777 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232780 70150 net.cpp:154]     with loss weight 1
I0122 19:14:42.232791 70150 net.cpp:159] Memory required for data: 566417404
I0122 19:14:42.232795 70150 layer_factory.hpp:77] Creating layer accuracy
I0122 19:14:42.232800 70150 net.cpp:94] Creating Layer accuracy
I0122 19:14:42.232803 70150 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 19:14:42.232807 70150 net.cpp:435] accuracy <- label_data_1_split_1
I0122 19:14:42.232813 70150 net.cpp:409] accuracy -> accuracy
I0122 19:14:42.232825 70150 net.cpp:144] Setting up accuracy
I0122 19:14:42.232831 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232834 70150 net.cpp:159] Memory required for data: 566417408
I0122 19:14:42.232836 70150 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 19:14:42.232841 70150 net.cpp:94] Creating Layer accuracy-top1
I0122 19:14:42.232844 70150 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 19:14:42.232848 70150 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 19:14:42.232852 70150 net.cpp:409] accuracy-top1 -> top-1
I0122 19:14:42.232858 70150 net.cpp:144] Setting up accuracy-top1
I0122 19:14:42.232861 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232864 70150 net.cpp:159] Memory required for data: 566417412
I0122 19:14:42.232867 70150 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 19:14:42.232873 70150 net.cpp:94] Creating Layer accuracy-top5
I0122 19:14:42.232875 70150 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 19:14:42.232879 70150 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 19:14:42.232883 70150 net.cpp:409] accuracy-top5 -> top-5
I0122 19:14:42.232897 70150 net.cpp:144] Setting up accuracy-top5
I0122 19:14:42.232899 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232901 70150 net.cpp:159] Memory required for data: 566417416
I0122 19:14:42.232904 70150 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 19:14:42.232908 70150 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 19:14:42.232913 70150 net.cpp:222] accuracy does not need backward computation.
I0122 19:14:42.232915 70150 net.cpp:220] loss needs backward computation.
I0122 19:14:42.232919 70150 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 19:14:42.232923 70150 net.cpp:220] loss/classifier needs backward computation.
I0122 19:14:42.232925 70150 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:14:42.232928 70150 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:14:42.232931 70150 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:14:42.232935 70150 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:14:42.232939 70150 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:14:42.232941 70150 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:14:42.232944 70150 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:14:42.232947 70150 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:14:42.232950 70150 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:14:42.232954 70150 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:14:42.232956 70150 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:14:42.232960 70150 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:14:42.232964 70150 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:14:42.232966 70150 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:14:42.232969 70150 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:14:42.232972 70150 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:14:42.232975 70150 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:14:42.232978 70150 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:14:42.232981 70150 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:14:42.232985 70150 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:14:42.232988 70150 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.232991 70150 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.232995 70150 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:14:42.232997 70150 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:14:42.233000 70150 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:14:42.233005 70150 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:14:42.233007 70150 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:14:42.233011 70150 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:14:42.233013 70150 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:14:42.233016 70150 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:14:42.233019 70150 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:14:42.233022 70150 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:14:42.233026 70150 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:14:42.233029 70150 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:14:42.233032 70150 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:14:42.233036 70150 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:14:42.233041 70150 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:14:42.233048 70150 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:14:42.233050 70150 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:14:42.233054 70150 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:14:42.233057 70150 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:14:42.233062 70150 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:14:42.233064 70150 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:14:42.233067 70150 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:14:42.233070 70150 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:14:42.233074 70150 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:14:42.233076 70150 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:14:42.233080 70150 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:14:42.233083 70150 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:14:42.233086 70150 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:14:42.233089 70150 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:14:42.233093 70150 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:14:42.233096 70150 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:14:42.233098 70150 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:14:42.233103 70150 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:14:42.233105 70150 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:14:42.233109 70150 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:14:42.233114 70150 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:14:42.233116 70150 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.233120 70150 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.233124 70150 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:14:42.233126 70150 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:14:42.233130 70150 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:14:42.233134 70150 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:14:42.233136 70150 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:14:42.233139 70150 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:14:42.233144 70150 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:14:42.233146 70150 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:14:42.233150 70150 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:14:42.233152 70150 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:14:42.233155 70150 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:14:42.233160 70150 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:14:42.233162 70150 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:14:42.233165 70150 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:14:42.233167 70150 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:14:42.233171 70150 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:14:42.233175 70150 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:14:42.233177 70150 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:14:42.233180 70150 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:14:42.233184 70150 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:14:42.233187 70150 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:14:42.233199 70150 net.cpp:222] label_data_1_split does not need backward computation.
I0122 19:14:42.233203 70150 net.cpp:222] data does not need backward computation.
I0122 19:14:42.233206 70150 net.cpp:264] This network produces output accuracy
I0122 19:14:42.233209 70150 net.cpp:264] This network produces output loss
I0122 19:14:42.233212 70150 net.cpp:264] This network produces output top-1
I0122 19:14:42.233217 70150 net.cpp:264] This network produces output top-5
I0122 19:14:42.233286 70150 net.cpp:284] Network initialization done.
I0122 19:14:42.233621 70150 solver.cpp:63] Solver scaffolding done.
I0122 19:14:42.238093 70150 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/sparse.caffemodel
I0122 19:14:42.282122 70150 caffe_interface.cpp:527] Starting Optimization
I0122 19:14:42.282140 70150 solver.cpp:335] Solving 
I0122 19:14:42.282142 70150 solver.cpp:336] Learning Rate Policy: step
I0122 19:14:42.284685 70150 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 19:14:43.738059 70150 solver.cpp:517]     Test net output #0: accuracy = 0.893888
I0122 19:14:43.738085 70150 solver.cpp:517]     Test net output #1: loss = 0.399975 (* 1 = 0.399975 loss)
I0122 19:14:43.738090 70150 solver.cpp:517]     Test net output #2: top-1 = 0.893888
I0122 19:14:43.738092 70150 solver.cpp:517]     Test net output #3: top-5 = 0.994445
I0122 19:14:43.818171 70150 solver.cpp:266] Iteration 0 (0 iter/s, 1.53593s/100 iter), loss = 0.00423868
I0122 19:14:43.818205 70150 solver.cpp:285]     Train net output #0: loss = 0.00423868 (* 1 = 0.00423868 loss)
I0122 19:14:43.818222 70150 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 19:14:49.940099 70150 solver.cpp:266] Iteration 100 (16.3354 iter/s, 6.12166s/100 iter), loss = 1.25813
I0122 19:14:49.940126 70150 solver.cpp:285]     Train net output #0: loss = 1.25813 (* 1 = 1.25813 loss)
I0122 19:14:49.940132 70150 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 19:14:56.055441 70150 solver.cpp:266] Iteration 200 (16.353 iter/s, 6.11508s/100 iter), loss = 1.11228
I0122 19:14:56.055467 70150 solver.cpp:285]     Train net output #0: loss = 1.11228 (* 1 = 1.11228 loss)
I0122 19:14:56.055474 70150 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 19:15:02.184532 70150 solver.cpp:266] Iteration 300 (16.3163 iter/s, 6.12883s/100 iter), loss = 0.929449
I0122 19:15:02.184561 70150 solver.cpp:285]     Train net output #0: loss = 0.929449 (* 1 = 0.929449 loss)
I0122 19:15:02.184567 70150 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 19:15:08.317096 70150 solver.cpp:266] Iteration 400 (16.3071 iter/s, 6.1323s/100 iter), loss = 0.795218
I0122 19:15:08.317124 70150 solver.cpp:285]     Train net output #0: loss = 0.795218 (* 1 = 0.795218 loss)
I0122 19:15:08.317129 70150 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 19:15:14.488174 70150 solver.cpp:266] Iteration 500 (16.2053 iter/s, 6.17081s/100 iter), loss = 0.950878
I0122 19:15:14.488265 70150 solver.cpp:285]     Train net output #0: loss = 0.950878 (* 1 = 0.950878 loss)
I0122 19:15:14.488273 70150 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 19:15:20.691821 70150 solver.cpp:266] Iteration 600 (16.1204 iter/s, 6.20332s/100 iter), loss = 0.672483
I0122 19:15:20.691862 70150 solver.cpp:285]     Train net output #0: loss = 0.672483 (* 1 = 0.672483 loss)
I0122 19:15:20.691869 70150 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 19:15:26.917599 70150 solver.cpp:266] Iteration 700 (16.063 iter/s, 6.2255s/100 iter), loss = 0.838136
I0122 19:15:26.917627 70150 solver.cpp:285]     Train net output #0: loss = 0.838136 (* 1 = 0.838136 loss)
I0122 19:15:26.917634 70150 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 19:15:33.142577 70150 solver.cpp:266] Iteration 800 (16.065 iter/s, 6.22471s/100 iter), loss = 0.767428
I0122 19:15:33.142617 70150 solver.cpp:285]     Train net output #0: loss = 0.767428 (* 1 = 0.767428 loss)
I0122 19:15:33.142623 70150 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 19:15:39.360252 70150 solver.cpp:266] Iteration 900 (16.0839 iter/s, 6.2174s/100 iter), loss = 0.549655
I0122 19:15:39.360280 70150 solver.cpp:285]     Train net output #0: loss = 0.549655 (* 1 = 0.549655 loss)
I0122 19:15:39.360285 70150 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 19:15:45.525362 70150 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 19:15:46.975481 70150 solver.cpp:517]     Test net output #0: accuracy = 0.274778
I0122 19:15:46.975505 70150 solver.cpp:517]     Test net output #1: loss = 5.34173 (* 1 = 5.34173 loss)
I0122 19:15:46.975510 70150 solver.cpp:517]     Test net output #2: top-1 = 0.274778
I0122 19:15:46.975513 70150 solver.cpp:517]     Test net output #3: top-5 = 0.860444
I0122 19:15:47.037056 70150 solver.cpp:266] Iteration 1000 (13.0268 iter/s, 7.67649s/100 iter), loss = 0.734602
I0122 19:15:47.037077 70150 solver.cpp:285]     Train net output #0: loss = 0.734602 (* 1 = 0.734602 loss)
I0122 19:15:47.037083 70150 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 19:15:53.268682 70150 solver.cpp:266] Iteration 1100 (16.0478 iter/s, 6.23137s/100 iter), loss = 0.665912
I0122 19:15:53.268708 70150 solver.cpp:285]     Train net output #0: loss = 0.665912 (* 1 = 0.665912 loss)
I0122 19:15:53.268714 70150 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 19:15:59.480968 70150 solver.cpp:266] Iteration 1200 (16.0978 iter/s, 6.21202s/100 iter), loss = 0.5749
I0122 19:15:59.480996 70150 solver.cpp:285]     Train net output #0: loss = 0.5749 (* 1 = 0.5749 loss)
I0122 19:15:59.481003 70150 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 19:16:05.700275 70150 solver.cpp:266] Iteration 1300 (16.0796 iter/s, 6.21904s/100 iter), loss = 0.602998
I0122 19:16:05.700304 70150 solver.cpp:285]     Train net output #0: loss = 0.602998 (* 1 = 0.602998 loss)
I0122 19:16:05.700310 70150 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 19:16:11.930851 70150 solver.cpp:266] Iteration 1400 (16.0506 iter/s, 6.23031s/100 iter), loss = 0.54741
I0122 19:16:11.930878 70150 solver.cpp:285]     Train net output #0: loss = 0.54741 (* 1 = 0.54741 loss)
I0122 19:16:11.930884 70150 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 19:16:18.155632 70150 solver.cpp:266] Iteration 1500 (16.0655 iter/s, 6.22451s/100 iter), loss = 0.442638
I0122 19:16:18.155691 70150 solver.cpp:285]     Train net output #0: loss = 0.442638 (* 1 = 0.442638 loss)
I0122 19:16:18.155699 70150 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 19:16:24.384464 70150 solver.cpp:266] Iteration 1600 (16.0551 iter/s, 6.22854s/100 iter), loss = 0.636615
I0122 19:16:24.384488 70150 solver.cpp:285]     Train net output #0: loss = 0.636615 (* 1 = 0.636615 loss)
I0122 19:16:24.384493 70150 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 19:16:30.604219 70150 solver.cpp:266] Iteration 1700 (16.0785 iter/s, 6.21949s/100 iter), loss = 0.46785
I0122 19:16:30.604249 70150 solver.cpp:285]     Train net output #0: loss = 0.46785 (* 1 = 0.46785 loss)
I0122 19:16:30.604254 70150 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 19:16:36.814716 70150 solver.cpp:266] Iteration 1800 (16.1025 iter/s, 6.21023s/100 iter), loss = 0.484275
I0122 19:16:36.814745 70150 solver.cpp:285]     Train net output #0: loss = 0.484275 (* 1 = 0.484275 loss)
I0122 19:16:36.814751 70150 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 19:16:43.046514 70150 solver.cpp:266] Iteration 1900 (16.0474 iter/s, 6.23153s/100 iter), loss = 0.500228
I0122 19:16:43.046540 70150 solver.cpp:285]     Train net output #0: loss = 0.500228 (* 1 = 0.500228 loss)
I0122 19:16:43.046546 70150 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 19:16:49.212767 70150 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 19:16:50.664784 70150 solver.cpp:517]     Test net output #0: accuracy = 0.482556
I0122 19:16:50.664809 70150 solver.cpp:517]     Test net output #1: loss = 1.45698 (* 1 = 1.45698 loss)
I0122 19:16:50.664814 70150 solver.cpp:517]     Test net output #2: top-1 = 0.482556
I0122 19:16:50.664819 70150 solver.cpp:517]     Test net output #3: top-5 = 0.898333
I0122 19:16:50.726555 70150 solver.cpp:266] Iteration 2000 (13.0213 iter/s, 7.67973s/100 iter), loss = 0.508224
I0122 19:16:50.726574 70150 solver.cpp:285]     Train net output #0: loss = 0.508224 (* 1 = 0.508224 loss)
I0122 19:16:50.726580 70150 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 19:16:56.929675 70150 solver.cpp:266] Iteration 2100 (16.1216 iter/s, 6.20286s/100 iter), loss = 0.626684
I0122 19:16:56.929703 70150 solver.cpp:285]     Train net output #0: loss = 0.626684 (* 1 = 0.626684 loss)
I0122 19:16:56.929709 70150 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 19:17:03.153697 70150 solver.cpp:266] Iteration 2200 (16.0675 iter/s, 6.22375s/100 iter), loss = 0.383567
I0122 19:17:03.153724 70150 solver.cpp:285]     Train net output #0: loss = 0.383567 (* 1 = 0.383567 loss)
I0122 19:17:03.153730 70150 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 19:17:09.391223 70150 solver.cpp:266] Iteration 2300 (16.0327 iter/s, 6.23726s/100 iter), loss = 0.586729
I0122 19:17:09.391252 70150 solver.cpp:285]     Train net output #0: loss = 0.586729 (* 1 = 0.586729 loss)
I0122 19:17:09.391258 70150 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 19:17:15.616552 70150 solver.cpp:266] Iteration 2400 (16.0641 iter/s, 6.22506s/100 iter), loss = 0.49179
I0122 19:17:15.616580 70150 solver.cpp:285]     Train net output #0: loss = 0.49179 (* 1 = 0.49179 loss)
I0122 19:17:15.616586 70150 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 19:17:21.854074 70150 solver.cpp:266] Iteration 2500 (16.0327 iter/s, 6.23726s/100 iter), loss = 0.522156
I0122 19:17:21.854161 70150 solver.cpp:285]     Train net output #0: loss = 0.522156 (* 1 = 0.522156 loss)
I0122 19:17:21.854167 70150 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 19:17:28.088827 70150 solver.cpp:266] Iteration 2600 (16.04 iter/s, 6.23443s/100 iter), loss = 0.450405
I0122 19:17:28.088855 70150 solver.cpp:285]     Train net output #0: loss = 0.450405 (* 1 = 0.450405 loss)
I0122 19:17:28.088858 70150 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 19:17:34.314723 70150 solver.cpp:266] Iteration 2700 (16.0626 iter/s, 6.22563s/100 iter), loss = 0.605673
I0122 19:17:34.314751 70150 solver.cpp:285]     Train net output #0: loss = 0.605673 (* 1 = 0.605673 loss)
I0122 19:17:34.314756 70150 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 19:17:40.544445 70150 solver.cpp:266] Iteration 2800 (16.0528 iter/s, 6.22945s/100 iter), loss = 0.651193
I0122 19:17:40.544473 70150 solver.cpp:285]     Train net output #0: loss = 0.651193 (* 1 = 0.651193 loss)
I0122 19:17:40.544478 70150 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 19:17:46.769840 70150 solver.cpp:266] Iteration 2900 (16.0639 iter/s, 6.22513s/100 iter), loss = 0.5326
I0122 19:17:46.769868 70150 solver.cpp:285]     Train net output #0: loss = 0.5326 (* 1 = 0.5326 loss)
I0122 19:17:46.769874 70150 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 19:17:52.944090 70150 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 19:17:54.390592 70150 solver.cpp:517]     Test net output #0: accuracy = 0.584556
I0122 19:17:54.390617 70150 solver.cpp:517]     Test net output #1: loss = 1.17491 (* 1 = 1.17491 loss)
I0122 19:17:54.390621 70150 solver.cpp:517]     Test net output #2: top-1 = 0.584556
I0122 19:17:54.390625 70150 solver.cpp:517]     Test net output #3: top-5 = 0.944667
I0122 19:17:54.452087 70150 solver.cpp:266] Iteration 3000 (13.0176 iter/s, 7.68193s/100 iter), loss = 0.511255
I0122 19:17:54.452118 70150 solver.cpp:285]     Train net output #0: loss = 0.511255 (* 1 = 0.511255 loss)
I0122 19:17:54.452126 70150 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 19:18:00.660567 70150 solver.cpp:266] Iteration 3100 (16.1077 iter/s, 6.20821s/100 iter), loss = 0.424389
I0122 19:18:00.660594 70150 solver.cpp:285]     Train net output #0: loss = 0.424389 (* 1 = 0.424389 loss)
I0122 19:18:00.660599 70150 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 19:18:06.887193 70150 solver.cpp:266] Iteration 3200 (16.0607 iter/s, 6.22636s/100 iter), loss = 0.53792
I0122 19:18:06.887221 70150 solver.cpp:285]     Train net output #0: loss = 0.53792 (* 1 = 0.53792 loss)
I0122 19:18:06.887228 70150 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 19:18:13.107560 70150 solver.cpp:266] Iteration 3300 (16.0769 iter/s, 6.2201s/100 iter), loss = 0.382567
I0122 19:18:13.107589 70150 solver.cpp:285]     Train net output #0: loss = 0.382567 (* 1 = 0.382567 loss)
I0122 19:18:13.107594 70150 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 19:18:19.319162 70150 solver.cpp:266] Iteration 3400 (16.0996 iter/s, 6.21134s/100 iter), loss = 0.527776
I0122 19:18:19.319190 70150 solver.cpp:285]     Train net output #0: loss = 0.527776 (* 1 = 0.527776 loss)
I0122 19:18:19.319195 70150 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 19:18:25.540992 70150 solver.cpp:266] Iteration 3500 (16.0731 iter/s, 6.22157s/100 iter), loss = 0.444462
I0122 19:18:25.541069 70150 solver.cpp:285]     Train net output #0: loss = 0.444462 (* 1 = 0.444462 loss)
I0122 19:18:25.541075 70150 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 19:18:31.779860 70150 solver.cpp:266] Iteration 3600 (16.0294 iter/s, 6.23855s/100 iter), loss = 0.606412
I0122 19:18:31.779887 70150 solver.cpp:285]     Train net output #0: loss = 0.606412 (* 1 = 0.606412 loss)
I0122 19:18:31.779893 70150 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 19:18:37.974907 70150 solver.cpp:266] Iteration 3700 (16.1426 iter/s, 6.19478s/100 iter), loss = 0.460023
I0122 19:18:37.974934 70150 solver.cpp:285]     Train net output #0: loss = 0.460023 (* 1 = 0.460023 loss)
I0122 19:18:37.974941 70150 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 19:18:44.204859 70150 solver.cpp:266] Iteration 3800 (16.0522 iter/s, 6.22969s/100 iter), loss = 0.443886
I0122 19:18:44.204885 70150 solver.cpp:285]     Train net output #0: loss = 0.443886 (* 1 = 0.443886 loss)
I0122 19:18:44.204891 70150 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 19:18:50.446863 70150 solver.cpp:266] Iteration 3900 (16.0212 iter/s, 6.24174s/100 iter), loss = 0.452235
I0122 19:18:50.446890 70150 solver.cpp:285]     Train net output #0: loss = 0.452235 (* 1 = 0.452235 loss)
I0122 19:18:50.446897 70150 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 19:18:56.600204 70150 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 19:18:58.051595 70150 solver.cpp:517]     Test net output #0: accuracy = 0.477111
I0122 19:18:58.051620 70150 solver.cpp:517]     Test net output #1: loss = 1.48279 (* 1 = 1.48279 loss)
I0122 19:18:58.051623 70150 solver.cpp:517]     Test net output #2: top-1 = 0.477111
I0122 19:18:58.051626 70150 solver.cpp:517]     Test net output #3: top-5 = 0.904555
I0122 19:18:58.113306 70150 solver.cpp:266] Iteration 4000 (13.0444 iter/s, 7.66613s/100 iter), loss = 0.560308
I0122 19:18:58.113325 70150 solver.cpp:285]     Train net output #0: loss = 0.560308 (* 1 = 0.560308 loss)
I0122 19:18:58.113332 70150 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 19:19:04.330579 70150 solver.cpp:266] Iteration 4100 (16.0849 iter/s, 6.21702s/100 iter), loss = 0.430297
I0122 19:19:04.330606 70150 solver.cpp:285]     Train net output #0: loss = 0.430297 (* 1 = 0.430297 loss)
I0122 19:19:04.330612 70150 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 19:19:10.551937 70150 solver.cpp:266] Iteration 4200 (16.0743 iter/s, 6.22109s/100 iter), loss = 0.478692
I0122 19:19:10.551965 70150 solver.cpp:285]     Train net output #0: loss = 0.478692 (* 1 = 0.478692 loss)
I0122 19:19:10.551971 70150 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 19:19:16.774919 70150 solver.cpp:266] Iteration 4300 (16.0701 iter/s, 6.22272s/100 iter), loss = 0.552574
I0122 19:19:16.774947 70150 solver.cpp:285]     Train net output #0: loss = 0.552574 (* 1 = 0.552574 loss)
I0122 19:19:16.774953 70150 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 19:19:22.996904 70150 solver.cpp:266] Iteration 4400 (16.0727 iter/s, 6.22172s/100 iter), loss = 0.595786
I0122 19:19:22.996932 70150 solver.cpp:285]     Train net output #0: loss = 0.595786 (* 1 = 0.595786 loss)
I0122 19:19:22.996937 70150 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 19:19:29.214701 70150 solver.cpp:266] Iteration 4500 (16.0836 iter/s, 6.21753s/100 iter), loss = 0.432837
I0122 19:19:29.214778 70150 solver.cpp:285]     Train net output #0: loss = 0.432837 (* 1 = 0.432837 loss)
I0122 19:19:29.214785 70150 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 19:19:35.435325 70150 solver.cpp:266] Iteration 4600 (16.0764 iter/s, 6.22031s/100 iter), loss = 0.65526
I0122 19:19:35.435353 70150 solver.cpp:285]     Train net output #0: loss = 0.65526 (* 1 = 0.65526 loss)
I0122 19:19:35.435359 70150 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 19:19:41.649689 70150 solver.cpp:266] Iteration 4700 (16.0924 iter/s, 6.2141s/100 iter), loss = 0.567955
I0122 19:19:41.649718 70150 solver.cpp:285]     Train net output #0: loss = 0.567955 (* 1 = 0.567955 loss)
I0122 19:19:41.649722 70150 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 19:19:47.868736 70150 solver.cpp:266] Iteration 4800 (16.0803 iter/s, 6.21878s/100 iter), loss = 0.485153
I0122 19:19:47.868764 70150 solver.cpp:285]     Train net output #0: loss = 0.485153 (* 1 = 0.485153 loss)
I0122 19:19:47.868769 70150 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 19:19:54.091894 70150 solver.cpp:266] Iteration 4900 (16.0697 iter/s, 6.22289s/100 iter), loss = 0.661399
I0122 19:19:54.091922 70150 solver.cpp:285]     Train net output #0: loss = 0.661399 (* 1 = 0.661399 loss)
I0122 19:19:54.091928 70150 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 19:20:00.239329 70150 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 19:20:01.690448 70150 solver.cpp:517]     Test net output #0: accuracy = 0.356333
I0122 19:20:01.690471 70150 solver.cpp:517]     Test net output #1: loss = 2.54482 (* 1 = 2.54482 loss)
I0122 19:20:01.690475 70150 solver.cpp:517]     Test net output #2: top-1 = 0.356333
I0122 19:20:01.690479 70150 solver.cpp:517]     Test net output #3: top-5 = 0.825111
I0122 19:20:01.753614 70150 solver.cpp:266] Iteration 5000 (13.0524 iter/s, 7.6614s/100 iter), loss = 0.675043
I0122 19:20:01.753634 70150 solver.cpp:285]     Train net output #0: loss = 0.675043 (* 1 = 0.675043 loss)
I0122 19:20:01.753640 70150 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 19:20:07.981106 70150 solver.cpp:266] Iteration 5100 (16.0585 iter/s, 6.22723s/100 iter), loss = 0.459239
I0122 19:20:07.981133 70150 solver.cpp:285]     Train net output #0: loss = 0.459239 (* 1 = 0.459239 loss)
I0122 19:20:07.981138 70150 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 19:20:14.205879 70150 solver.cpp:266] Iteration 5200 (16.0655 iter/s, 6.22451s/100 iter), loss = 0.525893
I0122 19:20:14.205910 70150 solver.cpp:285]     Train net output #0: loss = 0.525893 (* 1 = 0.525893 loss)
I0122 19:20:14.205917 70150 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 19:20:20.418462 70150 solver.cpp:266] Iteration 5300 (16.0971 iter/s, 6.21231s/100 iter), loss = 0.566218
I0122 19:20:20.418491 70150 solver.cpp:285]     Train net output #0: loss = 0.566218 (* 1 = 0.566218 loss)
I0122 19:20:20.418496 70150 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 19:20:26.668099 70150 solver.cpp:266] Iteration 5400 (16.0016 iter/s, 6.24937s/100 iter), loss = 0.604607
I0122 19:20:26.668128 70150 solver.cpp:285]     Train net output #0: loss = 0.604607 (* 1 = 0.604607 loss)
I0122 19:20:26.668133 70150 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 19:20:32.874366 70150 solver.cpp:266] Iteration 5500 (16.1134 iter/s, 6.206s/100 iter), loss = 0.466477
I0122 19:20:32.874428 70150 solver.cpp:285]     Train net output #0: loss = 0.466477 (* 1 = 0.466477 loss)
I0122 19:20:32.874433 70150 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 19:20:39.093215 70150 solver.cpp:266] Iteration 5600 (16.0809 iter/s, 6.21855s/100 iter), loss = 0.431836
I0122 19:20:39.093243 70150 solver.cpp:285]     Train net output #0: loss = 0.431836 (* 1 = 0.431836 loss)
I0122 19:20:39.093248 70150 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 19:20:45.320828 70150 solver.cpp:266] Iteration 5700 (16.0582 iter/s, 6.22735s/100 iter), loss = 0.261399
I0122 19:20:45.320857 70150 solver.cpp:285]     Train net output #0: loss = 0.261399 (* 1 = 0.261399 loss)
I0122 19:20:45.320861 70150 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 19:20:51.538655 70150 solver.cpp:266] Iteration 5800 (16.0835 iter/s, 6.21756s/100 iter), loss = 0.612623
I0122 19:20:51.538683 70150 solver.cpp:285]     Train net output #0: loss = 0.612623 (* 1 = 0.612623 loss)
I0122 19:20:51.538689 70150 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 19:20:57.759114 70150 solver.cpp:266] Iteration 5900 (16.0767 iter/s, 6.22019s/100 iter), loss = 0.55342
I0122 19:20:57.759140 70150 solver.cpp:285]     Train net output #0: loss = 0.55342 (* 1 = 0.55342 loss)
I0122 19:20:57.759145 70150 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 19:21:03.925514 70150 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 19:21:05.377826 70150 solver.cpp:517]     Test net output #0: accuracy = 0.610334
I0122 19:21:05.377851 70150 solver.cpp:517]     Test net output #1: loss = 1.08865 (* 1 = 1.08865 loss)
I0122 19:21:05.377856 70150 solver.cpp:517]     Test net output #2: top-1 = 0.610334
I0122 19:21:05.377859 70150 solver.cpp:517]     Test net output #3: top-5 = 0.945556
I0122 19:21:05.440246 70150 solver.cpp:266] Iteration 6000 (13.0195 iter/s, 7.68082s/100 iter), loss = 0.663952
I0122 19:21:05.440265 70150 solver.cpp:285]     Train net output #0: loss = 0.663952 (* 1 = 0.663952 loss)
I0122 19:21:05.440271 70150 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 19:21:11.664819 70150 solver.cpp:266] Iteration 6100 (16.066 iter/s, 6.22432s/100 iter), loss = 0.374827
I0122 19:21:11.664845 70150 solver.cpp:285]     Train net output #0: loss = 0.374827 (* 1 = 0.374827 loss)
I0122 19:21:11.664850 70150 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 19:21:17.880829 70150 solver.cpp:266] Iteration 6200 (16.0882 iter/s, 6.21575s/100 iter), loss = 0.418449
I0122 19:21:17.880858 70150 solver.cpp:285]     Train net output #0: loss = 0.418449 (* 1 = 0.418449 loss)
I0122 19:21:17.880863 70150 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 19:21:24.107398 70150 solver.cpp:266] Iteration 6300 (16.0609 iter/s, 6.2263s/100 iter), loss = 0.412811
I0122 19:21:24.107427 70150 solver.cpp:285]     Train net output #0: loss = 0.412811 (* 1 = 0.412811 loss)
I0122 19:21:24.107434 70150 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 19:21:30.322089 70150 solver.cpp:266] Iteration 6400 (16.0916 iter/s, 6.21442s/100 iter), loss = 0.553206
I0122 19:21:30.322114 70150 solver.cpp:285]     Train net output #0: loss = 0.553206 (* 1 = 0.553206 loss)
I0122 19:21:30.322119 70150 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 19:21:36.549777 70150 solver.cpp:266] Iteration 6500 (16.058 iter/s, 6.22742s/100 iter), loss = 0.726911
I0122 19:21:36.549839 70150 solver.cpp:285]     Train net output #0: loss = 0.726911 (* 1 = 0.726911 loss)
I0122 19:21:36.549846 70150 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 19:21:42.757158 70150 solver.cpp:266] Iteration 6600 (16.1106 iter/s, 6.20708s/100 iter), loss = 0.547003
I0122 19:21:42.757186 70150 solver.cpp:285]     Train net output #0: loss = 0.547003 (* 1 = 0.547003 loss)
I0122 19:21:42.757191 70150 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 19:21:48.989859 70150 solver.cpp:266] Iteration 6700 (16.0451 iter/s, 6.23243s/100 iter), loss = 0.366781
I0122 19:21:48.989886 70150 solver.cpp:285]     Train net output #0: loss = 0.366781 (* 1 = 0.366781 loss)
I0122 19:21:48.989892 70150 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 19:21:55.213654 70150 solver.cpp:266] Iteration 6800 (16.0681 iter/s, 6.22353s/100 iter), loss = 0.445867
I0122 19:21:55.213681 70150 solver.cpp:285]     Train net output #0: loss = 0.445867 (* 1 = 0.445867 loss)
I0122 19:21:55.213686 70150 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 19:22:01.435297 70150 solver.cpp:266] Iteration 6900 (16.0736 iter/s, 6.22138s/100 iter), loss = 0.47588
I0122 19:22:01.435325 70150 solver.cpp:285]     Train net output #0: loss = 0.47588 (* 1 = 0.47588 loss)
I0122 19:22:01.435331 70150 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 19:22:07.595698 70150 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 19:22:09.046017 70150 solver.cpp:517]     Test net output #0: accuracy = 0.543333
I0122 19:22:09.046042 70150 solver.cpp:517]     Test net output #1: loss = 1.41143 (* 1 = 1.41143 loss)
I0122 19:22:09.046046 70150 solver.cpp:517]     Test net output #2: top-1 = 0.543333
I0122 19:22:09.046049 70150 solver.cpp:517]     Test net output #3: top-5 = 0.899
I0122 19:22:09.107784 70150 solver.cpp:266] Iteration 7000 (13.0341 iter/s, 7.67217s/100 iter), loss = 0.367308
I0122 19:22:09.107803 70150 solver.cpp:285]     Train net output #0: loss = 0.367308 (* 1 = 0.367308 loss)
I0122 19:22:09.107810 70150 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 19:22:15.338147 70150 solver.cpp:266] Iteration 7100 (16.0511 iter/s, 6.2301s/100 iter), loss = 0.642479
I0122 19:22:15.338176 70150 solver.cpp:285]     Train net output #0: loss = 0.642479 (* 1 = 0.642479 loss)
I0122 19:22:15.338181 70150 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 19:22:21.555619 70150 solver.cpp:266] Iteration 7200 (16.0844 iter/s, 6.21721s/100 iter), loss = 0.412763
I0122 19:22:21.555646 70150 solver.cpp:285]     Train net output #0: loss = 0.412763 (* 1 = 0.412763 loss)
I0122 19:22:21.555652 70150 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 19:22:27.783730 70150 solver.cpp:266] Iteration 7300 (16.0569 iter/s, 6.22785s/100 iter), loss = 0.509895
I0122 19:22:27.783759 70150 solver.cpp:285]     Train net output #0: loss = 0.509895 (* 1 = 0.509895 loss)
I0122 19:22:27.783764 70150 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 19:22:34.000885 70150 solver.cpp:266] Iteration 7400 (16.0852 iter/s, 6.21689s/100 iter), loss = 0.422114
I0122 19:22:34.000914 70150 solver.cpp:285]     Train net output #0: loss = 0.422114 (* 1 = 0.422114 loss)
I0122 19:22:34.000919 70150 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 19:22:40.211117 70150 solver.cpp:266] Iteration 7500 (16.1031 iter/s, 6.20997s/100 iter), loss = 0.447746
I0122 19:22:40.211179 70150 solver.cpp:285]     Train net output #0: loss = 0.447746 (* 1 = 0.447746 loss)
I0122 19:22:40.211184 70150 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 19:22:46.441730 70150 solver.cpp:266] Iteration 7600 (16.0506 iter/s, 6.23031s/100 iter), loss = 0.420806
I0122 19:22:46.441756 70150 solver.cpp:285]     Train net output #0: loss = 0.420806 (* 1 = 0.420806 loss)
I0122 19:22:46.441762 70150 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 19:22:52.677601 70150 solver.cpp:266] Iteration 7700 (16.0369 iter/s, 6.23561s/100 iter), loss = 0.50006
I0122 19:22:52.677628 70150 solver.cpp:285]     Train net output #0: loss = 0.50006 (* 1 = 0.50006 loss)
I0122 19:22:52.677634 70150 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 19:22:58.916968 70150 solver.cpp:266] Iteration 7800 (16.028 iter/s, 6.2391s/100 iter), loss = 0.413227
I0122 19:22:58.916995 70150 solver.cpp:285]     Train net output #0: loss = 0.413227 (* 1 = 0.413227 loss)
I0122 19:22:58.917001 70150 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 19:23:05.122239 70150 solver.cpp:266] Iteration 7900 (16.116 iter/s, 6.20501s/100 iter), loss = 0.566429
I0122 19:23:05.122268 70150 solver.cpp:285]     Train net output #0: loss = 0.566429 (* 1 = 0.566429 loss)
I0122 19:23:05.122273 70150 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 19:23:11.272780 70150 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 19:23:12.719866 70150 solver.cpp:517]     Test net output #0: accuracy = 0.620667
I0122 19:23:12.719892 70150 solver.cpp:517]     Test net output #1: loss = 1.08059 (* 1 = 1.08059 loss)
I0122 19:23:12.719895 70150 solver.cpp:517]     Test net output #2: top-1 = 0.620667
I0122 19:23:12.719898 70150 solver.cpp:517]     Test net output #3: top-5 = 0.962667
I0122 19:23:12.781333 70150 solver.cpp:266] Iteration 8000 (13.0569 iter/s, 7.65878s/100 iter), loss = 0.428761
I0122 19:23:12.781353 70150 solver.cpp:285]     Train net output #0: loss = 0.428761 (* 1 = 0.428761 loss)
I0122 19:23:12.781359 70150 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 19:23:19.006014 70150 solver.cpp:266] Iteration 8100 (16.0657 iter/s, 6.22442s/100 iter), loss = 0.53741
I0122 19:23:19.006042 70150 solver.cpp:285]     Train net output #0: loss = 0.53741 (* 1 = 0.53741 loss)
I0122 19:23:19.006047 70150 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 19:23:25.214885 70150 solver.cpp:266] Iteration 8200 (16.1067 iter/s, 6.20861s/100 iter), loss = 0.459828
I0122 19:23:25.214915 70150 solver.cpp:285]     Train net output #0: loss = 0.459828 (* 1 = 0.459828 loss)
I0122 19:23:25.214920 70150 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 19:23:31.433703 70150 solver.cpp:266] Iteration 8300 (16.0809 iter/s, 6.21855s/100 iter), loss = 0.465649
I0122 19:23:31.433732 70150 solver.cpp:285]     Train net output #0: loss = 0.465649 (* 1 = 0.465649 loss)
I0122 19:23:31.433738 70150 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 19:23:37.641274 70150 solver.cpp:266] Iteration 8400 (16.1101 iter/s, 6.2073s/100 iter), loss = 0.324254
I0122 19:23:37.641304 70150 solver.cpp:285]     Train net output #0: loss = 0.324254 (* 1 = 0.324254 loss)
I0122 19:23:37.641309 70150 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 19:23:43.863898 70150 solver.cpp:266] Iteration 8500 (16.0711 iter/s, 6.22236s/100 iter), loss = 0.605635
I0122 19:23:43.864020 70150 solver.cpp:285]     Train net output #0: loss = 0.605635 (* 1 = 0.605635 loss)
I0122 19:23:43.864027 70150 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 19:23:50.082763 70150 solver.cpp:266] Iteration 8600 (16.081 iter/s, 6.21851s/100 iter), loss = 0.3013
I0122 19:23:50.082792 70150 solver.cpp:285]     Train net output #0: loss = 0.3013 (* 1 = 0.3013 loss)
I0122 19:23:50.082796 70150 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 19:23:56.306480 70150 solver.cpp:266] Iteration 8700 (16.0683 iter/s, 6.22345s/100 iter), loss = 0.494012
I0122 19:23:56.306509 70150 solver.cpp:285]     Train net output #0: loss = 0.494012 (* 1 = 0.494012 loss)
I0122 19:23:56.306514 70150 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 19:24:02.521104 70150 solver.cpp:266] Iteration 8800 (16.0918 iter/s, 6.21436s/100 iter), loss = 0.474666
I0122 19:24:02.521144 70150 solver.cpp:285]     Train net output #0: loss = 0.474666 (* 1 = 0.474666 loss)
I0122 19:24:02.521149 70150 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 19:24:08.760970 70150 solver.cpp:266] Iteration 8900 (16.0267 iter/s, 6.23959s/100 iter), loss = 0.514508
I0122 19:24:08.760998 70150 solver.cpp:285]     Train net output #0: loss = 0.514508 (* 1 = 0.514508 loss)
I0122 19:24:08.761004 70150 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 19:24:14.908576 70150 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 19:24:16.365938 70150 solver.cpp:517]     Test net output #0: accuracy = 0.600556
I0122 19:24:16.365963 70150 solver.cpp:517]     Test net output #1: loss = 1.31525 (* 1 = 1.31525 loss)
I0122 19:24:16.365968 70150 solver.cpp:517]     Test net output #2: top-1 = 0.600556
I0122 19:24:16.365988 70150 solver.cpp:517]     Test net output #3: top-5 = 0.910556
I0122 19:24:16.427012 70150 solver.cpp:266] Iteration 9000 (13.0451 iter/s, 7.66573s/100 iter), loss = 0.432712
I0122 19:24:16.427031 70150 solver.cpp:285]     Train net output #0: loss = 0.432712 (* 1 = 0.432712 loss)
I0122 19:24:16.427038 70150 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 19:24:22.649243 70150 solver.cpp:266] Iteration 9100 (16.0721 iter/s, 6.22197s/100 iter), loss = 0.380256
I0122 19:24:22.649271 70150 solver.cpp:285]     Train net output #0: loss = 0.380256 (* 1 = 0.380256 loss)
I0122 19:24:22.649276 70150 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 19:24:28.852450 70150 solver.cpp:266] Iteration 9200 (16.1214 iter/s, 6.20294s/100 iter), loss = 0.617243
I0122 19:24:28.852478 70150 solver.cpp:285]     Train net output #0: loss = 0.617243 (* 1 = 0.617243 loss)
I0122 19:24:28.852483 70150 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 19:24:35.068184 70150 solver.cpp:266] Iteration 9300 (16.0889 iter/s, 6.21547s/100 iter), loss = 0.441609
I0122 19:24:35.068212 70150 solver.cpp:285]     Train net output #0: loss = 0.441609 (* 1 = 0.441609 loss)
I0122 19:24:35.068217 70150 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 19:24:41.291199 70150 solver.cpp:266] Iteration 9400 (16.0701 iter/s, 6.22275s/100 iter), loss = 0.40118
I0122 19:24:41.291229 70150 solver.cpp:285]     Train net output #0: loss = 0.40118 (* 1 = 0.40118 loss)
I0122 19:24:41.291234 70150 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 19:24:47.528439 70150 solver.cpp:266] Iteration 9500 (16.0334 iter/s, 6.23697s/100 iter), loss = 0.354021
I0122 19:24:47.528519 70150 solver.cpp:285]     Train net output #0: loss = 0.354021 (* 1 = 0.354021 loss)
I0122 19:24:47.528525 70150 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 19:24:53.736138 70150 solver.cpp:266] Iteration 9600 (16.1098 iter/s, 6.20738s/100 iter), loss = 0.441208
I0122 19:24:53.736166 70150 solver.cpp:285]     Train net output #0: loss = 0.441208 (* 1 = 0.441208 loss)
I0122 19:24:53.736171 70150 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 19:24:59.973932 70150 solver.cpp:266] Iteration 9700 (16.032 iter/s, 6.23753s/100 iter), loss = 0.361417
I0122 19:24:59.973959 70150 solver.cpp:285]     Train net output #0: loss = 0.361417 (* 1 = 0.361417 loss)
I0122 19:24:59.973965 70150 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 19:25:06.182102 70150 solver.cpp:266] Iteration 9800 (16.1085 iter/s, 6.2079s/100 iter), loss = 0.298844
I0122 19:25:06.182130 70150 solver.cpp:285]     Train net output #0: loss = 0.298844 (* 1 = 0.298844 loss)
I0122 19:25:06.182137 70150 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 19:25:12.411068 70150 solver.cpp:266] Iteration 9900 (16.0547 iter/s, 6.2287s/100 iter), loss = 0.615343
I0122 19:25:12.411096 70150 solver.cpp:285]     Train net output #0: loss = 0.615343 (* 1 = 0.615343 loss)
I0122 19:25:12.411101 70150 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 19:25:18.560156 70150 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 19:25:20.013784 70150 solver.cpp:517]     Test net output #0: accuracy = 0.625334
I0122 19:25:20.013808 70150 solver.cpp:517]     Test net output #1: loss = 1.04104 (* 1 = 1.04104 loss)
I0122 19:25:20.013813 70150 solver.cpp:517]     Test net output #2: top-1 = 0.625334
I0122 19:25:20.013816 70150 solver.cpp:517]     Test net output #3: top-5 = 0.968
I0122 19:25:20.076792 70150 solver.cpp:266] Iteration 10000 (13.0456 iter/s, 7.66541s/100 iter), loss = 0.56636
I0122 19:25:20.076812 70150 solver.cpp:285]     Train net output #0: loss = 0.56636 (* 1 = 0.56636 loss)
I0122 19:25:20.076817 70150 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 19:25:26.284796 70150 solver.cpp:266] Iteration 10100 (16.1089 iter/s, 6.20775s/100 iter), loss = 0.388755
I0122 19:25:26.284826 70150 solver.cpp:285]     Train net output #0: loss = 0.388755 (* 1 = 0.388755 loss)
I0122 19:25:26.284832 70150 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 19:25:32.505280 70150 solver.cpp:266] Iteration 10200 (16.0766 iter/s, 6.22022s/100 iter), loss = 0.363727
I0122 19:25:32.505308 70150 solver.cpp:285]     Train net output #0: loss = 0.363727 (* 1 = 0.363727 loss)
I0122 19:25:32.505314 70150 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 19:25:38.715667 70150 solver.cpp:266] Iteration 10300 (16.1027 iter/s, 6.21012s/100 iter), loss = 0.253103
I0122 19:25:38.715695 70150 solver.cpp:285]     Train net output #0: loss = 0.253103 (* 1 = 0.253103 loss)
I0122 19:25:38.715703 70150 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 19:25:44.938701 70150 solver.cpp:266] Iteration 10400 (16.07 iter/s, 6.22277s/100 iter), loss = 0.325292
I0122 19:25:44.938730 70150 solver.cpp:285]     Train net output #0: loss = 0.325292 (* 1 = 0.325292 loss)
I0122 19:25:44.938735 70150 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 19:25:51.150843 70150 solver.cpp:266] Iteration 10500 (16.0982 iter/s, 6.21187s/100 iter), loss = 0.224911
I0122 19:25:51.150900 70150 solver.cpp:285]     Train net output #0: loss = 0.224911 (* 1 = 0.224911 loss)
I0122 19:25:51.150907 70150 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 19:25:57.373355 70150 solver.cpp:266] Iteration 10600 (16.0714 iter/s, 6.22222s/100 iter), loss = 0.277413
I0122 19:25:57.373384 70150 solver.cpp:285]     Train net output #0: loss = 0.277413 (* 1 = 0.277413 loss)
I0122 19:25:57.373389 70150 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 19:26:03.599154 70150 solver.cpp:266] Iteration 10700 (16.0629 iter/s, 6.22553s/100 iter), loss = 0.36948
I0122 19:26:03.599184 70150 solver.cpp:285]     Train net output #0: loss = 0.36948 (* 1 = 0.36948 loss)
I0122 19:26:03.599189 70150 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 19:26:09.820917 70150 solver.cpp:266] Iteration 10800 (16.0733 iter/s, 6.2215s/100 iter), loss = 0.134858
I0122 19:26:09.820946 70150 solver.cpp:285]     Train net output #0: loss = 0.134858 (* 1 = 0.134858 loss)
I0122 19:26:09.820951 70150 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 19:26:16.040807 70150 solver.cpp:266] Iteration 10900 (16.0781 iter/s, 6.21962s/100 iter), loss = 0.25409
I0122 19:26:16.040834 70150 solver.cpp:285]     Train net output #0: loss = 0.25409 (* 1 = 0.25409 loss)
I0122 19:26:16.040840 70150 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 19:26:22.202950 70150 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 19:26:23.645543 70150 solver.cpp:517]     Test net output #0: accuracy = 0.762555
I0122 19:26:23.645568 70150 solver.cpp:517]     Test net output #1: loss = 0.781333 (* 1 = 0.781333 loss)
I0122 19:26:23.645573 70150 solver.cpp:517]     Test net output #2: top-1 = 0.762555
I0122 19:26:23.645576 70150 solver.cpp:517]     Test net output #3: top-5 = 0.968667
I0122 19:26:23.707342 70150 solver.cpp:266] Iteration 11000 (13.0442 iter/s, 7.66622s/100 iter), loss = 0.221403
I0122 19:26:23.707362 70150 solver.cpp:285]     Train net output #0: loss = 0.221403 (* 1 = 0.221403 loss)
I0122 19:26:23.707368 70150 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 19:26:29.923468 70150 solver.cpp:266] Iteration 11100 (16.0879 iter/s, 6.21587s/100 iter), loss = 0.135854
I0122 19:26:29.923496 70150 solver.cpp:285]     Train net output #0: loss = 0.135854 (* 1 = 0.135854 loss)
I0122 19:26:29.923501 70150 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 19:26:36.159714 70150 solver.cpp:266] Iteration 11200 (16.036 iter/s, 6.23598s/100 iter), loss = 0.169898
I0122 19:26:36.159741 70150 solver.cpp:285]     Train net output #0: loss = 0.169898 (* 1 = 0.169898 loss)
I0122 19:26:36.159746 70150 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 19:26:42.380164 70150 solver.cpp:266] Iteration 11300 (16.0767 iter/s, 6.22019s/100 iter), loss = 0.170482
I0122 19:26:42.380192 70150 solver.cpp:285]     Train net output #0: loss = 0.170482 (* 1 = 0.170482 loss)
I0122 19:26:42.380198 70150 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 19:26:48.597903 70150 solver.cpp:266] Iteration 11400 (16.0837 iter/s, 6.21747s/100 iter), loss = 0.123951
I0122 19:26:48.597931 70150 solver.cpp:285]     Train net output #0: loss = 0.123951 (* 1 = 0.123951 loss)
I0122 19:26:48.597937 70150 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 19:26:54.799692 70150 solver.cpp:266] Iteration 11500 (16.1251 iter/s, 6.20152s/100 iter), loss = 0.145438
I0122 19:26:54.799760 70150 solver.cpp:285]     Train net output #0: loss = 0.145438 (* 1 = 0.145438 loss)
I0122 19:26:54.799767 70150 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 19:27:01.022464 70150 solver.cpp:266] Iteration 11600 (16.0708 iter/s, 6.22247s/100 iter), loss = 0.206715
I0122 19:27:01.022491 70150 solver.cpp:285]     Train net output #0: loss = 0.206715 (* 1 = 0.206715 loss)
I0122 19:27:01.022497 70150 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 19:27:07.238479 70150 solver.cpp:266] Iteration 11700 (16.0882 iter/s, 6.21575s/100 iter), loss = 0.167745
I0122 19:27:07.238507 70150 solver.cpp:285]     Train net output #0: loss = 0.167745 (* 1 = 0.167745 loss)
I0122 19:27:07.238513 70150 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 19:27:13.459792 70150 solver.cpp:266] Iteration 11800 (16.0745 iter/s, 6.22105s/100 iter), loss = 0.245001
I0122 19:27:13.459821 70150 solver.cpp:285]     Train net output #0: loss = 0.245001 (* 1 = 0.245001 loss)
I0122 19:27:13.459826 70150 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 19:27:19.675848 70150 solver.cpp:266] Iteration 11900 (16.0881 iter/s, 6.21579s/100 iter), loss = 0.114138
I0122 19:27:19.675878 70150 solver.cpp:285]     Train net output #0: loss = 0.114138 (* 1 = 0.114138 loss)
I0122 19:27:19.675882 70150 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 19:27:25.830821 70150 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 19:27:27.280431 70150 solver.cpp:517]     Test net output #0: accuracy = 0.627667
I0122 19:27:27.280455 70150 solver.cpp:517]     Test net output #1: loss = 1.1647 (* 1 = 1.1647 loss)
I0122 19:27:27.280459 70150 solver.cpp:517]     Test net output #2: top-1 = 0.627667
I0122 19:27:27.280462 70150 solver.cpp:517]     Test net output #3: top-5 = 0.924555
I0122 19:27:27.343180 70150 solver.cpp:266] Iteration 12000 (13.0429 iter/s, 7.66701s/100 iter), loss = 0.162135
I0122 19:27:27.343199 70150 solver.cpp:285]     Train net output #0: loss = 0.162135 (* 1 = 0.162135 loss)
I0122 19:27:27.343206 70150 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 19:27:33.571576 70150 solver.cpp:266] Iteration 12100 (16.0562 iter/s, 6.22814s/100 iter), loss = 0.153156
I0122 19:27:33.571604 70150 solver.cpp:285]     Train net output #0: loss = 0.153156 (* 1 = 0.153156 loss)
I0122 19:27:33.571609 70150 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 19:27:39.790396 70150 solver.cpp:266] Iteration 12200 (16.0809 iter/s, 6.21856s/100 iter), loss = 0.12169
I0122 19:27:39.790424 70150 solver.cpp:285]     Train net output #0: loss = 0.12169 (* 1 = 0.12169 loss)
I0122 19:27:39.790429 70150 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 19:27:46.013109 70150 solver.cpp:266] Iteration 12300 (16.0708 iter/s, 6.22245s/100 iter), loss = 0.15634
I0122 19:27:46.013135 70150 solver.cpp:285]     Train net output #0: loss = 0.15634 (* 1 = 0.15634 loss)
I0122 19:27:46.013141 70150 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 19:27:52.246809 70150 solver.cpp:266] Iteration 12400 (16.0425 iter/s, 6.23343s/100 iter), loss = 0.0855931
I0122 19:27:52.246836 70150 solver.cpp:285]     Train net output #0: loss = 0.0855932 (* 1 = 0.0855932 loss)
I0122 19:27:52.246841 70150 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 19:27:58.458202 70150 solver.cpp:266] Iteration 12500 (16.1001 iter/s, 6.21113s/100 iter), loss = 0.120416
I0122 19:27:58.458307 70150 solver.cpp:285]     Train net output #0: loss = 0.120416 (* 1 = 0.120416 loss)
I0122 19:27:58.458313 70150 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 19:28:04.689791 70150 solver.cpp:266] Iteration 12600 (16.0481 iter/s, 6.23125s/100 iter), loss = 0.100138
I0122 19:28:04.689821 70150 solver.cpp:285]     Train net output #0: loss = 0.100138 (* 1 = 0.100138 loss)
I0122 19:28:04.689826 70150 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 19:28:10.916849 70150 solver.cpp:266] Iteration 12700 (16.0596 iter/s, 6.22679s/100 iter), loss = 0.155736
I0122 19:28:10.916878 70150 solver.cpp:285]     Train net output #0: loss = 0.155736 (* 1 = 0.155736 loss)
I0122 19:28:10.916884 70150 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 19:28:17.120147 70150 solver.cpp:266] Iteration 12800 (16.1211 iter/s, 6.20303s/100 iter), loss = 0.15678
I0122 19:28:17.120177 70150 solver.cpp:285]     Train net output #0: loss = 0.156781 (* 1 = 0.156781 loss)
I0122 19:28:17.120182 70150 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 19:28:23.334728 70150 solver.cpp:266] Iteration 12900 (16.0919 iter/s, 6.21431s/100 iter), loss = 0.0421701
I0122 19:28:23.334754 70150 solver.cpp:285]     Train net output #0: loss = 0.0421702 (* 1 = 0.0421702 loss)
I0122 19:28:23.334760 70150 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 19:28:29.504596 70150 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 19:28:30.959388 70150 solver.cpp:517]     Test net output #0: accuracy = 0.666445
I0122 19:28:30.959414 70150 solver.cpp:517]     Test net output #1: loss = 1.05614 (* 1 = 1.05614 loss)
I0122 19:28:30.959419 70150 solver.cpp:517]     Test net output #2: top-1 = 0.666445
I0122 19:28:30.959422 70150 solver.cpp:517]     Test net output #3: top-5 = 0.937889
I0122 19:28:31.021075 70150 solver.cpp:266] Iteration 13000 (13.0106 iter/s, 7.68603s/100 iter), loss = 0.124309
I0122 19:28:31.021095 70150 solver.cpp:285]     Train net output #0: loss = 0.124309 (* 1 = 0.124309 loss)
I0122 19:28:31.021100 70150 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 19:28:37.247654 70150 solver.cpp:266] Iteration 13100 (16.0608 iter/s, 6.22632s/100 iter), loss = 0.108597
I0122 19:28:37.247681 70150 solver.cpp:285]     Train net output #0: loss = 0.108597 (* 1 = 0.108597 loss)
I0122 19:28:37.247686 70150 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 19:28:43.448292 70150 solver.cpp:266] Iteration 13200 (16.1281 iter/s, 6.20037s/100 iter), loss = 0.137022
I0122 19:28:43.448319 70150 solver.cpp:285]     Train net output #0: loss = 0.137022 (* 1 = 0.137022 loss)
I0122 19:28:43.448325 70150 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 19:28:49.669896 70150 solver.cpp:266] Iteration 13300 (16.0737 iter/s, 6.22134s/100 iter), loss = 0.141365
I0122 19:28:49.669926 70150 solver.cpp:285]     Train net output #0: loss = 0.141365 (* 1 = 0.141365 loss)
I0122 19:28:49.669932 70150 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 19:28:55.889130 70150 solver.cpp:266] Iteration 13400 (16.0798 iter/s, 6.21897s/100 iter), loss = 0.106572
I0122 19:28:55.889170 70150 solver.cpp:285]     Train net output #0: loss = 0.106572 (* 1 = 0.106572 loss)
I0122 19:28:55.889178 70150 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 19:29:02.108470 70150 solver.cpp:266] Iteration 13500 (16.0796 iter/s, 6.21906s/100 iter), loss = 0.140567
I0122 19:29:02.108546 70150 solver.cpp:285]     Train net output #0: loss = 0.140567 (* 1 = 0.140567 loss)
I0122 19:29:02.108552 70150 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 19:29:08.333077 70150 solver.cpp:266] Iteration 13600 (16.0661 iter/s, 6.2243s/100 iter), loss = 0.0664153
I0122 19:29:08.333106 70150 solver.cpp:285]     Train net output #0: loss = 0.0664154 (* 1 = 0.0664154 loss)
I0122 19:29:08.333111 70150 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 19:29:14.552700 70150 solver.cpp:266] Iteration 13700 (16.0788 iter/s, 6.21936s/100 iter), loss = 0.0876411
I0122 19:29:14.552726 70150 solver.cpp:285]     Train net output #0: loss = 0.0876411 (* 1 = 0.0876411 loss)
I0122 19:29:14.552731 70150 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 19:29:20.767001 70150 solver.cpp:266] Iteration 13800 (16.0926 iter/s, 6.21404s/100 iter), loss = 0.0924054
I0122 19:29:20.767029 70150 solver.cpp:285]     Train net output #0: loss = 0.0924055 (* 1 = 0.0924055 loss)
I0122 19:29:20.767033 70150 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 19:29:26.975220 70150 solver.cpp:266] Iteration 13900 (16.1084 iter/s, 6.20795s/100 iter), loss = 0.0624133
I0122 19:29:26.975250 70150 solver.cpp:285]     Train net output #0: loss = 0.0624134 (* 1 = 0.0624134 loss)
I0122 19:29:26.975255 70150 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 19:29:33.136056 70150 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 19:29:34.586225 70150 solver.cpp:517]     Test net output #0: accuracy = 0.737
I0122 19:29:34.586251 70150 solver.cpp:517]     Test net output #1: loss = 0.83262 (* 1 = 0.83262 loss)
I0122 19:29:34.586256 70150 solver.cpp:517]     Test net output #2: top-1 = 0.737
I0122 19:29:34.586259 70150 solver.cpp:517]     Test net output #3: top-5 = 0.962778
I0122 19:29:34.647413 70150 solver.cpp:266] Iteration 14000 (13.0346 iter/s, 7.67187s/100 iter), loss = 0.0434508
I0122 19:29:34.647434 70150 solver.cpp:285]     Train net output #0: loss = 0.0434508 (* 1 = 0.0434508 loss)
I0122 19:29:34.647439 70150 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 19:29:40.849295 70150 solver.cpp:266] Iteration 14100 (16.1248 iter/s, 6.20162s/100 iter), loss = 0.0902235
I0122 19:29:40.849323 70150 solver.cpp:285]     Train net output #0: loss = 0.0902235 (* 1 = 0.0902235 loss)
I0122 19:29:40.849328 70150 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 19:29:47.067126 70150 solver.cpp:266] Iteration 14200 (16.0835 iter/s, 6.21757s/100 iter), loss = 0.096448
I0122 19:29:47.067154 70150 solver.cpp:285]     Train net output #0: loss = 0.096448 (* 1 = 0.096448 loss)
I0122 19:29:47.067160 70150 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 19:29:53.284965 70150 solver.cpp:266] Iteration 14300 (16.0834 iter/s, 6.21757s/100 iter), loss = 0.0584663
I0122 19:29:53.284994 70150 solver.cpp:285]     Train net output #0: loss = 0.0584663 (* 1 = 0.0584663 loss)
I0122 19:29:53.285001 70150 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 19:29:59.493878 70150 solver.cpp:266] Iteration 14400 (16.1066 iter/s, 6.20865s/100 iter), loss = 0.0615307
I0122 19:29:59.493908 70150 solver.cpp:285]     Train net output #0: loss = 0.0615307 (* 1 = 0.0615307 loss)
I0122 19:29:59.493916 70150 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 19:30:05.728168 70150 solver.cpp:266] Iteration 14500 (16.041 iter/s, 6.23402s/100 iter), loss = 0.065477
I0122 19:30:05.728245 70150 solver.cpp:285]     Train net output #0: loss = 0.065477 (* 1 = 0.065477 loss)
I0122 19:30:05.728251 70150 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 19:30:11.942858 70150 solver.cpp:266] Iteration 14600 (16.0917 iter/s, 6.21438s/100 iter), loss = 0.0744797
I0122 19:30:11.942886 70150 solver.cpp:285]     Train net output #0: loss = 0.0744797 (* 1 = 0.0744797 loss)
I0122 19:30:11.942893 70150 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 19:30:18.166646 70150 solver.cpp:266] Iteration 14700 (16.0681 iter/s, 6.22352s/100 iter), loss = 0.0409808
I0122 19:30:18.166674 70150 solver.cpp:285]     Train net output #0: loss = 0.0409808 (* 1 = 0.0409808 loss)
I0122 19:30:18.166682 70150 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 19:30:24.395748 70150 solver.cpp:266] Iteration 14800 (16.0544 iter/s, 6.22883s/100 iter), loss = 0.0967879
I0122 19:30:24.395777 70150 solver.cpp:285]     Train net output #0: loss = 0.0967879 (* 1 = 0.0967879 loss)
I0122 19:30:24.395783 70150 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 19:30:30.616502 70150 solver.cpp:266] Iteration 14900 (16.0759 iter/s, 6.22048s/100 iter), loss = 0.0984037
I0122 19:30:30.616530 70150 solver.cpp:285]     Train net output #0: loss = 0.0984038 (* 1 = 0.0984038 loss)
I0122 19:30:30.616535 70150 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 19:30:36.781687 70150 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 19:30:38.237386 70150 solver.cpp:517]     Test net output #0: accuracy = 0.801889
I0122 19:30:38.237411 70150 solver.cpp:517]     Test net output #1: loss = 0.634521 (* 1 = 0.634521 loss)
I0122 19:30:38.237416 70150 solver.cpp:517]     Test net output #2: top-1 = 0.801889
I0122 19:30:38.237419 70150 solver.cpp:517]     Test net output #3: top-5 = 0.977111
I0122 19:30:38.299099 70150 solver.cpp:266] Iteration 15000 (13.017 iter/s, 7.68228s/100 iter), loss = 0.0904752
I0122 19:30:38.299119 70150 solver.cpp:285]     Train net output #0: loss = 0.0904752 (* 1 = 0.0904752 loss)
I0122 19:30:38.299125 70150 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 19:30:44.492694 70150 solver.cpp:266] Iteration 15100 (16.1464 iter/s, 6.19334s/100 iter), loss = 0.0657369
I0122 19:30:44.492722 70150 solver.cpp:285]     Train net output #0: loss = 0.0657369 (* 1 = 0.0657369 loss)
I0122 19:30:44.492727 70150 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 19:30:50.707473 70150 solver.cpp:266] Iteration 15200 (16.0914 iter/s, 6.21451s/100 iter), loss = 0.126144
I0122 19:30:50.707499 70150 solver.cpp:285]     Train net output #0: loss = 0.126144 (* 1 = 0.126144 loss)
I0122 19:30:50.707505 70150 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 19:30:56.915509 70150 solver.cpp:266] Iteration 15300 (16.1088 iter/s, 6.20777s/100 iter), loss = 0.108526
I0122 19:30:56.915537 70150 solver.cpp:285]     Train net output #0: loss = 0.108526 (* 1 = 0.108526 loss)
I0122 19:30:56.915544 70150 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 19:31:03.140408 70150 solver.cpp:266] Iteration 15400 (16.0652 iter/s, 6.22463s/100 iter), loss = 0.116298
I0122 19:31:03.140434 70150 solver.cpp:285]     Train net output #0: loss = 0.116298 (* 1 = 0.116298 loss)
I0122 19:31:03.140439 70150 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 19:31:09.361614 70150 solver.cpp:266] Iteration 15500 (16.0747 iter/s, 6.22094s/100 iter), loss = 0.0528261
I0122 19:31:09.361747 70150 solver.cpp:285]     Train net output #0: loss = 0.0528261 (* 1 = 0.0528261 loss)
I0122 19:31:09.361752 70150 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 19:31:15.592190 70150 solver.cpp:266] Iteration 15600 (16.0508 iter/s, 6.23021s/100 iter), loss = 0.0723195
I0122 19:31:15.592218 70150 solver.cpp:285]     Train net output #0: loss = 0.0723195 (* 1 = 0.0723195 loss)
I0122 19:31:15.592224 70150 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 19:31:21.805833 70150 solver.cpp:266] Iteration 15700 (16.0943 iter/s, 6.21338s/100 iter), loss = 0.0724916
I0122 19:31:21.805861 70150 solver.cpp:285]     Train net output #0: loss = 0.0724916 (* 1 = 0.0724916 loss)
I0122 19:31:21.805866 70150 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 19:31:28.019763 70150 solver.cpp:266] Iteration 15800 (16.0936 iter/s, 6.21366s/100 iter), loss = 0.0720787
I0122 19:31:28.019791 70150 solver.cpp:285]     Train net output #0: loss = 0.0720787 (* 1 = 0.0720787 loss)
I0122 19:31:28.019798 70150 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 19:31:34.253968 70150 solver.cpp:266] Iteration 15900 (16.0412 iter/s, 6.23394s/100 iter), loss = 0.176178
I0122 19:31:34.253998 70150 solver.cpp:285]     Train net output #0: loss = 0.176178 (* 1 = 0.176178 loss)
I0122 19:31:34.254004 70150 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 19:31:40.407955 70150 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 19:31:41.857888 70150 solver.cpp:517]     Test net output #0: accuracy = 0.840667
I0122 19:31:41.857918 70150 solver.cpp:517]     Test net output #1: loss = 0.49005 (* 1 = 0.49005 loss)
I0122 19:31:41.857923 70150 solver.cpp:517]     Test net output #2: top-1 = 0.840667
I0122 19:31:41.857926 70150 solver.cpp:517]     Test net output #3: top-5 = 0.986445
I0122 19:31:41.919157 70150 solver.cpp:266] Iteration 16000 (13.0465 iter/s, 7.66487s/100 iter), loss = 0.0579828
I0122 19:31:41.919178 70150 solver.cpp:285]     Train net output #0: loss = 0.0579828 (* 1 = 0.0579828 loss)
I0122 19:31:41.919184 70150 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 19:31:48.134356 70150 solver.cpp:266] Iteration 16100 (16.0903 iter/s, 6.21494s/100 iter), loss = 0.103673
I0122 19:31:48.134384 70150 solver.cpp:285]     Train net output #0: loss = 0.103673 (* 1 = 0.103673 loss)
I0122 19:31:48.134390 70150 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 19:31:54.345978 70150 solver.cpp:266] Iteration 16200 (16.0995 iter/s, 6.21136s/100 iter), loss = 0.0724588
I0122 19:31:54.346006 70150 solver.cpp:285]     Train net output #0: loss = 0.0724588 (* 1 = 0.0724588 loss)
I0122 19:31:54.346012 70150 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 19:32:00.571449 70150 solver.cpp:266] Iteration 16300 (16.0637 iter/s, 6.2252s/100 iter), loss = 0.0824212
I0122 19:32:00.571476 70150 solver.cpp:285]     Train net output #0: loss = 0.0824213 (* 1 = 0.0824213 loss)
I0122 19:32:00.571481 70150 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 19:32:06.794075 70150 solver.cpp:266] Iteration 16400 (16.0711 iter/s, 6.22236s/100 iter), loss = 0.0454191
I0122 19:32:06.794104 70150 solver.cpp:285]     Train net output #0: loss = 0.0454191 (* 1 = 0.0454191 loss)
I0122 19:32:06.794109 70150 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 19:32:13.027962 70150 solver.cpp:266] Iteration 16500 (16.042 iter/s, 6.23362s/100 iter), loss = 0.0880136
I0122 19:32:13.028060 70150 solver.cpp:285]     Train net output #0: loss = 0.0880136 (* 1 = 0.0880136 loss)
I0122 19:32:13.028067 70150 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 19:32:19.257848 70150 solver.cpp:266] Iteration 16600 (16.0525 iter/s, 6.22955s/100 iter), loss = 0.0315357
I0122 19:32:19.257875 70150 solver.cpp:285]     Train net output #0: loss = 0.0315358 (* 1 = 0.0315358 loss)
I0122 19:32:19.257880 70150 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 19:32:25.462321 70150 solver.cpp:266] Iteration 16700 (16.1181 iter/s, 6.20421s/100 iter), loss = 0.0705796
I0122 19:32:25.462348 70150 solver.cpp:285]     Train net output #0: loss = 0.0705796 (* 1 = 0.0705796 loss)
I0122 19:32:25.462353 70150 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 19:32:31.677991 70150 solver.cpp:266] Iteration 16800 (16.0891 iter/s, 6.21541s/100 iter), loss = 0.0564493
I0122 19:32:31.678020 70150 solver.cpp:285]     Train net output #0: loss = 0.0564494 (* 1 = 0.0564494 loss)
I0122 19:32:31.678025 70150 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 19:32:37.885493 70150 solver.cpp:266] Iteration 16900 (16.1102 iter/s, 6.20724s/100 iter), loss = 0.0858311
I0122 19:32:37.885521 70150 solver.cpp:285]     Train net output #0: loss = 0.0858311 (* 1 = 0.0858311 loss)
I0122 19:32:37.885527 70150 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 19:32:44.039489 70150 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 19:32:45.493090 70150 solver.cpp:517]     Test net output #0: accuracy = 0.821778
I0122 19:32:45.493118 70150 solver.cpp:517]     Test net output #1: loss = 0.555862 (* 1 = 0.555862 loss)
I0122 19:32:45.493122 70150 solver.cpp:517]     Test net output #2: top-1 = 0.821778
I0122 19:32:45.493125 70150 solver.cpp:517]     Test net output #3: top-5 = 0.991667
I0122 19:32:45.555742 70150 solver.cpp:266] Iteration 17000 (13.0379 iter/s, 7.66993s/100 iter), loss = 0.0771669
I0122 19:32:45.555763 70150 solver.cpp:285]     Train net output #0: loss = 0.0771669 (* 1 = 0.0771669 loss)
I0122 19:32:45.555768 70150 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 19:32:51.774948 70150 solver.cpp:266] Iteration 17100 (16.0799 iter/s, 6.21895s/100 iter), loss = 0.0969128
I0122 19:32:51.774976 70150 solver.cpp:285]     Train net output #0: loss = 0.0969128 (* 1 = 0.0969128 loss)
I0122 19:32:51.774981 70150 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 19:32:57.985592 70150 solver.cpp:266] Iteration 17200 (16.1021 iter/s, 6.21038s/100 iter), loss = 0.117572
I0122 19:32:57.985621 70150 solver.cpp:285]     Train net output #0: loss = 0.117572 (* 1 = 0.117572 loss)
I0122 19:32:57.985627 70150 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 19:33:04.203012 70150 solver.cpp:266] Iteration 17300 (16.0845 iter/s, 6.21715s/100 iter), loss = 0.0901169
I0122 19:33:04.203039 70150 solver.cpp:285]     Train net output #0: loss = 0.090117 (* 1 = 0.090117 loss)
I0122 19:33:04.203044 70150 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 19:33:10.427541 70150 solver.cpp:266] Iteration 17400 (16.0662 iter/s, 6.22426s/100 iter), loss = 0.127178
I0122 19:33:10.427568 70150 solver.cpp:285]     Train net output #0: loss = 0.127178 (* 1 = 0.127178 loss)
I0122 19:33:10.427574 70150 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 19:33:16.639093 70150 solver.cpp:266] Iteration 17500 (16.0997 iter/s, 6.21129s/100 iter), loss = 0.0653958
I0122 19:33:16.639155 70150 solver.cpp:285]     Train net output #0: loss = 0.0653958 (* 1 = 0.0653958 loss)
I0122 19:33:16.639163 70150 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 19:33:22.863433 70150 solver.cpp:266] Iteration 17600 (16.0667 iter/s, 6.22404s/100 iter), loss = 0.0729783
I0122 19:33:22.863462 70150 solver.cpp:285]     Train net output #0: loss = 0.0729784 (* 1 = 0.0729784 loss)
I0122 19:33:22.863468 70150 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 19:33:29.087450 70150 solver.cpp:266] Iteration 17700 (16.0675 iter/s, 6.22375s/100 iter), loss = 0.0964679
I0122 19:33:29.087478 70150 solver.cpp:285]     Train net output #0: loss = 0.096468 (* 1 = 0.096468 loss)
I0122 19:33:29.087484 70150 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 19:33:35.302762 70150 solver.cpp:266] Iteration 17800 (16.09 iter/s, 6.21505s/100 iter), loss = 0.119218
I0122 19:33:35.302791 70150 solver.cpp:285]     Train net output #0: loss = 0.119218 (* 1 = 0.119218 loss)
I0122 19:33:35.302796 70150 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 19:33:41.514184 70150 solver.cpp:266] Iteration 17900 (16.1001 iter/s, 6.21116s/100 iter), loss = 0.0835027
I0122 19:33:41.514214 70150 solver.cpp:285]     Train net output #0: loss = 0.0835028 (* 1 = 0.0835028 loss)
I0122 19:33:41.514219 70150 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 19:33:47.675092 70150 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 19:33:49.125739 70150 solver.cpp:517]     Test net output #0: accuracy = 0.830889
I0122 19:33:49.125766 70150 solver.cpp:517]     Test net output #1: loss = 0.552905 (* 1 = 0.552905 loss)
I0122 19:33:49.125769 70150 solver.cpp:517]     Test net output #2: top-1 = 0.830889
I0122 19:33:49.125773 70150 solver.cpp:517]     Test net output #3: top-5 = 0.990556
I0122 19:33:49.186766 70150 solver.cpp:266] Iteration 18000 (13.034 iter/s, 7.67226s/100 iter), loss = 0.0980126
I0122 19:33:49.186786 70150 solver.cpp:285]     Train net output #0: loss = 0.0980126 (* 1 = 0.0980126 loss)
I0122 19:33:49.186792 70150 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 19:33:55.391520 70150 solver.cpp:266] Iteration 18100 (16.1173 iter/s, 6.20449s/100 iter), loss = 0.110057
I0122 19:33:55.391546 70150 solver.cpp:285]     Train net output #0: loss = 0.110057 (* 1 = 0.110057 loss)
I0122 19:33:55.391551 70150 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 19:34:01.608678 70150 solver.cpp:266] Iteration 18200 (16.0852 iter/s, 6.2169s/100 iter), loss = 0.021914
I0122 19:34:01.608707 70150 solver.cpp:285]     Train net output #0: loss = 0.0219141 (* 1 = 0.0219141 loss)
I0122 19:34:01.608713 70150 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 19:34:07.829689 70150 solver.cpp:266] Iteration 18300 (16.0753 iter/s, 6.22074s/100 iter), loss = 0.090258
I0122 19:34:07.829715 70150 solver.cpp:285]     Train net output #0: loss = 0.090258 (* 1 = 0.090258 loss)
I0122 19:34:07.829721 70150 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 19:34:14.042291 70150 solver.cpp:266] Iteration 18400 (16.097 iter/s, 6.21234s/100 iter), loss = 0.0899571
I0122 19:34:14.042321 70150 solver.cpp:285]     Train net output #0: loss = 0.0899572 (* 1 = 0.0899572 loss)
I0122 19:34:14.042326 70150 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 19:34:20.243587 70150 solver.cpp:266] Iteration 18500 (16.1264 iter/s, 6.20103s/100 iter), loss = 0.0884359
I0122 19:34:20.243646 70150 solver.cpp:285]     Train net output #0: loss = 0.088436 (* 1 = 0.088436 loss)
I0122 19:34:20.243652 70150 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 19:34:26.464516 70150 solver.cpp:266] Iteration 18600 (16.0755 iter/s, 6.22063s/100 iter), loss = 0.0640559
I0122 19:34:26.464545 70150 solver.cpp:285]     Train net output #0: loss = 0.064056 (* 1 = 0.064056 loss)
I0122 19:34:26.464550 70150 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 19:34:32.685844 70150 solver.cpp:266] Iteration 18700 (16.0744 iter/s, 6.22106s/100 iter), loss = 0.066129
I0122 19:34:32.685875 70150 solver.cpp:285]     Train net output #0: loss = 0.066129 (* 1 = 0.066129 loss)
I0122 19:34:32.685881 70150 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 19:34:38.901546 70150 solver.cpp:266] Iteration 18800 (16.089 iter/s, 6.21543s/100 iter), loss = 0.0862644
I0122 19:34:38.901572 70150 solver.cpp:285]     Train net output #0: loss = 0.0862644 (* 1 = 0.0862644 loss)
I0122 19:34:38.901577 70150 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 19:34:45.125531 70150 solver.cpp:266] Iteration 18900 (16.0676 iter/s, 6.22372s/100 iter), loss = 0.157567
I0122 19:34:45.125558 70150 solver.cpp:285]     Train net output #0: loss = 0.157567 (* 1 = 0.157567 loss)
I0122 19:34:45.125563 70150 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 19:34:51.296509 70150 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 19:34:52.744686 70150 solver.cpp:517]     Test net output #0: accuracy = 0.834
I0122 19:34:52.744710 70150 solver.cpp:517]     Test net output #1: loss = 0.560868 (* 1 = 0.560868 loss)
I0122 19:34:52.744714 70150 solver.cpp:517]     Test net output #2: top-1 = 0.834
I0122 19:34:52.744716 70150 solver.cpp:517]     Test net output #3: top-5 = 0.988445
I0122 19:34:52.807360 70150 solver.cpp:266] Iteration 19000 (13.0183 iter/s, 7.68151s/100 iter), loss = 0.11238
I0122 19:34:52.807380 70150 solver.cpp:285]     Train net output #0: loss = 0.11238 (* 1 = 0.11238 loss)
I0122 19:34:52.807386 70150 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 19:34:59.024546 70150 solver.cpp:266] Iteration 19100 (16.0851 iter/s, 6.21693s/100 iter), loss = 0.0358767
I0122 19:34:59.024574 70150 solver.cpp:285]     Train net output #0: loss = 0.0358768 (* 1 = 0.0358768 loss)
I0122 19:34:59.024577 70150 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 19:35:05.254570 70150 solver.cpp:266] Iteration 19200 (16.052 iter/s, 6.22976s/100 iter), loss = 0.0883437
I0122 19:35:05.254600 70150 solver.cpp:285]     Train net output #0: loss = 0.0883438 (* 1 = 0.0883438 loss)
I0122 19:35:05.254606 70150 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 19:35:11.463620 70150 solver.cpp:266] Iteration 19300 (16.1062 iter/s, 6.20878s/100 iter), loss = 0.0786895
I0122 19:35:11.463649 70150 solver.cpp:285]     Train net output #0: loss = 0.0786896 (* 1 = 0.0786896 loss)
I0122 19:35:11.463654 70150 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 19:35:17.688979 70150 solver.cpp:266] Iteration 19400 (16.064 iter/s, 6.22509s/100 iter), loss = 0.048529
I0122 19:35:17.689007 70150 solver.cpp:285]     Train net output #0: loss = 0.0485291 (* 1 = 0.0485291 loss)
I0122 19:35:17.689013 70150 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 19:35:23.892796 70150 solver.cpp:266] Iteration 19500 (16.1198 iter/s, 6.20355s/100 iter), loss = 0.0561548
I0122 19:35:23.892918 70150 solver.cpp:285]     Train net output #0: loss = 0.0561549 (* 1 = 0.0561549 loss)
I0122 19:35:23.892925 70150 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 19:35:30.112458 70150 solver.cpp:266] Iteration 19600 (16.079 iter/s, 6.2193s/100 iter), loss = 0.116496
I0122 19:35:30.112488 70150 solver.cpp:285]     Train net output #0: loss = 0.116496 (* 1 = 0.116496 loss)
I0122 19:35:30.112493 70150 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 19:35:36.347358 70150 solver.cpp:266] Iteration 19700 (16.0394 iter/s, 6.23463s/100 iter), loss = 0.0556548
I0122 19:35:36.347384 70150 solver.cpp:285]     Train net output #0: loss = 0.055655 (* 1 = 0.055655 loss)
I0122 19:35:36.347390 70150 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 19:35:42.548925 70150 solver.cpp:266] Iteration 19800 (16.1256 iter/s, 6.2013s/100 iter), loss = 0.083052
I0122 19:35:42.548954 70150 solver.cpp:285]     Train net output #0: loss = 0.0830521 (* 1 = 0.0830521 loss)
I0122 19:35:42.548959 70150 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 19:35:48.772580 70150 solver.cpp:266] Iteration 19900 (16.0684 iter/s, 6.22339s/100 iter), loss = 0.100059
I0122 19:35:48.772609 70150 solver.cpp:285]     Train net output #0: loss = 0.100059 (* 1 = 0.100059 loss)
I0122 19:35:48.772615 70150 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 19:35:54.920383 70150 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_20000.caffemodel
I0122 19:35:54.971206 70150 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_20000.solverstate
I0122 19:35:54.978705 70150 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 19:35:56.430891 70150 solver.cpp:517]     Test net output #0: accuracy = 0.855555
I0122 19:35:56.430917 70150 solver.cpp:517]     Test net output #1: loss = 0.46605 (* 1 = 0.46605 loss)
I0122 19:35:56.430922 70150 solver.cpp:517]     Test net output #2: top-1 = 0.855555
I0122 19:35:56.430925 70150 solver.cpp:517]     Test net output #3: top-5 = 0.991889
I0122 19:35:56.491998 70150 solver.cpp:266] Iteration 20000 (12.9549 iter/s, 7.7191s/100 iter), loss = 0.0390945
I0122 19:35:56.492017 70150 solver.cpp:285]     Train net output #0: loss = 0.0390946 (* 1 = 0.0390946 loss)
I0122 19:35:56.492024 70150 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 19:36:02.709403 70150 solver.cpp:266] Iteration 20100 (16.0845 iter/s, 6.21715s/100 iter), loss = 0.0905178
I0122 19:36:02.709430 70150 solver.cpp:285]     Train net output #0: loss = 0.0905179 (* 1 = 0.0905179 loss)
I0122 19:36:02.709435 70150 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 19:36:08.931900 70150 solver.cpp:266] Iteration 20200 (16.0714 iter/s, 6.22223s/100 iter), loss = 0.0556366
I0122 19:36:08.931928 70150 solver.cpp:285]     Train net output #0: loss = 0.0556367 (* 1 = 0.0556367 loss)
I0122 19:36:08.931934 70150 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 19:36:15.150508 70150 solver.cpp:266] Iteration 20300 (16.0815 iter/s, 6.21834s/100 iter), loss = 0.0128
I0122 19:36:15.150537 70150 solver.cpp:285]     Train net output #0: loss = 0.0128001 (* 1 = 0.0128001 loss)
I0122 19:36:15.150543 70150 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 19:36:21.362161 70150 solver.cpp:266] Iteration 20400 (16.0995 iter/s, 6.21139s/100 iter), loss = 0.039436
I0122 19:36:21.362190 70150 solver.cpp:285]     Train net output #0: loss = 0.0394361 (* 1 = 0.0394361 loss)
I0122 19:36:21.362195 70150 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 19:36:27.589540 70150 solver.cpp:266] Iteration 20500 (16.0588 iter/s, 6.22711s/100 iter), loss = 0.0197996
I0122 19:36:27.589614 70150 solver.cpp:285]     Train net output #0: loss = 0.0197997 (* 1 = 0.0197997 loss)
I0122 19:36:27.589620 70150 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 19:36:33.798336 70150 solver.cpp:266] Iteration 20600 (16.107 iter/s, 6.20849s/100 iter), loss = 0.0421147
I0122 19:36:33.798364 70150 solver.cpp:285]     Train net output #0: loss = 0.0421148 (* 1 = 0.0421148 loss)
I0122 19:36:33.798370 70150 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 19:36:40.010828 70150 solver.cpp:266] Iteration 20700 (16.0973 iter/s, 6.21222s/100 iter), loss = 0.0287026
I0122 19:36:40.010856 70150 solver.cpp:285]     Train net output #0: loss = 0.0287027 (* 1 = 0.0287027 loss)
I0122 19:36:40.010862 70150 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 19:36:46.229856 70150 solver.cpp:266] Iteration 20800 (16.0804 iter/s, 6.21876s/100 iter), loss = 0.0311837
I0122 19:36:46.229884 70150 solver.cpp:285]     Train net output #0: loss = 0.0311838 (* 1 = 0.0311838 loss)
I0122 19:36:46.229889 70150 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 19:36:52.441628 70150 solver.cpp:266] Iteration 20900 (16.0992 iter/s, 6.21151s/100 iter), loss = 0.0349463
I0122 19:36:52.441656 70150 solver.cpp:285]     Train net output #0: loss = 0.0349464 (* 1 = 0.0349464 loss)
I0122 19:36:52.441661 70150 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 19:36:58.597787 70150 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 19:37:00.049422 70150 solver.cpp:517]     Test net output #0: accuracy = 0.893111
I0122 19:37:00.049445 70150 solver.cpp:517]     Test net output #1: loss = 0.35508 (* 1 = 0.35508 loss)
I0122 19:37:00.049449 70150 solver.cpp:517]     Test net output #2: top-1 = 0.893111
I0122 19:37:00.049453 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:37:00.113008 70150 solver.cpp:266] Iteration 21000 (13.036 iter/s, 7.67106s/100 iter), loss = 0.0208964
I0122 19:37:00.113029 70150 solver.cpp:285]     Train net output #0: loss = 0.0208966 (* 1 = 0.0208966 loss)
I0122 19:37:00.113034 70150 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 19:37:06.330373 70150 solver.cpp:266] Iteration 21100 (16.0847 iter/s, 6.2171s/100 iter), loss = 0.0349755
I0122 19:37:06.330399 70150 solver.cpp:285]     Train net output #0: loss = 0.0349757 (* 1 = 0.0349757 loss)
I0122 19:37:06.330405 70150 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 19:37:12.552666 70150 solver.cpp:266] Iteration 21200 (16.0719 iter/s, 6.22203s/100 iter), loss = 0.0209821
I0122 19:37:12.552695 70150 solver.cpp:285]     Train net output #0: loss = 0.0209823 (* 1 = 0.0209823 loss)
I0122 19:37:12.552700 70150 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 19:37:18.777735 70150 solver.cpp:266] Iteration 21300 (16.0648 iter/s, 6.2248s/100 iter), loss = 0.0224267
I0122 19:37:18.777763 70150 solver.cpp:285]     Train net output #0: loss = 0.0224268 (* 1 = 0.0224268 loss)
I0122 19:37:18.777770 70150 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 19:37:24.985726 70150 solver.cpp:266] Iteration 21400 (16.109 iter/s, 6.20772s/100 iter), loss = 0.0171163
I0122 19:37:24.985755 70150 solver.cpp:285]     Train net output #0: loss = 0.0171164 (* 1 = 0.0171164 loss)
I0122 19:37:24.985760 70150 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 19:37:31.202812 70150 solver.cpp:266] Iteration 21500 (16.0854 iter/s, 6.21682s/100 iter), loss = 0.0141914
I0122 19:37:31.202888 70150 solver.cpp:285]     Train net output #0: loss = 0.0141915 (* 1 = 0.0141915 loss)
I0122 19:37:31.202895 70150 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 19:37:37.425863 70150 solver.cpp:266] Iteration 21600 (16.0701 iter/s, 6.22274s/100 iter), loss = 0.0105316
I0122 19:37:37.425891 70150 solver.cpp:285]     Train net output #0: loss = 0.0105317 (* 1 = 0.0105317 loss)
I0122 19:37:37.425897 70150 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 19:37:43.637696 70150 solver.cpp:266] Iteration 21700 (16.099 iter/s, 6.21157s/100 iter), loss = 0.0328662
I0122 19:37:43.637725 70150 solver.cpp:285]     Train net output #0: loss = 0.0328663 (* 1 = 0.0328663 loss)
I0122 19:37:43.637732 70150 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 19:37:49.869005 70150 solver.cpp:266] Iteration 21800 (16.0487 iter/s, 6.23104s/100 iter), loss = 0.0108618
I0122 19:37:49.869033 70150 solver.cpp:285]     Train net output #0: loss = 0.0108619 (* 1 = 0.0108619 loss)
I0122 19:37:49.869040 70150 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 19:37:56.089406 70150 solver.cpp:266] Iteration 21900 (16.0768 iter/s, 6.22013s/100 iter), loss = 0.0329153
I0122 19:37:56.089434 70150 solver.cpp:285]     Train net output #0: loss = 0.0329154 (* 1 = 0.0329154 loss)
I0122 19:37:56.089439 70150 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 19:38:02.228863 70150 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 19:38:03.689090 70150 solver.cpp:517]     Test net output #0: accuracy = 0.894
I0122 19:38:03.689118 70150 solver.cpp:517]     Test net output #1: loss = 0.35629 (* 1 = 0.35629 loss)
I0122 19:38:03.689122 70150 solver.cpp:517]     Test net output #2: top-1 = 0.894
I0122 19:38:03.689126 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:38:03.750754 70150 solver.cpp:266] Iteration 22000 (13.0531 iter/s, 7.66103s/100 iter), loss = 0.00883062
I0122 19:38:03.750775 70150 solver.cpp:285]     Train net output #0: loss = 0.00883071 (* 1 = 0.00883071 loss)
I0122 19:38:03.750782 70150 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 19:38:09.960041 70150 solver.cpp:266] Iteration 22100 (16.1056 iter/s, 6.20903s/100 iter), loss = 0.0133934
I0122 19:38:09.960069 70150 solver.cpp:285]     Train net output #0: loss = 0.0133935 (* 1 = 0.0133935 loss)
I0122 19:38:09.960075 70150 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 19:38:16.165992 70150 solver.cpp:266] Iteration 22200 (16.1143 iter/s, 6.20568s/100 iter), loss = 0.0121722
I0122 19:38:16.166018 70150 solver.cpp:285]     Train net output #0: loss = 0.0121723 (* 1 = 0.0121723 loss)
I0122 19:38:16.166023 70150 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 19:38:22.391011 70150 solver.cpp:266] Iteration 22300 (16.0649 iter/s, 6.22475s/100 iter), loss = 0.00731063
I0122 19:38:22.391041 70150 solver.cpp:285]     Train net output #0: loss = 0.00731074 (* 1 = 0.00731074 loss)
I0122 19:38:22.391047 70150 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 19:38:28.607813 70150 solver.cpp:266] Iteration 22400 (16.0861 iter/s, 6.21654s/100 iter), loss = 0.0275765
I0122 19:38:28.607843 70150 solver.cpp:285]     Train net output #0: loss = 0.0275766 (* 1 = 0.0275766 loss)
I0122 19:38:28.607849 70150 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 19:38:34.834848 70150 solver.cpp:266] Iteration 22500 (16.0597 iter/s, 6.22677s/100 iter), loss = 0.0204486
I0122 19:38:34.834928 70150 solver.cpp:285]     Train net output #0: loss = 0.0204488 (* 1 = 0.0204488 loss)
I0122 19:38:34.834934 70150 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 19:38:41.048125 70150 solver.cpp:266] Iteration 22600 (16.0954 iter/s, 6.21296s/100 iter), loss = 0.0124224
I0122 19:38:41.048154 70150 solver.cpp:285]     Train net output #0: loss = 0.0124225 (* 1 = 0.0124225 loss)
I0122 19:38:41.048159 70150 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 19:38:47.277765 70150 solver.cpp:266] Iteration 22700 (16.053 iter/s, 6.22937s/100 iter), loss = 0.00829685
I0122 19:38:47.277794 70150 solver.cpp:285]     Train net output #0: loss = 0.00829695 (* 1 = 0.00829695 loss)
I0122 19:38:47.277801 70150 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 19:38:53.482733 70150 solver.cpp:266] Iteration 22800 (16.1168 iter/s, 6.2047s/100 iter), loss = 0.0150871
I0122 19:38:53.482762 70150 solver.cpp:285]     Train net output #0: loss = 0.0150872 (* 1 = 0.0150872 loss)
I0122 19:38:53.482769 70150 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 19:38:59.703203 70150 solver.cpp:266] Iteration 22900 (16.0766 iter/s, 6.2202s/100 iter), loss = 0.0125403
I0122 19:38:59.703233 70150 solver.cpp:285]     Train net output #0: loss = 0.0125404 (* 1 = 0.0125404 loss)
I0122 19:38:59.703238 70150 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 19:39:05.855891 70150 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 19:39:07.318126 70150 solver.cpp:517]     Test net output #0: accuracy = 0.895889
I0122 19:39:07.318153 70150 solver.cpp:517]     Test net output #1: loss = 0.355898 (* 1 = 0.355898 loss)
I0122 19:39:07.318158 70150 solver.cpp:517]     Test net output #2: top-1 = 0.895889
I0122 19:39:07.318162 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:39:07.379325 70150 solver.cpp:266] Iteration 23000 (13.028 iter/s, 7.6758s/100 iter), loss = 0.013273
I0122 19:39:07.379346 70150 solver.cpp:285]     Train net output #0: loss = 0.0132731 (* 1 = 0.0132731 loss)
I0122 19:39:07.379354 70150 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 19:39:13.590361 70150 solver.cpp:266] Iteration 23100 (16.101 iter/s, 6.21078s/100 iter), loss = 0.0278716
I0122 19:39:13.590389 70150 solver.cpp:285]     Train net output #0: loss = 0.0278717 (* 1 = 0.0278717 loss)
I0122 19:39:13.590394 70150 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 19:39:19.801761 70150 solver.cpp:266] Iteration 23200 (16.1001 iter/s, 6.21113s/100 iter), loss = 0.017362
I0122 19:39:19.801790 70150 solver.cpp:285]     Train net output #0: loss = 0.0173621 (* 1 = 0.0173621 loss)
I0122 19:39:19.801796 70150 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 19:39:26.019927 70150 solver.cpp:266] Iteration 23300 (16.0826 iter/s, 6.2179s/100 iter), loss = 0.011181
I0122 19:39:26.019956 70150 solver.cpp:285]     Train net output #0: loss = 0.0111811 (* 1 = 0.0111811 loss)
I0122 19:39:26.019963 70150 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 19:39:32.245880 70150 solver.cpp:266] Iteration 23400 (16.0625 iter/s, 6.22569s/100 iter), loss = 0.00746509
I0122 19:39:32.245913 70150 solver.cpp:285]     Train net output #0: loss = 0.0074652 (* 1 = 0.0074652 loss)
I0122 19:39:32.245918 70150 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 19:39:38.457939 70150 solver.cpp:266] Iteration 23500 (16.0984 iter/s, 6.21179s/100 iter), loss = 0.00818163
I0122 19:39:38.457999 70150 solver.cpp:285]     Train net output #0: loss = 0.00818174 (* 1 = 0.00818174 loss)
I0122 19:39:38.458005 70150 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 19:39:44.670742 70150 solver.cpp:266] Iteration 23600 (16.0966 iter/s, 6.2125s/100 iter), loss = 0.010044
I0122 19:39:44.670771 70150 solver.cpp:285]     Train net output #0: loss = 0.0100441 (* 1 = 0.0100441 loss)
I0122 19:39:44.670778 70150 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 19:39:50.898322 70150 solver.cpp:266] Iteration 23700 (16.0583 iter/s, 6.22731s/100 iter), loss = 0.0130135
I0122 19:39:50.898351 70150 solver.cpp:285]     Train net output #0: loss = 0.0130136 (* 1 = 0.0130136 loss)
I0122 19:39:50.898357 70150 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 19:39:57.100436 70150 solver.cpp:266] Iteration 23800 (16.1242 iter/s, 6.20185s/100 iter), loss = 0.0168062
I0122 19:39:57.100464 70150 solver.cpp:285]     Train net output #0: loss = 0.0168063 (* 1 = 0.0168063 loss)
I0122 19:39:57.100471 70150 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 19:40:03.314843 70150 solver.cpp:266] Iteration 23900 (16.0923 iter/s, 6.21414s/100 iter), loss = 0.00458494
I0122 19:40:03.314872 70150 solver.cpp:285]     Train net output #0: loss = 0.00458506 (* 1 = 0.00458506 loss)
I0122 19:40:03.314878 70150 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 19:40:09.488466 70150 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 19:40:10.943063 70150 solver.cpp:517]     Test net output #0: accuracy = 0.896111
I0122 19:40:10.943087 70150 solver.cpp:517]     Test net output #1: loss = 0.364683 (* 1 = 0.364683 loss)
I0122 19:40:10.943091 70150 solver.cpp:517]     Test net output #2: top-1 = 0.896111
I0122 19:40:10.943096 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:40:11.004300 70150 solver.cpp:266] Iteration 24000 (13.0054 iter/s, 7.68914s/100 iter), loss = 0.0163786
I0122 19:40:11.004321 70150 solver.cpp:285]     Train net output #0: loss = 0.0163787 (* 1 = 0.0163787 loss)
I0122 19:40:11.004328 70150 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 19:40:17.218783 70150 solver.cpp:266] Iteration 24100 (16.0921 iter/s, 6.21422s/100 iter), loss = 0.00686169
I0122 19:40:17.218813 70150 solver.cpp:285]     Train net output #0: loss = 0.00686181 (* 1 = 0.00686181 loss)
I0122 19:40:17.218819 70150 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 19:40:23.443899 70150 solver.cpp:266] Iteration 24200 (16.0646 iter/s, 6.22485s/100 iter), loss = 0.00461503
I0122 19:40:23.443928 70150 solver.cpp:285]     Train net output #0: loss = 0.00461514 (* 1 = 0.00461514 loss)
I0122 19:40:23.443933 70150 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 19:40:29.661643 70150 solver.cpp:266] Iteration 24300 (16.0837 iter/s, 6.21748s/100 iter), loss = 0.0118496
I0122 19:40:29.661671 70150 solver.cpp:285]     Train net output #0: loss = 0.0118497 (* 1 = 0.0118497 loss)
I0122 19:40:29.661677 70150 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 19:40:35.874075 70150 solver.cpp:266] Iteration 24400 (16.0974 iter/s, 6.21217s/100 iter), loss = 0.00938774
I0122 19:40:35.874104 70150 solver.cpp:285]     Train net output #0: loss = 0.00938786 (* 1 = 0.00938786 loss)
I0122 19:40:35.874110 70150 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 19:40:42.081856 70150 solver.cpp:266] Iteration 24500 (16.1095 iter/s, 6.20751s/100 iter), loss = 0.010699
I0122 19:40:42.081914 70150 solver.cpp:285]     Train net output #0: loss = 0.0106992 (* 1 = 0.0106992 loss)
I0122 19:40:42.081921 70150 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 19:40:48.291522 70150 solver.cpp:266] Iteration 24600 (16.1047 iter/s, 6.20937s/100 iter), loss = 0.00945086
I0122 19:40:48.291551 70150 solver.cpp:285]     Train net output #0: loss = 0.00945098 (* 1 = 0.00945098 loss)
I0122 19:40:48.291556 70150 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 19:40:54.518649 70150 solver.cpp:266] Iteration 24700 (16.0595 iter/s, 6.22686s/100 iter), loss = 0.00888818
I0122 19:40:54.518679 70150 solver.cpp:285]     Train net output #0: loss = 0.00888829 (* 1 = 0.00888829 loss)
I0122 19:40:54.518685 70150 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 19:41:00.749910 70150 solver.cpp:266] Iteration 24800 (16.0488 iter/s, 6.23099s/100 iter), loss = 0.0114981
I0122 19:41:00.749939 70150 solver.cpp:285]     Train net output #0: loss = 0.0114982 (* 1 = 0.0114982 loss)
I0122 19:41:00.749944 70150 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 19:41:06.965870 70150 solver.cpp:266] Iteration 24900 (16.0883 iter/s, 6.21569s/100 iter), loss = 0.0061258
I0122 19:41:06.965899 70150 solver.cpp:285]     Train net output #0: loss = 0.00612592 (* 1 = 0.00612592 loss)
I0122 19:41:06.965907 70150 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 19:41:13.121024 70150 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 19:41:14.567129 70150 solver.cpp:517]     Test net output #0: accuracy = 0.896556
I0122 19:41:14.567154 70150 solver.cpp:517]     Test net output #1: loss = 0.365047 (* 1 = 0.365047 loss)
I0122 19:41:14.567158 70150 solver.cpp:517]     Test net output #2: top-1 = 0.896556
I0122 19:41:14.567162 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:41:14.628885 70150 solver.cpp:266] Iteration 25000 (13.0502 iter/s, 7.6627s/100 iter), loss = 0.00604529
I0122 19:41:14.628904 70150 solver.cpp:285]     Train net output #0: loss = 0.0060454 (* 1 = 0.0060454 loss)
I0122 19:41:14.628911 70150 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 19:41:20.841931 70150 solver.cpp:266] Iteration 25100 (16.0958 iter/s, 6.21279s/100 iter), loss = 0.0105012
I0122 19:41:20.841958 70150 solver.cpp:285]     Train net output #0: loss = 0.0105013 (* 1 = 0.0105013 loss)
I0122 19:41:20.841964 70150 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 19:41:27.057256 70150 solver.cpp:266] Iteration 25200 (16.09 iter/s, 6.21506s/100 iter), loss = 0.0223255
I0122 19:41:27.057282 70150 solver.cpp:285]     Train net output #0: loss = 0.0223257 (* 1 = 0.0223257 loss)
I0122 19:41:27.057288 70150 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 19:41:33.254170 70150 solver.cpp:266] Iteration 25300 (16.1377 iter/s, 6.19665s/100 iter), loss = 0.0190515
I0122 19:41:33.254197 70150 solver.cpp:285]     Train net output #0: loss = 0.0190516 (* 1 = 0.0190516 loss)
I0122 19:41:33.254204 70150 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 19:41:39.460932 70150 solver.cpp:266] Iteration 25400 (16.1121 iter/s, 6.2065s/100 iter), loss = 0.00488548
I0122 19:41:39.460959 70150 solver.cpp:285]     Train net output #0: loss = 0.00488559 (* 1 = 0.00488559 loss)
I0122 19:41:39.460964 70150 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 19:41:45.691339 70150 solver.cpp:266] Iteration 25500 (16.051 iter/s, 6.23014s/100 iter), loss = 0.0082303
I0122 19:41:45.691402 70150 solver.cpp:285]     Train net output #0: loss = 0.00823041 (* 1 = 0.00823041 loss)
I0122 19:41:45.691409 70150 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 19:41:51.914716 70150 solver.cpp:266] Iteration 25600 (16.0692 iter/s, 6.22308s/100 iter), loss = 0.0168281
I0122 19:41:51.914744 70150 solver.cpp:285]     Train net output #0: loss = 0.0168283 (* 1 = 0.0168283 loss)
I0122 19:41:51.914750 70150 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 19:41:58.140595 70150 solver.cpp:266] Iteration 25700 (16.0627 iter/s, 6.22561s/100 iter), loss = 0.00859447
I0122 19:41:58.140622 70150 solver.cpp:285]     Train net output #0: loss = 0.00859458 (* 1 = 0.00859458 loss)
I0122 19:41:58.140628 70150 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 19:42:04.348424 70150 solver.cpp:266] Iteration 25800 (16.1094 iter/s, 6.20756s/100 iter), loss = 0.00760521
I0122 19:42:04.348453 70150 solver.cpp:285]     Train net output #0: loss = 0.00760532 (* 1 = 0.00760532 loss)
I0122 19:42:04.348457 70150 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 19:42:10.567236 70150 solver.cpp:266] Iteration 25900 (16.0809 iter/s, 6.21855s/100 iter), loss = 0.0235795
I0122 19:42:10.567263 70150 solver.cpp:285]     Train net output #0: loss = 0.0235796 (* 1 = 0.0235796 loss)
I0122 19:42:10.567270 70150 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 19:42:16.714184 70150 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 19:42:18.180953 70150 solver.cpp:517]     Test net output #0: accuracy = 0.897
I0122 19:42:18.180977 70150 solver.cpp:517]     Test net output #1: loss = 0.366687 (* 1 = 0.366687 loss)
I0122 19:42:18.180981 70150 solver.cpp:517]     Test net output #2: top-1 = 0.897
I0122 19:42:18.180985 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:42:18.243052 70150 solver.cpp:266] Iteration 26000 (13.0285 iter/s, 7.6755s/100 iter), loss = 0.00483005
I0122 19:42:18.243073 70150 solver.cpp:285]     Train net output #0: loss = 0.00483016 (* 1 = 0.00483016 loss)
I0122 19:42:18.243079 70150 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 19:42:24.440557 70150 solver.cpp:266] Iteration 26100 (16.1362 iter/s, 6.19725s/100 iter), loss = 0.0125857
I0122 19:42:24.440582 70150 solver.cpp:285]     Train net output #0: loss = 0.0125858 (* 1 = 0.0125858 loss)
I0122 19:42:24.440587 70150 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 19:42:30.657882 70150 solver.cpp:266] Iteration 26200 (16.0848 iter/s, 6.21706s/100 iter), loss = 0.00612374
I0122 19:42:30.657912 70150 solver.cpp:285]     Train net output #0: loss = 0.00612385 (* 1 = 0.00612385 loss)
I0122 19:42:30.657917 70150 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 19:42:36.881939 70150 solver.cpp:266] Iteration 26300 (16.0674 iter/s, 6.22379s/100 iter), loss = 0.00930021
I0122 19:42:36.881966 70150 solver.cpp:285]     Train net output #0: loss = 0.00930032 (* 1 = 0.00930032 loss)
I0122 19:42:36.881973 70150 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 19:42:43.090756 70150 solver.cpp:266] Iteration 26400 (16.1068 iter/s, 6.20855s/100 iter), loss = 0.00376087
I0122 19:42:43.090785 70150 solver.cpp:285]     Train net output #0: loss = 0.00376098 (* 1 = 0.00376098 loss)
I0122 19:42:43.090790 70150 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 19:42:49.305392 70150 solver.cpp:266] Iteration 26500 (16.0917 iter/s, 6.21437s/100 iter), loss = 0.00665337
I0122 19:42:49.305506 70150 solver.cpp:285]     Train net output #0: loss = 0.00665348 (* 1 = 0.00665348 loss)
I0122 19:42:49.305513 70150 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 19:42:55.527822 70150 solver.cpp:266] Iteration 26600 (16.0718 iter/s, 6.22208s/100 iter), loss = 0.00329714
I0122 19:42:55.527850 70150 solver.cpp:285]     Train net output #0: loss = 0.00329725 (* 1 = 0.00329725 loss)
I0122 19:42:55.527856 70150 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 19:43:01.746975 70150 solver.cpp:266] Iteration 26700 (16.0801 iter/s, 6.21889s/100 iter), loss = 0.00632371
I0122 19:43:01.747004 70150 solver.cpp:285]     Train net output #0: loss = 0.00632381 (* 1 = 0.00632381 loss)
I0122 19:43:01.747009 70150 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 19:43:07.959177 70150 solver.cpp:266] Iteration 26800 (16.098 iter/s, 6.21193s/100 iter), loss = 0.0118378
I0122 19:43:07.959204 70150 solver.cpp:285]     Train net output #0: loss = 0.0118379 (* 1 = 0.0118379 loss)
I0122 19:43:07.959210 70150 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 19:43:14.184235 70150 solver.cpp:266] Iteration 26900 (16.0648 iter/s, 6.22479s/100 iter), loss = 0.00787863
I0122 19:43:14.184264 70150 solver.cpp:285]     Train net output #0: loss = 0.00787873 (* 1 = 0.00787873 loss)
I0122 19:43:14.184270 70150 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 19:43:20.347813 70150 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 19:43:21.801232 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898555
I0122 19:43:21.801257 70150 solver.cpp:517]     Test net output #1: loss = 0.367626 (* 1 = 0.367626 loss)
I0122 19:43:21.801262 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898555
I0122 19:43:21.801265 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:43:21.863291 70150 solver.cpp:266] Iteration 27000 (13.023 iter/s, 7.67874s/100 iter), loss = 0.00437688
I0122 19:43:21.863310 70150 solver.cpp:285]     Train net output #0: loss = 0.00437699 (* 1 = 0.00437699 loss)
I0122 19:43:21.863317 70150 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 19:43:28.068631 70150 solver.cpp:266] Iteration 27100 (16.1158 iter/s, 6.20508s/100 iter), loss = 0.00807521
I0122 19:43:28.068660 70150 solver.cpp:285]     Train net output #0: loss = 0.00807531 (* 1 = 0.00807531 loss)
I0122 19:43:28.068665 70150 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 19:43:34.277794 70150 solver.cpp:266] Iteration 27200 (16.1059 iter/s, 6.2089s/100 iter), loss = 0.00716029
I0122 19:43:34.277822 70150 solver.cpp:285]     Train net output #0: loss = 0.0071604 (* 1 = 0.0071604 loss)
I0122 19:43:34.277827 70150 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 19:43:40.486564 70150 solver.cpp:266] Iteration 27300 (16.1069 iter/s, 6.2085s/100 iter), loss = 0.00691377
I0122 19:43:40.486591 70150 solver.cpp:285]     Train net output #0: loss = 0.00691388 (* 1 = 0.00691388 loss)
I0122 19:43:40.486598 70150 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 19:43:46.706609 70150 solver.cpp:266] Iteration 27400 (16.0777 iter/s, 6.21978s/100 iter), loss = 0.0043936
I0122 19:43:46.706637 70150 solver.cpp:285]     Train net output #0: loss = 0.00439371 (* 1 = 0.00439371 loss)
I0122 19:43:46.706643 70150 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 19:43:52.936846 70150 solver.cpp:266] Iteration 27500 (16.0514 iter/s, 6.22997s/100 iter), loss = 0.00338937
I0122 19:43:52.936967 70150 solver.cpp:285]     Train net output #0: loss = 0.00338948 (* 1 = 0.00338948 loss)
I0122 19:43:52.936975 70150 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 19:43:59.149878 70150 solver.cpp:266] Iteration 27600 (16.0961 iter/s, 6.21267s/100 iter), loss = 0.00435661
I0122 19:43:59.149909 70150 solver.cpp:285]     Train net output #0: loss = 0.00435672 (* 1 = 0.00435672 loss)
I0122 19:43:59.149917 70150 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 19:44:05.353561 70150 solver.cpp:266] Iteration 27700 (16.1201 iter/s, 6.20342s/100 iter), loss = 0.00478638
I0122 19:44:05.353591 70150 solver.cpp:285]     Train net output #0: loss = 0.00478649 (* 1 = 0.00478649 loss)
I0122 19:44:05.353596 70150 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 19:44:11.575939 70150 solver.cpp:266] Iteration 27800 (16.0717 iter/s, 6.22211s/100 iter), loss = 0.00823996
I0122 19:44:11.575968 70150 solver.cpp:285]     Train net output #0: loss = 0.00824007 (* 1 = 0.00824007 loss)
I0122 19:44:11.575974 70150 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 19:44:17.784318 70150 solver.cpp:266] Iteration 27900 (16.108 iter/s, 6.20811s/100 iter), loss = 0.00576458
I0122 19:44:17.784346 70150 solver.cpp:285]     Train net output #0: loss = 0.0057647 (* 1 = 0.0057647 loss)
I0122 19:44:17.784353 70150 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 19:44:23.965171 70150 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 19:44:25.418027 70150 solver.cpp:517]     Test net output #0: accuracy = 0.897222
I0122 19:44:25.418052 70150 solver.cpp:517]     Test net output #1: loss = 0.373937 (* 1 = 0.373937 loss)
I0122 19:44:25.418057 70150 solver.cpp:517]     Test net output #2: top-1 = 0.897222
I0122 19:44:25.418061 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:44:25.480788 70150 solver.cpp:266] Iteration 28000 (12.9935 iter/s, 7.69615s/100 iter), loss = 0.00581858
I0122 19:44:25.480808 70150 solver.cpp:285]     Train net output #0: loss = 0.00581869 (* 1 = 0.00581869 loss)
I0122 19:44:25.480814 70150 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 19:44:31.696087 70150 solver.cpp:266] Iteration 28100 (16.09 iter/s, 6.21504s/100 iter), loss = 0.0031265
I0122 19:44:31.696115 70150 solver.cpp:285]     Train net output #0: loss = 0.00312661 (* 1 = 0.00312661 loss)
I0122 19:44:31.696120 70150 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 19:44:37.907635 70150 solver.cpp:266] Iteration 28200 (16.0997 iter/s, 6.21128s/100 iter), loss = 0.00570234
I0122 19:44:37.907663 70150 solver.cpp:285]     Train net output #0: loss = 0.00570245 (* 1 = 0.00570245 loss)
I0122 19:44:37.907670 70150 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 19:44:44.130863 70150 solver.cpp:266] Iteration 28300 (16.0695 iter/s, 6.22296s/100 iter), loss = 0.00522284
I0122 19:44:44.130892 70150 solver.cpp:285]     Train net output #0: loss = 0.00522296 (* 1 = 0.00522296 loss)
I0122 19:44:44.130897 70150 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 19:44:50.336782 70150 solver.cpp:266] Iteration 28400 (16.1143 iter/s, 6.20565s/100 iter), loss = 0.00928687
I0122 19:44:50.336809 70150 solver.cpp:285]     Train net output #0: loss = 0.00928699 (* 1 = 0.00928699 loss)
I0122 19:44:50.336815 70150 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 19:44:56.556126 70150 solver.cpp:266] Iteration 28500 (16.0796 iter/s, 6.21908s/100 iter), loss = 0.00509278
I0122 19:44:56.556198 70150 solver.cpp:285]     Train net output #0: loss = 0.0050929 (* 1 = 0.0050929 loss)
I0122 19:44:56.556205 70150 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 19:45:02.777241 70150 solver.cpp:266] Iteration 28600 (16.0751 iter/s, 6.22081s/100 iter), loss = 0.0113358
I0122 19:45:02.777271 70150 solver.cpp:285]     Train net output #0: loss = 0.0113359 (* 1 = 0.0113359 loss)
I0122 19:45:02.777276 70150 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 19:45:09.013074 70150 solver.cpp:266] Iteration 28700 (16.037 iter/s, 6.23556s/100 iter), loss = 0.006137
I0122 19:45:09.013103 70150 solver.cpp:285]     Train net output #0: loss = 0.00613712 (* 1 = 0.00613712 loss)
I0122 19:45:09.013109 70150 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 19:45:15.222398 70150 solver.cpp:266] Iteration 28800 (16.1055 iter/s, 6.20906s/100 iter), loss = 0.00495127
I0122 19:45:15.222425 70150 solver.cpp:285]     Train net output #0: loss = 0.00495138 (* 1 = 0.00495138 loss)
I0122 19:45:15.222431 70150 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 19:45:21.429255 70150 solver.cpp:266] Iteration 28900 (16.1119 iter/s, 6.20659s/100 iter), loss = 0.00730286
I0122 19:45:21.429283 70150 solver.cpp:285]     Train net output #0: loss = 0.00730298 (* 1 = 0.00730298 loss)
I0122 19:45:21.429288 70150 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 19:45:27.577875 70150 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 19:45:29.025182 70150 solver.cpp:517]     Test net output #0: accuracy = 0.897889
I0122 19:45:29.025207 70150 solver.cpp:517]     Test net output #1: loss = 0.370851 (* 1 = 0.370851 loss)
I0122 19:45:29.025211 70150 solver.cpp:517]     Test net output #2: top-1 = 0.897889
I0122 19:45:29.025214 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:45:29.086731 70150 solver.cpp:266] Iteration 29000 (13.0597 iter/s, 7.65716s/100 iter), loss = 0.00926577
I0122 19:45:29.086751 70150 solver.cpp:285]     Train net output #0: loss = 0.00926589 (* 1 = 0.00926589 loss)
I0122 19:45:29.086757 70150 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 19:45:35.304352 70150 solver.cpp:266] Iteration 29100 (16.084 iter/s, 6.21736s/100 iter), loss = 0.0058046
I0122 19:45:35.304380 70150 solver.cpp:285]     Train net output #0: loss = 0.00580472 (* 1 = 0.00580472 loss)
I0122 19:45:35.304386 70150 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 19:45:41.527976 70150 solver.cpp:266] Iteration 29200 (16.0685 iter/s, 6.22336s/100 iter), loss = 0.00379637
I0122 19:45:41.528004 70150 solver.cpp:285]     Train net output #0: loss = 0.00379649 (* 1 = 0.00379649 loss)
I0122 19:45:41.528010 70150 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 19:45:47.736470 70150 solver.cpp:266] Iteration 29300 (16.1077 iter/s, 6.20823s/100 iter), loss = 0.00576155
I0122 19:45:47.736497 70150 solver.cpp:285]     Train net output #0: loss = 0.00576167 (* 1 = 0.00576167 loss)
I0122 19:45:47.736502 70150 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 19:45:53.946504 70150 solver.cpp:266] Iteration 29400 (16.1037 iter/s, 6.20977s/100 iter), loss = 0.00838575
I0122 19:45:53.946532 70150 solver.cpp:285]     Train net output #0: loss = 0.00838587 (* 1 = 0.00838587 loss)
I0122 19:45:53.946538 70150 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 19:46:00.170878 70150 solver.cpp:266] Iteration 29500 (16.0666 iter/s, 6.22411s/100 iter), loss = 0.00419161
I0122 19:46:00.170940 70150 solver.cpp:285]     Train net output #0: loss = 0.00419173 (* 1 = 0.00419173 loss)
I0122 19:46:00.170948 70150 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 19:46:06.391711 70150 solver.cpp:266] Iteration 29600 (16.0758 iter/s, 6.22053s/100 iter), loss = 0.00806917
I0122 19:46:06.391741 70150 solver.cpp:285]     Train net output #0: loss = 0.00806929 (* 1 = 0.00806929 loss)
I0122 19:46:06.391746 70150 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 19:46:12.610632 70150 solver.cpp:266] Iteration 29700 (16.0806 iter/s, 6.21866s/100 iter), loss = 0.00500866
I0122 19:46:12.610658 70150 solver.cpp:285]     Train net output #0: loss = 0.00500878 (* 1 = 0.00500878 loss)
I0122 19:46:12.610663 70150 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 19:46:18.808943 70150 solver.cpp:266] Iteration 29800 (16.1341 iter/s, 6.19805s/100 iter), loss = 0.00861661
I0122 19:46:18.808971 70150 solver.cpp:285]     Train net output #0: loss = 0.00861673 (* 1 = 0.00861673 loss)
I0122 19:46:18.808977 70150 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 19:46:25.030289 70150 solver.cpp:266] Iteration 29900 (16.0744 iter/s, 6.22108s/100 iter), loss = 0.00454319
I0122 19:46:25.030318 70150 solver.cpp:285]     Train net output #0: loss = 0.00454331 (* 1 = 0.00454331 loss)
I0122 19:46:25.030323 70150 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 19:46:31.187882 70150 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 19:46:32.643746 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898667
I0122 19:46:32.643770 70150 solver.cpp:517]     Test net output #1: loss = 0.368807 (* 1 = 0.368807 loss)
I0122 19:46:32.643774 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898667
I0122 19:46:32.643776 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:46:32.706395 70150 solver.cpp:266] Iteration 30000 (13.028 iter/s, 7.67579s/100 iter), loss = 0.00470067
I0122 19:46:32.706418 70150 solver.cpp:285]     Train net output #0: loss = 0.00470079 (* 1 = 0.00470079 loss)
I0122 19:46:32.706423 70150 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 19:46:38.914158 70150 solver.cpp:266] Iteration 30100 (16.1095 iter/s, 6.2075s/100 iter), loss = 0.00493961
I0122 19:46:38.914186 70150 solver.cpp:285]     Train net output #0: loss = 0.00493973 (* 1 = 0.00493973 loss)
I0122 19:46:38.914191 70150 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 19:46:45.144767 70150 solver.cpp:266] Iteration 30200 (16.0505 iter/s, 6.23034s/100 iter), loss = 0.0094814
I0122 19:46:45.144795 70150 solver.cpp:285]     Train net output #0: loss = 0.00948152 (* 1 = 0.00948152 loss)
I0122 19:46:45.144803 70150 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 19:46:51.349139 70150 solver.cpp:266] Iteration 30300 (16.1184 iter/s, 6.20411s/100 iter), loss = 0.0049786
I0122 19:46:51.349166 70150 solver.cpp:285]     Train net output #0: loss = 0.00497871 (* 1 = 0.00497871 loss)
I0122 19:46:51.349172 70150 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 19:46:57.568737 70150 solver.cpp:266] Iteration 30400 (16.0789 iter/s, 6.21933s/100 iter), loss = 0.00729034
I0122 19:46:57.568768 70150 solver.cpp:285]     Train net output #0: loss = 0.00729045 (* 1 = 0.00729045 loss)
I0122 19:46:57.568773 70150 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 19:47:03.796612 70150 solver.cpp:266] Iteration 30500 (16.0575 iter/s, 6.22761s/100 iter), loss = 0.00502126
I0122 19:47:03.796716 70150 solver.cpp:285]     Train net output #0: loss = 0.00502137 (* 1 = 0.00502137 loss)
I0122 19:47:03.796725 70150 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 19:47:10.013018 70150 solver.cpp:266] Iteration 30600 (16.0873 iter/s, 6.21606s/100 iter), loss = 0.0128749
I0122 19:47:10.013046 70150 solver.cpp:285]     Train net output #0: loss = 0.012875 (* 1 = 0.012875 loss)
I0122 19:47:10.013052 70150 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 19:47:16.220129 70150 solver.cpp:266] Iteration 30700 (16.1112 iter/s, 6.20684s/100 iter), loss = 0.00427631
I0122 19:47:16.220156 70150 solver.cpp:285]     Train net output #0: loss = 0.00427642 (* 1 = 0.00427642 loss)
I0122 19:47:16.220163 70150 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 19:47:22.447544 70150 solver.cpp:266] Iteration 30800 (16.0587 iter/s, 6.22715s/100 iter), loss = 0.00643535
I0122 19:47:22.447572 70150 solver.cpp:285]     Train net output #0: loss = 0.00643547 (* 1 = 0.00643547 loss)
I0122 19:47:22.447578 70150 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 19:47:28.655616 70150 solver.cpp:266] Iteration 30900 (16.1088 iter/s, 6.20781s/100 iter), loss = 0.00482409
I0122 19:47:28.655643 70150 solver.cpp:285]     Train net output #0: loss = 0.0048242 (* 1 = 0.0048242 loss)
I0122 19:47:28.655649 70150 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 19:47:34.811815 70150 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 19:47:36.262728 70150 solver.cpp:517]     Test net output #0: accuracy = 0.899777
I0122 19:47:36.262753 70150 solver.cpp:517]     Test net output #1: loss = 0.374028 (* 1 = 0.374028 loss)
I0122 19:47:36.262758 70150 solver.cpp:517]     Test net output #2: top-1 = 0.899777
I0122 19:47:36.262761 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995333
I0122 19:47:36.324932 70150 solver.cpp:266] Iteration 31000 (13.0395 iter/s, 7.669s/100 iter), loss = 0.00909286
I0122 19:47:36.324964 70150 solver.cpp:285]     Train net output #0: loss = 0.00909297 (* 1 = 0.00909297 loss)
I0122 19:47:36.324971 70150 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 19:47:42.543099 70150 solver.cpp:266] Iteration 31100 (16.0826 iter/s, 6.2179s/100 iter), loss = 0.00319791
I0122 19:47:42.543128 70150 solver.cpp:285]     Train net output #0: loss = 0.00319802 (* 1 = 0.00319802 loss)
I0122 19:47:42.543133 70150 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 19:47:48.747033 70150 solver.cpp:266] Iteration 31200 (16.1195 iter/s, 6.20367s/100 iter), loss = 0.00403034
I0122 19:47:48.747061 70150 solver.cpp:285]     Train net output #0: loss = 0.00403045 (* 1 = 0.00403045 loss)
I0122 19:47:48.747067 70150 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 19:47:54.960762 70150 solver.cpp:266] Iteration 31300 (16.0941 iter/s, 6.21346s/100 iter), loss = 0.0037317
I0122 19:47:54.960801 70150 solver.cpp:285]     Train net output #0: loss = 0.00373181 (* 1 = 0.00373181 loss)
I0122 19:47:54.960808 70150 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 19:48:01.168474 70150 solver.cpp:266] Iteration 31400 (16.1097 iter/s, 6.20744s/100 iter), loss = 0.00585818
I0122 19:48:01.168501 70150 solver.cpp:285]     Train net output #0: loss = 0.00585829 (* 1 = 0.00585829 loss)
I0122 19:48:01.168507 70150 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 19:48:07.395442 70150 solver.cpp:266] Iteration 31500 (16.0599 iter/s, 6.2267s/100 iter), loss = 0.00935338
I0122 19:48:07.395583 70150 solver.cpp:285]     Train net output #0: loss = 0.0093535 (* 1 = 0.0093535 loss)
I0122 19:48:07.395603 70150 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 19:48:13.621448 70150 solver.cpp:266] Iteration 31600 (16.0626 iter/s, 6.22564s/100 iter), loss = 0.00393303
I0122 19:48:13.621475 70150 solver.cpp:285]     Train net output #0: loss = 0.00393314 (* 1 = 0.00393314 loss)
I0122 19:48:13.621481 70150 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 19:48:19.822548 70150 solver.cpp:266] Iteration 31700 (16.1269 iter/s, 6.20084s/100 iter), loss = 0.00454511
I0122 19:48:19.822576 70150 solver.cpp:285]     Train net output #0: loss = 0.00454523 (* 1 = 0.00454523 loss)
I0122 19:48:19.822582 70150 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 19:48:26.034678 70150 solver.cpp:266] Iteration 31800 (16.0982 iter/s, 6.21187s/100 iter), loss = 0.0088902
I0122 19:48:26.034706 70150 solver.cpp:285]     Train net output #0: loss = 0.00889032 (* 1 = 0.00889032 loss)
I0122 19:48:26.034713 70150 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 19:48:32.255187 70150 solver.cpp:266] Iteration 31900 (16.0765 iter/s, 6.22024s/100 iter), loss = 0.0040614
I0122 19:48:32.255214 70150 solver.cpp:285]     Train net output #0: loss = 0.00406152 (* 1 = 0.00406152 loss)
I0122 19:48:32.255220 70150 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 19:48:38.410944 70150 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 19:48:39.860770 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898666
I0122 19:48:39.860795 70150 solver.cpp:517]     Test net output #1: loss = 0.377 (* 1 = 0.377 loss)
I0122 19:48:39.860798 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898666
I0122 19:48:39.860802 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:48:39.922246 70150 solver.cpp:266] Iteration 32000 (13.0433 iter/s, 7.66674s/100 iter), loss = 0.00522233
I0122 19:48:39.922266 70150 solver.cpp:285]     Train net output #0: loss = 0.00522244 (* 1 = 0.00522244 loss)
I0122 19:48:39.922272 70150 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 19:48:46.124562 70150 solver.cpp:266] Iteration 32100 (16.1237 iter/s, 6.20206s/100 iter), loss = 0.00775704
I0122 19:48:46.124589 70150 solver.cpp:285]     Train net output #0: loss = 0.00775716 (* 1 = 0.00775716 loss)
I0122 19:48:46.124595 70150 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 19:48:52.327733 70150 solver.cpp:266] Iteration 32200 (16.1215 iter/s, 6.20291s/100 iter), loss = 0.00522871
I0122 19:48:52.327761 70150 solver.cpp:285]     Train net output #0: loss = 0.00522883 (* 1 = 0.00522883 loss)
I0122 19:48:52.327767 70150 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 19:48:58.537919 70150 solver.cpp:266] Iteration 32300 (16.1033 iter/s, 6.20992s/100 iter), loss = 0.00410707
I0122 19:48:58.537947 70150 solver.cpp:285]     Train net output #0: loss = 0.00410719 (* 1 = 0.00410719 loss)
I0122 19:48:58.537955 70150 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 19:49:04.754902 70150 solver.cpp:266] Iteration 32400 (16.0857 iter/s, 6.21672s/100 iter), loss = 0.00592915
I0122 19:49:04.754930 70150 solver.cpp:285]     Train net output #0: loss = 0.00592927 (* 1 = 0.00592927 loss)
I0122 19:49:04.754936 70150 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 19:49:10.964131 70150 solver.cpp:266] Iteration 32500 (16.1057 iter/s, 6.20896s/100 iter), loss = 0.00525934
I0122 19:49:10.964253 70150 solver.cpp:285]     Train net output #0: loss = 0.00525946 (* 1 = 0.00525946 loss)
I0122 19:49:10.964260 70150 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 19:49:17.186167 70150 solver.cpp:266] Iteration 32600 (16.0728 iter/s, 6.22168s/100 iter), loss = 0.00618377
I0122 19:49:17.186195 70150 solver.cpp:285]     Train net output #0: loss = 0.00618388 (* 1 = 0.00618388 loss)
I0122 19:49:17.186201 70150 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 19:49:23.392019 70150 solver.cpp:266] Iteration 32700 (16.1145 iter/s, 6.20559s/100 iter), loss = 0.00698022
I0122 19:49:23.392048 70150 solver.cpp:285]     Train net output #0: loss = 0.00698034 (* 1 = 0.00698034 loss)
I0122 19:49:23.392055 70150 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 19:49:29.616541 70150 solver.cpp:266] Iteration 32800 (16.0662 iter/s, 6.22426s/100 iter), loss = 0.00377313
I0122 19:49:29.616570 70150 solver.cpp:285]     Train net output #0: loss = 0.00377325 (* 1 = 0.00377325 loss)
I0122 19:49:29.616576 70150 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 19:49:35.837186 70150 solver.cpp:266] Iteration 32900 (16.0762 iter/s, 6.22038s/100 iter), loss = 0.00307026
I0122 19:49:35.837227 70150 solver.cpp:285]     Train net output #0: loss = 0.00307038 (* 1 = 0.00307038 loss)
I0122 19:49:35.837234 70150 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 19:49:41.979615 70150 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 19:49:43.430042 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898555
I0122 19:49:43.430068 70150 solver.cpp:517]     Test net output #1: loss = 0.378238 (* 1 = 0.378238 loss)
I0122 19:49:43.430073 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898555
I0122 19:49:43.430076 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:49:43.491667 70150 solver.cpp:266] Iteration 33000 (13.0648 iter/s, 7.65415s/100 iter), loss = 0.00331975
I0122 19:49:43.491686 70150 solver.cpp:285]     Train net output #0: loss = 0.00331987 (* 1 = 0.00331987 loss)
I0122 19:49:43.491693 70150 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 19:49:49.709844 70150 solver.cpp:266] Iteration 33100 (16.0826 iter/s, 6.21792s/100 iter), loss = 0.00537874
I0122 19:49:49.709873 70150 solver.cpp:285]     Train net output #0: loss = 0.00537886 (* 1 = 0.00537886 loss)
I0122 19:49:49.709879 70150 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 19:49:55.937376 70150 solver.cpp:266] Iteration 33200 (16.0584 iter/s, 6.22727s/100 iter), loss = 0.00196811
I0122 19:49:55.937405 70150 solver.cpp:285]     Train net output #0: loss = 0.00196823 (* 1 = 0.00196823 loss)
I0122 19:49:55.937412 70150 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 19:50:02.172973 70150 solver.cpp:266] Iteration 33300 (16.0376 iter/s, 6.23533s/100 iter), loss = 0.00487675
I0122 19:50:02.173002 70150 solver.cpp:285]     Train net output #0: loss = 0.00487687 (* 1 = 0.00487687 loss)
I0122 19:50:02.173007 70150 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 19:50:08.384338 70150 solver.cpp:266] Iteration 33400 (16.1002 iter/s, 6.2111s/100 iter), loss = 0.00753214
I0122 19:50:08.384366 70150 solver.cpp:285]     Train net output #0: loss = 0.00753226 (* 1 = 0.00753226 loss)
I0122 19:50:08.384371 70150 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 19:50:14.591679 70150 solver.cpp:266] Iteration 33500 (16.1106 iter/s, 6.20708s/100 iter), loss = 0.00540347
I0122 19:50:14.591759 70150 solver.cpp:285]     Train net output #0: loss = 0.00540359 (* 1 = 0.00540359 loss)
I0122 19:50:14.591766 70150 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 19:50:20.813853 70150 solver.cpp:266] Iteration 33600 (16.0724 iter/s, 6.22186s/100 iter), loss = 0.0050367
I0122 19:50:20.813879 70150 solver.cpp:285]     Train net output #0: loss = 0.00503682 (* 1 = 0.00503682 loss)
I0122 19:50:20.813885 70150 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 19:50:27.007165 70150 solver.cpp:266] Iteration 33700 (16.1471 iter/s, 6.19305s/100 iter), loss = 0.00393901
I0122 19:50:27.007194 70150 solver.cpp:285]     Train net output #0: loss = 0.00393913 (* 1 = 0.00393913 loss)
I0122 19:50:27.007200 70150 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 19:50:33.228997 70150 solver.cpp:266] Iteration 33800 (16.0731 iter/s, 6.22156s/100 iter), loss = 0.00792413
I0122 19:50:33.229023 70150 solver.cpp:285]     Train net output #0: loss = 0.00792425 (* 1 = 0.00792425 loss)
I0122 19:50:33.229029 70150 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 19:50:39.468901 70150 solver.cpp:266] Iteration 33900 (16.0266 iter/s, 6.23964s/100 iter), loss = 0.00625323
I0122 19:50:39.468930 70150 solver.cpp:285]     Train net output #0: loss = 0.00625335 (* 1 = 0.00625335 loss)
I0122 19:50:39.468935 70150 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 19:50:45.605279 70150 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 19:50:47.064173 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898444
I0122 19:50:47.064199 70150 solver.cpp:517]     Test net output #1: loss = 0.378746 (* 1 = 0.378746 loss)
I0122 19:50:47.064204 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898444
I0122 19:50:47.064208 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:50:47.125617 70150 solver.cpp:266] Iteration 34000 (13.061 iter/s, 7.6564s/100 iter), loss = 0.00441094
I0122 19:50:47.125638 70150 solver.cpp:285]     Train net output #0: loss = 0.00441107 (* 1 = 0.00441107 loss)
I0122 19:50:47.125645 70150 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 19:50:53.340131 70150 solver.cpp:266] Iteration 34100 (16.092 iter/s, 6.21426s/100 iter), loss = 0.00389687
I0122 19:50:53.340162 70150 solver.cpp:285]     Train net output #0: loss = 0.00389699 (* 1 = 0.00389699 loss)
I0122 19:50:53.340167 70150 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 19:50:59.561499 70150 solver.cpp:266] Iteration 34200 (16.0743 iter/s, 6.2211s/100 iter), loss = 0.00512571
I0122 19:50:59.561528 70150 solver.cpp:285]     Train net output #0: loss = 0.00512584 (* 1 = 0.00512584 loss)
I0122 19:50:59.561534 70150 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 19:51:05.777884 70150 solver.cpp:266] Iteration 34300 (16.0872 iter/s, 6.21612s/100 iter), loss = 0.00708723
I0122 19:51:05.777915 70150 solver.cpp:285]     Train net output #0: loss = 0.00708735 (* 1 = 0.00708735 loss)
I0122 19:51:05.777920 70150 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 19:51:11.990631 70150 solver.cpp:266] Iteration 34400 (16.0966 iter/s, 6.21248s/100 iter), loss = 0.0240946
I0122 19:51:11.990659 70150 solver.cpp:285]     Train net output #0: loss = 0.0240947 (* 1 = 0.0240947 loss)
I0122 19:51:11.990665 70150 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 19:51:18.213773 70150 solver.cpp:266] Iteration 34500 (16.0697 iter/s, 6.22287s/100 iter), loss = 0.00832194
I0122 19:51:18.213848 70150 solver.cpp:285]     Train net output #0: loss = 0.00832206 (* 1 = 0.00832206 loss)
I0122 19:51:18.213855 70150 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 19:51:24.432430 70150 solver.cpp:266] Iteration 34600 (16.0814 iter/s, 6.21834s/100 iter), loss = 0.0111192
I0122 19:51:24.432458 70150 solver.cpp:285]     Train net output #0: loss = 0.0111193 (* 1 = 0.0111193 loss)
I0122 19:51:24.432464 70150 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 19:51:30.649785 70150 solver.cpp:266] Iteration 34700 (16.0847 iter/s, 6.21709s/100 iter), loss = 0.00395112
I0122 19:51:30.649813 70150 solver.cpp:285]     Train net output #0: loss = 0.00395125 (* 1 = 0.00395125 loss)
I0122 19:51:30.649819 70150 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 19:51:36.857863 70150 solver.cpp:266] Iteration 34800 (16.1087 iter/s, 6.20781s/100 iter), loss = 0.00173259
I0122 19:51:36.857892 70150 solver.cpp:285]     Train net output #0: loss = 0.00173272 (* 1 = 0.00173272 loss)
I0122 19:51:36.857897 70150 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 19:51:43.081982 70150 solver.cpp:266] Iteration 34900 (16.0672 iter/s, 6.22385s/100 iter), loss = 0.0162705
I0122 19:51:43.082010 70150 solver.cpp:285]     Train net output #0: loss = 0.0162707 (* 1 = 0.0162707 loss)
I0122 19:51:43.082015 70150 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 19:51:49.244995 70150 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 19:51:50.693311 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898889
I0122 19:51:50.693337 70150 solver.cpp:517]     Test net output #1: loss = 0.378843 (* 1 = 0.378843 loss)
I0122 19:51:50.693342 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898889
I0122 19:51:50.693346 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:51:50.755636 70150 solver.cpp:266] Iteration 35000 (13.0321 iter/s, 7.67334s/100 iter), loss = 0.00684125
I0122 19:51:50.755657 70150 solver.cpp:285]     Train net output #0: loss = 0.00684138 (* 1 = 0.00684138 loss)
I0122 19:51:50.755664 70150 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 19:51:56.977768 70150 solver.cpp:266] Iteration 35100 (16.0723 iter/s, 6.22187s/100 iter), loss = 0.00632922
I0122 19:51:56.977797 70150 solver.cpp:285]     Train net output #0: loss = 0.00632935 (* 1 = 0.00632935 loss)
I0122 19:51:56.977802 70150 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 19:52:03.198464 70150 solver.cpp:266] Iteration 35200 (16.0761 iter/s, 6.22043s/100 iter), loss = 0.00776129
I0122 19:52:03.198491 70150 solver.cpp:285]     Train net output #0: loss = 0.00776141 (* 1 = 0.00776141 loss)
I0122 19:52:03.198498 70150 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 19:52:09.404314 70150 solver.cpp:266] Iteration 35300 (16.1145 iter/s, 6.20559s/100 iter), loss = 0.00572698
I0122 19:52:09.404343 70150 solver.cpp:285]     Train net output #0: loss = 0.0057271 (* 1 = 0.0057271 loss)
I0122 19:52:09.404350 70150 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 19:52:15.610841 70150 solver.cpp:266] Iteration 35400 (16.1128 iter/s, 6.20626s/100 iter), loss = 0.00334044
I0122 19:52:15.610867 70150 solver.cpp:285]     Train net output #0: loss = 0.00334057 (* 1 = 0.00334057 loss)
I0122 19:52:15.610874 70150 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 19:52:21.817446 70150 solver.cpp:266] Iteration 35500 (16.1126 iter/s, 6.20634s/100 iter), loss = 0.00344861
I0122 19:52:21.817564 70150 solver.cpp:285]     Train net output #0: loss = 0.00344873 (* 1 = 0.00344873 loss)
I0122 19:52:21.817571 70150 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 19:52:28.036125 70150 solver.cpp:266] Iteration 35600 (16.0815 iter/s, 6.21832s/100 iter), loss = 0.00470345
I0122 19:52:28.036152 70150 solver.cpp:285]     Train net output #0: loss = 0.00470357 (* 1 = 0.00470357 loss)
I0122 19:52:28.036159 70150 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 19:52:34.248597 70150 solver.cpp:266] Iteration 35700 (16.0973 iter/s, 6.21221s/100 iter), loss = 0.00712676
I0122 19:52:34.248625 70150 solver.cpp:285]     Train net output #0: loss = 0.00712688 (* 1 = 0.00712688 loss)
I0122 19:52:34.248631 70150 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 19:52:40.447438 70150 solver.cpp:266] Iteration 35800 (16.1327 iter/s, 6.19858s/100 iter), loss = 0.0042336
I0122 19:52:40.447465 70150 solver.cpp:285]     Train net output #0: loss = 0.00423372 (* 1 = 0.00423372 loss)
I0122 19:52:40.447471 70150 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 19:52:46.674176 70150 solver.cpp:266] Iteration 35900 (16.0605 iter/s, 6.22647s/100 iter), loss = 0.00498635
I0122 19:52:46.674206 70150 solver.cpp:285]     Train net output #0: loss = 0.00498648 (* 1 = 0.00498648 loss)
I0122 19:52:46.674211 70150 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 19:52:52.824470 70150 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 19:52:54.272326 70150 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 19:52:54.272352 70150 solver.cpp:517]     Test net output #1: loss = 0.379099 (* 1 = 0.379099 loss)
I0122 19:52:54.272356 70150 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 19:52:54.272361 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:52:54.334120 70150 solver.cpp:266] Iteration 36000 (13.0555 iter/s, 7.65963s/100 iter), loss = 0.0051952
I0122 19:52:54.334141 70150 solver.cpp:285]     Train net output #0: loss = 0.00519532 (* 1 = 0.00519532 loss)
I0122 19:52:54.334147 70150 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 19:53:00.546123 70150 solver.cpp:266] Iteration 36100 (16.0985 iter/s, 6.21174s/100 iter), loss = 0.00937422
I0122 19:53:00.546149 70150 solver.cpp:285]     Train net output #0: loss = 0.00937434 (* 1 = 0.00937434 loss)
I0122 19:53:00.546154 70150 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 19:53:06.787921 70150 solver.cpp:266] Iteration 36200 (16.0217 iter/s, 6.24153s/100 iter), loss = 0.00370327
I0122 19:53:06.787950 70150 solver.cpp:285]     Train net output #0: loss = 0.00370339 (* 1 = 0.00370339 loss)
I0122 19:53:06.787955 70150 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 19:53:13.007416 70150 solver.cpp:266] Iteration 36300 (16.0792 iter/s, 6.21923s/100 iter), loss = 0.00713929
I0122 19:53:13.007445 70150 solver.cpp:285]     Train net output #0: loss = 0.00713941 (* 1 = 0.00713941 loss)
I0122 19:53:13.007452 70150 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 19:53:19.217502 70150 solver.cpp:266] Iteration 36400 (16.1035 iter/s, 6.20982s/100 iter), loss = 0.00768716
I0122 19:53:19.217530 70150 solver.cpp:285]     Train net output #0: loss = 0.00768728 (* 1 = 0.00768728 loss)
I0122 19:53:19.217536 70150 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 19:53:25.431821 70150 solver.cpp:266] Iteration 36500 (16.0926 iter/s, 6.21405s/100 iter), loss = 0.00759163
I0122 19:53:25.431929 70150 solver.cpp:285]     Train net output #0: loss = 0.00759176 (* 1 = 0.00759176 loss)
I0122 19:53:25.431936 70150 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 19:53:31.640586 70150 solver.cpp:266] Iteration 36600 (16.1072 iter/s, 6.20842s/100 iter), loss = 0.00697354
I0122 19:53:31.640615 70150 solver.cpp:285]     Train net output #0: loss = 0.00697366 (* 1 = 0.00697366 loss)
I0122 19:53:31.640622 70150 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 19:53:37.849354 70150 solver.cpp:266] Iteration 36700 (16.1069 iter/s, 6.2085s/100 iter), loss = 0.00638892
I0122 19:53:37.849382 70150 solver.cpp:285]     Train net output #0: loss = 0.00638904 (* 1 = 0.00638904 loss)
I0122 19:53:37.849388 70150 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 19:53:44.074949 70150 solver.cpp:266] Iteration 36800 (16.0634 iter/s, 6.22533s/100 iter), loss = 0.0115707
I0122 19:53:44.074976 70150 solver.cpp:285]     Train net output #0: loss = 0.0115708 (* 1 = 0.0115708 loss)
I0122 19:53:44.074982 70150 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 19:53:50.293267 70150 solver.cpp:266] Iteration 36900 (16.0822 iter/s, 6.21805s/100 iter), loss = 0.00880824
I0122 19:53:50.293296 70150 solver.cpp:285]     Train net output #0: loss = 0.00880836 (* 1 = 0.00880836 loss)
I0122 19:53:50.293301 70150 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 19:53:56.454706 70150 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 19:53:57.901545 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898778
I0122 19:53:57.901568 70150 solver.cpp:517]     Test net output #1: loss = 0.379288 (* 1 = 0.379288 loss)
I0122 19:53:57.901573 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898778
I0122 19:53:57.901576 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:53:57.963016 70150 solver.cpp:266] Iteration 37000 (13.0388 iter/s, 7.66943s/100 iter), loss = 0.00514285
I0122 19:53:57.963037 70150 solver.cpp:285]     Train net output #0: loss = 0.00514298 (* 1 = 0.00514298 loss)
I0122 19:53:57.963043 70150 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 19:54:04.177218 70150 solver.cpp:266] Iteration 37100 (16.0928 iter/s, 6.21394s/100 iter), loss = 0.00713336
I0122 19:54:04.177247 70150 solver.cpp:285]     Train net output #0: loss = 0.00713349 (* 1 = 0.00713349 loss)
I0122 19:54:04.177253 70150 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 19:54:10.396308 70150 solver.cpp:266] Iteration 37200 (16.0802 iter/s, 6.21882s/100 iter), loss = 0.00513117
I0122 19:54:10.396335 70150 solver.cpp:285]     Train net output #0: loss = 0.0051313 (* 1 = 0.0051313 loss)
I0122 19:54:10.396342 70150 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 19:54:16.606330 70150 solver.cpp:266] Iteration 37300 (16.1037 iter/s, 6.20976s/100 iter), loss = 0.00704005
I0122 19:54:16.606359 70150 solver.cpp:285]     Train net output #0: loss = 0.00704018 (* 1 = 0.00704018 loss)
I0122 19:54:16.606364 70150 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 19:54:22.812228 70150 solver.cpp:266] Iteration 37400 (16.1144 iter/s, 6.20563s/100 iter), loss = 0.00451495
I0122 19:54:22.812255 70150 solver.cpp:285]     Train net output #0: loss = 0.00451508 (* 1 = 0.00451508 loss)
I0122 19:54:22.812261 70150 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 19:54:29.042784 70150 solver.cpp:266] Iteration 37500 (16.0506 iter/s, 6.23029s/100 iter), loss = 0.00468551
I0122 19:54:29.042886 70150 solver.cpp:285]     Train net output #0: loss = 0.00468564 (* 1 = 0.00468564 loss)
I0122 19:54:29.042892 70150 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 19:54:35.240146 70150 solver.cpp:266] Iteration 37600 (16.1368 iter/s, 6.19702s/100 iter), loss = 0.00749289
I0122 19:54:35.240175 70150 solver.cpp:285]     Train net output #0: loss = 0.00749302 (* 1 = 0.00749302 loss)
I0122 19:54:35.240181 70150 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 19:54:41.462998 70150 solver.cpp:266] Iteration 37700 (16.0705 iter/s, 6.22259s/100 iter), loss = 0.00692974
I0122 19:54:41.463027 70150 solver.cpp:285]     Train net output #0: loss = 0.00692987 (* 1 = 0.00692987 loss)
I0122 19:54:41.463032 70150 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 19:54:47.686713 70150 solver.cpp:266] Iteration 37800 (16.0683 iter/s, 6.22345s/100 iter), loss = 0.00570611
I0122 19:54:47.686741 70150 solver.cpp:285]     Train net output #0: loss = 0.00570624 (* 1 = 0.00570624 loss)
I0122 19:54:47.686748 70150 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 19:54:53.900586 70150 solver.cpp:266] Iteration 37900 (16.0937 iter/s, 6.21361s/100 iter), loss = 0.00460478
I0122 19:54:53.900614 70150 solver.cpp:285]     Train net output #0: loss = 0.00460491 (* 1 = 0.00460491 loss)
I0122 19:54:53.900620 70150 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 19:55:00.045719 70150 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 19:55:01.500828 70150 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 19:55:01.500854 70150 solver.cpp:517]     Test net output #1: loss = 0.379312 (* 1 = 0.379312 loss)
I0122 19:55:01.500859 70150 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 19:55:01.500861 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:55:01.562127 70150 solver.cpp:266] Iteration 38000 (13.0527 iter/s, 7.66123s/100 iter), loss = 0.00984005
I0122 19:55:01.562149 70150 solver.cpp:285]     Train net output #0: loss = 0.00984018 (* 1 = 0.00984018 loss)
I0122 19:55:01.562155 70150 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 19:55:07.776778 70150 solver.cpp:266] Iteration 38100 (16.0917 iter/s, 6.21439s/100 iter), loss = 0.00349904
I0122 19:55:07.776805 70150 solver.cpp:285]     Train net output #0: loss = 0.00349917 (* 1 = 0.00349917 loss)
I0122 19:55:07.776813 70150 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 19:55:13.990429 70150 solver.cpp:266] Iteration 38200 (16.0943 iter/s, 6.21339s/100 iter), loss = 0.00642482
I0122 19:55:13.990458 70150 solver.cpp:285]     Train net output #0: loss = 0.00642495 (* 1 = 0.00642495 loss)
I0122 19:55:13.990463 70150 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 19:55:20.216651 70150 solver.cpp:266] Iteration 38300 (16.0618 iter/s, 6.22596s/100 iter), loss = 0.00320348
I0122 19:55:20.216679 70150 solver.cpp:285]     Train net output #0: loss = 0.00320361 (* 1 = 0.00320361 loss)
I0122 19:55:20.216686 70150 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 19:55:26.433964 70150 solver.cpp:266] Iteration 38400 (16.0848 iter/s, 6.21705s/100 iter), loss = 0.0200862
I0122 19:55:26.433990 70150 solver.cpp:285]     Train net output #0: loss = 0.0200863 (* 1 = 0.0200863 loss)
I0122 19:55:26.433996 70150 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 19:55:32.634124 70150 solver.cpp:266] Iteration 38500 (16.1293 iter/s, 6.1999s/100 iter), loss = 0.00811058
I0122 19:55:32.634224 70150 solver.cpp:285]     Train net output #0: loss = 0.00811071 (* 1 = 0.00811071 loss)
I0122 19:55:32.634232 70150 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 19:55:38.839541 70150 solver.cpp:266] Iteration 38600 (16.1158 iter/s, 6.20508s/100 iter), loss = 0.00468184
I0122 19:55:38.839570 70150 solver.cpp:285]     Train net output #0: loss = 0.00468197 (* 1 = 0.00468197 loss)
I0122 19:55:38.839576 70150 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 19:55:45.046783 70150 solver.cpp:266] Iteration 38700 (16.1109 iter/s, 6.20698s/100 iter), loss = 0.00299491
I0122 19:55:45.046809 70150 solver.cpp:285]     Train net output #0: loss = 0.00299504 (* 1 = 0.00299504 loss)
I0122 19:55:45.046815 70150 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 19:55:51.257177 70150 solver.cpp:266] Iteration 38800 (16.1027 iter/s, 6.21013s/100 iter), loss = 0.00316681
I0122 19:55:51.257205 70150 solver.cpp:285]     Train net output #0: loss = 0.00316694 (* 1 = 0.00316694 loss)
I0122 19:55:51.257211 70150 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 19:55:57.472005 70150 solver.cpp:266] Iteration 38900 (16.0912 iter/s, 6.21456s/100 iter), loss = 0.00517019
I0122 19:55:57.472033 70150 solver.cpp:285]     Train net output #0: loss = 0.00517032 (* 1 = 0.00517032 loss)
I0122 19:55:57.472039 70150 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 19:56:03.647307 70150 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 19:56:05.096380 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898667
I0122 19:56:05.096406 70150 solver.cpp:517]     Test net output #1: loss = 0.379441 (* 1 = 0.379441 loss)
I0122 19:56:05.096411 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898667
I0122 19:56:05.096415 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:56:05.158684 70150 solver.cpp:266] Iteration 39000 (13.0101 iter/s, 7.68636s/100 iter), loss = 0.00601964
I0122 19:56:05.158704 70150 solver.cpp:285]     Train net output #0: loss = 0.00601977 (* 1 = 0.00601977 loss)
I0122 19:56:05.158710 70150 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 19:56:11.375030 70150 solver.cpp:266] Iteration 39100 (16.0873 iter/s, 6.21609s/100 iter), loss = 0.004733
I0122 19:56:11.375058 70150 solver.cpp:285]     Train net output #0: loss = 0.00473313 (* 1 = 0.00473313 loss)
I0122 19:56:11.375063 70150 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 19:56:17.591724 70150 solver.cpp:266] Iteration 39200 (16.0864 iter/s, 6.21643s/100 iter), loss = 0.00686415
I0122 19:56:17.591753 70150 solver.cpp:285]     Train net output #0: loss = 0.00686428 (* 1 = 0.00686428 loss)
I0122 19:56:17.591759 70150 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 19:56:23.811558 70150 solver.cpp:266] Iteration 39300 (16.0783 iter/s, 6.21957s/100 iter), loss = 0.00957751
I0122 19:56:23.811586 70150 solver.cpp:285]     Train net output #0: loss = 0.00957764 (* 1 = 0.00957764 loss)
I0122 19:56:23.811592 70150 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 19:56:30.016363 70150 solver.cpp:266] Iteration 39400 (16.1172 iter/s, 6.20454s/100 iter), loss = 0.00373957
I0122 19:56:30.016391 70150 solver.cpp:285]     Train net output #0: loss = 0.0037397 (* 1 = 0.0037397 loss)
I0122 19:56:30.016397 70150 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 19:56:36.239533 70150 solver.cpp:266] Iteration 39500 (16.0697 iter/s, 6.2229s/100 iter), loss = 0.00350312
I0122 19:56:36.239650 70150 solver.cpp:285]     Train net output #0: loss = 0.00350325 (* 1 = 0.00350325 loss)
I0122 19:56:36.239656 70150 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 19:56:42.443735 70150 solver.cpp:266] Iteration 39600 (16.119 iter/s, 6.20385s/100 iter), loss = 0.00655002
I0122 19:56:42.443763 70150 solver.cpp:285]     Train net output #0: loss = 0.00655015 (* 1 = 0.00655015 loss)
I0122 19:56:42.443768 70150 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 19:56:48.665303 70150 solver.cpp:266] Iteration 39700 (16.0738 iter/s, 6.2213s/100 iter), loss = 0.00250925
I0122 19:56:48.665333 70150 solver.cpp:285]     Train net output #0: loss = 0.00250938 (* 1 = 0.00250938 loss)
I0122 19:56:48.665338 70150 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 19:56:54.880671 70150 solver.cpp:266] Iteration 39800 (16.0898 iter/s, 6.2151s/100 iter), loss = 0.0118811
I0122 19:56:54.880699 70150 solver.cpp:285]     Train net output #0: loss = 0.0118812 (* 1 = 0.0118812 loss)
I0122 19:56:54.880705 70150 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 19:57:01.092326 70150 solver.cpp:266] Iteration 39900 (16.0995 iter/s, 6.21139s/100 iter), loss = 0.0093539
I0122 19:57:01.092355 70150 solver.cpp:285]     Train net output #0: loss = 0.00935403 (* 1 = 0.00935403 loss)
I0122 19:57:01.092361 70150 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 19:57:07.249833 70150 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_40000.caffemodel
I0122 19:57:07.292649 70150 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_40000.solverstate
I0122 19:57:07.321705 70150 solver.cpp:378] Iteration 40000, loss = 0.00199301
I0122 19:57:07.321735 70150 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 19:57:08.774235 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898444
I0122 19:57:08.774261 70150 solver.cpp:517]     Test net output #1: loss = 0.379542 (* 1 = 0.379542 loss)
I0122 19:57:08.774266 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898444
I0122 19:57:08.774269 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:57:08.774273 70150 solver.cpp:386] Optimization Done (15.7561 iter/s).
I0122 19:57:08.774277 70150 caffe_interface.cpp:530] Optimization Done.
