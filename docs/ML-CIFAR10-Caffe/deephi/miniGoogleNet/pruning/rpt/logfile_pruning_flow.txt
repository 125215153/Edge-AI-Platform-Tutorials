#!/bin/sh

PRUNE_ROOT=$HOME/ML/DNNDK/tools
WORK_DIR=cifar10/deephi/miniGoogleNet/pruning

#take the caffemodel with a soft link to save HD space
ln -s $HOME/ML/cifar10/caffe/models/miniGoogleNet/m3/snapshot_3_miniGoogleNet__iter_40000.caffemodel ${WORK_DIR}/float.caffemodel

# leave commented the next lines, here added only for "documentation" 
#copy the solver and edit it by reducing the amount of iterations and changing the pathnames
#cp $CAFFE_DIR/models/m3/pruning_solver_3_miniGoogleNet.prototxt ./solver.prototxt
#copy the description model and edit it by adding top-1 and top-5 accuracy layers at the bottom and changing the pathnames
#cp $CAFFE_DIR/models/m3/pruning_train_val_3_miniGoogleNet.prototxt ./train_val.prototxt

# analysis: you do it only once
$PRUNE_ROOT/deephi_compress ana -config ${WORK_DIR}/config0.prototxt      2>&1 | tee ${WORK_DIR}/rpt/logfile_ana_miniGoogleNet.txt
I0122 16:51:44.391129 58582 deephi_compress.cpp:203] Starting analysis of cifar10/deephi/miniGoogleNet/pruning/float.caffemodel
I0122 16:51:44.391299 58582 sens_analyser.cpp:145] Analysis completed 0%
I0122 16:52:10.886132 58582 sens_analyser.cpp:212] Analysing layer [conv1/3x3_s1] done
I0122 16:52:10.886147 58582 sens_analyser.cpp:213] Analysis completed 5%
I0122 16:52:33.306921 58582 sens_analyser.cpp:212] Analysing layer [inception_2a/1x1] done
I0122 16:52:33.306957 58582 sens_analyser.cpp:213] Analysis completed 10%
I0122 16:52:56.399132 58582 sens_analyser.cpp:212] Analysing layer [inception_2a/3x3] done
I0122 16:52:56.399148 58582 sens_analyser.cpp:213] Analysis completed 15%
I0122 16:53:19.400136 58582 sens_analyser.cpp:212] Analysing layer [inception_3a/1x1] done
I0122 16:53:19.400168 58582 sens_analyser.cpp:213] Analysis completed 21%
I0122 16:53:42.210876 58582 sens_analyser.cpp:212] Analysing layer [inception_3a/3x3] done
I0122 16:53:42.210893 58582 sens_analyser.cpp:213] Analysis completed 26%
I0122 16:54:05.165217 58582 sens_analyser.cpp:212] Analysing layer [downsample_4/3x3_s2] done
I0122 16:54:05.165251 58582 sens_analyser.cpp:213] Analysis completed 31%
I0122 16:54:27.857753 58582 sens_analyser.cpp:212] Analysing layer [inception_5a/1x1] done
I0122 16:54:27.857769 58582 sens_analyser.cpp:213] Analysis completed 36%
I0122 16:54:50.721323 58582 sens_analyser.cpp:212] Analysing layer [inception_5a/3x3] done
I0122 16:54:50.721365 58582 sens_analyser.cpp:213] Analysis completed 42%
I0122 16:55:13.657909 58582 sens_analyser.cpp:212] Analysing layer [inception_6a/1x1] done
I0122 16:55:13.657927 58582 sens_analyser.cpp:213] Analysis completed 47%
I0122 16:55:36.620350 58582 sens_analyser.cpp:212] Analysing layer [inception_6a/3x3] done
I0122 16:55:36.620383 58582 sens_analyser.cpp:213] Analysis completed 52%
I0122 16:55:59.267009 58582 sens_analyser.cpp:212] Analysing layer [inception_7a/1x1] done
I0122 16:55:59.267024 58582 sens_analyser.cpp:213] Analysis completed 57%
I0122 16:56:22.720840 58582 sens_analyser.cpp:212] Analysing layer [inception_7a/3x3] done
I0122 16:56:22.720872 58582 sens_analyser.cpp:213] Analysis completed 63%
I0122 16:56:45.941893 58582 sens_analyser.cpp:212] Analysing layer [inception_8a/1x1] done
I0122 16:56:45.941915 58582 sens_analyser.cpp:213] Analysis completed 68%
I0122 16:57:09.440927 58582 sens_analyser.cpp:212] Analysing layer [inception_8a/3x3] done
I0122 16:57:09.440958 58582 sens_analyser.cpp:213] Analysis completed 73%
I0122 16:57:32.555454 58582 sens_analyser.cpp:212] Analysing layer [downsample_9/3x3_s2] done
I0122 16:57:32.555474 58582 sens_analyser.cpp:213] Analysis completed 78%
I0122 16:57:56.337994 58582 sens_analyser.cpp:212] Analysing layer [inception_10a/1x1] done
I0122 16:57:56.338030 58582 sens_analyser.cpp:213] Analysis completed 84%
I0122 16:58:20.081768 58582 sens_analyser.cpp:212] Analysing layer [inception_10a/3x3] done
I0122 16:58:20.081794 58582 sens_analyser.cpp:213] Analysis completed 89%
I0122 16:58:43.605628 58582 sens_analyser.cpp:212] Analysing layer [inception_11a/1x1] done
I0122 16:58:43.605659 58582 sens_analyser.cpp:213] Analysis completed 94%
I0122 16:59:06.772861 58582 sens_analyser.cpp:212] Analysing layer [inception_11a/3x3] done
I0122 16:59:06.772881 58582 sens_analyser.cpp:213] Analysis completed 100%
I0122 16:59:06.773077 58582 deephi_compress.cpp:205] Analysis done.
Now you can compress the model with the following command:
deephi_compress compress -config cifar10/deephi/miniGoogleNet/pruning/config0.prototxt
 
# compression: zero run
$PRUNE_ROOT/deephi_compress compress -config ${WORK_DIR}/config0.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_compress0_miniGoogleNet.txt
I0122 16:59:07.010464 64041 pruning_runner.cpp:190] Sens info found, use it.
I0122 16:59:07.023865 64041 pruning_runner.cpp:217] Start compressing, please wait...
I0122 16:59:08.776701 64041 caffe_interface.cpp:66] Use GPU with device ID 0
I0122 16:59:08.776991 64041 caffe_interface.cpp:70] GPU device name: Quadro P6000
I0122 16:59:08.777845 64041 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 16:59:08.778393 64041 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 16:59:08.778708 64041 layer_factory.hpp:77] Creating layer data
I0122 16:59:08.778749 64041 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:08.779090 64041 net.cpp:94] Creating Layer data
I0122 16:59:08.779098 64041 net.cpp:409] data -> data
I0122 16:59:08.779106 64041 net.cpp:409] data -> label
I0122 16:59:08.780210 64188 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 16:59:08.780242 64188 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 16:59:08.780362 64041 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 16:59:08.780442 64041 data_layer.cpp:83] output data size: 50,3,32,32
I0122 16:59:08.783089 64041 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:08.783144 64041 net.cpp:144] Setting up data
I0122 16:59:08.783151 64041 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 16:59:08.783155 64041 net.cpp:151] Top shape: 50 (50)
I0122 16:59:08.783157 64041 net.cpp:159] Memory required for data: 614600
I0122 16:59:08.783162 64041 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 16:59:08.783170 64041 net.cpp:94] Creating Layer label_data_1_split
I0122 16:59:08.783179 64041 net.cpp:435] label_data_1_split <- label
I0122 16:59:08.783185 64041 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 16:59:08.783195 64041 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 16:59:08.783201 64041 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 16:59:08.783207 64041 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 16:59:08.783298 64041 net.cpp:144] Setting up label_data_1_split
I0122 16:59:08.783304 64041 net.cpp:151] Top shape: 50 (50)
I0122 16:59:08.783308 64041 net.cpp:151] Top shape: 50 (50)
I0122 16:59:08.783311 64041 net.cpp:151] Top shape: 50 (50)
I0122 16:59:08.783314 64041 net.cpp:151] Top shape: 50 (50)
I0122 16:59:08.783318 64041 net.cpp:159] Memory required for data: 615400
I0122 16:59:08.783320 64041 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 16:59:08.783329 64041 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 16:59:08.783332 64041 net.cpp:435] conv1/3x3_s1 <- data
I0122 16:59:08.783339 64041 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 16:59:08.784853 64041 net.cpp:144] Setting up conv1/3x3_s1
I0122 16:59:08.784864 64041 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:08.784867 64041 net.cpp:159] Memory required for data: 20276200
I0122 16:59:08.784876 64041 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 16:59:08.784883 64041 net.cpp:94] Creating Layer conv1/bn1
I0122 16:59:08.784886 64041 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 16:59:08.784891 64041 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 16:59:08.785583 64041 net.cpp:144] Setting up conv1/bn1
I0122 16:59:08.785589 64041 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:08.785593 64041 net.cpp:159] Memory required for data: 39937000
I0122 16:59:08.785604 64041 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 16:59:08.785611 64041 net.cpp:94] Creating Layer conv1/relu1
I0122 16:59:08.785617 64041 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 16:59:08.785621 64041 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 16:59:08.785629 64041 net.cpp:144] Setting up conv1/relu1
I0122 16:59:08.785632 64041 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:08.785635 64041 net.cpp:159] Memory required for data: 59597800
I0122 16:59:08.785637 64041 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:08.785642 64041 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:08.785645 64041 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 16:59:08.785650 64041 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:08.785656 64041 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:08.785706 64041 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:08.785712 64041 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:08.785717 64041 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:08.785718 64041 net.cpp:159] Memory required for data: 98919400
I0122 16:59:08.785722 64041 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 16:59:08.785729 64041 net.cpp:94] Creating Layer inception_2a/1x1
I0122 16:59:08.785732 64041 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:08.785738 64041 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 16:59:08.786020 64041 net.cpp:144] Setting up inception_2a/1x1
I0122 16:59:08.786026 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.786031 64041 net.cpp:159] Memory required for data: 105473000
I0122 16:59:08.786037 64041 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 16:59:08.786044 64041 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 16:59:08.786049 64041 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 16:59:08.786056 64041 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 16:59:08.786757 64041 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 16:59:08.786763 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.786767 64041 net.cpp:159] Memory required for data: 112026600
I0122 16:59:08.786774 64041 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 16:59:08.786780 64041 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 16:59:08.786782 64041 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 16:59:08.786787 64041 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 16:59:08.786806 64041 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 16:59:08.786810 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.786813 64041 net.cpp:159] Memory required for data: 118580200
I0122 16:59:08.786816 64041 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 16:59:08.786824 64041 net.cpp:94] Creating Layer inception_2a/3x3
I0122 16:59:08.786828 64041 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:08.786833 64041 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 16:59:08.787919 64041 net.cpp:144] Setting up inception_2a/3x3
I0122 16:59:08.787931 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.787935 64041 net.cpp:159] Memory required for data: 125133800
I0122 16:59:08.787940 64041 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 16:59:08.787950 64041 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 16:59:08.787953 64041 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 16:59:08.787958 64041 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 16:59:08.788605 64041 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 16:59:08.788612 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.788616 64041 net.cpp:159] Memory required for data: 131687400
I0122 16:59:08.788628 64041 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 16:59:08.788635 64041 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 16:59:08.788640 64041 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 16:59:08.788643 64041 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 16:59:08.788650 64041 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 16:59:08.788653 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.788656 64041 net.cpp:159] Memory required for data: 138241000
I0122 16:59:08.788659 64041 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 16:59:08.788664 64041 net.cpp:94] Creating Layer inception_2a/output
I0122 16:59:08.788667 64041 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 16:59:08.788672 64041 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 16:59:08.788677 64041 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 16:59:08.788697 64041 net.cpp:144] Setting up inception_2a/output
I0122 16:59:08.788702 64041 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:08.788707 64041 net.cpp:159] Memory required for data: 151348200
I0122 16:59:08.788709 64041 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:08.788713 64041 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:08.788717 64041 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 16:59:08.788722 64041 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:08.788727 64041 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:08.788792 64041 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 16:59:08.788799 64041 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:08.788802 64041 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:08.788805 64041 net.cpp:159] Memory required for data: 177562600
I0122 16:59:08.788807 64041 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 16:59:08.788816 64041 net.cpp:94] Creating Layer inception_3a/1x1
I0122 16:59:08.788821 64041 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:08.788826 64041 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 16:59:08.789042 64041 net.cpp:144] Setting up inception_3a/1x1
I0122 16:59:08.789048 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.789052 64041 net.cpp:159] Memory required for data: 184116200
I0122 16:59:08.789068 64041 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 16:59:08.789075 64041 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 16:59:08.789078 64041 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 16:59:08.789085 64041 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 16:59:08.789737 64041 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 16:59:08.789743 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.789747 64041 net.cpp:159] Memory required for data: 190669800
I0122 16:59:08.789755 64041 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 16:59:08.789762 64041 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 16:59:08.789764 64041 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 16:59:08.789769 64041 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 16:59:08.789775 64041 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 16:59:08.789779 64041 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:08.789782 64041 net.cpp:159] Memory required for data: 197223400
I0122 16:59:08.789784 64041 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 16:59:08.789793 64041 net.cpp:94] Creating Layer inception_3a/3x3
I0122 16:59:08.789796 64041 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:08.789803 64041 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 16:59:08.790189 64041 net.cpp:144] Setting up inception_3a/3x3
I0122 16:59:08.790199 64041 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:08.790202 64041 net.cpp:159] Memory required for data: 207053800
I0122 16:59:08.790206 64041 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 16:59:08.790213 64041 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 16:59:08.790216 64041 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 16:59:08.790222 64041 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 16:59:08.790858 64041 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 16:59:08.790864 64041 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:08.790868 64041 net.cpp:159] Memory required for data: 216884200
I0122 16:59:08.790879 64041 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 16:59:08.790885 64041 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 16:59:08.790889 64041 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 16:59:08.790894 64041 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 16:59:08.790899 64041 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 16:59:08.790904 64041 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:08.790905 64041 net.cpp:159] Memory required for data: 226714600
I0122 16:59:08.790910 64041 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 16:59:08.790915 64041 net.cpp:94] Creating Layer inception_3a/output
I0122 16:59:08.790917 64041 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 16:59:08.790920 64041 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 16:59:08.790925 64041 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 16:59:08.790946 64041 net.cpp:144] Setting up inception_3a/output
I0122 16:59:08.790951 64041 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:08.790954 64041 net.cpp:159] Memory required for data: 243098600
I0122 16:59:08.790957 64041 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:08.790962 64041 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:08.790966 64041 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 16:59:08.790971 64041 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:08.790978 64041 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:08.791043 64041 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 16:59:08.791059 64041 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:08.791064 64041 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:08.791066 64041 net.cpp:159] Memory required for data: 275866600
I0122 16:59:08.791069 64041 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 16:59:08.791079 64041 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 16:59:08.791081 64041 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:08.791087 64041 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 16:59:08.791618 64041 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 16:59:08.791626 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.791630 64041 net.cpp:159] Memory required for data: 279962600
I0122 16:59:08.791635 64041 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 16:59:08.791642 64041 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 16:59:08.791647 64041 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 16:59:08.791652 64041 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:08.792374 64041 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 16:59:08.792381 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.792383 64041 net.cpp:159] Memory required for data: 284058600
I0122 16:59:08.792392 64041 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 16:59:08.792399 64041 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 16:59:08.792402 64041 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 16:59:08.792407 64041 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:08.792412 64041 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 16:59:08.792418 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.792420 64041 net.cpp:159] Memory required for data: 288154600
I0122 16:59:08.792423 64041 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 16:59:08.792429 64041 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 16:59:08.792433 64041 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:08.792438 64041 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 16:59:08.792469 64041 net.cpp:144] Setting up downsample_4/pool_s2
I0122 16:59:08.792475 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.792480 64041 net.cpp:159] Memory required for data: 292250600
I0122 16:59:08.792484 64041 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 16:59:08.792487 64041 net.cpp:94] Creating Layer downsample_4/output
I0122 16:59:08.792490 64041 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 16:59:08.792495 64041 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 16:59:08.792498 64041 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 16:59:08.792556 64041 net.cpp:144] Setting up downsample_4/output
I0122 16:59:08.792560 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.792564 64041 net.cpp:159] Memory required for data: 300442600
I0122 16:59:08.792567 64041 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:08.792572 64041 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:08.792574 64041 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 16:59:08.792579 64041 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:08.792585 64041 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:08.792611 64041 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 16:59:08.792618 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.792624 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.792636 64041 net.cpp:159] Memory required for data: 316826600
I0122 16:59:08.792645 64041 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 16:59:08.792652 64041 net.cpp:94] Creating Layer inception_5a/1x1
I0122 16:59:08.792656 64041 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:08.792662 64041 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 16:59:08.792978 64041 net.cpp:144] Setting up inception_5a/1x1
I0122 16:59:08.792984 64041 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:08.792989 64041 net.cpp:159] Memory required for data: 322561000
I0122 16:59:08.792994 64041 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 16:59:08.792999 64041 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 16:59:08.793004 64041 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 16:59:08.793010 64041 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 16:59:08.793694 64041 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 16:59:08.793700 64041 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:08.793704 64041 net.cpp:159] Memory required for data: 328295400
I0122 16:59:08.793714 64041 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 16:59:08.793718 64041 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 16:59:08.793721 64041 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 16:59:08.793725 64041 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 16:59:08.793731 64041 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 16:59:08.793735 64041 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:08.793738 64041 net.cpp:159] Memory required for data: 334029800
I0122 16:59:08.793742 64041 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 16:59:08.793751 64041 net.cpp:94] Creating Layer inception_5a/3x3
I0122 16:59:08.793756 64041 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:08.793761 64041 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 16:59:08.794416 64041 net.cpp:144] Setting up inception_5a/3x3
I0122 16:59:08.794425 64041 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:08.794428 64041 net.cpp:159] Memory required for data: 336487400
I0122 16:59:08.794433 64041 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 16:59:08.794441 64041 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 16:59:08.794447 64041 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 16:59:08.794452 64041 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 16:59:08.795142 64041 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 16:59:08.795148 64041 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:08.795151 64041 net.cpp:159] Memory required for data: 338945000
I0122 16:59:08.795159 64041 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 16:59:08.795164 64041 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 16:59:08.795167 64041 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 16:59:08.795172 64041 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 16:59:08.795178 64041 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 16:59:08.795182 64041 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:08.795186 64041 net.cpp:159] Memory required for data: 341402600
I0122 16:59:08.795189 64041 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 16:59:08.795194 64041 net.cpp:94] Creating Layer inception_5a/output
I0122 16:59:08.795197 64041 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 16:59:08.795200 64041 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 16:59:08.795207 64041 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 16:59:08.795223 64041 net.cpp:144] Setting up inception_5a/output
I0122 16:59:08.795228 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.795231 64041 net.cpp:159] Memory required for data: 349594600
I0122 16:59:08.795245 64041 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:08.795250 64041 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:08.795253 64041 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 16:59:08.795258 64041 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:08.795266 64041 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:08.795328 64041 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 16:59:08.795333 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.795337 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.795341 64041 net.cpp:159] Memory required for data: 365978600
I0122 16:59:08.795344 64041 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 16:59:08.795352 64041 net.cpp:94] Creating Layer inception_6a/1x1
I0122 16:59:08.795356 64041 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:08.795362 64041 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 16:59:08.796360 64041 net.cpp:144] Setting up inception_6a/1x1
I0122 16:59:08.796371 64041 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:08.796375 64041 net.cpp:159] Memory required for data: 370893800
I0122 16:59:08.796380 64041 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 16:59:08.796389 64041 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 16:59:08.796394 64041 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 16:59:08.796401 64041 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 16:59:08.797013 64041 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 16:59:08.797020 64041 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:08.797024 64041 net.cpp:159] Memory required for data: 375809000
I0122 16:59:08.797031 64041 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 16:59:08.797039 64041 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 16:59:08.797041 64041 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 16:59:08.797046 64041 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 16:59:08.797052 64041 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 16:59:08.797056 64041 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:08.797060 64041 net.cpp:159] Memory required for data: 380724200
I0122 16:59:08.797061 64041 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 16:59:08.797070 64041 net.cpp:94] Creating Layer inception_6a/3x3
I0122 16:59:08.797075 64041 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:08.797080 64041 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 16:59:08.798454 64041 net.cpp:144] Setting up inception_6a/3x3
I0122 16:59:08.798466 64041 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:08.798470 64041 net.cpp:159] Memory required for data: 384001000
I0122 16:59:08.798481 64041 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 16:59:08.798491 64041 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 16:59:08.798494 64041 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 16:59:08.798501 64041 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 16:59:08.799118 64041 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 16:59:08.799124 64041 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:08.799126 64041 net.cpp:159] Memory required for data: 387277800
I0122 16:59:08.799135 64041 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 16:59:08.799142 64041 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 16:59:08.799145 64041 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 16:59:08.799150 64041 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 16:59:08.799170 64041 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 16:59:08.799173 64041 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:08.799175 64041 net.cpp:159] Memory required for data: 390554600
I0122 16:59:08.799178 64041 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 16:59:08.799183 64041 net.cpp:94] Creating Layer inception_6a/output
I0122 16:59:08.799186 64041 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 16:59:08.799190 64041 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 16:59:08.799194 64041 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 16:59:08.799212 64041 net.cpp:144] Setting up inception_6a/output
I0122 16:59:08.799217 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.799221 64041 net.cpp:159] Memory required for data: 398746600
I0122 16:59:08.799223 64041 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:08.799228 64041 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:08.799232 64041 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 16:59:08.799235 64041 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:08.799242 64041 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:08.799270 64041 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 16:59:08.799276 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.799280 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.799283 64041 net.cpp:159] Memory required for data: 415130600
I0122 16:59:08.799286 64041 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 16:59:08.799294 64041 net.cpp:94] Creating Layer inception_7a/1x1
I0122 16:59:08.799299 64041 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:08.799305 64041 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 16:59:08.799585 64041 net.cpp:144] Setting up inception_7a/1x1
I0122 16:59:08.799592 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.799594 64041 net.cpp:159] Memory required for data: 419226600
I0122 16:59:08.799599 64041 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 16:59:08.799605 64041 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 16:59:08.799608 64041 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 16:59:08.799614 64041 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 16:59:08.800216 64041 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 16:59:08.800223 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.800226 64041 net.cpp:159] Memory required for data: 423322600
I0122 16:59:08.800235 64041 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 16:59:08.800238 64041 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 16:59:08.800242 64041 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 16:59:08.800246 64041 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 16:59:08.800252 64041 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 16:59:08.800256 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.800259 64041 net.cpp:159] Memory required for data: 427418600
I0122 16:59:08.800262 64041 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 16:59:08.800269 64041 net.cpp:94] Creating Layer inception_7a/3x3
I0122 16:59:08.800272 64041 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:08.800278 64041 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 16:59:08.801133 64041 net.cpp:144] Setting up inception_7a/3x3
I0122 16:59:08.801143 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.801146 64041 net.cpp:159] Memory required for data: 431514600
I0122 16:59:08.801162 64041 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 16:59:08.801172 64041 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 16:59:08.801177 64041 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 16:59:08.801182 64041 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 16:59:08.801797 64041 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 16:59:08.801805 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.801807 64041 net.cpp:159] Memory required for data: 435610600
I0122 16:59:08.801815 64041 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 16:59:08.801820 64041 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 16:59:08.801825 64041 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 16:59:08.801828 64041 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 16:59:08.801834 64041 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 16:59:08.801838 64041 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:08.801841 64041 net.cpp:159] Memory required for data: 439706600
I0122 16:59:08.801843 64041 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 16:59:08.801848 64041 net.cpp:94] Creating Layer inception_7a/output
I0122 16:59:08.801851 64041 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 16:59:08.801856 64041 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 16:59:08.801859 64041 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 16:59:08.801877 64041 net.cpp:144] Setting up inception_7a/output
I0122 16:59:08.801882 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.801884 64041 net.cpp:159] Memory required for data: 447898600
I0122 16:59:08.801887 64041 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:08.801892 64041 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:08.801895 64041 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 16:59:08.801900 64041 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:08.801921 64041 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:08.801947 64041 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 16:59:08.801952 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.801956 64041 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:08.801959 64041 net.cpp:159] Memory required for data: 464282600
I0122 16:59:08.801961 64041 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 16:59:08.801970 64041 net.cpp:94] Creating Layer inception_8a/1x1
I0122 16:59:08.801972 64041 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:08.801977 64041 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 16:59:08.802229 64041 net.cpp:144] Setting up inception_8a/1x1
I0122 16:59:08.802237 64041 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:08.802240 64041 net.cpp:159] Memory required for data: 466740200
I0122 16:59:08.802245 64041 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 16:59:08.802251 64041 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 16:59:08.802255 64041 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 16:59:08.802260 64041 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 16:59:08.802875 64041 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 16:59:08.802881 64041 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:08.802884 64041 net.cpp:159] Memory required for data: 469197800
I0122 16:59:08.802892 64041 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 16:59:08.802896 64041 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 16:59:08.802899 64041 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 16:59:08.802904 64041 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 16:59:08.802922 64041 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 16:59:08.802925 64041 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:08.802927 64041 net.cpp:159] Memory required for data: 471655400
I0122 16:59:08.802932 64041 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 16:59:08.802938 64041 net.cpp:94] Creating Layer inception_8a/3x3
I0122 16:59:08.802942 64041 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:08.802948 64041 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 16:59:08.804577 64041 net.cpp:144] Setting up inception_8a/3x3
I0122 16:59:08.804590 64041 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:08.804592 64041 net.cpp:159] Memory required for data: 476570600
I0122 16:59:08.804599 64041 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 16:59:08.804622 64041 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 16:59:08.804627 64041 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 16:59:08.804632 64041 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 16:59:08.805259 64041 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 16:59:08.805266 64041 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:08.805270 64041 net.cpp:159] Memory required for data: 481485800
I0122 16:59:08.805279 64041 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 16:59:08.805284 64041 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 16:59:08.805287 64041 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 16:59:08.805291 64041 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 16:59:08.805297 64041 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 16:59:08.805301 64041 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:08.805305 64041 net.cpp:159] Memory required for data: 486401000
I0122 16:59:08.805307 64041 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 16:59:08.805311 64041 net.cpp:94] Creating Layer inception_8a/output
I0122 16:59:08.805315 64041 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 16:59:08.805320 64041 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 16:59:08.805323 64041 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 16:59:08.805341 64041 net.cpp:144] Setting up inception_8a/output
I0122 16:59:08.805346 64041 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:08.805349 64041 net.cpp:159] Memory required for data: 493773800
I0122 16:59:08.805351 64041 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:08.805356 64041 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:08.805359 64041 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 16:59:08.805364 64041 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:08.805371 64041 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:08.805395 64041 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 16:59:08.805400 64041 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:08.805405 64041 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:08.805408 64041 net.cpp:159] Memory required for data: 508519400
I0122 16:59:08.805410 64041 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 16:59:08.805418 64041 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 16:59:08.805423 64041 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:08.805429 64041 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 16:59:08.810297 64041 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 16:59:08.810307 64041 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:08.810309 64041 net.cpp:159] Memory required for data: 509748200
I0122 16:59:08.810324 64041 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 16:59:08.810331 64041 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 16:59:08.810334 64041 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 16:59:08.810340 64041 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:08.810999 64041 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 16:59:08.811007 64041 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:08.811022 64041 net.cpp:159] Memory required for data: 510977000
I0122 16:59:08.811030 64041 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 16:59:08.811038 64041 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 16:59:08.811039 64041 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 16:59:08.811044 64041 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:08.811050 64041 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 16:59:08.811072 64041 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:08.811074 64041 net.cpp:159] Memory required for data: 512205800
I0122 16:59:08.811077 64041 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 16:59:08.811084 64041 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 16:59:08.811087 64041 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:08.811092 64041 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 16:59:08.811121 64041 net.cpp:144] Setting up downsample_9/pool_s2
I0122 16:59:08.811126 64041 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 16:59:08.811130 64041 net.cpp:159] Memory required for data: 514049000
I0122 16:59:08.811132 64041 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 16:59:08.811139 64041 net.cpp:94] Creating Layer downsample_9/output
I0122 16:59:08.811146 64041 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 16:59:08.811148 64041 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 16:59:08.811153 64041 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 16:59:08.811169 64041 net.cpp:144] Setting up downsample_9/output
I0122 16:59:08.811175 64041 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:08.811178 64041 net.cpp:159] Memory required for data: 517121000
I0122 16:59:08.811182 64041 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:08.811187 64041 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:08.811189 64041 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 16:59:08.811194 64041 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:08.811200 64041 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:08.811225 64041 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 16:59:08.811230 64041 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:08.811234 64041 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:08.811236 64041 net.cpp:159] Memory required for data: 523265000
I0122 16:59:08.811239 64041 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 16:59:08.811247 64041 net.cpp:94] Creating Layer inception_10a/1x1
I0122 16:59:08.811250 64041 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:08.811255 64041 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 16:59:08.811704 64041 net.cpp:144] Setting up inception_10a/1x1
I0122 16:59:08.811712 64041 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:08.811714 64041 net.cpp:159] Memory required for data: 525517800
I0122 16:59:08.811719 64041 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 16:59:08.811727 64041 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 16:59:08.811740 64041 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 16:59:08.811748 64041 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 16:59:08.812372 64041 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 16:59:08.812378 64041 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:08.812382 64041 net.cpp:159] Memory required for data: 527770600
I0122 16:59:08.812389 64041 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 16:59:08.812394 64041 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 16:59:08.812397 64041 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 16:59:08.812402 64041 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 16:59:08.812408 64041 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 16:59:08.812412 64041 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:08.812414 64041 net.cpp:159] Memory required for data: 530023400
I0122 16:59:08.812417 64041 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 16:59:08.812425 64041 net.cpp:94] Creating Layer inception_10a/3x3
I0122 16:59:08.812430 64041 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:08.812436 64041 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 16:59:08.815471 64041 net.cpp:144] Setting up inception_10a/3x3
I0122 16:59:08.815485 64041 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:08.815487 64041 net.cpp:159] Memory required for data: 532071400
I0122 16:59:08.815493 64041 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 16:59:08.815501 64041 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 16:59:08.815505 64041 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 16:59:08.815510 64041 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 16:59:08.816133 64041 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 16:59:08.816141 64041 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:08.816144 64041 net.cpp:159] Memory required for data: 534119400
I0122 16:59:08.816152 64041 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 16:59:08.816157 64041 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 16:59:08.816161 64041 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 16:59:08.816165 64041 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 16:59:08.816172 64041 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 16:59:08.816175 64041 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:08.816179 64041 net.cpp:159] Memory required for data: 536167400
I0122 16:59:08.816181 64041 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 16:59:08.816186 64041 net.cpp:94] Creating Layer inception_10a/output
I0122 16:59:08.816190 64041 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 16:59:08.816193 64041 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 16:59:08.816197 64041 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 16:59:08.816215 64041 net.cpp:144] Setting up inception_10a/output
I0122 16:59:08.816220 64041 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:08.816224 64041 net.cpp:159] Memory required for data: 540468200
I0122 16:59:08.816227 64041 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:08.816232 64041 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:08.816236 64041 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 16:59:08.816241 64041 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:08.816246 64041 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:08.816270 64041 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 16:59:08.816277 64041 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:08.816292 64041 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:08.816294 64041 net.cpp:159] Memory required for data: 549069800
I0122 16:59:08.816296 64041 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 16:59:08.816304 64041 net.cpp:94] Creating Layer inception_11a/1x1
I0122 16:59:08.816310 64041 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:08.816315 64041 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 16:59:08.816853 64041 net.cpp:144] Setting up inception_11a/1x1
I0122 16:59:08.816860 64041 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:08.816864 64041 net.cpp:159] Memory required for data: 551322600
I0122 16:59:08.816869 64041 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 16:59:08.816875 64041 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 16:59:08.816879 64041 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 16:59:08.816885 64041 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 16:59:08.817499 64041 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 16:59:08.817505 64041 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:08.817509 64041 net.cpp:159] Memory required for data: 553575400
I0122 16:59:08.817517 64041 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 16:59:08.817523 64041 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 16:59:08.817525 64041 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 16:59:08.817529 64041 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 16:59:08.817536 64041 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 16:59:08.817539 64041 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:08.817543 64041 net.cpp:159] Memory required for data: 555828200
I0122 16:59:08.817545 64041 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 16:59:08.817553 64041 net.cpp:94] Creating Layer inception_11a/3x3
I0122 16:59:08.817557 64041 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:08.817564 64041 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 16:59:08.821300 64041 net.cpp:144] Setting up inception_11a/3x3
I0122 16:59:08.821316 64041 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:08.821319 64041 net.cpp:159] Memory required for data: 557876200
I0122 16:59:08.821326 64041 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 16:59:08.821352 64041 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 16:59:08.821357 64041 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 16:59:08.821367 64041 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 16:59:08.822005 64041 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 16:59:08.822012 64041 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:08.822016 64041 net.cpp:159] Memory required for data: 559924200
I0122 16:59:08.822031 64041 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 16:59:08.822037 64041 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 16:59:08.822041 64041 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 16:59:08.822046 64041 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 16:59:08.822052 64041 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 16:59:08.822057 64041 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:08.822059 64041 net.cpp:159] Memory required for data: 561972200
I0122 16:59:08.822062 64041 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 16:59:08.822067 64041 net.cpp:94] Creating Layer inception_11a/output
I0122 16:59:08.822069 64041 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 16:59:08.822072 64041 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 16:59:08.822078 64041 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 16:59:08.822098 64041 net.cpp:144] Setting up inception_11a/output
I0122 16:59:08.822103 64041 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:08.822116 64041 net.cpp:159] Memory required for data: 566273000
I0122 16:59:08.822120 64041 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 16:59:08.822126 64041 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 16:59:08.822129 64041 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 16:59:08.822134 64041 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 16:59:08.822154 64041 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 16:59:08.822158 64041 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 16:59:08.822160 64041 net.cpp:159] Memory required for data: 566340200
I0122 16:59:08.822163 64041 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 16:59:08.822170 64041 net.cpp:94] Creating Layer drop_8x8_s1
I0122 16:59:08.822171 64041 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 16:59:08.822176 64041 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 16:59:08.822192 64041 net.cpp:144] Setting up drop_8x8_s1
I0122 16:59:08.822198 64041 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 16:59:08.822201 64041 net.cpp:159] Memory required for data: 566407400
I0122 16:59:08.822203 64041 layer_factory.hpp:77] Creating layer loss/classifier
I0122 16:59:08.822209 64041 net.cpp:94] Creating Layer loss/classifier
I0122 16:59:08.822212 64041 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 16:59:08.822217 64041 net.cpp:409] loss/classifier -> loss/classifier
I0122 16:59:08.822376 64041 net.cpp:144] Setting up loss/classifier
I0122 16:59:08.822381 64041 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:08.822384 64041 net.cpp:159] Memory required for data: 566409400
I0122 16:59:08.822389 64041 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 16:59:08.822396 64041 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 16:59:08.822398 64041 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 16:59:08.822403 64041 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 16:59:08.822409 64041 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 16:59:08.822415 64041 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 16:59:08.822420 64041 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 16:59:08.822466 64041 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 16:59:08.822471 64041 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:08.822475 64041 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:08.822479 64041 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:08.822481 64041 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:08.822484 64041 net.cpp:159] Memory required for data: 566417400
I0122 16:59:08.822486 64041 layer_factory.hpp:77] Creating layer loss
I0122 16:59:08.822491 64041 net.cpp:94] Creating Layer loss
I0122 16:59:08.822495 64041 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 16:59:08.822499 64041 net.cpp:435] loss <- label_data_1_split_0
I0122 16:59:08.822504 64041 net.cpp:409] loss -> loss
I0122 16:59:08.822510 64041 layer_factory.hpp:77] Creating layer loss
I0122 16:59:08.822583 64041 net.cpp:144] Setting up loss
I0122 16:59:08.822588 64041 net.cpp:151] Top shape: (1)
I0122 16:59:08.822590 64041 net.cpp:154]     with loss weight 1
I0122 16:59:08.822602 64041 net.cpp:159] Memory required for data: 566417404
I0122 16:59:08.822605 64041 layer_factory.hpp:77] Creating layer accuracy
I0122 16:59:08.822612 64041 net.cpp:94] Creating Layer accuracy
I0122 16:59:08.822614 64041 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 16:59:08.822618 64041 net.cpp:435] accuracy <- label_data_1_split_1
I0122 16:59:08.822623 64041 net.cpp:409] accuracy -> accuracy
I0122 16:59:08.822633 64041 net.cpp:144] Setting up accuracy
I0122 16:59:08.822639 64041 net.cpp:151] Top shape: (1)
I0122 16:59:08.822649 64041 net.cpp:159] Memory required for data: 566417408
I0122 16:59:08.822652 64041 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 16:59:08.822657 64041 net.cpp:94] Creating Layer accuracy-top1
I0122 16:59:08.822659 64041 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 16:59:08.822664 64041 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 16:59:08.822669 64041 net.cpp:409] accuracy-top1 -> top-1
I0122 16:59:08.822674 64041 net.cpp:144] Setting up accuracy-top1
I0122 16:59:08.822677 64041 net.cpp:151] Top shape: (1)
I0122 16:59:08.822680 64041 net.cpp:159] Memory required for data: 566417412
I0122 16:59:08.822683 64041 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 16:59:08.822687 64041 net.cpp:94] Creating Layer accuracy-top5
I0122 16:59:08.822690 64041 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 16:59:08.822695 64041 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 16:59:08.822700 64041 net.cpp:409] accuracy-top5 -> top-5
I0122 16:59:08.822705 64041 net.cpp:144] Setting up accuracy-top5
I0122 16:59:08.822707 64041 net.cpp:151] Top shape: (1)
I0122 16:59:08.822710 64041 net.cpp:159] Memory required for data: 566417416
I0122 16:59:08.822713 64041 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 16:59:08.822716 64041 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 16:59:08.822721 64041 net.cpp:222] accuracy does not need backward computation.
I0122 16:59:08.822724 64041 net.cpp:220] loss needs backward computation.
I0122 16:59:08.822728 64041 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 16:59:08.822731 64041 net.cpp:220] loss/classifier needs backward computation.
I0122 16:59:08.822734 64041 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 16:59:08.822737 64041 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 16:59:08.822741 64041 net.cpp:220] inception_11a/output needs backward computation.
I0122 16:59:08.822744 64041 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 16:59:08.822746 64041 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 16:59:08.822749 64041 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 16:59:08.822752 64041 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 16:59:08.822755 64041 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 16:59:08.822758 64041 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 16:59:08.822762 64041 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 16:59:08.822767 64041 net.cpp:220] inception_10a/output needs backward computation.
I0122 16:59:08.822770 64041 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 16:59:08.822772 64041 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 16:59:08.822775 64041 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 16:59:08.822779 64041 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 16:59:08.822782 64041 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 16:59:08.822784 64041 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 16:59:08.822788 64041 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 16:59:08.822791 64041 net.cpp:220] downsample_9/output needs backward computation.
I0122 16:59:08.822795 64041 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 16:59:08.822798 64041 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 16:59:08.822801 64041 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 16:59:08.822805 64041 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 16:59:08.822808 64041 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 16:59:08.822811 64041 net.cpp:220] inception_8a/output needs backward computation.
I0122 16:59:08.822820 64041 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 16:59:08.822824 64041 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 16:59:08.822826 64041 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 16:59:08.822830 64041 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 16:59:08.822834 64041 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 16:59:08.822836 64041 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 16:59:08.822840 64041 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 16:59:08.822844 64041 net.cpp:220] inception_7a/output needs backward computation.
I0122 16:59:08.822847 64041 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 16:59:08.822851 64041 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 16:59:08.822854 64041 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 16:59:08.822857 64041 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 16:59:08.822860 64041 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 16:59:08.822863 64041 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 16:59:08.822866 64041 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 16:59:08.822870 64041 net.cpp:220] inception_6a/output needs backward computation.
I0122 16:59:08.822873 64041 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 16:59:08.822877 64041 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 16:59:08.822880 64041 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 16:59:08.822882 64041 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 16:59:08.822886 64041 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 16:59:08.822890 64041 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 16:59:08.822893 64041 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 16:59:08.822896 64041 net.cpp:220] inception_5a/output needs backward computation.
I0122 16:59:08.822901 64041 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 16:59:08.822903 64041 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 16:59:08.822906 64041 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 16:59:08.822911 64041 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 16:59:08.822913 64041 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 16:59:08.822916 64041 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 16:59:08.822921 64041 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 16:59:08.822924 64041 net.cpp:220] downsample_4/output needs backward computation.
I0122 16:59:08.822928 64041 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 16:59:08.822932 64041 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 16:59:08.822935 64041 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 16:59:08.822938 64041 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 16:59:08.822942 64041 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 16:59:08.822945 64041 net.cpp:220] inception_3a/output needs backward computation.
I0122 16:59:08.822949 64041 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 16:59:08.822952 64041 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 16:59:08.822955 64041 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 16:59:08.822959 64041 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 16:59:08.822962 64041 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 16:59:08.822964 64041 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 16:59:08.822973 64041 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 16:59:08.822978 64041 net.cpp:220] inception_2a/output needs backward computation.
I0122 16:59:08.822980 64041 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 16:59:08.822984 64041 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 16:59:08.822986 64041 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 16:59:08.822990 64041 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 16:59:08.822993 64041 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 16:59:08.822996 64041 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 16:59:08.823000 64041 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 16:59:08.823017 64041 net.cpp:220] conv1/relu1 needs backward computation.
I0122 16:59:08.823020 64041 net.cpp:220] conv1/bn1 needs backward computation.
I0122 16:59:08.823022 64041 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 16:59:08.823026 64041 net.cpp:222] label_data_1_split does not need backward computation.
I0122 16:59:08.823031 64041 net.cpp:222] data does not need backward computation.
I0122 16:59:08.823034 64041 net.cpp:264] This network produces output accuracy
I0122 16:59:08.823036 64041 net.cpp:264] This network produces output loss
I0122 16:59:08.823040 64041 net.cpp:264] This network produces output top-1
I0122 16:59:08.823043 64041 net.cpp:264] This network produces output top-5
I0122 16:59:08.823107 64041 net.cpp:284] Network initialization done.
W0122 16:59:08.823654 64041 net.cpp:860] Force copying param 4 weights from layer 'conv1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.831416 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.836287 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.848234 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.855720 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.855983 64041 net.cpp:860] Force copying param 4 weights from layer 'downsample_4/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.856161 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.856432 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.856604 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.856909 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.857077 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.857414 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.857574 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.857940 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.858300 64041 net.cpp:860] Force copying param 4 weights from layer 'downsample_9/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.858516 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.859140 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.859385 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:08.860234 64041 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
I0122 16:59:08.860287 64041 caffe_interface.cpp:363] Running for 180 iterations.
I0122 16:59:08.883935 64041 caffe_interface.cpp:125] Batch 0, accuracy = 0.86
I0122 16:59:08.883955 64041 caffe_interface.cpp:125] Batch 0, loss = 0.373597
I0122 16:59:08.883960 64041 caffe_interface.cpp:125] Batch 0, top-1 = 0.86
I0122 16:59:08.883963 64041 caffe_interface.cpp:125] Batch 0, top-5 = 1
I0122 16:59:08.893633 64041 caffe_interface.cpp:125] Batch 1, accuracy = 0.92
I0122 16:59:08.893646 64041 caffe_interface.cpp:125] Batch 1, loss = 0.273298
I0122 16:59:08.893651 64041 caffe_interface.cpp:125] Batch 1, top-1 = 0.92
I0122 16:59:08.893653 64041 caffe_interface.cpp:125] Batch 1, top-5 = 1
I0122 16:59:08.903329 64041 caffe_interface.cpp:125] Batch 2, accuracy = 0.94
I0122 16:59:08.903340 64041 caffe_interface.cpp:125] Batch 2, loss = 0.211412
I0122 16:59:08.903343 64041 caffe_interface.cpp:125] Batch 2, top-1 = 0.94
I0122 16:59:08.903347 64041 caffe_interface.cpp:125] Batch 2, top-5 = 1
I0122 16:59:08.919044 64041 caffe_interface.cpp:125] Batch 3, accuracy = 0.84
I0122 16:59:08.919055 64041 caffe_interface.cpp:125] Batch 3, loss = 0.788672
I0122 16:59:08.919059 64041 caffe_interface.cpp:125] Batch 3, top-1 = 0.84
I0122 16:59:08.919060 64041 caffe_interface.cpp:125] Batch 3, top-5 = 1
I0122 16:59:08.958971 64041 caffe_interface.cpp:125] Batch 4, accuracy = 0.94
I0122 16:59:08.958982 64041 caffe_interface.cpp:125] Batch 4, loss = 0.23368
I0122 16:59:08.958987 64041 caffe_interface.cpp:125] Batch 4, top-1 = 0.94
I0122 16:59:08.958990 64041 caffe_interface.cpp:125] Batch 4, top-5 = 1
I0122 16:59:08.967170 64041 caffe_interface.cpp:125] Batch 5, accuracy = 0.94
I0122 16:59:08.967178 64041 caffe_interface.cpp:125] Batch 5, loss = 0.199806
I0122 16:59:08.967182 64041 caffe_interface.cpp:125] Batch 5, top-1 = 0.94
I0122 16:59:08.967185 64041 caffe_interface.cpp:125] Batch 5, top-5 = 1
I0122 16:59:08.975153 64041 caffe_interface.cpp:125] Batch 6, accuracy = 0.88
I0122 16:59:08.975164 64041 caffe_interface.cpp:125] Batch 6, loss = 0.350235
I0122 16:59:08.975168 64041 caffe_interface.cpp:125] Batch 6, top-1 = 0.88
I0122 16:59:08.975172 64041 caffe_interface.cpp:125] Batch 6, top-5 = 1
I0122 16:59:08.983114 64041 caffe_interface.cpp:125] Batch 7, accuracy = 0.98
I0122 16:59:08.983124 64041 caffe_interface.cpp:125] Batch 7, loss = 0.0883951
I0122 16:59:08.983127 64041 caffe_interface.cpp:125] Batch 7, top-1 = 0.98
I0122 16:59:08.983130 64041 caffe_interface.cpp:125] Batch 7, top-5 = 1
I0122 16:59:08.992708 64041 caffe_interface.cpp:125] Batch 8, accuracy = 0.94
I0122 16:59:08.992718 64041 caffe_interface.cpp:125] Batch 8, loss = 0.352786
I0122 16:59:08.992722 64041 caffe_interface.cpp:125] Batch 8, top-1 = 0.94
I0122 16:59:08.992724 64041 caffe_interface.cpp:125] Batch 8, top-5 = 1
I0122 16:59:09.002522 64041 caffe_interface.cpp:125] Batch 9, accuracy = 0.9
I0122 16:59:09.002532 64041 caffe_interface.cpp:125] Batch 9, loss = 0.3576
I0122 16:59:09.002534 64041 caffe_interface.cpp:125] Batch 9, top-1 = 0.9
I0122 16:59:09.002550 64041 caffe_interface.cpp:125] Batch 9, top-5 = 0.98
I0122 16:59:09.018231 64041 caffe_interface.cpp:125] Batch 10, accuracy = 0.9
I0122 16:59:09.018242 64041 caffe_interface.cpp:125] Batch 10, loss = 0.256177
I0122 16:59:09.018246 64041 caffe_interface.cpp:125] Batch 10, top-1 = 0.9
I0122 16:59:09.018249 64041 caffe_interface.cpp:125] Batch 10, top-5 = 1
I0122 16:59:09.057624 64041 caffe_interface.cpp:125] Batch 11, accuracy = 0.9
I0122 16:59:09.057634 64041 caffe_interface.cpp:125] Batch 11, loss = 0.27878
I0122 16:59:09.057637 64041 caffe_interface.cpp:125] Batch 11, top-1 = 0.9
I0122 16:59:09.057641 64041 caffe_interface.cpp:125] Batch 11, top-5 = 1
I0122 16:59:09.065598 64041 caffe_interface.cpp:125] Batch 12, accuracy = 0.94
I0122 16:59:09.065608 64041 caffe_interface.cpp:125] Batch 12, loss = 0.179157
I0122 16:59:09.065611 64041 caffe_interface.cpp:125] Batch 12, top-1 = 0.94
I0122 16:59:09.065614 64041 caffe_interface.cpp:125] Batch 12, top-5 = 1
I0122 16:59:09.074147 64041 caffe_interface.cpp:125] Batch 13, accuracy = 0.9
I0122 16:59:09.074156 64041 caffe_interface.cpp:125] Batch 13, loss = 0.237425
I0122 16:59:09.074160 64041 caffe_interface.cpp:125] Batch 13, top-1 = 0.9
I0122 16:59:09.074163 64041 caffe_interface.cpp:125] Batch 13, top-5 = 1
I0122 16:59:09.082392 64041 caffe_interface.cpp:125] Batch 14, accuracy = 0.98
I0122 16:59:09.082402 64041 caffe_interface.cpp:125] Batch 14, loss = 0.0675962
I0122 16:59:09.082406 64041 caffe_interface.cpp:125] Batch 14, top-1 = 0.98
I0122 16:59:09.082410 64041 caffe_interface.cpp:125] Batch 14, top-5 = 1
I0122 16:59:09.091734 64041 caffe_interface.cpp:125] Batch 15, accuracy = 0.94
I0122 16:59:09.091743 64041 caffe_interface.cpp:125] Batch 15, loss = 0.223892
I0122 16:59:09.091747 64041 caffe_interface.cpp:125] Batch 15, top-1 = 0.94
I0122 16:59:09.091749 64041 caffe_interface.cpp:125] Batch 15, top-5 = 1
I0122 16:59:09.101022 64041 caffe_interface.cpp:125] Batch 16, accuracy = 0.94
I0122 16:59:09.101032 64041 caffe_interface.cpp:125] Batch 16, loss = 0.222412
I0122 16:59:09.101034 64041 caffe_interface.cpp:125] Batch 16, top-1 = 0.94
I0122 16:59:09.101037 64041 caffe_interface.cpp:125] Batch 16, top-5 = 0.98
I0122 16:59:09.117777 64041 caffe_interface.cpp:125] Batch 17, accuracy = 0.92
I0122 16:59:09.117791 64041 caffe_interface.cpp:125] Batch 17, loss = 0.300902
I0122 16:59:09.117795 64041 caffe_interface.cpp:125] Batch 17, top-1 = 0.92
I0122 16:59:09.117797 64041 caffe_interface.cpp:125] Batch 17, top-5 = 1
I0122 16:59:09.157197 64041 caffe_interface.cpp:125] Batch 18, accuracy = 0.88
I0122 16:59:09.157208 64041 caffe_interface.cpp:125] Batch 18, loss = 0.54097
I0122 16:59:09.157212 64041 caffe_interface.cpp:125] Batch 18, top-1 = 0.88
I0122 16:59:09.157214 64041 caffe_interface.cpp:125] Batch 18, top-5 = 1
I0122 16:59:09.165190 64041 caffe_interface.cpp:125] Batch 19, accuracy = 0.9
I0122 16:59:09.165200 64041 caffe_interface.cpp:125] Batch 19, loss = 0.347541
I0122 16:59:09.165205 64041 caffe_interface.cpp:125] Batch 19, top-1 = 0.9
I0122 16:59:09.165207 64041 caffe_interface.cpp:125] Batch 19, top-5 = 1
I0122 16:59:09.173683 64041 caffe_interface.cpp:125] Batch 20, accuracy = 0.86
I0122 16:59:09.173693 64041 caffe_interface.cpp:125] Batch 20, loss = 0.369313
I0122 16:59:09.173697 64041 caffe_interface.cpp:125] Batch 20, top-1 = 0.86
I0122 16:59:09.173701 64041 caffe_interface.cpp:125] Batch 20, top-5 = 1
I0122 16:59:09.181947 64041 caffe_interface.cpp:125] Batch 21, accuracy = 0.84
I0122 16:59:09.181957 64041 caffe_interface.cpp:125] Batch 21, loss = 0.376397
I0122 16:59:09.181960 64041 caffe_interface.cpp:125] Batch 21, top-1 = 0.84
I0122 16:59:09.181963 64041 caffe_interface.cpp:125] Batch 21, top-5 = 1
I0122 16:59:09.191545 64041 caffe_interface.cpp:125] Batch 22, accuracy = 0.92
I0122 16:59:09.191556 64041 caffe_interface.cpp:125] Batch 22, loss = 0.208123
I0122 16:59:09.191560 64041 caffe_interface.cpp:125] Batch 22, top-1 = 0.92
I0122 16:59:09.191562 64041 caffe_interface.cpp:125] Batch 22, top-5 = 1
I0122 16:59:09.201123 64041 caffe_interface.cpp:125] Batch 23, accuracy = 0.94
I0122 16:59:09.201133 64041 caffe_interface.cpp:125] Batch 23, loss = 0.156555
I0122 16:59:09.201138 64041 caffe_interface.cpp:125] Batch 23, top-1 = 0.94
I0122 16:59:09.201139 64041 caffe_interface.cpp:125] Batch 23, top-5 = 1
I0122 16:59:09.217203 64041 caffe_interface.cpp:125] Batch 24, accuracy = 0.86
I0122 16:59:09.217214 64041 caffe_interface.cpp:125] Batch 24, loss = 0.339308
I0122 16:59:09.217218 64041 caffe_interface.cpp:125] Batch 24, top-1 = 0.86
I0122 16:59:09.217221 64041 caffe_interface.cpp:125] Batch 24, top-5 = 1
I0122 16:59:09.257782 64041 caffe_interface.cpp:125] Batch 25, accuracy = 0.94
I0122 16:59:09.257792 64041 caffe_interface.cpp:125] Batch 25, loss = 0.236005
I0122 16:59:09.257797 64041 caffe_interface.cpp:125] Batch 25, top-1 = 0.94
I0122 16:59:09.257799 64041 caffe_interface.cpp:125] Batch 25, top-5 = 0.98
I0122 16:59:09.266288 64041 caffe_interface.cpp:125] Batch 26, accuracy = 0.96
I0122 16:59:09.266299 64041 caffe_interface.cpp:125] Batch 26, loss = 0.128962
I0122 16:59:09.266302 64041 caffe_interface.cpp:125] Batch 26, top-1 = 0.96
I0122 16:59:09.266304 64041 caffe_interface.cpp:125] Batch 26, top-5 = 1
I0122 16:59:09.274241 64041 caffe_interface.cpp:125] Batch 27, accuracy = 0.94
I0122 16:59:09.274250 64041 caffe_interface.cpp:125] Batch 27, loss = 0.139265
I0122 16:59:09.274253 64041 caffe_interface.cpp:125] Batch 27, top-1 = 0.94
I0122 16:59:09.274256 64041 caffe_interface.cpp:125] Batch 27, top-5 = 1
I0122 16:59:09.282202 64041 caffe_interface.cpp:125] Batch 28, accuracy = 0.94
I0122 16:59:09.282212 64041 caffe_interface.cpp:125] Batch 28, loss = 0.277802
I0122 16:59:09.282215 64041 caffe_interface.cpp:125] Batch 28, top-1 = 0.94
I0122 16:59:09.282218 64041 caffe_interface.cpp:125] Batch 28, top-5 = 1
I0122 16:59:09.291879 64041 caffe_interface.cpp:125] Batch 29, accuracy = 0.98
I0122 16:59:09.291889 64041 caffe_interface.cpp:125] Batch 29, loss = 0.195268
I0122 16:59:09.291893 64041 caffe_interface.cpp:125] Batch 29, top-1 = 0.98
I0122 16:59:09.291896 64041 caffe_interface.cpp:125] Batch 29, top-5 = 1
I0122 16:59:09.301555 64041 caffe_interface.cpp:125] Batch 30, accuracy = 0.92
I0122 16:59:09.301564 64041 caffe_interface.cpp:125] Batch 30, loss = 0.202983
I0122 16:59:09.301568 64041 caffe_interface.cpp:125] Batch 30, top-1 = 0.92
I0122 16:59:09.301571 64041 caffe_interface.cpp:125] Batch 30, top-5 = 1
I0122 16:59:09.317337 64041 caffe_interface.cpp:125] Batch 31, accuracy = 0.88
I0122 16:59:09.317348 64041 caffe_interface.cpp:125] Batch 31, loss = 0.342248
I0122 16:59:09.317353 64041 caffe_interface.cpp:125] Batch 31, top-1 = 0.88
I0122 16:59:09.317355 64041 caffe_interface.cpp:125] Batch 31, top-5 = 0.98
I0122 16:59:09.357645 64041 caffe_interface.cpp:125] Batch 32, accuracy = 0.92
I0122 16:59:09.357656 64041 caffe_interface.cpp:125] Batch 32, loss = 0.344327
I0122 16:59:09.357658 64041 caffe_interface.cpp:125] Batch 32, top-1 = 0.92
I0122 16:59:09.357661 64041 caffe_interface.cpp:125] Batch 32, top-5 = 1
I0122 16:59:09.365696 64041 caffe_interface.cpp:125] Batch 33, accuracy = 0.84
I0122 16:59:09.365706 64041 caffe_interface.cpp:125] Batch 33, loss = 0.583012
I0122 16:59:09.365710 64041 caffe_interface.cpp:125] Batch 33, top-1 = 0.84
I0122 16:59:09.365713 64041 caffe_interface.cpp:125] Batch 33, top-5 = 0.98
I0122 16:59:09.374258 64041 caffe_interface.cpp:125] Batch 34, accuracy = 0.94
I0122 16:59:09.374266 64041 caffe_interface.cpp:125] Batch 34, loss = 0.153923
I0122 16:59:09.374269 64041 caffe_interface.cpp:125] Batch 34, top-1 = 0.94
I0122 16:59:09.374272 64041 caffe_interface.cpp:125] Batch 34, top-5 = 1
I0122 16:59:09.382504 64041 caffe_interface.cpp:125] Batch 35, accuracy = 0.88
I0122 16:59:09.382514 64041 caffe_interface.cpp:125] Batch 35, loss = 0.434497
I0122 16:59:09.382519 64041 caffe_interface.cpp:125] Batch 35, top-1 = 0.88
I0122 16:59:09.382521 64041 caffe_interface.cpp:125] Batch 35, top-5 = 1
I0122 16:59:09.391968 64041 caffe_interface.cpp:125] Batch 36, accuracy = 0.9
I0122 16:59:09.391988 64041 caffe_interface.cpp:125] Batch 36, loss = 0.418974
I0122 16:59:09.391991 64041 caffe_interface.cpp:125] Batch 36, top-1 = 0.9
I0122 16:59:09.391994 64041 caffe_interface.cpp:125] Batch 36, top-5 = 1
I0122 16:59:09.402015 64041 caffe_interface.cpp:125] Batch 37, accuracy = 0.9
I0122 16:59:09.402024 64041 caffe_interface.cpp:125] Batch 37, loss = 0.323754
I0122 16:59:09.402029 64041 caffe_interface.cpp:125] Batch 37, top-1 = 0.9
I0122 16:59:09.402031 64041 caffe_interface.cpp:125] Batch 37, top-5 = 1
I0122 16:59:09.416551 64041 caffe_interface.cpp:125] Batch 38, accuracy = 0.92
I0122 16:59:09.416563 64041 caffe_interface.cpp:125] Batch 38, loss = 0.306795
I0122 16:59:09.416565 64041 caffe_interface.cpp:125] Batch 38, top-1 = 0.92
I0122 16:59:09.416568 64041 caffe_interface.cpp:125] Batch 38, top-5 = 1
I0122 16:59:09.456616 64041 caffe_interface.cpp:125] Batch 39, accuracy = 0.9
I0122 16:59:09.456626 64041 caffe_interface.cpp:125] Batch 39, loss = 0.301814
I0122 16:59:09.456631 64041 caffe_interface.cpp:125] Batch 39, top-1 = 0.9
I0122 16:59:09.456634 64041 caffe_interface.cpp:125] Batch 39, top-5 = 0.98
I0122 16:59:09.465514 64041 caffe_interface.cpp:125] Batch 40, accuracy = 0.96
I0122 16:59:09.465524 64041 caffe_interface.cpp:125] Batch 40, loss = 0.15833
I0122 16:59:09.465529 64041 caffe_interface.cpp:125] Batch 40, top-1 = 0.96
I0122 16:59:09.465533 64041 caffe_interface.cpp:125] Batch 40, top-5 = 1
I0122 16:59:09.473796 64041 caffe_interface.cpp:125] Batch 41, accuracy = 0.84
I0122 16:59:09.473807 64041 caffe_interface.cpp:125] Batch 41, loss = 0.620913
I0122 16:59:09.473811 64041 caffe_interface.cpp:125] Batch 41, top-1 = 0.84
I0122 16:59:09.473814 64041 caffe_interface.cpp:125] Batch 41, top-5 = 1
I0122 16:59:09.482128 64041 caffe_interface.cpp:125] Batch 42, accuracy = 0.78
I0122 16:59:09.482138 64041 caffe_interface.cpp:125] Batch 42, loss = 0.792859
I0122 16:59:09.482142 64041 caffe_interface.cpp:125] Batch 42, top-1 = 0.78
I0122 16:59:09.482146 64041 caffe_interface.cpp:125] Batch 42, top-5 = 0.98
I0122 16:59:09.491333 64041 caffe_interface.cpp:125] Batch 43, accuracy = 0.9
I0122 16:59:09.491343 64041 caffe_interface.cpp:125] Batch 43, loss = 0.368302
I0122 16:59:09.491346 64041 caffe_interface.cpp:125] Batch 43, top-1 = 0.9
I0122 16:59:09.491349 64041 caffe_interface.cpp:125] Batch 43, top-5 = 1
I0122 16:59:09.501538 64041 caffe_interface.cpp:125] Batch 44, accuracy = 0.92
I0122 16:59:09.501549 64041 caffe_interface.cpp:125] Batch 44, loss = 0.264398
I0122 16:59:09.501552 64041 caffe_interface.cpp:125] Batch 44, top-1 = 0.92
I0122 16:59:09.501555 64041 caffe_interface.cpp:125] Batch 44, top-5 = 1
I0122 16:59:09.516314 64041 caffe_interface.cpp:125] Batch 45, accuracy = 0.98
I0122 16:59:09.516325 64041 caffe_interface.cpp:125] Batch 45, loss = 0.0684032
I0122 16:59:09.516340 64041 caffe_interface.cpp:125] Batch 45, top-1 = 0.98
I0122 16:59:09.516341 64041 caffe_interface.cpp:125] Batch 45, top-5 = 1
I0122 16:59:09.556321 64041 caffe_interface.cpp:125] Batch 46, accuracy = 0.94
I0122 16:59:09.556330 64041 caffe_interface.cpp:125] Batch 46, loss = 0.183102
I0122 16:59:09.556344 64041 caffe_interface.cpp:125] Batch 46, top-1 = 0.94
I0122 16:59:09.556346 64041 caffe_interface.cpp:125] Batch 46, top-5 = 1
I0122 16:59:09.564661 64041 caffe_interface.cpp:125] Batch 47, accuracy = 0.94
I0122 16:59:09.564671 64041 caffe_interface.cpp:125] Batch 47, loss = 0.120581
I0122 16:59:09.564677 64041 caffe_interface.cpp:125] Batch 47, top-1 = 0.94
I0122 16:59:09.564679 64041 caffe_interface.cpp:125] Batch 47, top-5 = 1
I0122 16:59:09.573014 64041 caffe_interface.cpp:125] Batch 48, accuracy = 0.9
I0122 16:59:09.573024 64041 caffe_interface.cpp:125] Batch 48, loss = 0.293893
I0122 16:59:09.573026 64041 caffe_interface.cpp:125] Batch 48, top-1 = 0.9
I0122 16:59:09.573029 64041 caffe_interface.cpp:125] Batch 48, top-5 = 1
I0122 16:59:09.581336 64041 caffe_interface.cpp:125] Batch 49, accuracy = 0.9
I0122 16:59:09.581346 64041 caffe_interface.cpp:125] Batch 49, loss = 0.415545
I0122 16:59:09.581349 64041 caffe_interface.cpp:125] Batch 49, top-1 = 0.9
I0122 16:59:09.581365 64041 caffe_interface.cpp:125] Batch 49, top-5 = 1
I0122 16:59:09.590533 64041 caffe_interface.cpp:125] Batch 50, accuracy = 0.94
I0122 16:59:09.590544 64041 caffe_interface.cpp:125] Batch 50, loss = 0.274572
I0122 16:59:09.590548 64041 caffe_interface.cpp:125] Batch 50, top-1 = 0.94
I0122 16:59:09.590551 64041 caffe_interface.cpp:125] Batch 50, top-5 = 1
I0122 16:59:09.600575 64041 caffe_interface.cpp:125] Batch 51, accuracy = 0.88
I0122 16:59:09.600584 64041 caffe_interface.cpp:125] Batch 51, loss = 0.281022
I0122 16:59:09.600589 64041 caffe_interface.cpp:125] Batch 51, top-1 = 0.88
I0122 16:59:09.600591 64041 caffe_interface.cpp:125] Batch 51, top-5 = 0.98
I0122 16:59:09.615367 64041 caffe_interface.cpp:125] Batch 52, accuracy = 0.84
I0122 16:59:09.615377 64041 caffe_interface.cpp:125] Batch 52, loss = 0.397684
I0122 16:59:09.615381 64041 caffe_interface.cpp:125] Batch 52, top-1 = 0.84
I0122 16:59:09.615383 64041 caffe_interface.cpp:125] Batch 52, top-5 = 1
I0122 16:59:09.655267 64041 caffe_interface.cpp:125] Batch 53, accuracy = 0.76
I0122 16:59:09.655275 64041 caffe_interface.cpp:125] Batch 53, loss = 0.74728
I0122 16:59:09.655279 64041 caffe_interface.cpp:125] Batch 53, top-1 = 0.76
I0122 16:59:09.655282 64041 caffe_interface.cpp:125] Batch 53, top-5 = 1
I0122 16:59:09.663532 64041 caffe_interface.cpp:125] Batch 54, accuracy = 0.94
I0122 16:59:09.663542 64041 caffe_interface.cpp:125] Batch 54, loss = 0.316229
I0122 16:59:09.663547 64041 caffe_interface.cpp:125] Batch 54, top-1 = 0.94
I0122 16:59:09.663549 64041 caffe_interface.cpp:125] Batch 54, top-5 = 1
I0122 16:59:09.672216 64041 caffe_interface.cpp:125] Batch 55, accuracy = 0.9
I0122 16:59:09.672227 64041 caffe_interface.cpp:125] Batch 55, loss = 0.187135
I0122 16:59:09.672231 64041 caffe_interface.cpp:125] Batch 55, top-1 = 0.9
I0122 16:59:09.672235 64041 caffe_interface.cpp:125] Batch 55, top-5 = 1
I0122 16:59:09.680594 64041 caffe_interface.cpp:125] Batch 56, accuracy = 0.92
I0122 16:59:09.680605 64041 caffe_interface.cpp:125] Batch 56, loss = 0.232003
I0122 16:59:09.680609 64041 caffe_interface.cpp:125] Batch 56, top-1 = 0.92
I0122 16:59:09.680613 64041 caffe_interface.cpp:125] Batch 56, top-5 = 1
I0122 16:59:09.689849 64041 caffe_interface.cpp:125] Batch 57, accuracy = 0.92
I0122 16:59:09.689858 64041 caffe_interface.cpp:125] Batch 57, loss = 0.260078
I0122 16:59:09.689862 64041 caffe_interface.cpp:125] Batch 57, top-1 = 0.92
I0122 16:59:09.689864 64041 caffe_interface.cpp:125] Batch 57, top-5 = 1
I0122 16:59:09.699929 64041 caffe_interface.cpp:125] Batch 58, accuracy = 0.88
I0122 16:59:09.699939 64041 caffe_interface.cpp:125] Batch 58, loss = 0.266759
I0122 16:59:09.699942 64041 caffe_interface.cpp:125] Batch 58, top-1 = 0.88
I0122 16:59:09.699945 64041 caffe_interface.cpp:125] Batch 58, top-5 = 1
I0122 16:59:09.714812 64041 caffe_interface.cpp:125] Batch 59, accuracy = 0.92
I0122 16:59:09.714823 64041 caffe_interface.cpp:125] Batch 59, loss = 0.262843
I0122 16:59:09.714826 64041 caffe_interface.cpp:125] Batch 59, top-1 = 0.92
I0122 16:59:09.714828 64041 caffe_interface.cpp:125] Batch 59, top-5 = 1
I0122 16:59:09.754808 64041 caffe_interface.cpp:125] Batch 60, accuracy = 0.86
I0122 16:59:09.754817 64041 caffe_interface.cpp:125] Batch 60, loss = 0.237942
I0122 16:59:09.754820 64041 caffe_interface.cpp:125] Batch 60, top-1 = 0.86
I0122 16:59:09.754822 64041 caffe_interface.cpp:125] Batch 60, top-5 = 1
I0122 16:59:09.763080 64041 caffe_interface.cpp:125] Batch 61, accuracy = 0.84
I0122 16:59:09.763090 64041 caffe_interface.cpp:125] Batch 61, loss = 0.558042
I0122 16:59:09.763094 64041 caffe_interface.cpp:125] Batch 61, top-1 = 0.84
I0122 16:59:09.763098 64041 caffe_interface.cpp:125] Batch 61, top-5 = 1
I0122 16:59:09.771572 64041 caffe_interface.cpp:125] Batch 62, accuracy = 0.86
I0122 16:59:09.771582 64041 caffe_interface.cpp:125] Batch 62, loss = 0.281388
I0122 16:59:09.771586 64041 caffe_interface.cpp:125] Batch 62, top-1 = 0.86
I0122 16:59:09.771589 64041 caffe_interface.cpp:125] Batch 62, top-5 = 1
I0122 16:59:09.779978 64041 caffe_interface.cpp:125] Batch 63, accuracy = 0.88
I0122 16:59:09.779989 64041 caffe_interface.cpp:125] Batch 63, loss = 0.544679
I0122 16:59:09.779992 64041 caffe_interface.cpp:125] Batch 63, top-1 = 0.88
I0122 16:59:09.779995 64041 caffe_interface.cpp:125] Batch 63, top-5 = 0.98
I0122 16:59:09.789067 64041 caffe_interface.cpp:125] Batch 64, accuracy = 0.84
I0122 16:59:09.789075 64041 caffe_interface.cpp:125] Batch 64, loss = 0.39617
I0122 16:59:09.789079 64041 caffe_interface.cpp:125] Batch 64, top-1 = 0.84
I0122 16:59:09.789083 64041 caffe_interface.cpp:125] Batch 64, top-5 = 1
I0122 16:59:09.799603 64041 caffe_interface.cpp:125] Batch 65, accuracy = 0.96
I0122 16:59:09.799612 64041 caffe_interface.cpp:125] Batch 65, loss = 0.173906
I0122 16:59:09.799614 64041 caffe_interface.cpp:125] Batch 65, top-1 = 0.96
I0122 16:59:09.799616 64041 caffe_interface.cpp:125] Batch 65, top-5 = 0.98
I0122 16:59:09.814580 64041 caffe_interface.cpp:125] Batch 66, accuracy = 0.86
I0122 16:59:09.814590 64041 caffe_interface.cpp:125] Batch 66, loss = 0.406937
I0122 16:59:09.814594 64041 caffe_interface.cpp:125] Batch 66, top-1 = 0.86
I0122 16:59:09.814596 64041 caffe_interface.cpp:125] Batch 66, top-5 = 1
I0122 16:59:09.854658 64041 caffe_interface.cpp:125] Batch 67, accuracy = 0.82
I0122 16:59:09.854670 64041 caffe_interface.cpp:125] Batch 67, loss = 0.574615
I0122 16:59:09.854674 64041 caffe_interface.cpp:125] Batch 67, top-1 = 0.82
I0122 16:59:09.854677 64041 caffe_interface.cpp:125] Batch 67, top-5 = 1
I0122 16:59:09.863235 64041 caffe_interface.cpp:125] Batch 68, accuracy = 0.96
I0122 16:59:09.863245 64041 caffe_interface.cpp:125] Batch 68, loss = 0.0924121
I0122 16:59:09.863250 64041 caffe_interface.cpp:125] Batch 68, top-1 = 0.96
I0122 16:59:09.863252 64041 caffe_interface.cpp:125] Batch 68, top-5 = 1
I0122 16:59:09.871599 64041 caffe_interface.cpp:125] Batch 69, accuracy = 0.96
I0122 16:59:09.871609 64041 caffe_interface.cpp:125] Batch 69, loss = 0.118735
I0122 16:59:09.871613 64041 caffe_interface.cpp:125] Batch 69, top-1 = 0.96
I0122 16:59:09.871615 64041 caffe_interface.cpp:125] Batch 69, top-5 = 1
I0122 16:59:09.880074 64041 caffe_interface.cpp:125] Batch 70, accuracy = 0.84
I0122 16:59:09.880082 64041 caffe_interface.cpp:125] Batch 70, loss = 0.495717
I0122 16:59:09.880086 64041 caffe_interface.cpp:125] Batch 70, top-1 = 0.84
I0122 16:59:09.880089 64041 caffe_interface.cpp:125] Batch 70, top-5 = 1
I0122 16:59:09.889348 64041 caffe_interface.cpp:125] Batch 71, accuracy = 0.86
I0122 16:59:09.889358 64041 caffe_interface.cpp:125] Batch 71, loss = 0.640312
I0122 16:59:09.889362 64041 caffe_interface.cpp:125] Batch 71, top-1 = 0.86
I0122 16:59:09.889364 64041 caffe_interface.cpp:125] Batch 71, top-5 = 0.98
I0122 16:59:09.899108 64041 caffe_interface.cpp:125] Batch 72, accuracy = 0.84
I0122 16:59:09.899117 64041 caffe_interface.cpp:125] Batch 72, loss = 0.382007
I0122 16:59:09.899121 64041 caffe_interface.cpp:125] Batch 72, top-1 = 0.84
I0122 16:59:09.899124 64041 caffe_interface.cpp:125] Batch 72, top-5 = 1
I0122 16:59:09.915002 64041 caffe_interface.cpp:125] Batch 73, accuracy = 0.9
I0122 16:59:09.915012 64041 caffe_interface.cpp:125] Batch 73, loss = 0.260317
I0122 16:59:09.915016 64041 caffe_interface.cpp:125] Batch 73, top-1 = 0.9
I0122 16:59:09.915019 64041 caffe_interface.cpp:125] Batch 73, top-5 = 1
I0122 16:59:09.955114 64041 caffe_interface.cpp:125] Batch 74, accuracy = 0.84
I0122 16:59:09.955126 64041 caffe_interface.cpp:125] Batch 74, loss = 0.636951
I0122 16:59:09.955129 64041 caffe_interface.cpp:125] Batch 74, top-1 = 0.84
I0122 16:59:09.955132 64041 caffe_interface.cpp:125] Batch 74, top-5 = 1
I0122 16:59:09.963490 64041 caffe_interface.cpp:125] Batch 75, accuracy = 0.92
I0122 16:59:09.963500 64041 caffe_interface.cpp:125] Batch 75, loss = 0.378257
I0122 16:59:09.963505 64041 caffe_interface.cpp:125] Batch 75, top-1 = 0.92
I0122 16:59:09.963506 64041 caffe_interface.cpp:125] Batch 75, top-5 = 1
I0122 16:59:09.971876 64041 caffe_interface.cpp:125] Batch 76, accuracy = 0.86
I0122 16:59:09.971885 64041 caffe_interface.cpp:125] Batch 76, loss = 0.424764
I0122 16:59:09.971901 64041 caffe_interface.cpp:125] Batch 76, top-1 = 0.86
I0122 16:59:09.971904 64041 caffe_interface.cpp:125] Batch 76, top-5 = 0.98
I0122 16:59:09.980376 64041 caffe_interface.cpp:125] Batch 77, accuracy = 0.92
I0122 16:59:09.980386 64041 caffe_interface.cpp:125] Batch 77, loss = 0.20672
I0122 16:59:09.980389 64041 caffe_interface.cpp:125] Batch 77, top-1 = 0.92
I0122 16:59:09.980391 64041 caffe_interface.cpp:125] Batch 77, top-5 = 1
I0122 16:59:09.989634 64041 caffe_interface.cpp:125] Batch 78, accuracy = 0.96
I0122 16:59:09.989645 64041 caffe_interface.cpp:125] Batch 78, loss = 0.148806
I0122 16:59:09.989648 64041 caffe_interface.cpp:125] Batch 78, top-1 = 0.96
I0122 16:59:09.989651 64041 caffe_interface.cpp:125] Batch 78, top-5 = 1
I0122 16:59:09.999259 64041 caffe_interface.cpp:125] Batch 79, accuracy = 0.92
I0122 16:59:09.999269 64041 caffe_interface.cpp:125] Batch 79, loss = 0.280653
I0122 16:59:09.999272 64041 caffe_interface.cpp:125] Batch 79, top-1 = 0.92
I0122 16:59:09.999275 64041 caffe_interface.cpp:125] Batch 79, top-5 = 1
I0122 16:59:10.015308 64041 caffe_interface.cpp:125] Batch 80, accuracy = 0.88
I0122 16:59:10.015318 64041 caffe_interface.cpp:125] Batch 80, loss = 0.251938
I0122 16:59:10.015321 64041 caffe_interface.cpp:125] Batch 80, top-1 = 0.88
I0122 16:59:10.015324 64041 caffe_interface.cpp:125] Batch 80, top-5 = 1
I0122 16:59:10.055542 64041 caffe_interface.cpp:125] Batch 81, accuracy = 0.9
I0122 16:59:10.055553 64041 caffe_interface.cpp:125] Batch 81, loss = 0.268036
I0122 16:59:10.055557 64041 caffe_interface.cpp:125] Batch 81, top-1 = 0.9
I0122 16:59:10.055559 64041 caffe_interface.cpp:125] Batch 81, top-5 = 1
I0122 16:59:10.063848 64041 caffe_interface.cpp:125] Batch 82, accuracy = 0.9
I0122 16:59:10.063858 64041 caffe_interface.cpp:125] Batch 82, loss = 0.350619
I0122 16:59:10.063863 64041 caffe_interface.cpp:125] Batch 82, top-1 = 0.9
I0122 16:59:10.063866 64041 caffe_interface.cpp:125] Batch 82, top-5 = 0.98
I0122 16:59:10.072661 64041 caffe_interface.cpp:125] Batch 83, accuracy = 0.92
I0122 16:59:10.072670 64041 caffe_interface.cpp:125] Batch 83, loss = 0.347332
I0122 16:59:10.072674 64041 caffe_interface.cpp:125] Batch 83, top-1 = 0.92
I0122 16:59:10.072676 64041 caffe_interface.cpp:125] Batch 83, top-5 = 1
I0122 16:59:10.080994 64041 caffe_interface.cpp:125] Batch 84, accuracy = 0.9
I0122 16:59:10.081004 64041 caffe_interface.cpp:125] Batch 84, loss = 0.492204
I0122 16:59:10.081008 64041 caffe_interface.cpp:125] Batch 84, top-1 = 0.9
I0122 16:59:10.081012 64041 caffe_interface.cpp:125] Batch 84, top-5 = 0.96
I0122 16:59:10.090482 64041 caffe_interface.cpp:125] Batch 85, accuracy = 0.98
I0122 16:59:10.090490 64041 caffe_interface.cpp:125] Batch 85, loss = 0.204117
I0122 16:59:10.090495 64041 caffe_interface.cpp:125] Batch 85, top-1 = 0.98
I0122 16:59:10.090497 64041 caffe_interface.cpp:125] Batch 85, top-5 = 1
I0122 16:59:10.100366 64041 caffe_interface.cpp:125] Batch 86, accuracy = 0.94
I0122 16:59:10.100376 64041 caffe_interface.cpp:125] Batch 86, loss = 0.210304
I0122 16:59:10.100380 64041 caffe_interface.cpp:125] Batch 86, top-1 = 0.94
I0122 16:59:10.100383 64041 caffe_interface.cpp:125] Batch 86, top-5 = 0.98
I0122 16:59:10.115437 64041 caffe_interface.cpp:125] Batch 87, accuracy = 0.9
I0122 16:59:10.115447 64041 caffe_interface.cpp:125] Batch 87, loss = 0.277258
I0122 16:59:10.115451 64041 caffe_interface.cpp:125] Batch 87, top-1 = 0.9
I0122 16:59:10.115453 64041 caffe_interface.cpp:125] Batch 87, top-5 = 1
I0122 16:59:10.156229 64041 caffe_interface.cpp:125] Batch 88, accuracy = 0.9
I0122 16:59:10.156239 64041 caffe_interface.cpp:125] Batch 88, loss = 0.248976
I0122 16:59:10.156244 64041 caffe_interface.cpp:125] Batch 88, top-1 = 0.9
I0122 16:59:10.156245 64041 caffe_interface.cpp:125] Batch 88, top-5 = 1
I0122 16:59:10.164551 64041 caffe_interface.cpp:125] Batch 89, accuracy = 0.92
I0122 16:59:10.164561 64041 caffe_interface.cpp:125] Batch 89, loss = 0.269425
I0122 16:59:10.164566 64041 caffe_interface.cpp:125] Batch 89, top-1 = 0.92
I0122 16:59:10.164582 64041 caffe_interface.cpp:125] Batch 89, top-5 = 0.98
I0122 16:59:10.173182 64041 caffe_interface.cpp:125] Batch 90, accuracy = 0.9
I0122 16:59:10.173192 64041 caffe_interface.cpp:125] Batch 90, loss = 0.476729
I0122 16:59:10.173195 64041 caffe_interface.cpp:125] Batch 90, top-1 = 0.9
I0122 16:59:10.173197 64041 caffe_interface.cpp:125] Batch 90, top-5 = 0.98
I0122 16:59:10.181409 64041 caffe_interface.cpp:125] Batch 91, accuracy = 0.92
I0122 16:59:10.181418 64041 caffe_interface.cpp:125] Batch 91, loss = 0.226886
I0122 16:59:10.181422 64041 caffe_interface.cpp:125] Batch 91, top-1 = 0.92
I0122 16:59:10.181426 64041 caffe_interface.cpp:125] Batch 91, top-5 = 1
I0122 16:59:10.190760 64041 caffe_interface.cpp:125] Batch 92, accuracy = 0.88
I0122 16:59:10.190769 64041 caffe_interface.cpp:125] Batch 92, loss = 0.345703
I0122 16:59:10.190773 64041 caffe_interface.cpp:125] Batch 92, top-1 = 0.88
I0122 16:59:10.190775 64041 caffe_interface.cpp:125] Batch 92, top-5 = 0.96
I0122 16:59:10.200897 64041 caffe_interface.cpp:125] Batch 93, accuracy = 0.92
I0122 16:59:10.200907 64041 caffe_interface.cpp:125] Batch 93, loss = 0.361548
I0122 16:59:10.200911 64041 caffe_interface.cpp:125] Batch 93, top-1 = 0.92
I0122 16:59:10.200913 64041 caffe_interface.cpp:125] Batch 93, top-5 = 1
I0122 16:59:10.214808 64041 caffe_interface.cpp:125] Batch 94, accuracy = 0.84
I0122 16:59:10.214818 64041 caffe_interface.cpp:125] Batch 94, loss = 0.669362
I0122 16:59:10.214823 64041 caffe_interface.cpp:125] Batch 94, top-1 = 0.84
I0122 16:59:10.214825 64041 caffe_interface.cpp:125] Batch 94, top-5 = 1
I0122 16:59:10.255067 64041 caffe_interface.cpp:125] Batch 95, accuracy = 0.92
I0122 16:59:10.255077 64041 caffe_interface.cpp:125] Batch 95, loss = 0.196305
I0122 16:59:10.255081 64041 caffe_interface.cpp:125] Batch 95, top-1 = 0.92
I0122 16:59:10.255084 64041 caffe_interface.cpp:125] Batch 95, top-5 = 1
I0122 16:59:10.263360 64041 caffe_interface.cpp:125] Batch 96, accuracy = 0.84
I0122 16:59:10.263370 64041 caffe_interface.cpp:125] Batch 96, loss = 0.499885
I0122 16:59:10.263375 64041 caffe_interface.cpp:125] Batch 96, top-1 = 0.84
I0122 16:59:10.263377 64041 caffe_interface.cpp:125] Batch 96, top-5 = 0.96
I0122 16:59:10.271845 64041 caffe_interface.cpp:125] Batch 97, accuracy = 0.9
I0122 16:59:10.271855 64041 caffe_interface.cpp:125] Batch 97, loss = 0.349193
I0122 16:59:10.271858 64041 caffe_interface.cpp:125] Batch 97, top-1 = 0.9
I0122 16:59:10.271862 64041 caffe_interface.cpp:125] Batch 97, top-5 = 1
I0122 16:59:10.280120 64041 caffe_interface.cpp:125] Batch 98, accuracy = 0.9
I0122 16:59:10.280131 64041 caffe_interface.cpp:125] Batch 98, loss = 0.320775
I0122 16:59:10.280135 64041 caffe_interface.cpp:125] Batch 98, top-1 = 0.9
I0122 16:59:10.280138 64041 caffe_interface.cpp:125] Batch 98, top-5 = 1
I0122 16:59:10.289523 64041 caffe_interface.cpp:125] Batch 99, accuracy = 0.86
I0122 16:59:10.289532 64041 caffe_interface.cpp:125] Batch 99, loss = 0.662893
I0122 16:59:10.289536 64041 caffe_interface.cpp:125] Batch 99, top-1 = 0.86
I0122 16:59:10.289539 64041 caffe_interface.cpp:125] Batch 99, top-5 = 1
I0122 16:59:10.299427 64041 caffe_interface.cpp:125] Batch 100, accuracy = 0.9
I0122 16:59:10.299437 64041 caffe_interface.cpp:125] Batch 100, loss = 0.339474
I0122 16:59:10.299440 64041 caffe_interface.cpp:125] Batch 100, top-1 = 0.9
I0122 16:59:10.299443 64041 caffe_interface.cpp:125] Batch 100, top-5 = 1
I0122 16:59:10.314128 64041 caffe_interface.cpp:125] Batch 101, accuracy = 0.86
I0122 16:59:10.314138 64041 caffe_interface.cpp:125] Batch 101, loss = 0.261841
I0122 16:59:10.314142 64041 caffe_interface.cpp:125] Batch 101, top-1 = 0.86
I0122 16:59:10.314146 64041 caffe_interface.cpp:125] Batch 101, top-5 = 1
I0122 16:59:10.353828 64041 caffe_interface.cpp:125] Batch 102, accuracy = 0.86
I0122 16:59:10.353837 64041 caffe_interface.cpp:125] Batch 102, loss = 0.516473
I0122 16:59:10.353842 64041 caffe_interface.cpp:125] Batch 102, top-1 = 0.86
I0122 16:59:10.353843 64041 caffe_interface.cpp:125] Batch 102, top-5 = 1
I0122 16:59:10.361847 64041 caffe_interface.cpp:125] Batch 103, accuracy = 0.94
I0122 16:59:10.361858 64041 caffe_interface.cpp:125] Batch 103, loss = 0.13744
I0122 16:59:10.361862 64041 caffe_interface.cpp:125] Batch 103, top-1 = 0.94
I0122 16:59:10.361865 64041 caffe_interface.cpp:125] Batch 103, top-5 = 1
I0122 16:59:10.370359 64041 caffe_interface.cpp:125] Batch 104, accuracy = 0.9
I0122 16:59:10.370369 64041 caffe_interface.cpp:125] Batch 104, loss = 0.384198
I0122 16:59:10.370373 64041 caffe_interface.cpp:125] Batch 104, top-1 = 0.9
I0122 16:59:10.370376 64041 caffe_interface.cpp:125] Batch 104, top-5 = 0.98
I0122 16:59:10.378370 64041 caffe_interface.cpp:125] Batch 105, accuracy = 0.94
I0122 16:59:10.378379 64041 caffe_interface.cpp:125] Batch 105, loss = 0.160826
I0122 16:59:10.378383 64041 caffe_interface.cpp:125] Batch 105, top-1 = 0.94
I0122 16:59:10.378386 64041 caffe_interface.cpp:125] Batch 105, top-5 = 1
I0122 16:59:10.387817 64041 caffe_interface.cpp:125] Batch 106, accuracy = 0.92
I0122 16:59:10.387828 64041 caffe_interface.cpp:125] Batch 106, loss = 0.354832
I0122 16:59:10.387832 64041 caffe_interface.cpp:125] Batch 106, top-1 = 0.92
I0122 16:59:10.387835 64041 caffe_interface.cpp:125] Batch 106, top-5 = 1
I0122 16:59:10.395813 64041 caffe_interface.cpp:125] Batch 107, accuracy = 0.86
I0122 16:59:10.395823 64041 caffe_interface.cpp:125] Batch 107, loss = 0.528053
I0122 16:59:10.395828 64041 caffe_interface.cpp:125] Batch 107, top-1 = 0.86
I0122 16:59:10.395830 64041 caffe_interface.cpp:125] Batch 107, top-5 = 0.98
I0122 16:59:10.412426 64041 caffe_interface.cpp:125] Batch 108, accuracy = 0.84
I0122 16:59:10.412437 64041 caffe_interface.cpp:125] Batch 108, loss = 0.542655
I0122 16:59:10.412441 64041 caffe_interface.cpp:125] Batch 108, top-1 = 0.84
I0122 16:59:10.412444 64041 caffe_interface.cpp:125] Batch 108, top-5 = 1
I0122 16:59:10.452374 64041 caffe_interface.cpp:125] Batch 109, accuracy = 0.94
I0122 16:59:10.452384 64041 caffe_interface.cpp:125] Batch 109, loss = 0.151747
I0122 16:59:10.452388 64041 caffe_interface.cpp:125] Batch 109, top-1 = 0.94
I0122 16:59:10.452389 64041 caffe_interface.cpp:125] Batch 109, top-5 = 1
I0122 16:59:10.460410 64041 caffe_interface.cpp:125] Batch 110, accuracy = 0.84
I0122 16:59:10.460420 64041 caffe_interface.cpp:125] Batch 110, loss = 0.598989
I0122 16:59:10.460424 64041 caffe_interface.cpp:125] Batch 110, top-1 = 0.84
I0122 16:59:10.460427 64041 caffe_interface.cpp:125] Batch 110, top-5 = 1
I0122 16:59:10.468791 64041 caffe_interface.cpp:125] Batch 111, accuracy = 0.92
I0122 16:59:10.468801 64041 caffe_interface.cpp:125] Batch 111, loss = 0.390577
I0122 16:59:10.468806 64041 caffe_interface.cpp:125] Batch 111, top-1 = 0.92
I0122 16:59:10.468807 64041 caffe_interface.cpp:125] Batch 111, top-5 = 1
I0122 16:59:10.476781 64041 caffe_interface.cpp:125] Batch 112, accuracy = 0.96
I0122 16:59:10.476791 64041 caffe_interface.cpp:125] Batch 112, loss = 0.127492
I0122 16:59:10.476795 64041 caffe_interface.cpp:125] Batch 112, top-1 = 0.96
I0122 16:59:10.476799 64041 caffe_interface.cpp:125] Batch 112, top-5 = 1
I0122 16:59:10.486287 64041 caffe_interface.cpp:125] Batch 113, accuracy = 0.9
I0122 16:59:10.486297 64041 caffe_interface.cpp:125] Batch 113, loss = 0.287975
I0122 16:59:10.486301 64041 caffe_interface.cpp:125] Batch 113, top-1 = 0.9
I0122 16:59:10.486304 64041 caffe_interface.cpp:125] Batch 113, top-5 = 1
I0122 16:59:10.494284 64041 caffe_interface.cpp:125] Batch 114, accuracy = 0.88
I0122 16:59:10.494295 64041 caffe_interface.cpp:125] Batch 114, loss = 0.346925
I0122 16:59:10.494298 64041 caffe_interface.cpp:125] Batch 114, top-1 = 0.88
I0122 16:59:10.494302 64041 caffe_interface.cpp:125] Batch 114, top-5 = 1
I0122 16:59:10.504572 64041 caffe_interface.cpp:125] Batch 115, accuracy = 0.94
I0122 16:59:10.504581 64041 caffe_interface.cpp:125] Batch 115, loss = 0.154762
I0122 16:59:10.504585 64041 caffe_interface.cpp:125] Batch 115, top-1 = 0.94
I0122 16:59:10.504587 64041 caffe_interface.cpp:125] Batch 115, top-5 = 1
I0122 16:59:10.518463 64041 caffe_interface.cpp:125] Batch 116, accuracy = 0.86
I0122 16:59:10.518487 64041 caffe_interface.cpp:125] Batch 116, loss = 0.440384
I0122 16:59:10.518492 64041 caffe_interface.cpp:125] Batch 116, top-1 = 0.86
I0122 16:59:10.518494 64041 caffe_interface.cpp:125] Batch 116, top-5 = 1
I0122 16:59:10.555835 64041 caffe_interface.cpp:125] Batch 117, accuracy = 0.84
I0122 16:59:10.555845 64041 caffe_interface.cpp:125] Batch 117, loss = 0.422938
I0122 16:59:10.555850 64041 caffe_interface.cpp:125] Batch 117, top-1 = 0.84
I0122 16:59:10.555862 64041 caffe_interface.cpp:125] Batch 117, top-5 = 1
I0122 16:59:10.563848 64041 caffe_interface.cpp:125] Batch 118, accuracy = 0.96
I0122 16:59:10.563858 64041 caffe_interface.cpp:125] Batch 118, loss = 0.270987
I0122 16:59:10.563861 64041 caffe_interface.cpp:125] Batch 118, top-1 = 0.96
I0122 16:59:10.563864 64041 caffe_interface.cpp:125] Batch 118, top-5 = 0.98
I0122 16:59:10.572084 64041 caffe_interface.cpp:125] Batch 119, accuracy = 0.88
I0122 16:59:10.572094 64041 caffe_interface.cpp:125] Batch 119, loss = 0.35766
I0122 16:59:10.572098 64041 caffe_interface.cpp:125] Batch 119, top-1 = 0.88
I0122 16:59:10.572100 64041 caffe_interface.cpp:125] Batch 119, top-5 = 1
I0122 16:59:10.580065 64041 caffe_interface.cpp:125] Batch 120, accuracy = 0.88
I0122 16:59:10.580073 64041 caffe_interface.cpp:125] Batch 120, loss = 0.2801
I0122 16:59:10.580078 64041 caffe_interface.cpp:125] Batch 120, top-1 = 0.88
I0122 16:59:10.580081 64041 caffe_interface.cpp:125] Batch 120, top-5 = 1
I0122 16:59:10.589395 64041 caffe_interface.cpp:125] Batch 121, accuracy = 0.8
I0122 16:59:10.589402 64041 caffe_interface.cpp:125] Batch 121, loss = 0.641156
I0122 16:59:10.589406 64041 caffe_interface.cpp:125] Batch 121, top-1 = 0.8
I0122 16:59:10.589408 64041 caffe_interface.cpp:125] Batch 121, top-5 = 0.98
I0122 16:59:10.597368 64041 caffe_interface.cpp:125] Batch 122, accuracy = 0.92
I0122 16:59:10.597378 64041 caffe_interface.cpp:125] Batch 122, loss = 0.214573
I0122 16:59:10.597383 64041 caffe_interface.cpp:125] Batch 122, top-1 = 0.92
I0122 16:59:10.597384 64041 caffe_interface.cpp:125] Batch 122, top-5 = 1
I0122 16:59:10.615862 64041 caffe_interface.cpp:125] Batch 123, accuracy = 0.9
I0122 16:59:10.615875 64041 caffe_interface.cpp:125] Batch 123, loss = 0.267078
I0122 16:59:10.615878 64041 caffe_interface.cpp:125] Batch 123, top-1 = 0.9
I0122 16:59:10.615881 64041 caffe_interface.cpp:125] Batch 123, top-5 = 1
I0122 16:59:10.656328 64041 caffe_interface.cpp:125] Batch 124, accuracy = 0.98
I0122 16:59:10.656338 64041 caffe_interface.cpp:125] Batch 124, loss = 0.0808417
I0122 16:59:10.656343 64041 caffe_interface.cpp:125] Batch 124, top-1 = 0.98
I0122 16:59:10.656347 64041 caffe_interface.cpp:125] Batch 124, top-5 = 1
I0122 16:59:10.664595 64041 caffe_interface.cpp:125] Batch 125, accuracy = 0.88
I0122 16:59:10.664605 64041 caffe_interface.cpp:125] Batch 125, loss = 0.285608
I0122 16:59:10.664609 64041 caffe_interface.cpp:125] Batch 125, top-1 = 0.88
I0122 16:59:10.664613 64041 caffe_interface.cpp:125] Batch 125, top-5 = 1
I0122 16:59:10.672814 64041 caffe_interface.cpp:125] Batch 126, accuracy = 0.84
I0122 16:59:10.672824 64041 caffe_interface.cpp:125] Batch 126, loss = 0.589866
I0122 16:59:10.672828 64041 caffe_interface.cpp:125] Batch 126, top-1 = 0.84
I0122 16:59:10.672832 64041 caffe_interface.cpp:125] Batch 126, top-5 = 0.98
I0122 16:59:10.680796 64041 caffe_interface.cpp:125] Batch 127, accuracy = 0.88
I0122 16:59:10.680806 64041 caffe_interface.cpp:125] Batch 127, loss = 0.374888
I0122 16:59:10.680810 64041 caffe_interface.cpp:125] Batch 127, top-1 = 0.88
I0122 16:59:10.680814 64041 caffe_interface.cpp:125] Batch 127, top-5 = 1
I0122 16:59:10.689713 64041 caffe_interface.cpp:125] Batch 128, accuracy = 0.94
I0122 16:59:10.689721 64041 caffe_interface.cpp:125] Batch 128, loss = 0.182621
I0122 16:59:10.689725 64041 caffe_interface.cpp:125] Batch 128, top-1 = 0.94
I0122 16:59:10.689728 64041 caffe_interface.cpp:125] Batch 128, top-5 = 1
I0122 16:59:10.699787 64041 caffe_interface.cpp:125] Batch 129, accuracy = 0.86
I0122 16:59:10.699808 64041 caffe_interface.cpp:125] Batch 129, loss = 0.567452
I0122 16:59:10.699813 64041 caffe_interface.cpp:125] Batch 129, top-1 = 0.86
I0122 16:59:10.699815 64041 caffe_interface.cpp:125] Batch 129, top-5 = 1
I0122 16:59:10.714419 64041 caffe_interface.cpp:125] Batch 130, accuracy = 0.94
I0122 16:59:10.714432 64041 caffe_interface.cpp:125] Batch 130, loss = 0.257493
I0122 16:59:10.714435 64041 caffe_interface.cpp:125] Batch 130, top-1 = 0.94
I0122 16:59:10.714437 64041 caffe_interface.cpp:125] Batch 130, top-5 = 1
I0122 16:59:10.753983 64041 caffe_interface.cpp:125] Batch 131, accuracy = 0.8
I0122 16:59:10.753991 64041 caffe_interface.cpp:125] Batch 131, loss = 0.453802
I0122 16:59:10.753995 64041 caffe_interface.cpp:125] Batch 131, top-1 = 0.8
I0122 16:59:10.753998 64041 caffe_interface.cpp:125] Batch 131, top-5 = 0.98
I0122 16:59:10.763355 64041 caffe_interface.cpp:125] Batch 132, accuracy = 0.84
I0122 16:59:10.763365 64041 caffe_interface.cpp:125] Batch 132, loss = 0.629526
I0122 16:59:10.763370 64041 caffe_interface.cpp:125] Batch 132, top-1 = 0.84
I0122 16:59:10.763372 64041 caffe_interface.cpp:125] Batch 132, top-5 = 1
I0122 16:59:10.771585 64041 caffe_interface.cpp:125] Batch 133, accuracy = 0.86
I0122 16:59:10.771595 64041 caffe_interface.cpp:125] Batch 133, loss = 0.417656
I0122 16:59:10.771598 64041 caffe_interface.cpp:125] Batch 133, top-1 = 0.86
I0122 16:59:10.771601 64041 caffe_interface.cpp:125] Batch 133, top-5 = 0.98
I0122 16:59:10.779568 64041 caffe_interface.cpp:125] Batch 134, accuracy = 0.9
I0122 16:59:10.779578 64041 caffe_interface.cpp:125] Batch 134, loss = 0.355566
I0122 16:59:10.779582 64041 caffe_interface.cpp:125] Batch 134, top-1 = 0.9
I0122 16:59:10.779585 64041 caffe_interface.cpp:125] Batch 134, top-5 = 1
I0122 16:59:10.787544 64041 caffe_interface.cpp:125] Batch 135, accuracy = 0.82
I0122 16:59:10.787554 64041 caffe_interface.cpp:125] Batch 135, loss = 0.699569
I0122 16:59:10.787556 64041 caffe_interface.cpp:125] Batch 135, top-1 = 0.82
I0122 16:59:10.787559 64041 caffe_interface.cpp:125] Batch 135, top-5 = 1
I0122 16:59:10.798354 64041 caffe_interface.cpp:125] Batch 136, accuracy = 0.94
I0122 16:59:10.798363 64041 caffe_interface.cpp:125] Batch 136, loss = 0.158242
I0122 16:59:10.798367 64041 caffe_interface.cpp:125] Batch 136, top-1 = 0.94
I0122 16:59:10.798368 64041 caffe_interface.cpp:125] Batch 136, top-5 = 1
I0122 16:59:10.812376 64041 caffe_interface.cpp:125] Batch 137, accuracy = 0.94
I0122 16:59:10.812386 64041 caffe_interface.cpp:125] Batch 137, loss = 0.284061
I0122 16:59:10.812399 64041 caffe_interface.cpp:125] Batch 137, top-1 = 0.94
I0122 16:59:10.812402 64041 caffe_interface.cpp:125] Batch 137, top-5 = 1
I0122 16:59:10.849762 64041 caffe_interface.cpp:125] Batch 138, accuracy = 0.86
I0122 16:59:10.849772 64041 caffe_interface.cpp:125] Batch 138, loss = 0.434069
I0122 16:59:10.849776 64041 caffe_interface.cpp:125] Batch 138, top-1 = 0.86
I0122 16:59:10.849777 64041 caffe_interface.cpp:125] Batch 138, top-5 = 0.98
I0122 16:59:10.857741 64041 caffe_interface.cpp:125] Batch 139, accuracy = 0.9
I0122 16:59:10.857751 64041 caffe_interface.cpp:125] Batch 139, loss = 0.499191
I0122 16:59:10.857756 64041 caffe_interface.cpp:125] Batch 139, top-1 = 0.9
I0122 16:59:10.857759 64041 caffe_interface.cpp:125] Batch 139, top-5 = 0.98
I0122 16:59:10.867072 64041 caffe_interface.cpp:125] Batch 140, accuracy = 0.88
I0122 16:59:10.867082 64041 caffe_interface.cpp:125] Batch 140, loss = 0.694505
I0122 16:59:10.867085 64041 caffe_interface.cpp:125] Batch 140, top-1 = 0.88
I0122 16:59:10.867089 64041 caffe_interface.cpp:125] Batch 140, top-5 = 1
I0122 16:59:10.875058 64041 caffe_interface.cpp:125] Batch 141, accuracy = 0.92
I0122 16:59:10.875067 64041 caffe_interface.cpp:125] Batch 141, loss = 0.322201
I0122 16:59:10.875072 64041 caffe_interface.cpp:125] Batch 141, top-1 = 0.92
I0122 16:59:10.875075 64041 caffe_interface.cpp:125] Batch 141, top-5 = 1
I0122 16:59:10.883296 64041 caffe_interface.cpp:125] Batch 142, accuracy = 0.88
I0122 16:59:10.883304 64041 caffe_interface.cpp:125] Batch 142, loss = 0.42113
I0122 16:59:10.883322 64041 caffe_interface.cpp:125] Batch 142, top-1 = 0.88
I0122 16:59:10.883325 64041 caffe_interface.cpp:125] Batch 142, top-5 = 1
I0122 16:59:10.893288 64041 caffe_interface.cpp:125] Batch 143, accuracy = 0.9
I0122 16:59:10.893298 64041 caffe_interface.cpp:125] Batch 143, loss = 0.298506
I0122 16:59:10.893302 64041 caffe_interface.cpp:125] Batch 143, top-1 = 0.9
I0122 16:59:10.893304 64041 caffe_interface.cpp:125] Batch 143, top-5 = 1
I0122 16:59:10.908607 64041 caffe_interface.cpp:125] Batch 144, accuracy = 0.88
I0122 16:59:10.908617 64041 caffe_interface.cpp:125] Batch 144, loss = 0.365722
I0122 16:59:10.908620 64041 caffe_interface.cpp:125] Batch 144, top-1 = 0.88
I0122 16:59:10.908623 64041 caffe_interface.cpp:125] Batch 144, top-5 = 1
I0122 16:59:10.948176 64041 caffe_interface.cpp:125] Batch 145, accuracy = 0.96
I0122 16:59:10.948186 64041 caffe_interface.cpp:125] Batch 145, loss = 0.261301
I0122 16:59:10.948189 64041 caffe_interface.cpp:125] Batch 145, top-1 = 0.96
I0122 16:59:10.948191 64041 caffe_interface.cpp:125] Batch 145, top-5 = 1
I0122 16:59:10.956218 64041 caffe_interface.cpp:125] Batch 146, accuracy = 0.9
I0122 16:59:10.956228 64041 caffe_interface.cpp:125] Batch 146, loss = 0.524324
I0122 16:59:10.956231 64041 caffe_interface.cpp:125] Batch 146, top-1 = 0.9
I0122 16:59:10.956234 64041 caffe_interface.cpp:125] Batch 146, top-5 = 1
I0122 16:59:10.964224 64041 caffe_interface.cpp:125] Batch 147, accuracy = 0.86
I0122 16:59:10.964234 64041 caffe_interface.cpp:125] Batch 147, loss = 0.361927
I0122 16:59:10.964239 64041 caffe_interface.cpp:125] Batch 147, top-1 = 0.86
I0122 16:59:10.964242 64041 caffe_interface.cpp:125] Batch 147, top-5 = 1
I0122 16:59:10.973588 64041 caffe_interface.cpp:125] Batch 148, accuracy = 0.92
I0122 16:59:10.973598 64041 caffe_interface.cpp:125] Batch 148, loss = 0.170366
I0122 16:59:10.973601 64041 caffe_interface.cpp:125] Batch 148, top-1 = 0.92
I0122 16:59:10.973603 64041 caffe_interface.cpp:125] Batch 148, top-5 = 1
I0122 16:59:10.981580 64041 caffe_interface.cpp:125] Batch 149, accuracy = 0.96
I0122 16:59:10.981588 64041 caffe_interface.cpp:125] Batch 149, loss = 0.223591
I0122 16:59:10.981592 64041 caffe_interface.cpp:125] Batch 149, top-1 = 0.96
I0122 16:59:10.981595 64041 caffe_interface.cpp:125] Batch 149, top-5 = 1
I0122 16:59:10.991801 64041 caffe_interface.cpp:125] Batch 150, accuracy = 0.94
I0122 16:59:10.991811 64041 caffe_interface.cpp:125] Batch 150, loss = 0.23126
I0122 16:59:10.991816 64041 caffe_interface.cpp:125] Batch 150, top-1 = 0.94
I0122 16:59:10.991817 64041 caffe_interface.cpp:125] Batch 150, top-5 = 1
I0122 16:59:11.006589 64041 caffe_interface.cpp:125] Batch 151, accuracy = 0.86
I0122 16:59:11.006599 64041 caffe_interface.cpp:125] Batch 151, loss = 0.3872
I0122 16:59:11.006613 64041 caffe_interface.cpp:125] Batch 151, top-1 = 0.86
I0122 16:59:11.006615 64041 caffe_interface.cpp:125] Batch 151, top-5 = 1
I0122 16:59:11.046201 64041 caffe_interface.cpp:125] Batch 152, accuracy = 0.9
I0122 16:59:11.046212 64041 caffe_interface.cpp:125] Batch 152, loss = 0.275324
I0122 16:59:11.046217 64041 caffe_interface.cpp:125] Batch 152, top-1 = 0.9
I0122 16:59:11.046229 64041 caffe_interface.cpp:125] Batch 152, top-5 = 1
I0122 16:59:11.054458 64041 caffe_interface.cpp:125] Batch 153, accuracy = 0.94
I0122 16:59:11.054468 64041 caffe_interface.cpp:125] Batch 153, loss = 0.261662
I0122 16:59:11.054472 64041 caffe_interface.cpp:125] Batch 153, top-1 = 0.94
I0122 16:59:11.054476 64041 caffe_interface.cpp:125] Batch 153, top-5 = 1
I0122 16:59:11.062448 64041 caffe_interface.cpp:125] Batch 154, accuracy = 0.9
I0122 16:59:11.062458 64041 caffe_interface.cpp:125] Batch 154, loss = 0.259839
I0122 16:59:11.062463 64041 caffe_interface.cpp:125] Batch 154, top-1 = 0.9
I0122 16:59:11.062465 64041 caffe_interface.cpp:125] Batch 154, top-5 = 1
I0122 16:59:11.070447 64041 caffe_interface.cpp:125] Batch 155, accuracy = 0.94
I0122 16:59:11.070457 64041 caffe_interface.cpp:125] Batch 155, loss = 0.242614
I0122 16:59:11.070461 64041 caffe_interface.cpp:125] Batch 155, top-1 = 0.94
I0122 16:59:11.070477 64041 caffe_interface.cpp:125] Batch 155, top-5 = 1
I0122 16:59:11.079865 64041 caffe_interface.cpp:125] Batch 156, accuracy = 0.92
I0122 16:59:11.079876 64041 caffe_interface.cpp:125] Batch 156, loss = 0.28966
I0122 16:59:11.079880 64041 caffe_interface.cpp:125] Batch 156, top-1 = 0.92
I0122 16:59:11.079883 64041 caffe_interface.cpp:125] Batch 156, top-5 = 1
I0122 16:59:11.090107 64041 caffe_interface.cpp:125] Batch 157, accuracy = 0.88
I0122 16:59:11.090116 64041 caffe_interface.cpp:125] Batch 157, loss = 0.311646
I0122 16:59:11.090121 64041 caffe_interface.cpp:125] Batch 157, top-1 = 0.88
I0122 16:59:11.090123 64041 caffe_interface.cpp:125] Batch 157, top-5 = 1
I0122 16:59:11.105417 64041 caffe_interface.cpp:125] Batch 158, accuracy = 0.92
I0122 16:59:11.105428 64041 caffe_interface.cpp:125] Batch 158, loss = 0.334393
I0122 16:59:11.105443 64041 caffe_interface.cpp:125] Batch 158, top-1 = 0.92
I0122 16:59:11.105444 64041 caffe_interface.cpp:125] Batch 158, top-5 = 1
I0122 16:59:11.145836 64041 caffe_interface.cpp:125] Batch 159, accuracy = 0.78
I0122 16:59:11.145846 64041 caffe_interface.cpp:125] Batch 159, loss = 0.6086
I0122 16:59:11.145850 64041 caffe_interface.cpp:125] Batch 159, top-1 = 0.78
I0122 16:59:11.145853 64041 caffe_interface.cpp:125] Batch 159, top-5 = 0.98
I0122 16:59:11.154152 64041 caffe_interface.cpp:125] Batch 160, accuracy = 0.96
I0122 16:59:11.154163 64041 caffe_interface.cpp:125] Batch 160, loss = 0.136463
I0122 16:59:11.154166 64041 caffe_interface.cpp:125] Batch 160, top-1 = 0.96
I0122 16:59:11.154170 64041 caffe_interface.cpp:125] Batch 160, top-5 = 1
I0122 16:59:11.162133 64041 caffe_interface.cpp:125] Batch 161, accuracy = 0.88
I0122 16:59:11.162143 64041 caffe_interface.cpp:125] Batch 161, loss = 0.23929
I0122 16:59:11.162147 64041 caffe_interface.cpp:125] Batch 161, top-1 = 0.88
I0122 16:59:11.162150 64041 caffe_interface.cpp:125] Batch 161, top-5 = 1
I0122 16:59:11.170119 64041 caffe_interface.cpp:125] Batch 162, accuracy = 0.88
I0122 16:59:11.170128 64041 caffe_interface.cpp:125] Batch 162, loss = 0.526702
I0122 16:59:11.170132 64041 caffe_interface.cpp:125] Batch 162, top-1 = 0.88
I0122 16:59:11.170135 64041 caffe_interface.cpp:125] Batch 162, top-5 = 1
I0122 16:59:11.179144 64041 caffe_interface.cpp:125] Batch 163, accuracy = 0.94
I0122 16:59:11.179155 64041 caffe_interface.cpp:125] Batch 163, loss = 0.186522
I0122 16:59:11.179159 64041 caffe_interface.cpp:125] Batch 163, top-1 = 0.94
I0122 16:59:11.179162 64041 caffe_interface.cpp:125] Batch 163, top-5 = 1
I0122 16:59:11.189110 64041 caffe_interface.cpp:125] Batch 164, accuracy = 0.84
I0122 16:59:11.189121 64041 caffe_interface.cpp:125] Batch 164, loss = 0.359468
I0122 16:59:11.189124 64041 caffe_interface.cpp:125] Batch 164, top-1 = 0.84
I0122 16:59:11.189126 64041 caffe_interface.cpp:125] Batch 164, top-5 = 1
I0122 16:59:11.204818 64041 caffe_interface.cpp:125] Batch 165, accuracy = 0.88
I0122 16:59:11.204828 64041 caffe_interface.cpp:125] Batch 165, loss = 0.430336
I0122 16:59:11.204833 64041 caffe_interface.cpp:125] Batch 165, top-1 = 0.88
I0122 16:59:11.204835 64041 caffe_interface.cpp:125] Batch 165, top-5 = 0.98
I0122 16:59:11.244233 64041 caffe_interface.cpp:125] Batch 166, accuracy = 0.94
I0122 16:59:11.244242 64041 caffe_interface.cpp:125] Batch 166, loss = 0.210687
I0122 16:59:11.244246 64041 caffe_interface.cpp:125] Batch 166, top-1 = 0.94
I0122 16:59:11.244248 64041 caffe_interface.cpp:125] Batch 166, top-5 = 1
I0122 16:59:11.253603 64041 caffe_interface.cpp:125] Batch 167, accuracy = 0.88
I0122 16:59:11.253613 64041 caffe_interface.cpp:125] Batch 167, loss = 0.378716
I0122 16:59:11.253617 64041 caffe_interface.cpp:125] Batch 167, top-1 = 0.88
I0122 16:59:11.253619 64041 caffe_interface.cpp:125] Batch 167, top-5 = 0.98
I0122 16:59:11.261592 64041 caffe_interface.cpp:125] Batch 168, accuracy = 0.98
I0122 16:59:11.261602 64041 caffe_interface.cpp:125] Batch 168, loss = 0.148448
I0122 16:59:11.261606 64041 caffe_interface.cpp:125] Batch 168, top-1 = 0.98
I0122 16:59:11.261620 64041 caffe_interface.cpp:125] Batch 168, top-5 = 1
I0122 16:59:11.269866 64041 caffe_interface.cpp:125] Batch 169, accuracy = 0.88
I0122 16:59:11.269877 64041 caffe_interface.cpp:125] Batch 169, loss = 0.32872
I0122 16:59:11.269881 64041 caffe_interface.cpp:125] Batch 169, top-1 = 0.88
I0122 16:59:11.269884 64041 caffe_interface.cpp:125] Batch 169, top-5 = 1
I0122 16:59:11.277866 64041 caffe_interface.cpp:125] Batch 170, accuracy = 0.9
I0122 16:59:11.277878 64041 caffe_interface.cpp:125] Batch 170, loss = 0.270146
I0122 16:59:11.277881 64041 caffe_interface.cpp:125] Batch 170, top-1 = 0.9
I0122 16:59:11.277884 64041 caffe_interface.cpp:125] Batch 170, top-5 = 1
I0122 16:59:11.288353 64041 caffe_interface.cpp:125] Batch 171, accuracy = 0.9
I0122 16:59:11.288363 64041 caffe_interface.cpp:125] Batch 171, loss = 0.188352
I0122 16:59:11.288367 64041 caffe_interface.cpp:125] Batch 171, top-1 = 0.9
I0122 16:59:11.288369 64041 caffe_interface.cpp:125] Batch 171, top-5 = 1
I0122 16:59:11.304132 64041 caffe_interface.cpp:125] Batch 172, accuracy = 0.86
I0122 16:59:11.304141 64041 caffe_interface.cpp:125] Batch 172, loss = 0.437348
I0122 16:59:11.304144 64041 caffe_interface.cpp:125] Batch 172, top-1 = 0.86
I0122 16:59:11.304147 64041 caffe_interface.cpp:125] Batch 172, top-5 = 1
I0122 16:59:11.343621 64041 caffe_interface.cpp:125] Batch 173, accuracy = 0.92
I0122 16:59:11.343631 64041 caffe_interface.cpp:125] Batch 173, loss = 0.251402
I0122 16:59:11.343633 64041 caffe_interface.cpp:125] Batch 173, top-1 = 0.92
I0122 16:59:11.343645 64041 caffe_interface.cpp:125] Batch 173, top-5 = 1
I0122 16:59:11.353029 64041 caffe_interface.cpp:125] Batch 174, accuracy = 0.84
I0122 16:59:11.353039 64041 caffe_interface.cpp:125] Batch 174, loss = 0.398283
I0122 16:59:11.353042 64041 caffe_interface.cpp:125] Batch 174, top-1 = 0.84
I0122 16:59:11.353045 64041 caffe_interface.cpp:125] Batch 174, top-5 = 1
I0122 16:59:11.361059 64041 caffe_interface.cpp:125] Batch 175, accuracy = 0.88
I0122 16:59:11.361069 64041 caffe_interface.cpp:125] Batch 175, loss = 0.46234
I0122 16:59:11.361073 64041 caffe_interface.cpp:125] Batch 175, top-1 = 0.88
I0122 16:59:11.361076 64041 caffe_interface.cpp:125] Batch 175, top-5 = 1
I0122 16:59:11.369247 64041 caffe_interface.cpp:125] Batch 176, accuracy = 0.84
I0122 16:59:11.369257 64041 caffe_interface.cpp:125] Batch 176, loss = 0.760774
I0122 16:59:11.369261 64041 caffe_interface.cpp:125] Batch 176, top-1 = 0.84
I0122 16:59:11.369264 64041 caffe_interface.cpp:125] Batch 176, top-5 = 0.96
I0122 16:59:11.377218 64041 caffe_interface.cpp:125] Batch 177, accuracy = 0.86
I0122 16:59:11.377228 64041 caffe_interface.cpp:125] Batch 177, loss = 0.337022
I0122 16:59:11.377231 64041 caffe_interface.cpp:125] Batch 177, top-1 = 0.86
I0122 16:59:11.377234 64041 caffe_interface.cpp:125] Batch 177, top-5 = 1
I0122 16:59:11.388206 64041 caffe_interface.cpp:125] Batch 178, accuracy = 0.8
I0122 16:59:11.388214 64041 caffe_interface.cpp:125] Batch 178, loss = 0.520783
I0122 16:59:11.388217 64041 caffe_interface.cpp:125] Batch 178, top-1 = 0.8
I0122 16:59:11.388221 64041 caffe_interface.cpp:125] Batch 178, top-5 = 1
I0122 16:59:11.402361 64041 caffe_interface.cpp:125] Batch 179, accuracy = 0.88
I0122 16:59:11.402371 64041 caffe_interface.cpp:125] Batch 179, loss = 0.451741
I0122 16:59:11.402375 64041 caffe_interface.cpp:125] Batch 179, top-1 = 0.88
I0122 16:59:11.402379 64041 caffe_interface.cpp:125] Batch 179, top-5 = 1
I0122 16:59:11.402381 64041 caffe_interface.cpp:130] Loss: 0.337907
I0122 16:59:11.402384 64041 caffe_interface.cpp:142] accuracy = 0.897778
I0122 16:59:11.402391 64041 caffe_interface.cpp:142] loss = 0.337907 (* 1 = 0.337907 loss)
I0122 16:59:11.402395 64041 caffe_interface.cpp:142] top-1 = 0.897778
I0122 16:59:11.402400 64041 caffe_interface.cpp:142] top-5 = 0.996
I0122 16:59:11.577311 64041 pruning_runner.cpp:306] pruning done, output model: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/sparse.caffemodel
I0122 16:59:11.577334 64041 pruning_runner.cpp:320] summary of REGULAR compression with rate 0:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.897777736    | 0.897777736    | 0              |
+-------------------------------------------------------------------+
| Weights        | 1652899        | 1652899        | 0%             |
+-------------------------------------------------------------------+
| Operations     | 533938176      | 533938176      | 0%             |
+-------------------------------------------------------------------+
To fine-tune the compressed model, please run:
deephi_compress finetune -config cifar10/deephi/miniGoogleNet/pruning/config0.prototxt
# fine-tuning: zero run
$PRUNE_ROOT/deephi_compress finetune -config ${WORK_DIR}/config0.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_finetune0_miniGoogleNet.txt
I0122 16:59:11.823297 64218 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt
I0122 16:59:12.024067 64218 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 16:59:12.024616 64218 gpu_memory.cpp:55] Total memory: 25620447232, Free: 22988455936, dev_info[0]: total=25620447232 free=22988455936
I0122 16:59:12.024627 64218 caffe_interface.cpp:493] Using GPUs 0
I0122 16:59:12.024897 64218 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 16:59:12.778671 64218 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt"
type: "SGD"
I0122 16:59:12.778793 64218 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt
I0122 16:59:12.779477 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 16:59:12.779520 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 16:59:12.779525 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 16:59:12.779527 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 16:59:12.780129 64218 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 16:59:12.780447 64218 layer_factory.hpp:77] Creating layer data
I0122 16:59:12.780546 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.781373 64218 net.cpp:94] Creating Layer data
I0122 16:59:12.781383 64218 net.cpp:409] data -> data
I0122 16:59:12.781394 64218 net.cpp:409] data -> label
I0122 16:59:12.782855 64261 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 16:59:12.782902 64261 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 16:59:12.783011 64218 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 16:59:12.783097 64218 data_layer.cpp:83] output data size: 128,3,32,32
I0122 16:59:12.799222 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.799271 64218 net.cpp:144] Setting up data
I0122 16:59:12.799279 64218 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 16:59:12.799284 64218 net.cpp:151] Top shape: 128 (128)
I0122 16:59:12.799286 64218 net.cpp:159] Memory required for data: 1573376
I0122 16:59:12.799290 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 16:59:12.799304 64218 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 16:59:12.799307 64218 net.cpp:435] conv1/3x3_s1 <- data
I0122 16:59:12.799322 64218 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 16:59:12.801025 64218 net.cpp:144] Setting up conv1/3x3_s1
I0122 16:59:12.801044 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801048 64218 net.cpp:159] Memory required for data: 51905024
I0122 16:59:12.801064 64218 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 16:59:12.801074 64218 net.cpp:94] Creating Layer conv1/bn1
I0122 16:59:12.801079 64218 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 16:59:12.801085 64218 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.801731 64218 net.cpp:144] Setting up conv1/bn1
I0122 16:59:12.801739 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801743 64218 net.cpp:159] Memory required for data: 102236672
I0122 16:59:12.801754 64218 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 16:59:12.801761 64218 net.cpp:94] Creating Layer conv1/relu1
I0122 16:59:12.801764 64218 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 16:59:12.801769 64218 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.801780 64218 net.cpp:144] Setting up conv1/relu1
I0122 16:59:12.801796 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801800 64218 net.cpp:159] Memory required for data: 152568320
I0122 16:59:12.801802 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.801810 64218 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.801815 64218 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 16:59:12.801820 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.801827 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.801858 64218 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.801863 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801867 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801870 64218 net.cpp:159] Memory required for data: 253231616
I0122 16:59:12.801873 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 16:59:12.801882 64218 net.cpp:94] Creating Layer inception_2a/1x1
I0122 16:59:12.801887 64218 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.801892 64218 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 16:59:12.802145 64218 net.cpp:144] Setting up inception_2a/1x1
I0122 16:59:12.802152 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.802155 64218 net.cpp:159] Memory required for data: 270008832
I0122 16:59:12.802162 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 16:59:12.802170 64218 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 16:59:12.802173 64218 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 16:59:12.802179 64218 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.803603 64218 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 16:59:12.803611 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.803614 64218 net.cpp:159] Memory required for data: 286786048
I0122 16:59:12.803622 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 16:59:12.803627 64218 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 16:59:12.803632 64218 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 16:59:12.803637 64218 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.803642 64218 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 16:59:12.803647 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.803649 64218 net.cpp:159] Memory required for data: 303563264
I0122 16:59:12.803652 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 16:59:12.803661 64218 net.cpp:94] Creating Layer inception_2a/3x3
I0122 16:59:12.803665 64218 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.803670 64218 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 16:59:12.806650 64218 net.cpp:144] Setting up inception_2a/3x3
I0122 16:59:12.806664 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.806668 64218 net.cpp:159] Memory required for data: 320340480
I0122 16:59:12.806674 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 16:59:12.806695 64218 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 16:59:12.806701 64218 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 16:59:12.806716 64218 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.807451 64218 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 16:59:12.807459 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.807462 64218 net.cpp:159] Memory required for data: 337117696
I0122 16:59:12.807476 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 16:59:12.807482 64218 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 16:59:12.807485 64218 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 16:59:12.807492 64218 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.807512 64218 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 16:59:12.807516 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.807519 64218 net.cpp:159] Memory required for data: 353894912
I0122 16:59:12.807523 64218 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 16:59:12.807528 64218 net.cpp:94] Creating Layer inception_2a/output
I0122 16:59:12.807535 64218 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 16:59:12.807539 64218 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 16:59:12.807546 64218 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 16:59:12.807566 64218 net.cpp:144] Setting up inception_2a/output
I0122 16:59:12.807572 64218 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 16:59:12.807575 64218 net.cpp:159] Memory required for data: 387449344
I0122 16:59:12.807577 64218 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.807584 64218 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.807587 64218 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 16:59:12.807593 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.807601 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.807631 64218 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.807637 64218 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 16:59:12.807642 64218 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 16:59:12.807644 64218 net.cpp:159] Memory required for data: 454558208
I0122 16:59:12.807647 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 16:59:12.807657 64218 net.cpp:94] Creating Layer inception_3a/1x1
I0122 16:59:12.807658 64218 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.807665 64218 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 16:59:12.807904 64218 net.cpp:144] Setting up inception_3a/1x1
I0122 16:59:12.807911 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.807920 64218 net.cpp:159] Memory required for data: 471335424
I0122 16:59:12.807925 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 16:59:12.807934 64218 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 16:59:12.807936 64218 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 16:59:12.807943 64218 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.808595 64218 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 16:59:12.808603 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.808605 64218 net.cpp:159] Memory required for data: 488112640
I0122 16:59:12.808614 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 16:59:12.808620 64218 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 16:59:12.808622 64218 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 16:59:12.808630 64218 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.808636 64218 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 16:59:12.808642 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.808645 64218 net.cpp:159] Memory required for data: 504889856
I0122 16:59:12.808650 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 16:59:12.808660 64218 net.cpp:94] Creating Layer inception_3a/3x3
I0122 16:59:12.808665 64218 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.808670 64218 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 16:59:12.809062 64218 net.cpp:144] Setting up inception_3a/3x3
I0122 16:59:12.809068 64218 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 16:59:12.809072 64218 net.cpp:159] Memory required for data: 530055680
I0122 16:59:12.809077 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 16:59:12.809093 64218 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 16:59:12.809098 64218 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 16:59:12.809103 64218 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.810029 64218 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 16:59:12.810039 64218 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 16:59:12.810041 64218 net.cpp:159] Memory required for data: 555221504
I0122 16:59:12.810055 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 16:59:12.810060 64218 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 16:59:12.810065 64218 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 16:59:12.810072 64218 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.810081 64218 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 16:59:12.810084 64218 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 16:59:12.810087 64218 net.cpp:159] Memory required for data: 580387328
I0122 16:59:12.810091 64218 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 16:59:12.810096 64218 net.cpp:94] Creating Layer inception_3a/output
I0122 16:59:12.810097 64218 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 16:59:12.810108 64218 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 16:59:12.810114 64218 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 16:59:12.810133 64218 net.cpp:144] Setting up inception_3a/output
I0122 16:59:12.810142 64218 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 16:59:12.810147 64218 net.cpp:159] Memory required for data: 622330368
I0122 16:59:12.810148 64218 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.810154 64218 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.810158 64218 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 16:59:12.810164 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.810171 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.810197 64218 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.810206 64218 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 16:59:12.810210 64218 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 16:59:12.810212 64218 net.cpp:159] Memory required for data: 706216448
I0122 16:59:12.810215 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 16:59:12.810225 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 16:59:12.810228 64218 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.810235 64218 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 16:59:12.810788 64218 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 16:59:12.810796 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.810799 64218 net.cpp:159] Memory required for data: 716702208
I0122 16:59:12.810804 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 16:59:12.810814 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 16:59:12.810817 64218 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 16:59:12.810824 64218 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.811467 64218 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 16:59:12.811475 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.811477 64218 net.cpp:159] Memory required for data: 727187968
I0122 16:59:12.811486 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 16:59:12.811491 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 16:59:12.811493 64218 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 16:59:12.811511 64218 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.811519 64218 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 16:59:12.811522 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.811525 64218 net.cpp:159] Memory required for data: 737673728
I0122 16:59:12.811528 64218 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 16:59:12.811535 64218 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 16:59:12.811538 64218 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.811545 64218 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 16:59:12.811585 64218 net.cpp:144] Setting up downsample_4/pool_s2
I0122 16:59:12.811591 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.811595 64218 net.cpp:159] Memory required for data: 748159488
I0122 16:59:12.811599 64218 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 16:59:12.811605 64218 net.cpp:94] Creating Layer downsample_4/output
I0122 16:59:12.811609 64218 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 16:59:12.811612 64218 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 16:59:12.811616 64218 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 16:59:12.811635 64218 net.cpp:144] Setting up downsample_4/output
I0122 16:59:12.811640 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.811643 64218 net.cpp:159] Memory required for data: 769131008
I0122 16:59:12.811645 64218 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.811650 64218 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.811655 64218 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 16:59:12.811659 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.811666 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.811722 64218 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.811729 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.811733 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.811735 64218 net.cpp:159] Memory required for data: 811074048
I0122 16:59:12.811738 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 16:59:12.811748 64218 net.cpp:94] Creating Layer inception_5a/1x1
I0122 16:59:12.811754 64218 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.811759 64218 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 16:59:12.812187 64218 net.cpp:144] Setting up inception_5a/1x1
I0122 16:59:12.812196 64218 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 16:59:12.812198 64218 net.cpp:159] Memory required for data: 825754112
I0122 16:59:12.812203 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 16:59:12.812211 64218 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 16:59:12.812216 64218 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 16:59:12.812222 64218 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.812902 64218 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 16:59:12.812909 64218 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 16:59:12.812913 64218 net.cpp:159] Memory required for data: 840434176
I0122 16:59:12.812921 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 16:59:12.812927 64218 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 16:59:12.812929 64218 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 16:59:12.812934 64218 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.812940 64218 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 16:59:12.812944 64218 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 16:59:12.812955 64218 net.cpp:159] Memory required for data: 855114240
I0122 16:59:12.812959 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 16:59:12.812970 64218 net.cpp:94] Creating Layer inception_5a/3x3
I0122 16:59:12.812975 64218 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.812981 64218 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 16:59:12.813623 64218 net.cpp:144] Setting up inception_5a/3x3
I0122 16:59:12.813632 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.813634 64218 net.cpp:159] Memory required for data: 861405696
I0122 16:59:12.813639 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 16:59:12.813647 64218 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 16:59:12.813650 64218 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 16:59:12.813657 64218 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.814419 64218 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 16:59:12.814426 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.814436 64218 net.cpp:159] Memory required for data: 867697152
I0122 16:59:12.814445 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 16:59:12.814455 64218 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 16:59:12.814461 64218 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 16:59:12.814466 64218 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.814472 64218 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 16:59:12.814476 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.814479 64218 net.cpp:159] Memory required for data: 873988608
I0122 16:59:12.814482 64218 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 16:59:12.814486 64218 net.cpp:94] Creating Layer inception_5a/output
I0122 16:59:12.814489 64218 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 16:59:12.814493 64218 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 16:59:12.814498 64218 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 16:59:12.814620 64218 net.cpp:144] Setting up inception_5a/output
I0122 16:59:12.814626 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.814630 64218 net.cpp:159] Memory required for data: 894960128
I0122 16:59:12.814631 64218 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.814638 64218 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.814641 64218 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 16:59:12.814652 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.814658 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.814695 64218 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.814702 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.814707 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.814709 64218 net.cpp:159] Memory required for data: 936903168
I0122 16:59:12.814713 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 16:59:12.814723 64218 net.cpp:94] Creating Layer inception_6a/1x1
I0122 16:59:12.814734 64218 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.814740 64218 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 16:59:12.815892 64218 net.cpp:144] Setting up inception_6a/1x1
I0122 16:59:12.815904 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.815907 64218 net.cpp:159] Memory required for data: 949486080
I0122 16:59:12.815913 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 16:59:12.815922 64218 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 16:59:12.815937 64218 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 16:59:12.815946 64218 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.816663 64218 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 16:59:12.816670 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.816673 64218 net.cpp:159] Memory required for data: 962068992
I0122 16:59:12.816681 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 16:59:12.816686 64218 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 16:59:12.816689 64218 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 16:59:12.816695 64218 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.816704 64218 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 16:59:12.816709 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.816711 64218 net.cpp:159] Memory required for data: 974651904
I0122 16:59:12.816715 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 16:59:12.816725 64218 net.cpp:94] Creating Layer inception_6a/3x3
I0122 16:59:12.816730 64218 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.816736 64218 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 16:59:12.817507 64218 net.cpp:144] Setting up inception_6a/3x3
I0122 16:59:12.817517 64218 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:59:12.817520 64218 net.cpp:159] Memory required for data: 983040512
I0122 16:59:12.817533 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 16:59:12.817543 64218 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 16:59:12.817549 64218 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 16:59:12.817556 64218 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.818243 64218 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 16:59:12.818250 64218 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:59:12.818254 64218 net.cpp:159] Memory required for data: 991429120
I0122 16:59:12.818262 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 16:59:12.818267 64218 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 16:59:12.818270 64218 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 16:59:12.818276 64218 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.818282 64218 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 16:59:12.818285 64218 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:59:12.818289 64218 net.cpp:159] Memory required for data: 999817728
I0122 16:59:12.818292 64218 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 16:59:12.818297 64218 net.cpp:94] Creating Layer inception_6a/output
I0122 16:59:12.818301 64218 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 16:59:12.818305 64218 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 16:59:12.818310 64218 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 16:59:12.818329 64218 net.cpp:144] Setting up inception_6a/output
I0122 16:59:12.818336 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.818339 64218 net.cpp:159] Memory required for data: 1020789248
I0122 16:59:12.818342 64218 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.818349 64218 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.818354 64218 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 16:59:12.818361 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.818367 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.818394 64218 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.818401 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.818418 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.818420 64218 net.cpp:159] Memory required for data: 1062732288
I0122 16:59:12.818423 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 16:59:12.818433 64218 net.cpp:94] Creating Layer inception_7a/1x1
I0122 16:59:12.818439 64218 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.818445 64218 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 16:59:12.818769 64218 net.cpp:144] Setting up inception_7a/1x1
I0122 16:59:12.818775 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.818778 64218 net.cpp:159] Memory required for data: 1073218048
I0122 16:59:12.818784 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 16:59:12.818791 64218 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 16:59:12.818794 64218 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 16:59:12.818800 64218 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.819571 64218 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 16:59:12.819577 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.819581 64218 net.cpp:159] Memory required for data: 1083703808
I0122 16:59:12.819587 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 16:59:12.819595 64218 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 16:59:12.819598 64218 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 16:59:12.819603 64218 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.819614 64218 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 16:59:12.819620 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.819622 64218 net.cpp:159] Memory required for data: 1094189568
I0122 16:59:12.819627 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 16:59:12.819636 64218 net.cpp:94] Creating Layer inception_7a/3x3
I0122 16:59:12.819641 64218 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.819648 64218 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 16:59:12.820673 64218 net.cpp:144] Setting up inception_7a/3x3
I0122 16:59:12.820683 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.820686 64218 net.cpp:159] Memory required for data: 1104675328
I0122 16:59:12.820693 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 16:59:12.820701 64218 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 16:59:12.820704 64218 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 16:59:12.820713 64218 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.821383 64218 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 16:59:12.821390 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.821394 64218 net.cpp:159] Memory required for data: 1115161088
I0122 16:59:12.821403 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 16:59:12.821408 64218 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 16:59:12.821410 64218 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 16:59:12.821416 64218 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.821424 64218 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 16:59:12.821430 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.821434 64218 net.cpp:159] Memory required for data: 1125646848
I0122 16:59:12.821435 64218 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 16:59:12.821441 64218 net.cpp:94] Creating Layer inception_7a/output
I0122 16:59:12.821444 64218 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 16:59:12.821447 64218 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 16:59:12.821454 64218 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 16:59:12.821475 64218 net.cpp:144] Setting up inception_7a/output
I0122 16:59:12.821482 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.821494 64218 net.cpp:159] Memory required for data: 1146618368
I0122 16:59:12.821496 64218 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.821503 64218 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.821506 64218 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 16:59:12.821512 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.821518 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.821555 64218 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.821560 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.821563 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.821566 64218 net.cpp:159] Memory required for data: 1188561408
I0122 16:59:12.821569 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 16:59:12.821578 64218 net.cpp:94] Creating Layer inception_8a/1x1
I0122 16:59:12.821581 64218 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.821588 64218 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 16:59:12.822021 64218 net.cpp:144] Setting up inception_8a/1x1
I0122 16:59:12.822027 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.822031 64218 net.cpp:159] Memory required for data: 1194852864
I0122 16:59:12.822036 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 16:59:12.822043 64218 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 16:59:12.822048 64218 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 16:59:12.822054 64218 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.822726 64218 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 16:59:12.822733 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.822736 64218 net.cpp:159] Memory required for data: 1201144320
I0122 16:59:12.822743 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 16:59:12.822748 64218 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 16:59:12.822751 64218 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 16:59:12.822757 64218 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.822765 64218 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 16:59:12.822768 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.822772 64218 net.cpp:159] Memory required for data: 1207435776
I0122 16:59:12.822774 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 16:59:12.822782 64218 net.cpp:94] Creating Layer inception_8a/3x3
I0122 16:59:12.822788 64218 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.822794 64218 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 16:59:12.824553 64218 net.cpp:144] Setting up inception_8a/3x3
I0122 16:59:12.824566 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.824569 64218 net.cpp:159] Memory required for data: 1220018688
I0122 16:59:12.824586 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 16:59:12.824599 64218 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 16:59:12.824604 64218 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 16:59:12.824609 64218 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.825291 64218 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 16:59:12.825297 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.825300 64218 net.cpp:159] Memory required for data: 1232601600
I0122 16:59:12.825309 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 16:59:12.825315 64218 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 16:59:12.825320 64218 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 16:59:12.825340 64218 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.825346 64218 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 16:59:12.825350 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.825353 64218 net.cpp:159] Memory required for data: 1245184512
I0122 16:59:12.825356 64218 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 16:59:12.825362 64218 net.cpp:94] Creating Layer inception_8a/output
I0122 16:59:12.825368 64218 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 16:59:12.825371 64218 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 16:59:12.825376 64218 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 16:59:12.825397 64218 net.cpp:144] Setting up inception_8a/output
I0122 16:59:12.825402 64218 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 16:59:12.825405 64218 net.cpp:159] Memory required for data: 1264058880
I0122 16:59:12.825407 64218 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.825413 64218 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.825418 64218 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 16:59:12.825423 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.825429 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.825459 64218 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.825465 64218 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 16:59:12.825469 64218 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 16:59:12.825471 64218 net.cpp:159] Memory required for data: 1301807616
I0122 16:59:12.825475 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 16:59:12.825485 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 16:59:12.825490 64218 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.825496 64218 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 16:59:12.826444 64218 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 16:59:12.826455 64218 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 16:59:12.826457 64218 net.cpp:159] Memory required for data: 1304953344
I0122 16:59:12.826463 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 16:59:12.826470 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 16:59:12.826476 64218 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 16:59:12.826484 64218 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.827173 64218 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 16:59:12.827180 64218 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 16:59:12.827183 64218 net.cpp:159] Memory required for data: 1308099072
I0122 16:59:12.827191 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 16:59:12.827198 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 16:59:12.827200 64218 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 16:59:12.827209 64218 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.827215 64218 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 16:59:12.827221 64218 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 16:59:12.827224 64218 net.cpp:159] Memory required for data: 1311244800
I0122 16:59:12.827226 64218 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 16:59:12.827234 64218 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 16:59:12.827239 64218 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.827244 64218 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 16:59:12.827275 64218 net.cpp:144] Setting up downsample_9/pool_s2
I0122 16:59:12.827291 64218 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 16:59:12.827293 64218 net.cpp:159] Memory required for data: 1315963392
I0122 16:59:12.827296 64218 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 16:59:12.827301 64218 net.cpp:94] Creating Layer downsample_9/output
I0122 16:59:12.827304 64218 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 16:59:12.827307 64218 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 16:59:12.827314 64218 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 16:59:12.827333 64218 net.cpp:144] Setting up downsample_9/output
I0122 16:59:12.827338 64218 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 16:59:12.827342 64218 net.cpp:159] Memory required for data: 1323827712
I0122 16:59:12.827343 64218 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.827353 64218 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.827358 64218 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 16:59:12.827363 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.827368 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.827397 64218 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.827402 64218 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 16:59:12.827406 64218 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 16:59:12.827409 64218 net.cpp:159] Memory required for data: 1339556352
I0122 16:59:12.827412 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 16:59:12.827421 64218 net.cpp:94] Creating Layer inception_10a/1x1
I0122 16:59:12.827425 64218 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.827432 64218 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 16:59:12.827898 64218 net.cpp:144] Setting up inception_10a/1x1
I0122 16:59:12.827904 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.827908 64218 net.cpp:159] Memory required for data: 1345323520
I0122 16:59:12.827913 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 16:59:12.827920 64218 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 16:59:12.827925 64218 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 16:59:12.827931 64218 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.828604 64218 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 16:59:12.828611 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.828614 64218 net.cpp:159] Memory required for data: 1351090688
I0122 16:59:12.828622 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 16:59:12.828641 64218 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 16:59:12.828647 64218 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 16:59:12.828652 64218 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.828658 64218 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 16:59:12.828662 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.828665 64218 net.cpp:159] Memory required for data: 1356857856
I0122 16:59:12.828667 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 16:59:12.828678 64218 net.cpp:94] Creating Layer inception_10a/3x3
I0122 16:59:12.828683 64218 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.828689 64218 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 16:59:12.831926 64218 net.cpp:144] Setting up inception_10a/3x3
I0122 16:59:12.831938 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.831941 64218 net.cpp:159] Memory required for data: 1362100736
I0122 16:59:12.831948 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 16:59:12.831982 64218 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 16:59:12.831987 64218 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 16:59:12.831995 64218 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.832643 64218 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 16:59:12.832650 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.832653 64218 net.cpp:159] Memory required for data: 1367343616
I0122 16:59:12.832660 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 16:59:12.832669 64218 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 16:59:12.832671 64218 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 16:59:12.832675 64218 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.832684 64218 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 16:59:12.832691 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.832693 64218 net.cpp:159] Memory required for data: 1372586496
I0122 16:59:12.832696 64218 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 16:59:12.832700 64218 net.cpp:94] Creating Layer inception_10a/output
I0122 16:59:12.832705 64218 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 16:59:12.832708 64218 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 16:59:12.832715 64218 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 16:59:12.832734 64218 net.cpp:144] Setting up inception_10a/output
I0122 16:59:12.832741 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.832743 64218 net.cpp:159] Memory required for data: 1383596544
I0122 16:59:12.832746 64218 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.832751 64218 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.832756 64218 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 16:59:12.832762 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.832768 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.832796 64218 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.832803 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.832806 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.832809 64218 net.cpp:159] Memory required for data: 1405616640
I0122 16:59:12.832811 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 16:59:12.832820 64218 net.cpp:94] Creating Layer inception_11a/1x1
I0122 16:59:12.832824 64218 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.832830 64218 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 16:59:12.833395 64218 net.cpp:144] Setting up inception_11a/1x1
I0122 16:59:12.833403 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.833406 64218 net.cpp:159] Memory required for data: 1411383808
I0122 16:59:12.833411 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 16:59:12.833418 64218 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 16:59:12.833425 64218 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 16:59:12.833431 64218 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.834120 64218 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 16:59:12.834128 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.834132 64218 net.cpp:159] Memory required for data: 1417150976
I0122 16:59:12.834139 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 16:59:12.834146 64218 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 16:59:12.834149 64218 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 16:59:12.834154 64218 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.834172 64218 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 16:59:12.834177 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.834179 64218 net.cpp:159] Memory required for data: 1422918144
I0122 16:59:12.834183 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 16:59:12.834193 64218 net.cpp:94] Creating Layer inception_11a/3x3
I0122 16:59:12.834197 64218 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.834203 64218 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 16:59:12.837958 64218 net.cpp:144] Setting up inception_11a/3x3
I0122 16:59:12.837970 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.837973 64218 net.cpp:159] Memory required for data: 1428161024
I0122 16:59:12.837978 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 16:59:12.837988 64218 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 16:59:12.837991 64218 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 16:59:12.837997 64218 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.838650 64218 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 16:59:12.838659 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.838661 64218 net.cpp:159] Memory required for data: 1433403904
I0122 16:59:12.838680 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 16:59:12.838686 64218 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 16:59:12.838690 64218 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 16:59:12.838696 64218 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.838702 64218 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 16:59:12.838708 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.838711 64218 net.cpp:159] Memory required for data: 1438646784
I0122 16:59:12.838714 64218 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 16:59:12.838718 64218 net.cpp:94] Creating Layer inception_11a/output
I0122 16:59:12.838721 64218 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 16:59:12.838726 64218 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 16:59:12.838730 64218 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 16:59:12.838747 64218 net.cpp:144] Setting up inception_11a/output
I0122 16:59:12.838753 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.838757 64218 net.cpp:159] Memory required for data: 1449656832
I0122 16:59:12.838759 64218 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 16:59:12.838764 64218 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 16:59:12.838768 64218 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 16:59:12.838773 64218 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 16:59:12.838798 64218 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 16:59:12.838804 64218 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 16:59:12.838806 64218 net.cpp:159] Memory required for data: 1449828864
I0122 16:59:12.838809 64218 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 16:59:12.838814 64218 net.cpp:94] Creating Layer drop_8x8_s1
I0122 16:59:12.838816 64218 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 16:59:12.838821 64218 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 16:59:12.838840 64218 net.cpp:144] Setting up drop_8x8_s1
I0122 16:59:12.838845 64218 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 16:59:12.838846 64218 net.cpp:159] Memory required for data: 1450000896
I0122 16:59:12.838848 64218 layer_factory.hpp:77] Creating layer loss/classifier
I0122 16:59:12.838856 64218 net.cpp:94] Creating Layer loss/classifier
I0122 16:59:12.838860 64218 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 16:59:12.838865 64218 net.cpp:409] loss/classifier -> loss/classifier
I0122 16:59:12.839001 64218 net.cpp:144] Setting up loss/classifier
I0122 16:59:12.839016 64218 net.cpp:151] Top shape: 128 10 (1280)
I0122 16:59:12.839020 64218 net.cpp:159] Memory required for data: 1450006016
I0122 16:59:12.839025 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.839030 64218 net.cpp:94] Creating Layer loss
I0122 16:59:12.839032 64218 net.cpp:435] loss <- loss/classifier
I0122 16:59:12.839036 64218 net.cpp:435] loss <- label
I0122 16:59:12.839040 64218 net.cpp:409] loss -> loss
I0122 16:59:12.839049 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.839125 64218 net.cpp:144] Setting up loss
I0122 16:59:12.839130 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.839133 64218 net.cpp:154]     with loss weight 1
I0122 16:59:12.839143 64218 net.cpp:159] Memory required for data: 1450006020
I0122 16:59:12.839145 64218 net.cpp:220] loss needs backward computation.
I0122 16:59:12.839154 64218 net.cpp:220] loss/classifier needs backward computation.
I0122 16:59:12.839157 64218 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 16:59:12.839159 64218 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 16:59:12.839164 64218 net.cpp:220] inception_11a/output needs backward computation.
I0122 16:59:12.839167 64218 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 16:59:12.839169 64218 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 16:59:12.839172 64218 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 16:59:12.839175 64218 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 16:59:12.839179 64218 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 16:59:12.839181 64218 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 16:59:12.839184 64218 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 16:59:12.839190 64218 net.cpp:220] inception_10a/output needs backward computation.
I0122 16:59:12.839192 64218 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 16:59:12.839195 64218 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 16:59:12.839197 64218 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 16:59:12.839201 64218 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 16:59:12.839203 64218 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 16:59:12.839206 64218 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 16:59:12.839210 64218 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 16:59:12.839213 64218 net.cpp:220] downsample_9/output needs backward computation.
I0122 16:59:12.839216 64218 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 16:59:12.839220 64218 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.839222 64218 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.839226 64218 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 16:59:12.839229 64218 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 16:59:12.839232 64218 net.cpp:220] inception_8a/output needs backward computation.
I0122 16:59:12.839236 64218 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 16:59:12.839239 64218 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 16:59:12.839242 64218 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 16:59:12.839246 64218 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 16:59:12.839248 64218 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 16:59:12.839251 64218 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 16:59:12.839256 64218 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 16:59:12.839259 64218 net.cpp:220] inception_7a/output needs backward computation.
I0122 16:59:12.839262 64218 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 16:59:12.839272 64218 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 16:59:12.839274 64218 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 16:59:12.839277 64218 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 16:59:12.839280 64218 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 16:59:12.839284 64218 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 16:59:12.839287 64218 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 16:59:12.839291 64218 net.cpp:220] inception_6a/output needs backward computation.
I0122 16:59:12.839294 64218 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 16:59:12.839298 64218 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 16:59:12.839301 64218 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 16:59:12.839304 64218 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 16:59:12.839306 64218 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 16:59:12.839310 64218 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 16:59:12.839313 64218 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 16:59:12.839316 64218 net.cpp:220] inception_5a/output needs backward computation.
I0122 16:59:12.839319 64218 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 16:59:12.839323 64218 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 16:59:12.839326 64218 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 16:59:12.839329 64218 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 16:59:12.839332 64218 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 16:59:12.839335 64218 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 16:59:12.839339 64218 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 16:59:12.839342 64218 net.cpp:220] downsample_4/output needs backward computation.
I0122 16:59:12.839346 64218 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 16:59:12.839351 64218 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.839354 64218 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.839357 64218 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 16:59:12.839360 64218 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 16:59:12.839365 64218 net.cpp:220] inception_3a/output needs backward computation.
I0122 16:59:12.839368 64218 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 16:59:12.839371 64218 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 16:59:12.839375 64218 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 16:59:12.839378 64218 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 16:59:12.839381 64218 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 16:59:12.839383 64218 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 16:59:12.839386 64218 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 16:59:12.839390 64218 net.cpp:220] inception_2a/output needs backward computation.
I0122 16:59:12.839395 64218 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 16:59:12.839396 64218 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 16:59:12.839399 64218 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 16:59:12.839403 64218 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 16:59:12.839406 64218 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 16:59:12.839408 64218 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 16:59:12.839411 64218 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 16:59:12.839421 64218 net.cpp:220] conv1/relu1 needs backward computation.
I0122 16:59:12.839423 64218 net.cpp:220] conv1/bn1 needs backward computation.
I0122 16:59:12.839426 64218 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 16:59:12.839429 64218 net.cpp:222] data does not need backward computation.
I0122 16:59:12.839433 64218 net.cpp:264] This network produces output loss
I0122 16:59:12.839498 64218 net.cpp:284] Network initialization done.
I0122 16:59:12.840369 64218 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt
I0122 16:59:12.840448 64218 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 16:59:12.841073 64218 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 16:59:12.841380 64218 layer_factory.hpp:77] Creating layer data
I0122 16:59:12.841423 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.842232 64218 net.cpp:94] Creating Layer data
I0122 16:59:12.842248 64218 net.cpp:409] data -> data
I0122 16:59:12.842257 64218 net.cpp:409] data -> label
I0122 16:59:12.843333 64291 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 16:59:12.843369 64291 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 16:59:12.843453 64218 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 16:59:12.843559 64218 data_layer.cpp:83] output data size: 50,3,32,32
I0122 16:59:12.846608 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.846649 64218 net.cpp:144] Setting up data
I0122 16:59:12.846658 64218 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 16:59:12.846662 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846665 64218 net.cpp:159] Memory required for data: 614600
I0122 16:59:12.846670 64218 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 16:59:12.846679 64218 net.cpp:94] Creating Layer label_data_1_split
I0122 16:59:12.846685 64218 net.cpp:435] label_data_1_split <- label
I0122 16:59:12.846691 64218 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 16:59:12.846698 64218 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 16:59:12.846707 64218 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 16:59:12.846714 64218 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 16:59:12.846832 64218 net.cpp:144] Setting up label_data_1_split
I0122 16:59:12.846838 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846843 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846845 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846848 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846851 64218 net.cpp:159] Memory required for data: 615400
I0122 16:59:12.846854 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 16:59:12.846864 64218 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 16:59:12.846868 64218 net.cpp:435] conv1/3x3_s1 <- data
I0122 16:59:12.846875 64218 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 16:59:12.847229 64218 net.cpp:144] Setting up conv1/3x3_s1
I0122 16:59:12.847236 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.847239 64218 net.cpp:159] Memory required for data: 20276200
I0122 16:59:12.847247 64218 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 16:59:12.847256 64218 net.cpp:94] Creating Layer conv1/bn1
I0122 16:59:12.847259 64218 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 16:59:12.847275 64218 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.847965 64218 net.cpp:144] Setting up conv1/bn1
I0122 16:59:12.847971 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.847975 64218 net.cpp:159] Memory required for data: 39937000
I0122 16:59:12.847985 64218 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 16:59:12.847992 64218 net.cpp:94] Creating Layer conv1/relu1
I0122 16:59:12.847996 64218 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 16:59:12.848001 64218 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.848006 64218 net.cpp:144] Setting up conv1/relu1
I0122 16:59:12.848011 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.848013 64218 net.cpp:159] Memory required for data: 59597800
I0122 16:59:12.848016 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.848021 64218 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.848023 64218 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 16:59:12.848029 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.848035 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.848067 64218 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.848071 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.848076 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.848078 64218 net.cpp:159] Memory required for data: 98919400
I0122 16:59:12.848080 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 16:59:12.848088 64218 net.cpp:94] Creating Layer inception_2a/1x1
I0122 16:59:12.848093 64218 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.848100 64218 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 16:59:12.848708 64218 net.cpp:144] Setting up inception_2a/1x1
I0122 16:59:12.848714 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.848717 64218 net.cpp:159] Memory required for data: 105473000
I0122 16:59:12.848724 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 16:59:12.848734 64218 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 16:59:12.848738 64218 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 16:59:12.848745 64218 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.849553 64218 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 16:59:12.849560 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.849562 64218 net.cpp:159] Memory required for data: 112026600
I0122 16:59:12.849570 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 16:59:12.849577 64218 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 16:59:12.849581 64218 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 16:59:12.849587 64218 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.849593 64218 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 16:59:12.849596 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.849599 64218 net.cpp:159] Memory required for data: 118580200
I0122 16:59:12.849602 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 16:59:12.849611 64218 net.cpp:94] Creating Layer inception_2a/3x3
I0122 16:59:12.849617 64218 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.849622 64218 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 16:59:12.850091 64218 net.cpp:144] Setting up inception_2a/3x3
I0122 16:59:12.850113 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.850116 64218 net.cpp:159] Memory required for data: 125133800
I0122 16:59:12.850121 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 16:59:12.850127 64218 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 16:59:12.850134 64218 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 16:59:12.850152 64218 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.850898 64218 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 16:59:12.850904 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.850908 64218 net.cpp:159] Memory required for data: 131687400
I0122 16:59:12.850919 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 16:59:12.850927 64218 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 16:59:12.850930 64218 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 16:59:12.850935 64218 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.850942 64218 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 16:59:12.850946 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.850949 64218 net.cpp:159] Memory required for data: 138241000
I0122 16:59:12.850952 64218 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 16:59:12.850957 64218 net.cpp:94] Creating Layer inception_2a/output
I0122 16:59:12.850962 64218 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 16:59:12.850965 64218 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 16:59:12.850971 64218 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 16:59:12.851008 64218 net.cpp:144] Setting up inception_2a/output
I0122 16:59:12.851016 64218 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:12.851018 64218 net.cpp:159] Memory required for data: 151348200
I0122 16:59:12.851022 64218 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.851027 64218 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.851029 64218 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 16:59:12.851035 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.851042 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.851076 64218 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.851083 64218 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:12.851085 64218 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:12.851089 64218 net.cpp:159] Memory required for data: 177562600
I0122 16:59:12.851091 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 16:59:12.851099 64218 net.cpp:94] Creating Layer inception_3a/1x1
I0122 16:59:12.851104 64218 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.851110 64218 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 16:59:12.851418 64218 net.cpp:144] Setting up inception_3a/1x1
I0122 16:59:12.851425 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.851428 64218 net.cpp:159] Memory required for data: 184116200
I0122 16:59:12.851433 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 16:59:12.851441 64218 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 16:59:12.851444 64218 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 16:59:12.851451 64218 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.852210 64218 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 16:59:12.852216 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.852219 64218 net.cpp:159] Memory required for data: 190669800
I0122 16:59:12.852226 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 16:59:12.852234 64218 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 16:59:12.852237 64218 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 16:59:12.852242 64218 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.852249 64218 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 16:59:12.852253 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.852255 64218 net.cpp:159] Memory required for data: 197223400
I0122 16:59:12.852267 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 16:59:12.852278 64218 net.cpp:94] Creating Layer inception_3a/3x3
I0122 16:59:12.852283 64218 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.852289 64218 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 16:59:12.853443 64218 net.cpp:144] Setting up inception_3a/3x3
I0122 16:59:12.853456 64218 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:12.853459 64218 net.cpp:159] Memory required for data: 207053800
I0122 16:59:12.853466 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 16:59:12.853474 64218 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 16:59:12.853480 64218 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 16:59:12.853490 64218 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.854287 64218 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 16:59:12.854295 64218 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:12.854297 64218 net.cpp:159] Memory required for data: 216884200
I0122 16:59:12.854311 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 16:59:12.854319 64218 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 16:59:12.854323 64218 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 16:59:12.854329 64218 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.854338 64218 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 16:59:12.854342 64218 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:12.854346 64218 net.cpp:159] Memory required for data: 226714600
I0122 16:59:12.854348 64218 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 16:59:12.854353 64218 net.cpp:94] Creating Layer inception_3a/output
I0122 16:59:12.854357 64218 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 16:59:12.854360 64218 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 16:59:12.854365 64218 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 16:59:12.854449 64218 net.cpp:144] Setting up inception_3a/output
I0122 16:59:12.854454 64218 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:12.854456 64218 net.cpp:159] Memory required for data: 243098600
I0122 16:59:12.854460 64218 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.854465 64218 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.854470 64218 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 16:59:12.854475 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.854482 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.854521 64218 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.854527 64218 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:12.854530 64218 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:12.854533 64218 net.cpp:159] Memory required for data: 275866600
I0122 16:59:12.854537 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 16:59:12.854545 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 16:59:12.854548 64218 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.854557 64218 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 16:59:12.855120 64218 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 16:59:12.855129 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.855131 64218 net.cpp:159] Memory required for data: 279962600
I0122 16:59:12.855136 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 16:59:12.855147 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 16:59:12.855150 64218 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 16:59:12.855167 64218 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.855990 64218 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 16:59:12.855998 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.856000 64218 net.cpp:159] Memory required for data: 284058600
I0122 16:59:12.856009 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 16:59:12.856015 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 16:59:12.856019 64218 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 16:59:12.856024 64218 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.856031 64218 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 16:59:12.856036 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.856040 64218 net.cpp:159] Memory required for data: 288154600
I0122 16:59:12.856042 64218 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 16:59:12.856050 64218 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 16:59:12.856053 64218 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.856060 64218 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 16:59:12.856096 64218 net.cpp:144] Setting up downsample_4/pool_s2
I0122 16:59:12.856101 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.856103 64218 net.cpp:159] Memory required for data: 292250600
I0122 16:59:12.856107 64218 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 16:59:12.856113 64218 net.cpp:94] Creating Layer downsample_4/output
I0122 16:59:12.856117 64218 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 16:59:12.856120 64218 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 16:59:12.856127 64218 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 16:59:12.856199 64218 net.cpp:144] Setting up downsample_4/output
I0122 16:59:12.856204 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.856207 64218 net.cpp:159] Memory required for data: 300442600
I0122 16:59:12.856210 64218 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.856217 64218 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.856221 64218 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 16:59:12.856225 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.856233 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.856276 64218 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.856283 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.856288 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.856292 64218 net.cpp:159] Memory required for data: 316826600
I0122 16:59:12.856294 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 16:59:12.856304 64218 net.cpp:94] Creating Layer inception_5a/1x1
I0122 16:59:12.856312 64218 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.856328 64218 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 16:59:12.856690 64218 net.cpp:144] Setting up inception_5a/1x1
I0122 16:59:12.856696 64218 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:12.856699 64218 net.cpp:159] Memory required for data: 322561000
I0122 16:59:12.856705 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 16:59:12.856714 64218 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 16:59:12.856716 64218 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 16:59:12.856722 64218 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.857506 64218 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 16:59:12.857522 64218 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:12.857524 64218 net.cpp:159] Memory required for data: 328295400
I0122 16:59:12.857532 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 16:59:12.857542 64218 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 16:59:12.857545 64218 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 16:59:12.857551 64218 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.857561 64218 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 16:59:12.857574 64218 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:12.857578 64218 net.cpp:159] Memory required for data: 334029800
I0122 16:59:12.857580 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 16:59:12.857595 64218 net.cpp:94] Creating Layer inception_5a/3x3
I0122 16:59:12.857601 64218 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.857609 64218 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 16:59:12.858289 64218 net.cpp:144] Setting up inception_5a/3x3
I0122 16:59:12.858297 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.858301 64218 net.cpp:159] Memory required for data: 336487400
I0122 16:59:12.858306 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 16:59:12.858319 64218 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 16:59:12.858323 64218 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 16:59:12.858330 64218 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.859122 64218 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 16:59:12.859129 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.859133 64218 net.cpp:159] Memory required for data: 338945000
I0122 16:59:12.859141 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 16:59:12.859146 64218 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 16:59:12.859149 64218 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 16:59:12.859163 64218 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.859170 64218 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 16:59:12.859179 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.859182 64218 net.cpp:159] Memory required for data: 341402600
I0122 16:59:12.859184 64218 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 16:59:12.859189 64218 net.cpp:94] Creating Layer inception_5a/output
I0122 16:59:12.859195 64218 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 16:59:12.859199 64218 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 16:59:12.859203 64218 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 16:59:12.859227 64218 net.cpp:144] Setting up inception_5a/output
I0122 16:59:12.859232 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.859236 64218 net.cpp:159] Memory required for data: 349594600
I0122 16:59:12.859237 64218 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.859243 64218 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.859246 64218 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 16:59:12.859252 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.859258 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.859328 64218 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.859334 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.859338 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.859340 64218 net.cpp:159] Memory required for data: 365978600
I0122 16:59:12.859344 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 16:59:12.859351 64218 net.cpp:94] Creating Layer inception_6a/1x1
I0122 16:59:12.859375 64218 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.859381 64218 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 16:59:12.859725 64218 net.cpp:144] Setting up inception_6a/1x1
I0122 16:59:12.859733 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.859736 64218 net.cpp:159] Memory required for data: 370893800
I0122 16:59:12.859741 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 16:59:12.859750 64218 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 16:59:12.859755 64218 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 16:59:12.859760 64218 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.860559 64218 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 16:59:12.860568 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.860570 64218 net.cpp:159] Memory required for data: 375809000
I0122 16:59:12.860579 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 16:59:12.860590 64218 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 16:59:12.860594 64218 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 16:59:12.860599 64218 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.860611 64218 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 16:59:12.860615 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.860620 64218 net.cpp:159] Memory required for data: 380724200
I0122 16:59:12.860622 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 16:59:12.860632 64218 net.cpp:94] Creating Layer inception_6a/3x3
I0122 16:59:12.860636 64218 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.860642 64218 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 16:59:12.862144 64218 net.cpp:144] Setting up inception_6a/3x3
I0122 16:59:12.862157 64218 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:12.862160 64218 net.cpp:159] Memory required for data: 384001000
I0122 16:59:12.862175 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 16:59:12.862187 64218 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 16:59:12.862191 64218 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 16:59:12.862198 64218 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.863029 64218 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 16:59:12.863035 64218 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:12.863039 64218 net.cpp:159] Memory required for data: 387277800
I0122 16:59:12.863046 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 16:59:12.863054 64218 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 16:59:12.863057 64218 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 16:59:12.863063 64218 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.863070 64218 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 16:59:12.863075 64218 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:12.863078 64218 net.cpp:159] Memory required for data: 390554600
I0122 16:59:12.863081 64218 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 16:59:12.863086 64218 net.cpp:94] Creating Layer inception_6a/output
I0122 16:59:12.863090 64218 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 16:59:12.863093 64218 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 16:59:12.863101 64218 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 16:59:12.863121 64218 net.cpp:144] Setting up inception_6a/output
I0122 16:59:12.863127 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.863129 64218 net.cpp:159] Memory required for data: 398746600
I0122 16:59:12.863132 64218 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.863138 64218 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.863153 64218 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 16:59:12.863159 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.863168 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.863199 64218 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.863206 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.863209 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.863211 64218 net.cpp:159] Memory required for data: 415130600
I0122 16:59:12.863215 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 16:59:12.863225 64218 net.cpp:94] Creating Layer inception_7a/1x1
I0122 16:59:12.863230 64218 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.863236 64218 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 16:59:12.863554 64218 net.cpp:144] Setting up inception_7a/1x1
I0122 16:59:12.863561 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.863564 64218 net.cpp:159] Memory required for data: 419226600
I0122 16:59:12.863569 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 16:59:12.863575 64218 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 16:59:12.863579 64218 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 16:59:12.863585 64218 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.864289 64218 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 16:59:12.864296 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.864300 64218 net.cpp:159] Memory required for data: 423322600
I0122 16:59:12.864306 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 16:59:12.864315 64218 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 16:59:12.864317 64218 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 16:59:12.864322 64218 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.864328 64218 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 16:59:12.864332 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.864334 64218 net.cpp:159] Memory required for data: 427418600
I0122 16:59:12.864338 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 16:59:12.864346 64218 net.cpp:94] Creating Layer inception_7a/3x3
I0122 16:59:12.864351 64218 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.864358 64218 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 16:59:12.865245 64218 net.cpp:144] Setting up inception_7a/3x3
I0122 16:59:12.865255 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.865258 64218 net.cpp:159] Memory required for data: 431514600
I0122 16:59:12.865263 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 16:59:12.865272 64218 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 16:59:12.865278 64218 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 16:59:12.865283 64218 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.865990 64218 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 16:59:12.865998 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.866000 64218 net.cpp:159] Memory required for data: 435610600
I0122 16:59:12.866008 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 16:59:12.866014 64218 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 16:59:12.866019 64218 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 16:59:12.866024 64218 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.866031 64218 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 16:59:12.866036 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.866040 64218 net.cpp:159] Memory required for data: 439706600
I0122 16:59:12.866052 64218 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 16:59:12.866057 64218 net.cpp:94] Creating Layer inception_7a/output
I0122 16:59:12.866060 64218 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 16:59:12.866065 64218 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 16:59:12.866070 64218 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 16:59:12.866089 64218 net.cpp:144] Setting up inception_7a/output
I0122 16:59:12.866096 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.866098 64218 net.cpp:159] Memory required for data: 447898600
I0122 16:59:12.866101 64218 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.866107 64218 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.866111 64218 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 16:59:12.866116 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.866122 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.866154 64218 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.866159 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.866163 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.866166 64218 net.cpp:159] Memory required for data: 464282600
I0122 16:59:12.866168 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 16:59:12.866178 64218 net.cpp:94] Creating Layer inception_8a/1x1
I0122 16:59:12.866183 64218 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.866189 64218 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 16:59:12.866474 64218 net.cpp:144] Setting up inception_8a/1x1
I0122 16:59:12.866482 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.866484 64218 net.cpp:159] Memory required for data: 466740200
I0122 16:59:12.866489 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 16:59:12.866497 64218 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 16:59:12.866499 64218 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 16:59:12.866506 64218 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.867208 64218 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 16:59:12.867214 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.867218 64218 net.cpp:159] Memory required for data: 469197800
I0122 16:59:12.867225 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 16:59:12.867230 64218 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 16:59:12.867233 64218 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 16:59:12.867239 64218 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.867245 64218 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 16:59:12.867251 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.867254 64218 net.cpp:159] Memory required for data: 471655400
I0122 16:59:12.867256 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 16:59:12.867265 64218 net.cpp:94] Creating Layer inception_8a/3x3
I0122 16:59:12.867269 64218 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.867275 64218 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 16:59:12.868919 64218 net.cpp:144] Setting up inception_8a/3x3
I0122 16:59:12.868933 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.868935 64218 net.cpp:159] Memory required for data: 476570600
I0122 16:59:12.868942 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 16:59:12.868968 64218 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 16:59:12.868973 64218 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 16:59:12.868988 64218 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.869699 64218 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 16:59:12.869715 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.869719 64218 net.cpp:159] Memory required for data: 481485800
I0122 16:59:12.869727 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 16:59:12.869732 64218 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 16:59:12.869735 64218 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 16:59:12.869741 64218 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.869748 64218 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 16:59:12.869755 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.869757 64218 net.cpp:159] Memory required for data: 486401000
I0122 16:59:12.869761 64218 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 16:59:12.869765 64218 net.cpp:94] Creating Layer inception_8a/output
I0122 16:59:12.869768 64218 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 16:59:12.869771 64218 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 16:59:12.869778 64218 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 16:59:12.869797 64218 net.cpp:144] Setting up inception_8a/output
I0122 16:59:12.869802 64218 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:12.869805 64218 net.cpp:159] Memory required for data: 493773800
I0122 16:59:12.869808 64218 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.869814 64218 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.869817 64218 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 16:59:12.869823 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.869830 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.869861 64218 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.869866 64218 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:12.869870 64218 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:12.869874 64218 net.cpp:159] Memory required for data: 508519400
I0122 16:59:12.869876 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 16:59:12.869885 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 16:59:12.869889 64218 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.869897 64218 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 16:59:12.871490 64218 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 16:59:12.871501 64218 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:12.871505 64218 net.cpp:159] Memory required for data: 509748200
I0122 16:59:12.871510 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 16:59:12.871520 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 16:59:12.871523 64218 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 16:59:12.871529 64218 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.872220 64218 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 16:59:12.872227 64218 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:12.872231 64218 net.cpp:159] Memory required for data: 510977000
I0122 16:59:12.872237 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 16:59:12.872244 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 16:59:12.872247 64218 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 16:59:12.872252 64218 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.872258 64218 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 16:59:12.872262 64218 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:12.872275 64218 net.cpp:159] Memory required for data: 512205800
I0122 16:59:12.872278 64218 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 16:59:12.872283 64218 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 16:59:12.872290 64218 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.872297 64218 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 16:59:12.872329 64218 net.cpp:144] Setting up downsample_9/pool_s2
I0122 16:59:12.872335 64218 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 16:59:12.872339 64218 net.cpp:159] Memory required for data: 514049000
I0122 16:59:12.872341 64218 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 16:59:12.872350 64218 net.cpp:94] Creating Layer downsample_9/output
I0122 16:59:12.872355 64218 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 16:59:12.872359 64218 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 16:59:12.872364 64218 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 16:59:12.872381 64218 net.cpp:144] Setting up downsample_9/output
I0122 16:59:12.872386 64218 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:12.872390 64218 net.cpp:159] Memory required for data: 517121000
I0122 16:59:12.872392 64218 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.872400 64218 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.872406 64218 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 16:59:12.872411 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.872418 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.872447 64218 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.872452 64218 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:12.872457 64218 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:12.872459 64218 net.cpp:159] Memory required for data: 523265000
I0122 16:59:12.872462 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 16:59:12.872470 64218 net.cpp:94] Creating Layer inception_10a/1x1
I0122 16:59:12.872475 64218 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.872481 64218 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 16:59:12.872944 64218 net.cpp:144] Setting up inception_10a/1x1
I0122 16:59:12.872951 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.872954 64218 net.cpp:159] Memory required for data: 525517800
I0122 16:59:12.872959 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 16:59:12.872967 64218 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 16:59:12.872972 64218 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 16:59:12.872978 64218 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.873661 64218 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 16:59:12.873667 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.873672 64218 net.cpp:159] Memory required for data: 527770600
I0122 16:59:12.873678 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 16:59:12.873683 64218 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 16:59:12.873687 64218 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 16:59:12.873690 64218 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.873697 64218 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 16:59:12.873700 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.873703 64218 net.cpp:159] Memory required for data: 530023400
I0122 16:59:12.873705 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 16:59:12.873716 64218 net.cpp:94] Creating Layer inception_10a/3x3
I0122 16:59:12.873729 64218 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.873734 64218 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 16:59:12.876235 64218 net.cpp:144] Setting up inception_10a/3x3
I0122 16:59:12.876248 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.876250 64218 net.cpp:159] Memory required for data: 532071400
I0122 16:59:12.876255 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 16:59:12.876263 64218 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 16:59:12.876267 64218 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 16:59:12.876272 64218 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.876888 64218 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 16:59:12.876895 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.876899 64218 net.cpp:159] Memory required for data: 534119400
I0122 16:59:12.876905 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 16:59:12.876910 64218 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 16:59:12.876914 64218 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 16:59:12.876920 64218 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.876926 64218 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 16:59:12.876932 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.876935 64218 net.cpp:159] Memory required for data: 536167400
I0122 16:59:12.876937 64218 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 16:59:12.876941 64218 net.cpp:94] Creating Layer inception_10a/output
I0122 16:59:12.876945 64218 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 16:59:12.876948 64218 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 16:59:12.876955 64218 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 16:59:12.876972 64218 net.cpp:144] Setting up inception_10a/output
I0122 16:59:12.876978 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.876981 64218 net.cpp:159] Memory required for data: 540468200
I0122 16:59:12.876983 64218 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.876989 64218 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.876992 64218 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 16:59:12.876998 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.877004 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.877035 64218 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.877040 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.877043 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.877046 64218 net.cpp:159] Memory required for data: 549069800
I0122 16:59:12.877049 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 16:59:12.877058 64218 net.cpp:94] Creating Layer inception_11a/1x1
I0122 16:59:12.877060 64218 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.877068 64218 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 16:59:12.877626 64218 net.cpp:144] Setting up inception_11a/1x1
I0122 16:59:12.877634 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.877637 64218 net.cpp:159] Memory required for data: 551322600
I0122 16:59:12.877642 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 16:59:12.877650 64218 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 16:59:12.877653 64218 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 16:59:12.877660 64218 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.878376 64218 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 16:59:12.878384 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.878387 64218 net.cpp:159] Memory required for data: 553575400
I0122 16:59:12.878394 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 16:59:12.878401 64218 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 16:59:12.878403 64218 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 16:59:12.878408 64218 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.878414 64218 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 16:59:12.878419 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.878422 64218 net.cpp:159] Memory required for data: 555828200
I0122 16:59:12.878424 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 16:59:12.878433 64218 net.cpp:94] Creating Layer inception_11a/3x3
I0122 16:59:12.878438 64218 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.878444 64218 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 16:59:12.882194 64218 net.cpp:144] Setting up inception_11a/3x3
I0122 16:59:12.882205 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.882207 64218 net.cpp:159] Memory required for data: 557876200
I0122 16:59:12.882212 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 16:59:12.882221 64218 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 16:59:12.882225 64218 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 16:59:12.882231 64218 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.882923 64218 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 16:59:12.882931 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.882935 64218 net.cpp:159] Memory required for data: 559924200
I0122 16:59:12.882953 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 16:59:12.882961 64218 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 16:59:12.882964 64218 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 16:59:12.882969 64218 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.882977 64218 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 16:59:12.882982 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.882985 64218 net.cpp:159] Memory required for data: 561972200
I0122 16:59:12.882987 64218 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 16:59:12.882993 64218 net.cpp:94] Creating Layer inception_11a/output
I0122 16:59:12.882997 64218 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 16:59:12.882999 64218 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 16:59:12.883004 64218 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 16:59:12.883024 64218 net.cpp:144] Setting up inception_11a/output
I0122 16:59:12.883029 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.883033 64218 net.cpp:159] Memory required for data: 566273000
I0122 16:59:12.883034 64218 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 16:59:12.883041 64218 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 16:59:12.883044 64218 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 16:59:12.883049 64218 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 16:59:12.883071 64218 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 16:59:12.883076 64218 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 16:59:12.883080 64218 net.cpp:159] Memory required for data: 566340200
I0122 16:59:12.883081 64218 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 16:59:12.883086 64218 net.cpp:94] Creating Layer drop_8x8_s1
I0122 16:59:12.883090 64218 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 16:59:12.883095 64218 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 16:59:12.883113 64218 net.cpp:144] Setting up drop_8x8_s1
I0122 16:59:12.883119 64218 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 16:59:12.883133 64218 net.cpp:159] Memory required for data: 566407400
I0122 16:59:12.883136 64218 layer_factory.hpp:77] Creating layer loss/classifier
I0122 16:59:12.883143 64218 net.cpp:94] Creating Layer loss/classifier
I0122 16:59:12.883146 64218 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 16:59:12.883152 64218 net.cpp:409] loss/classifier -> loss/classifier
I0122 16:59:12.883302 64218 net.cpp:144] Setting up loss/classifier
I0122 16:59:12.883307 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883311 64218 net.cpp:159] Memory required for data: 566409400
I0122 16:59:12.883316 64218 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 16:59:12.883322 64218 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 16:59:12.883325 64218 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 16:59:12.883330 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 16:59:12.883337 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 16:59:12.883342 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 16:59:12.883347 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 16:59:12.883399 64218 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 16:59:12.883404 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883407 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883410 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883414 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883416 64218 net.cpp:159] Memory required for data: 566417400
I0122 16:59:12.883419 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.883424 64218 net.cpp:94] Creating Layer loss
I0122 16:59:12.883426 64218 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 16:59:12.883430 64218 net.cpp:435] loss <- label_data_1_split_0
I0122 16:59:12.883436 64218 net.cpp:409] loss -> loss
I0122 16:59:12.883445 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.883524 64218 net.cpp:144] Setting up loss
I0122 16:59:12.883530 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883533 64218 net.cpp:154]     with loss weight 1
I0122 16:59:12.883543 64218 net.cpp:159] Memory required for data: 566417404
I0122 16:59:12.883545 64218 layer_factory.hpp:77] Creating layer accuracy
I0122 16:59:12.883551 64218 net.cpp:94] Creating Layer accuracy
I0122 16:59:12.883554 64218 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 16:59:12.883558 64218 net.cpp:435] accuracy <- label_data_1_split_1
I0122 16:59:12.883563 64218 net.cpp:409] accuracy -> accuracy
I0122 16:59:12.883574 64218 net.cpp:144] Setting up accuracy
I0122 16:59:12.883579 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883581 64218 net.cpp:159] Memory required for data: 566417408
I0122 16:59:12.883584 64218 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 16:59:12.883589 64218 net.cpp:94] Creating Layer accuracy-top1
I0122 16:59:12.883591 64218 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 16:59:12.883594 64218 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 16:59:12.883599 64218 net.cpp:409] accuracy-top1 -> top-1
I0122 16:59:12.883605 64218 net.cpp:144] Setting up accuracy-top1
I0122 16:59:12.883608 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883610 64218 net.cpp:159] Memory required for data: 566417412
I0122 16:59:12.883612 64218 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 16:59:12.883620 64218 net.cpp:94] Creating Layer accuracy-top5
I0122 16:59:12.883622 64218 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 16:59:12.883626 64218 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 16:59:12.883630 64218 net.cpp:409] accuracy-top5 -> top-5
I0122 16:59:12.883636 64218 net.cpp:144] Setting up accuracy-top5
I0122 16:59:12.883647 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883651 64218 net.cpp:159] Memory required for data: 566417416
I0122 16:59:12.883652 64218 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 16:59:12.883657 64218 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 16:59:12.883661 64218 net.cpp:222] accuracy does not need backward computation.
I0122 16:59:12.883663 64218 net.cpp:220] loss needs backward computation.
I0122 16:59:12.883667 64218 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 16:59:12.883671 64218 net.cpp:220] loss/classifier needs backward computation.
I0122 16:59:12.883674 64218 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 16:59:12.883677 64218 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 16:59:12.883679 64218 net.cpp:220] inception_11a/output needs backward computation.
I0122 16:59:12.883684 64218 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 16:59:12.883687 64218 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 16:59:12.883689 64218 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 16:59:12.883692 64218 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 16:59:12.883695 64218 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 16:59:12.883698 64218 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 16:59:12.883702 64218 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 16:59:12.883705 64218 net.cpp:220] inception_10a/output needs backward computation.
I0122 16:59:12.883709 64218 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 16:59:12.883718 64218 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 16:59:12.883720 64218 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 16:59:12.883723 64218 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 16:59:12.883726 64218 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 16:59:12.883729 64218 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 16:59:12.883731 64218 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 16:59:12.883734 64218 net.cpp:220] downsample_9/output needs backward computation.
I0122 16:59:12.883739 64218 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 16:59:12.883743 64218 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.883744 64218 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.883747 64218 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 16:59:12.883751 64218 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 16:59:12.883754 64218 net.cpp:220] inception_8a/output needs backward computation.
I0122 16:59:12.883759 64218 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 16:59:12.883761 64218 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 16:59:12.883764 64218 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 16:59:12.883769 64218 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 16:59:12.883771 64218 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 16:59:12.883774 64218 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 16:59:12.883777 64218 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 16:59:12.883780 64218 net.cpp:220] inception_7a/output needs backward computation.
I0122 16:59:12.883783 64218 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 16:59:12.883786 64218 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 16:59:12.883790 64218 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 16:59:12.883792 64218 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 16:59:12.883800 64218 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 16:59:12.883803 64218 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 16:59:12.883807 64218 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 16:59:12.883810 64218 net.cpp:220] inception_6a/output needs backward computation.
I0122 16:59:12.883813 64218 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 16:59:12.883816 64218 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 16:59:12.883821 64218 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 16:59:12.883823 64218 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 16:59:12.883826 64218 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 16:59:12.883828 64218 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 16:59:12.883832 64218 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 16:59:12.883836 64218 net.cpp:220] inception_5a/output needs backward computation.
I0122 16:59:12.883838 64218 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 16:59:12.883841 64218 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 16:59:12.883844 64218 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 16:59:12.883847 64218 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 16:59:12.883850 64218 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 16:59:12.883853 64218 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 16:59:12.883857 64218 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 16:59:12.883859 64218 net.cpp:220] downsample_4/output needs backward computation.
I0122 16:59:12.883863 64218 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 16:59:12.883867 64218 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.883872 64218 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.883874 64218 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 16:59:12.883877 64218 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 16:59:12.883880 64218 net.cpp:220] inception_3a/output needs backward computation.
I0122 16:59:12.883884 64218 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 16:59:12.883888 64218 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 16:59:12.883890 64218 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 16:59:12.883893 64218 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 16:59:12.883896 64218 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 16:59:12.883899 64218 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 16:59:12.883903 64218 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 16:59:12.883905 64218 net.cpp:220] inception_2a/output needs backward computation.
I0122 16:59:12.883909 64218 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 16:59:12.883913 64218 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 16:59:12.883915 64218 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 16:59:12.883919 64218 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 16:59:12.883922 64218 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 16:59:12.883924 64218 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 16:59:12.883929 64218 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 16:59:12.883931 64218 net.cpp:220] conv1/relu1 needs backward computation.
I0122 16:59:12.883934 64218 net.cpp:220] conv1/bn1 needs backward computation.
I0122 16:59:12.883937 64218 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 16:59:12.883946 64218 net.cpp:222] label_data_1_split does not need backward computation.
I0122 16:59:12.883950 64218 net.cpp:222] data does not need backward computation.
I0122 16:59:12.883955 64218 net.cpp:264] This network produces output accuracy
I0122 16:59:12.883957 64218 net.cpp:264] This network produces output loss
I0122 16:59:12.883960 64218 net.cpp:264] This network produces output top-1
I0122 16:59:12.883963 64218 net.cpp:264] This network produces output top-5
I0122 16:59:12.884032 64218 net.cpp:284] Network initialization done.
I0122 16:59:12.884367 64218 solver.cpp:63] Solver scaffolding done.
I0122 16:59:12.888835 64218 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/sparse.caffemodel
W0122 16:59:12.919659 64218 net.cpp:860] Force copying param 4 weights from layer 'conv1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.931596 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.931886 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932065 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932283 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932576 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_4/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932781 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933123 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933321 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933655 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933851 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.934523 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.934718 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.935132 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.935515 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_9/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.935765 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.936470 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.936755 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.937646 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.954486 64218 net.cpp:860] Force copying param 4 weights from layer 'conv1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.954666 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.954879 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955204 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955425 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955710 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_4/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955924 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956250 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956452 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956777 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956976 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.957329 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.957525 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.957923 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.958315 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_9/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.958562 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.959252 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.959530 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.960383 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
I0122 16:59:12.960599 64218 caffe_interface.cpp:527] Starting Optimization
I0122 16:59:12.960605 64218 solver.cpp:335] Solving 
I0122 16:59:12.960608 64218 solver.cpp:336] Learning Rate Policy: step
I0122 16:59:12.963109 64218 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 16:59:15.289312 64218 solver.cpp:517]     Test net output #0: accuracy = 0.897778
I0122 16:59:15.289362 64218 solver.cpp:517]     Test net output #1: loss = 0.337907 (* 1 = 0.337907 loss)
I0122 16:59:15.289367 64218 solver.cpp:517]     Test net output #2: top-1 = 0.897778
I0122 16:59:15.289372 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 16:59:15.411653 64218 solver.cpp:266] Iteration 0 (0 iter/s, 2.45092s/100 iter), loss = 0.00980846
I0122 16:59:15.411685 64218 solver.cpp:285]     Train net output #0: loss = 0.00980846 (* 1 = 0.00980846 loss)
I0122 16:59:15.411697 64218 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 16:59:25.321040 64218 solver.cpp:266] Iteration 100 (10.0919 iter/s, 9.90898s/100 iter), loss = 1.23095
I0122 16:59:25.321074 64218 solver.cpp:285]     Train net output #0: loss = 1.23095 (* 1 = 1.23095 loss)
I0122 16:59:25.321080 64218 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 16:59:35.237478 64218 solver.cpp:266] Iteration 200 (10.0847 iter/s, 9.91603s/100 iter), loss = 1.18834
I0122 16:59:35.237511 64218 solver.cpp:285]     Train net output #0: loss = 1.18834 (* 1 = 1.18834 loss)
I0122 16:59:35.237519 64218 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 16:59:45.009392 64218 solver.cpp:266] Iteration 300 (10.2338 iter/s, 9.77151s/100 iter), loss = 0.978324
I0122 16:59:45.009469 64218 solver.cpp:285]     Train net output #0: loss = 0.978324 (* 1 = 0.978324 loss)
I0122 16:59:45.009476 64218 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 16:59:54.900861 64218 solver.cpp:266] Iteration 400 (10.1102 iter/s, 9.89102s/100 iter), loss = 0.781388
I0122 16:59:54.900907 64218 solver.cpp:285]     Train net output #0: loss = 0.781388 (* 1 = 0.781388 loss)
I0122 16:59:54.900914 64218 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 17:00:04.796079 64218 solver.cpp:266] Iteration 500 (10.1063 iter/s, 9.8948s/100 iter), loss = 0.834341
I0122 17:00:04.796113 64218 solver.cpp:285]     Train net output #0: loss = 0.834341 (* 1 = 0.834341 loss)
I0122 17:00:04.796120 64218 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 17:00:14.710749 64218 solver.cpp:266] Iteration 600 (10.0865 iter/s, 9.91426s/100 iter), loss = 0.737883
I0122 17:00:14.710781 64218 solver.cpp:285]     Train net output #0: loss = 0.737883 (* 1 = 0.737883 loss)
I0122 17:00:14.710788 64218 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 17:00:24.607306 64218 solver.cpp:266] Iteration 700 (10.1049 iter/s, 9.89615s/100 iter), loss = 0.84515
I0122 17:00:24.607372 64218 solver.cpp:285]     Train net output #0: loss = 0.84515 (* 1 = 0.84515 loss)
I0122 17:00:24.607380 64218 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 17:00:34.522425 64218 solver.cpp:266] Iteration 800 (10.0861 iter/s, 9.91467s/100 iter), loss = 0.905017
I0122 17:00:34.522459 64218 solver.cpp:285]     Train net output #0: loss = 0.905017 (* 1 = 0.905017 loss)
I0122 17:00:34.522465 64218 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 17:00:43.987553 64218 solver.cpp:266] Iteration 900 (10.5655 iter/s, 9.46473s/100 iter), loss = 0.618011
I0122 17:00:43.987586 64218 solver.cpp:285]     Train net output #0: loss = 0.618011 (* 1 = 0.618011 loss)
I0122 17:00:43.987591 64218 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 17:00:53.803179 64218 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 17:00:56.098443 64218 solver.cpp:517]     Test net output #0: accuracy = 0.198
I0122 17:00:56.098508 64218 solver.cpp:517]     Test net output #1: loss = 21.9294 (* 1 = 21.9294 loss)
I0122 17:00:56.098513 64218 solver.cpp:517]     Test net output #2: top-1 = 0.198
I0122 17:00:56.098517 64218 solver.cpp:517]     Test net output #3: top-5 = 0.665444
I0122 17:00:56.172874 64218 solver.cpp:266] Iteration 1000 (8.20694 iter/s, 12.1848s/100 iter), loss = 0.763146
I0122 17:00:56.172900 64218 solver.cpp:285]     Train net output #0: loss = 0.763146 (* 1 = 0.763146 loss)
I0122 17:00:56.172947 64218 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 17:01:06.090226 64218 solver.cpp:266] Iteration 1100 (10.0838 iter/s, 9.91689s/100 iter), loss = 0.701044
I0122 17:01:06.090270 64218 solver.cpp:285]     Train net output #0: loss = 0.701044 (* 1 = 0.701044 loss)
I0122 17:01:06.090276 64218 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 17:01:15.985049 64218 solver.cpp:266] Iteration 1200 (10.1067 iter/s, 9.89439s/100 iter), loss = 0.64415
I0122 17:01:15.985080 64218 solver.cpp:285]     Train net output #0: loss = 0.64415 (* 1 = 0.64415 loss)
I0122 17:01:15.985087 64218 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 17:01:25.924335 64218 solver.cpp:266] Iteration 1300 (10.0615 iter/s, 9.93887s/100 iter), loss = 0.63659
I0122 17:01:25.924368 64218 solver.cpp:285]     Train net output #0: loss = 0.63659 (* 1 = 0.63659 loss)
I0122 17:01:25.924376 64218 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 17:01:35.885099 64218 solver.cpp:266] Iteration 1400 (10.0398 iter/s, 9.96034s/100 iter), loss = 0.680251
I0122 17:01:35.885226 64218 solver.cpp:285]     Train net output #0: loss = 0.680251 (* 1 = 0.680251 loss)
I0122 17:01:35.885233 64218 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 17:01:45.788204 64218 solver.cpp:266] Iteration 1500 (10.0984 iter/s, 9.90259s/100 iter), loss = 0.648688
I0122 17:01:45.788239 64218 solver.cpp:285]     Train net output #0: loss = 0.648688 (* 1 = 0.648688 loss)
I0122 17:01:45.788244 64218 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 17:01:55.711263 64218 solver.cpp:266] Iteration 1600 (10.078 iter/s, 9.92264s/100 iter), loss = 0.707135
I0122 17:01:55.711297 64218 solver.cpp:285]     Train net output #0: loss = 0.707135 (* 1 = 0.707135 loss)
I0122 17:01:55.711303 64218 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 17:02:05.646179 64218 solver.cpp:266] Iteration 1700 (10.0659 iter/s, 9.93449s/100 iter), loss = 0.59069
I0122 17:02:05.646214 64218 solver.cpp:285]     Train net output #0: loss = 0.59069 (* 1 = 0.59069 loss)
I0122 17:02:05.646219 64218 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 17:02:15.599395 64218 solver.cpp:266] Iteration 1800 (10.0474 iter/s, 9.95279s/100 iter), loss = 0.63409
I0122 17:02:15.599452 64218 solver.cpp:285]     Train net output #0: loss = 0.63409 (* 1 = 0.63409 loss)
I0122 17:02:15.599474 64218 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 17:02:24.155696 64218 solver.cpp:266] Iteration 1900 (11.6878 iter/s, 8.55591s/100 iter), loss = 0.58959
I0122 17:02:24.155738 64218 solver.cpp:285]     Train net output #0: loss = 0.58959 (* 1 = 0.58959 loss)
I0122 17:02:24.155745 64218 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 17:02:30.852553 64218 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 17:02:32.325647 64218 solver.cpp:517]     Test net output #0: accuracy = 0.419889
I0122 17:02:32.325677 64218 solver.cpp:517]     Test net output #1: loss = 3.0678 (* 1 = 3.0678 loss)
I0122 17:02:32.325681 64218 solver.cpp:517]     Test net output #2: top-1 = 0.419889
I0122 17:02:32.325685 64218 solver.cpp:517]     Test net output #3: top-5 = 0.871777
I0122 17:02:32.389144 64218 solver.cpp:266] Iteration 2000 (12.1461 iter/s, 8.23309s/100 iter), loss = 0.543379
I0122 17:02:32.389176 64218 solver.cpp:285]     Train net output #0: loss = 0.543379 (* 1 = 0.543379 loss)
I0122 17:02:32.389183 64218 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 17:02:38.669178 64218 solver.cpp:266] Iteration 2100 (15.9242 iter/s, 6.27976s/100 iter), loss = 0.59188
I0122 17:02:38.669206 64218 solver.cpp:285]     Train net output #0: loss = 0.59188 (* 1 = 0.59188 loss)
I0122 17:02:38.669212 64218 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 17:02:44.957744 64218 solver.cpp:266] Iteration 2200 (15.9026 iter/s, 6.28829s/100 iter), loss = 0.44329
I0122 17:02:44.957774 64218 solver.cpp:285]     Train net output #0: loss = 0.44329 (* 1 = 0.44329 loss)
I0122 17:02:44.957780 64218 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 17:02:51.248493 64218 solver.cpp:266] Iteration 2300 (15.8971 iter/s, 6.29047s/100 iter), loss = 0.588783
I0122 17:02:51.248602 64218 solver.cpp:285]     Train net output #0: loss = 0.588783 (* 1 = 0.588783 loss)
I0122 17:02:51.248610 64218 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 17:02:57.532135 64218 solver.cpp:266] Iteration 2400 (15.9152 iter/s, 6.28329s/100 iter), loss = 0.443405
I0122 17:02:57.532166 64218 solver.cpp:285]     Train net output #0: loss = 0.443405 (* 1 = 0.443405 loss)
I0122 17:02:57.532171 64218 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 17:03:03.833413 64218 solver.cpp:266] Iteration 2500 (15.8705 iter/s, 6.301s/100 iter), loss = 0.500547
I0122 17:03:03.833442 64218 solver.cpp:285]     Train net output #0: loss = 0.500547 (* 1 = 0.500547 loss)
I0122 17:03:03.833448 64218 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 17:03:10.119339 64218 solver.cpp:266] Iteration 2600 (15.9093 iter/s, 6.28565s/100 iter), loss = 0.473666
I0122 17:03:10.119380 64218 solver.cpp:285]     Train net output #0: loss = 0.473666 (* 1 = 0.473666 loss)
I0122 17:03:10.119386 64218 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 17:03:16.400467 64218 solver.cpp:266] Iteration 2700 (15.9214 iter/s, 6.28084s/100 iter), loss = 0.65002
I0122 17:03:16.400497 64218 solver.cpp:285]     Train net output #0: loss = 0.65002 (* 1 = 0.65002 loss)
I0122 17:03:16.400502 64218 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 17:03:22.709966 64218 solver.cpp:266] Iteration 2800 (15.8498 iter/s, 6.30922s/100 iter), loss = 0.634212
I0122 17:03:22.710072 64218 solver.cpp:285]     Train net output #0: loss = 0.634212 (* 1 = 0.634212 loss)
I0122 17:03:22.710078 64218 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 17:03:28.970549 64218 solver.cpp:266] Iteration 2900 (15.9738 iter/s, 6.26023s/100 iter), loss = 0.535999
I0122 17:03:28.970579 64218 solver.cpp:285]     Train net output #0: loss = 0.535999 (* 1 = 0.535999 loss)
I0122 17:03:28.970585 64218 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 17:03:35.200136 64218 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 17:03:36.670575 64218 solver.cpp:517]     Test net output #0: accuracy = 0.531222
I0122 17:03:36.670600 64218 solver.cpp:517]     Test net output #1: loss = 2.16988 (* 1 = 2.16988 loss)
I0122 17:03:36.670604 64218 solver.cpp:517]     Test net output #2: top-1 = 0.531222
I0122 17:03:36.670608 64218 solver.cpp:517]     Test net output #3: top-5 = 0.914444
I0122 17:03:36.733899 64218 solver.cpp:266] Iteration 3000 (12.8816 iter/s, 7.76302s/100 iter), loss = 0.499563
I0122 17:03:36.733920 64218 solver.cpp:285]     Train net output #0: loss = 0.499563 (* 1 = 0.499563 loss)
I0122 17:03:36.733927 64218 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 17:03:43.005512 64218 solver.cpp:266] Iteration 3100 (15.9455 iter/s, 6.27135s/100 iter), loss = 0.508736
I0122 17:03:43.005553 64218 solver.cpp:285]     Train net output #0: loss = 0.508736 (* 1 = 0.508736 loss)
I0122 17:03:43.005558 64218 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 17:03:49.288455 64218 solver.cpp:266] Iteration 3200 (15.9168 iter/s, 6.28266s/100 iter), loss = 0.49204
I0122 17:03:49.288483 64218 solver.cpp:285]     Train net output #0: loss = 0.49204 (* 1 = 0.49204 loss)
I0122 17:03:49.288489 64218 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 17:03:55.554626 64218 solver.cpp:266] Iteration 3300 (15.9594 iter/s, 6.2659s/100 iter), loss = 0.458151
I0122 17:03:55.554697 64218 solver.cpp:285]     Train net output #0: loss = 0.458151 (* 1 = 0.458151 loss)
I0122 17:03:55.554703 64218 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 17:04:01.838019 64218 solver.cpp:266] Iteration 3400 (15.9158 iter/s, 6.28308s/100 iter), loss = 0.625705
I0122 17:04:01.838057 64218 solver.cpp:285]     Train net output #0: loss = 0.625705 (* 1 = 0.625705 loss)
I0122 17:04:01.838064 64218 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 17:04:08.147706 64218 solver.cpp:266] Iteration 3500 (15.8494 iter/s, 6.3094s/100 iter), loss = 0.435966
I0122 17:04:08.147733 64218 solver.cpp:285]     Train net output #0: loss = 0.435966 (* 1 = 0.435966 loss)
I0122 17:04:08.147738 64218 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 17:04:14.680032 64218 solver.cpp:266] Iteration 3600 (15.3091 iter/s, 6.53204s/100 iter), loss = 0.608255
I0122 17:04:14.680060 64218 solver.cpp:285]     Train net output #0: loss = 0.608255 (* 1 = 0.608255 loss)
I0122 17:04:14.680083 64218 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 17:04:21.159417 64218 solver.cpp:266] Iteration 3700 (15.4342 iter/s, 6.4791s/100 iter), loss = 0.48724
I0122 17:04:21.159447 64218 solver.cpp:285]     Train net output #0: loss = 0.48724 (* 1 = 0.48724 loss)
I0122 17:04:21.159452 64218 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 17:04:27.429881 64218 solver.cpp:266] Iteration 3800 (15.9485 iter/s, 6.27019s/100 iter), loss = 0.463679
I0122 17:04:27.430027 64218 solver.cpp:285]     Train net output #0: loss = 0.463679 (* 1 = 0.463679 loss)
I0122 17:04:27.430035 64218 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 17:04:33.688761 64218 solver.cpp:266] Iteration 3900 (15.9783 iter/s, 6.25849s/100 iter), loss = 0.561816
I0122 17:04:33.688791 64218 solver.cpp:285]     Train net output #0: loss = 0.561816 (* 1 = 0.561816 loss)
I0122 17:04:33.688796 64218 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 17:04:39.918716 64218 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 17:04:41.389219 64218 solver.cpp:517]     Test net output #0: accuracy = 0.497444
I0122 17:04:41.389245 64218 solver.cpp:517]     Test net output #1: loss = 2.14562 (* 1 = 2.14562 loss)
I0122 17:04:41.389250 64218 solver.cpp:517]     Test net output #2: top-1 = 0.497444
I0122 17:04:41.389255 64218 solver.cpp:517]     Test net output #3: top-5 = 0.860555
I0122 17:04:41.451529 64218 solver.cpp:266] Iteration 4000 (12.8825 iter/s, 7.76244s/100 iter), loss = 0.524706
I0122 17:04:41.451550 64218 solver.cpp:285]     Train net output #0: loss = 0.524706 (* 1 = 0.524706 loss)
I0122 17:04:41.451555 64218 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 17:04:47.719166 64218 solver.cpp:266] Iteration 4100 (15.9557 iter/s, 6.26737s/100 iter), loss = 0.524054
I0122 17:04:47.719195 64218 solver.cpp:285]     Train net output #0: loss = 0.524054 (* 1 = 0.524054 loss)
I0122 17:04:47.719202 64218 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 17:04:53.989893 64218 solver.cpp:266] Iteration 4200 (15.9478 iter/s, 6.27045s/100 iter), loss = 0.561482
I0122 17:04:53.989926 64218 solver.cpp:285]     Train net output #0: loss = 0.561482 (* 1 = 0.561482 loss)
I0122 17:04:53.989931 64218 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 17:05:00.281675 64218 solver.cpp:266] Iteration 4300 (15.8945 iter/s, 6.2915s/100 iter), loss = 0.572603
I0122 17:05:00.281738 64218 solver.cpp:285]     Train net output #0: loss = 0.572603 (* 1 = 0.572603 loss)
I0122 17:05:00.281745 64218 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 17:05:06.569659 64218 solver.cpp:266] Iteration 4400 (15.9041 iter/s, 6.28768s/100 iter), loss = 0.681291
I0122 17:05:06.569689 64218 solver.cpp:285]     Train net output #0: loss = 0.681291 (* 1 = 0.681291 loss)
I0122 17:05:06.569694 64218 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 17:05:12.853040 64218 solver.cpp:266] Iteration 4500 (15.9157 iter/s, 6.28311s/100 iter), loss = 0.416642
I0122 17:05:12.853082 64218 solver.cpp:285]     Train net output #0: loss = 0.416642 (* 1 = 0.416642 loss)
I0122 17:05:12.853090 64218 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 17:05:19.119536 64218 solver.cpp:266] Iteration 4600 (15.9586 iter/s, 6.26621s/100 iter), loss = 0.657684
I0122 17:05:19.119567 64218 solver.cpp:285]     Train net output #0: loss = 0.657684 (* 1 = 0.657684 loss)
I0122 17:05:19.119573 64218 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 17:05:25.405055 64218 solver.cpp:266] Iteration 4700 (15.9103 iter/s, 6.28524s/100 iter), loss = 0.687578
I0122 17:05:25.405083 64218 solver.cpp:285]     Train net output #0: loss = 0.687578 (* 1 = 0.687578 loss)
I0122 17:05:25.405089 64218 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 17:05:31.699404 64218 solver.cpp:266] Iteration 4800 (15.888 iter/s, 6.29407s/100 iter), loss = 0.528002
I0122 17:05:31.699499 64218 solver.cpp:285]     Train net output #0: loss = 0.528002 (* 1 = 0.528002 loss)
I0122 17:05:31.699507 64218 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 17:05:37.971904 64218 solver.cpp:266] Iteration 4900 (15.9435 iter/s, 6.27216s/100 iter), loss = 0.491155
I0122 17:05:37.971943 64218 solver.cpp:285]     Train net output #0: loss = 0.491155 (* 1 = 0.491155 loss)
I0122 17:05:37.971951 64218 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 17:05:44.179024 64218 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 17:05:45.643517 64218 solver.cpp:517]     Test net output #0: accuracy = 0.353889
I0122 17:05:45.643543 64218 solver.cpp:517]     Test net output #1: loss = 3.19469 (* 1 = 3.19469 loss)
I0122 17:05:45.643548 64218 solver.cpp:517]     Test net output #2: top-1 = 0.353889
I0122 17:05:45.643550 64218 solver.cpp:517]     Test net output #3: top-5 = 0.821444
I0122 17:05:45.706207 64218 solver.cpp:266] Iteration 5000 (12.93 iter/s, 7.73397s/100 iter), loss = 0.630112
I0122 17:05:45.706226 64218 solver.cpp:285]     Train net output #0: loss = 0.630112 (* 1 = 0.630112 loss)
I0122 17:05:45.706231 64218 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 17:05:51.968252 64218 solver.cpp:266] Iteration 5100 (15.9699 iter/s, 6.26178s/100 iter), loss = 0.430784
I0122 17:05:51.968281 64218 solver.cpp:285]     Train net output #0: loss = 0.430784 (* 1 = 0.430784 loss)
I0122 17:05:51.968286 64218 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 17:05:58.235421 64218 solver.cpp:266] Iteration 5200 (15.9569 iter/s, 6.2669s/100 iter), loss = 0.563418
I0122 17:05:58.235460 64218 solver.cpp:285]     Train net output #0: loss = 0.563418 (* 1 = 0.563418 loss)
I0122 17:05:58.235466 64218 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 17:06:04.501829 64218 solver.cpp:266] Iteration 5300 (15.9588 iter/s, 6.26613s/100 iter), loss = 0.600417
I0122 17:06:04.501895 64218 solver.cpp:285]     Train net output #0: loss = 0.600417 (* 1 = 0.600417 loss)
I0122 17:06:04.501901 64218 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 17:06:10.796906 64218 solver.cpp:266] Iteration 5400 (15.8862 iter/s, 6.29477s/100 iter), loss = 0.52509
I0122 17:06:10.796937 64218 solver.cpp:285]     Train net output #0: loss = 0.52509 (* 1 = 0.52509 loss)
I0122 17:06:10.796943 64218 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 17:06:17.070438 64218 solver.cpp:266] Iteration 5500 (15.9407 iter/s, 6.27326s/100 iter), loss = 0.575375
I0122 17:06:17.070480 64218 solver.cpp:285]     Train net output #0: loss = 0.575375 (* 1 = 0.575375 loss)
I0122 17:06:17.070487 64218 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 17:06:23.333393 64218 solver.cpp:266] Iteration 5600 (15.9676 iter/s, 6.26267s/100 iter), loss = 0.570814
I0122 17:06:23.333423 64218 solver.cpp:285]     Train net output #0: loss = 0.570814 (* 1 = 0.570814 loss)
I0122 17:06:23.333429 64218 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 17:06:29.616194 64218 solver.cpp:266] Iteration 5700 (15.9172 iter/s, 6.28253s/100 iter), loss = 0.446092
I0122 17:06:29.616225 64218 solver.cpp:285]     Train net output #0: loss = 0.446092 (* 1 = 0.446092 loss)
I0122 17:06:29.616230 64218 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 17:06:35.897192 64218 solver.cpp:266] Iteration 5800 (15.9217 iter/s, 6.28072s/100 iter), loss = 0.636296
I0122 17:06:35.897291 64218 solver.cpp:285]     Train net output #0: loss = 0.636296 (* 1 = 0.636296 loss)
I0122 17:06:35.897297 64218 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 17:06:42.162334 64218 solver.cpp:266] Iteration 5900 (15.9622 iter/s, 6.2648s/100 iter), loss = 0.723793
I0122 17:06:42.162364 64218 solver.cpp:285]     Train net output #0: loss = 0.723793 (* 1 = 0.723793 loss)
I0122 17:06:42.162369 64218 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 17:06:48.369484 64218 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 17:06:49.839665 64218 solver.cpp:517]     Test net output #0: accuracy = 0.681778
I0122 17:06:49.839691 64218 solver.cpp:517]     Test net output #1: loss = 0.998328 (* 1 = 0.998328 loss)
I0122 17:06:49.839695 64218 solver.cpp:517]     Test net output #2: top-1 = 0.681778
I0122 17:06:49.839699 64218 solver.cpp:517]     Test net output #3: top-5 = 0.962778
I0122 17:06:49.901908 64218 solver.cpp:266] Iteration 6000 (12.9212 iter/s, 7.73924s/100 iter), loss = 0.477444
I0122 17:06:49.901940 64218 solver.cpp:285]     Train net output #0: loss = 0.477444 (* 1 = 0.477444 loss)
I0122 17:06:49.901947 64218 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 17:06:56.164144 64218 solver.cpp:266] Iteration 6100 (15.9694 iter/s, 6.26197s/100 iter), loss = 0.396846
I0122 17:06:56.164175 64218 solver.cpp:285]     Train net output #0: loss = 0.396846 (* 1 = 0.396846 loss)
I0122 17:06:56.164180 64218 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 17:07:02.450959 64218 solver.cpp:266] Iteration 6200 (15.907 iter/s, 6.28654s/100 iter), loss = 0.484741
I0122 17:07:02.450999 64218 solver.cpp:285]     Train net output #0: loss = 0.484741 (* 1 = 0.484741 loss)
I0122 17:07:02.451004 64218 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 17:07:08.733575 64218 solver.cpp:266] Iteration 6300 (15.9177 iter/s, 6.28233s/100 iter), loss = 0.512145
I0122 17:07:08.733700 64218 solver.cpp:285]     Train net output #0: loss = 0.512145 (* 1 = 0.512145 loss)
I0122 17:07:08.733706 64218 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 17:07:14.993646 64218 solver.cpp:266] Iteration 6400 (15.9752 iter/s, 6.2597s/100 iter), loss = 0.474107
I0122 17:07:14.993675 64218 solver.cpp:285]     Train net output #0: loss = 0.474107 (* 1 = 0.474107 loss)
I0122 17:07:14.993681 64218 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 17:07:21.272835 64218 solver.cpp:266] Iteration 6500 (15.9263 iter/s, 6.27892s/100 iter), loss = 0.702613
I0122 17:07:21.272864 64218 solver.cpp:285]     Train net output #0: loss = 0.702613 (* 1 = 0.702613 loss)
I0122 17:07:21.272871 64218 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 17:07:27.534328 64218 solver.cpp:266] Iteration 6600 (15.9713 iter/s, 6.26122s/100 iter), loss = 0.538209
I0122 17:07:27.534358 64218 solver.cpp:285]     Train net output #0: loss = 0.538209 (* 1 = 0.538209 loss)
I0122 17:07:27.534363 64218 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 17:07:33.786643 64218 solver.cpp:266] Iteration 6700 (15.9948 iter/s, 6.25204s/100 iter), loss = 0.454453
I0122 17:07:33.786672 64218 solver.cpp:285]     Train net output #0: loss = 0.454453 (* 1 = 0.454453 loss)
I0122 17:07:33.786677 64218 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 17:07:40.071804 64218 solver.cpp:266] Iteration 6800 (15.9112 iter/s, 6.28489s/100 iter), loss = 0.475208
I0122 17:07:40.071909 64218 solver.cpp:285]     Train net output #0: loss = 0.475208 (* 1 = 0.475208 loss)
I0122 17:07:40.071915 64218 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 17:07:46.348884 64218 solver.cpp:266] Iteration 6900 (15.9319 iter/s, 6.27673s/100 iter), loss = 0.488271
I0122 17:07:46.348923 64218 solver.cpp:285]     Train net output #0: loss = 0.488271 (* 1 = 0.488271 loss)
I0122 17:07:46.348930 64218 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 17:07:52.562785 64218 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 17:07:54.038436 64218 solver.cpp:517]     Test net output #0: accuracy = 0.603555
I0122 17:07:54.038462 64218 solver.cpp:517]     Test net output #1: loss = 1.4267 (* 1 = 1.4267 loss)
I0122 17:07:54.038468 64218 solver.cpp:517]     Test net output #2: top-1 = 0.603555
I0122 17:07:54.038471 64218 solver.cpp:517]     Test net output #3: top-5 = 0.964111
I0122 17:07:54.101159 64218 solver.cpp:266] Iteration 7000 (12.9 iter/s, 7.75194s/100 iter), loss = 0.379201
I0122 17:07:54.101179 64218 solver.cpp:285]     Train net output #0: loss = 0.379201 (* 1 = 0.379201 loss)
I0122 17:07:54.101186 64218 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 17:08:00.345324 64218 solver.cpp:266] Iteration 7100 (16.0156 iter/s, 6.2439s/100 iter), loss = 0.720759
I0122 17:08:00.345351 64218 solver.cpp:285]     Train net output #0: loss = 0.720759 (* 1 = 0.720759 loss)
I0122 17:08:00.345357 64218 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 17:08:06.631608 64218 solver.cpp:266] Iteration 7200 (15.9083 iter/s, 6.28601s/100 iter), loss = 0.498259
I0122 17:08:06.631635 64218 solver.cpp:285]     Train net output #0: loss = 0.498259 (* 1 = 0.498259 loss)
I0122 17:08:06.631641 64218 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 17:08:12.893939 64218 solver.cpp:266] Iteration 7300 (15.9692 iter/s, 6.26206s/100 iter), loss = 0.556979
I0122 17:08:12.894022 64218 solver.cpp:285]     Train net output #0: loss = 0.556979 (* 1 = 0.556979 loss)
I0122 17:08:12.894029 64218 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 17:08:19.174314 64218 solver.cpp:266] Iteration 7400 (15.9234 iter/s, 6.28005s/100 iter), loss = 0.409164
I0122 17:08:19.174343 64218 solver.cpp:285]     Train net output #0: loss = 0.409164 (* 1 = 0.409164 loss)
I0122 17:08:19.174365 64218 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 17:08:25.454099 64218 solver.cpp:266] Iteration 7500 (15.9248 iter/s, 6.27951s/100 iter), loss = 0.518081
I0122 17:08:25.454128 64218 solver.cpp:285]     Train net output #0: loss = 0.518081 (* 1 = 0.518081 loss)
I0122 17:08:25.454134 64218 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 17:08:31.719002 64218 solver.cpp:266] Iteration 7600 (15.9626 iter/s, 6.26463s/100 iter), loss = 0.415282
I0122 17:08:31.719029 64218 solver.cpp:285]     Train net output #0: loss = 0.415282 (* 1 = 0.415282 loss)
I0122 17:08:31.719035 64218 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 17:08:37.986205 64218 solver.cpp:266] Iteration 7700 (15.9568 iter/s, 6.26693s/100 iter), loss = 0.434642
I0122 17:08:37.986235 64218 solver.cpp:285]     Train net output #0: loss = 0.434642 (* 1 = 0.434642 loss)
I0122 17:08:37.986240 64218 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 17:08:44.258890 64218 solver.cpp:266] Iteration 7800 (15.9428 iter/s, 6.27241s/100 iter), loss = 0.482292
I0122 17:08:44.258965 64218 solver.cpp:285]     Train net output #0: loss = 0.482292 (* 1 = 0.482292 loss)
I0122 17:08:44.258972 64218 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 17:08:50.503784 64218 solver.cpp:266] Iteration 7900 (16.0139 iter/s, 6.24458s/100 iter), loss = 0.458533
I0122 17:08:50.503814 64218 solver.cpp:285]     Train net output #0: loss = 0.458533 (* 1 = 0.458533 loss)
I0122 17:08:50.503819 64218 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 17:08:56.738329 64218 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 17:08:58.206267 64218 solver.cpp:517]     Test net output #0: accuracy = 0.457555
I0122 17:08:58.206295 64218 solver.cpp:517]     Test net output #1: loss = 2.35416 (* 1 = 2.35416 loss)
I0122 17:08:58.206300 64218 solver.cpp:517]     Test net output #2: top-1 = 0.457555
I0122 17:08:58.206303 64218 solver.cpp:517]     Test net output #3: top-5 = 0.902111
I0122 17:08:58.269250 64218 solver.cpp:266] Iteration 8000 (12.8781 iter/s, 7.76514s/100 iter), loss = 0.352352
I0122 17:08:58.269281 64218 solver.cpp:285]     Train net output #0: loss = 0.352352 (* 1 = 0.352352 loss)
I0122 17:08:58.269287 64218 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 17:09:04.540339 64218 solver.cpp:266] Iteration 8100 (15.9469 iter/s, 6.27081s/100 iter), loss = 0.564125
I0122 17:09:04.540367 64218 solver.cpp:285]     Train net output #0: loss = 0.564125 (* 1 = 0.564125 loss)
I0122 17:09:04.540374 64218 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 17:09:10.808583 64218 solver.cpp:266] Iteration 8200 (15.9541 iter/s, 6.26797s/100 iter), loss = 0.602894
I0122 17:09:10.808624 64218 solver.cpp:285]     Train net output #0: loss = 0.602894 (* 1 = 0.602894 loss)
I0122 17:09:10.808629 64218 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 17:09:17.070731 64218 solver.cpp:266] Iteration 8300 (15.9697 iter/s, 6.26187s/100 iter), loss = 0.451101
I0122 17:09:17.070806 64218 solver.cpp:285]     Train net output #0: loss = 0.451101 (* 1 = 0.451101 loss)
I0122 17:09:17.070812 64218 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 17:09:23.333205 64218 solver.cpp:266] Iteration 8400 (15.9689 iter/s, 6.26216s/100 iter), loss = 0.322735
I0122 17:09:23.333235 64218 solver.cpp:285]     Train net output #0: loss = 0.322735 (* 1 = 0.322735 loss)
I0122 17:09:23.333240 64218 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 17:09:29.612231 64218 solver.cpp:266] Iteration 8500 (15.9267 iter/s, 6.27875s/100 iter), loss = 0.602343
I0122 17:09:29.612270 64218 solver.cpp:285]     Train net output #0: loss = 0.602343 (* 1 = 0.602343 loss)
I0122 17:09:29.612277 64218 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 17:09:35.885840 64218 solver.cpp:266] Iteration 8600 (15.9405 iter/s, 6.27333s/100 iter), loss = 0.392096
I0122 17:09:35.885871 64218 solver.cpp:285]     Train net output #0: loss = 0.392096 (* 1 = 0.392096 loss)
I0122 17:09:35.885876 64218 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 17:09:42.152009 64218 solver.cpp:266] Iteration 8700 (15.9594 iter/s, 6.26589s/100 iter), loss = 0.410024
I0122 17:09:42.152040 64218 solver.cpp:285]     Train net output #0: loss = 0.410024 (* 1 = 0.410024 loss)
I0122 17:09:42.152046 64218 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 17:09:48.428818 64218 solver.cpp:266] Iteration 8800 (15.9324 iter/s, 6.27654s/100 iter), loss = 0.533433
I0122 17:09:48.428933 64218 solver.cpp:285]     Train net output #0: loss = 0.533433 (* 1 = 0.533433 loss)
I0122 17:09:48.428939 64218 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 17:09:54.685359 64218 solver.cpp:266] Iteration 8900 (15.9842 iter/s, 6.25618s/100 iter), loss = 0.531568
I0122 17:09:54.685387 64218 solver.cpp:285]     Train net output #0: loss = 0.531568 (* 1 = 0.531568 loss)
I0122 17:09:54.685392 64218 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 17:10:00.898070 64218 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 17:10:02.367183 64218 solver.cpp:517]     Test net output #0: accuracy = 0.638
I0122 17:10:02.367210 64218 solver.cpp:517]     Test net output #1: loss = 1.12431 (* 1 = 1.12431 loss)
I0122 17:10:02.367214 64218 solver.cpp:517]     Test net output #2: top-1 = 0.638
I0122 17:10:02.367218 64218 solver.cpp:517]     Test net output #3: top-5 = 0.964223
I0122 17:10:02.429210 64218 solver.cpp:266] Iteration 9000 (12.914 iter/s, 7.74353s/100 iter), loss = 0.478374
I0122 17:10:02.429230 64218 solver.cpp:285]     Train net output #0: loss = 0.478374 (* 1 = 0.478374 loss)
I0122 17:10:02.429235 64218 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 17:10:08.689282 64218 solver.cpp:266] Iteration 9100 (15.9749 iter/s, 6.25981s/100 iter), loss = 0.371375
I0122 17:10:08.689322 64218 solver.cpp:285]     Train net output #0: loss = 0.371375 (* 1 = 0.371375 loss)
I0122 17:10:08.689329 64218 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 17:10:14.971745 64218 solver.cpp:266] Iteration 9200 (15.918 iter/s, 6.28218s/100 iter), loss = 0.569353
I0122 17:10:14.971774 64218 solver.cpp:285]     Train net output #0: loss = 0.569353 (* 1 = 0.569353 loss)
I0122 17:10:14.971781 64218 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 17:10:21.248735 64218 solver.cpp:266] Iteration 9300 (15.9319 iter/s, 6.27672s/100 iter), loss = 0.426938
I0122 17:10:21.248837 64218 solver.cpp:285]     Train net output #0: loss = 0.426938 (* 1 = 0.426938 loss)
I0122 17:10:21.248843 64218 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 17:10:27.514166 64218 solver.cpp:266] Iteration 9400 (15.9615 iter/s, 6.26509s/100 iter), loss = 0.495651
I0122 17:10:27.514196 64218 solver.cpp:285]     Train net output #0: loss = 0.495651 (* 1 = 0.495651 loss)
I0122 17:10:27.514202 64218 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 17:10:33.766245 64218 solver.cpp:266] Iteration 9500 (15.9954 iter/s, 6.25181s/100 iter), loss = 0.30908
I0122 17:10:33.766285 64218 solver.cpp:285]     Train net output #0: loss = 0.30908 (* 1 = 0.30908 loss)
I0122 17:10:33.766291 64218 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 17:10:40.021956 64218 solver.cpp:266] Iteration 9600 (15.9861 iter/s, 6.25543s/100 iter), loss = 0.477014
I0122 17:10:40.021984 64218 solver.cpp:285]     Train net output #0: loss = 0.477014 (* 1 = 0.477014 loss)
I0122 17:10:40.021991 64218 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 17:10:46.275190 64218 solver.cpp:266] Iteration 9700 (15.9924 iter/s, 6.25296s/100 iter), loss = 0.475628
I0122 17:10:46.275218 64218 solver.cpp:285]     Train net output #0: loss = 0.475628 (* 1 = 0.475628 loss)
I0122 17:10:46.275224 64218 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 17:10:52.543401 64218 solver.cpp:266] Iteration 9800 (15.9542 iter/s, 6.26794s/100 iter), loss = 0.381351
I0122 17:10:52.543524 64218 solver.cpp:285]     Train net output #0: loss = 0.381351 (* 1 = 0.381351 loss)
I0122 17:10:52.543529 64218 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 17:10:58.805583 64218 solver.cpp:266] Iteration 9900 (15.9698 iter/s, 6.26182s/100 iter), loss = 0.471862
I0122 17:10:58.805613 64218 solver.cpp:285]     Train net output #0: loss = 0.471862 (* 1 = 0.471862 loss)
I0122 17:10:58.805619 64218 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 17:11:05.014190 64218 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 17:11:06.496549 64218 solver.cpp:517]     Test net output #0: accuracy = 0.582889
I0122 17:11:06.496577 64218 solver.cpp:517]     Test net output #1: loss = 1.29166 (* 1 = 1.29166 loss)
I0122 17:11:06.496582 64218 solver.cpp:517]     Test net output #2: top-1 = 0.582889
I0122 17:11:06.496585 64218 solver.cpp:517]     Test net output #3: top-5 = 0.957334
I0122 17:11:06.559161 64218 solver.cpp:266] Iteration 10000 (12.8978 iter/s, 7.75325s/100 iter), loss = 0.566057
I0122 17:11:06.559181 64218 solver.cpp:285]     Train net output #0: loss = 0.566057 (* 1 = 0.566057 loss)
I0122 17:11:06.559188 64218 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 17:11:12.812595 64218 solver.cpp:266] Iteration 10100 (15.9919 iter/s, 6.25317s/100 iter), loss = 0.383686
I0122 17:11:12.812635 64218 solver.cpp:285]     Train net output #0: loss = 0.383686 (* 1 = 0.383686 loss)
I0122 17:11:12.812642 64218 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 17:11:19.095630 64218 solver.cpp:266] Iteration 10200 (15.9166 iter/s, 6.28275s/100 iter), loss = 0.271836
I0122 17:11:19.095659 64218 solver.cpp:285]     Train net output #0: loss = 0.271836 (* 1 = 0.271836 loss)
I0122 17:11:19.095665 64218 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 17:11:25.367106 64218 solver.cpp:266] Iteration 10300 (15.9459 iter/s, 6.2712s/100 iter), loss = 0.234522
I0122 17:11:25.367182 64218 solver.cpp:285]     Train net output #0: loss = 0.234522 (* 1 = 0.234522 loss)
I0122 17:11:25.367189 64218 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 17:11:31.630383 64218 solver.cpp:266] Iteration 10400 (15.9669 iter/s, 6.26296s/100 iter), loss = 0.322251
I0122 17:11:31.630412 64218 solver.cpp:285]     Train net output #0: loss = 0.322251 (* 1 = 0.322251 loss)
I0122 17:11:31.630419 64218 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 17:11:37.900972 64218 solver.cpp:266] Iteration 10500 (15.9482 iter/s, 6.27032s/100 iter), loss = 0.26901
I0122 17:11:37.901000 64218 solver.cpp:285]     Train net output #0: loss = 0.26901 (* 1 = 0.26901 loss)
I0122 17:11:37.901006 64218 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 17:11:44.170627 64218 solver.cpp:266] Iteration 10600 (15.9505 iter/s, 6.26938s/100 iter), loss = 0.27378
I0122 17:11:44.170668 64218 solver.cpp:285]     Train net output #0: loss = 0.27378 (* 1 = 0.27378 loss)
I0122 17:11:44.170675 64218 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 17:11:50.442492 64218 solver.cpp:266] Iteration 10700 (15.9449 iter/s, 6.27158s/100 iter), loss = 0.278576
I0122 17:11:50.442522 64218 solver.cpp:285]     Train net output #0: loss = 0.278576 (* 1 = 0.278576 loss)
I0122 17:11:50.442528 64218 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 17:11:56.723294 64218 solver.cpp:266] Iteration 10800 (15.9222 iter/s, 6.28053s/100 iter), loss = 0.236032
I0122 17:11:56.723390 64218 solver.cpp:285]     Train net output #0: loss = 0.236032 (* 1 = 0.236032 loss)
I0122 17:11:56.723397 64218 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 17:12:02.989523 64218 solver.cpp:266] Iteration 10900 (15.9594 iter/s, 6.26589s/100 iter), loss = 0.220214
I0122 17:12:02.989552 64218 solver.cpp:285]     Train net output #0: loss = 0.220214 (* 1 = 0.220214 loss)
I0122 17:12:02.989558 64218 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 17:12:09.187188 64218 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 17:12:10.658397 64218 solver.cpp:517]     Test net output #0: accuracy = 0.804777
I0122 17:12:10.658423 64218 solver.cpp:517]     Test net output #1: loss = 0.655865 (* 1 = 0.655865 loss)
I0122 17:12:10.658427 64218 solver.cpp:517]     Test net output #2: top-1 = 0.804777
I0122 17:12:10.658432 64218 solver.cpp:517]     Test net output #3: top-5 = 0.976445
I0122 17:12:10.721186 64218 solver.cpp:266] Iteration 11000 (12.9344 iter/s, 7.73134s/100 iter), loss = 0.271104
I0122 17:12:10.721217 64218 solver.cpp:285]     Train net output #0: loss = 0.271104 (* 1 = 0.271104 loss)
I0122 17:12:10.721225 64218 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 17:12:16.980860 64218 solver.cpp:266] Iteration 11100 (15.9759 iter/s, 6.25941s/100 iter), loss = 0.228013
I0122 17:12:16.980890 64218 solver.cpp:285]     Train net output #0: loss = 0.228013 (* 1 = 0.228013 loss)
I0122 17:12:16.980895 64218 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 17:12:23.239878 64218 solver.cpp:266] Iteration 11200 (15.9776 iter/s, 6.25875s/100 iter), loss = 0.14163
I0122 17:12:23.239907 64218 solver.cpp:285]     Train net output #0: loss = 0.14163 (* 1 = 0.14163 loss)
I0122 17:12:23.239912 64218 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 17:12:29.511394 64218 solver.cpp:266] Iteration 11300 (15.9458 iter/s, 6.27124s/100 iter), loss = 0.157528
I0122 17:12:29.511478 64218 solver.cpp:285]     Train net output #0: loss = 0.157528 (* 1 = 0.157528 loss)
I0122 17:12:29.511485 64218 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 17:12:35.767679 64218 solver.cpp:266] Iteration 11400 (15.9848 iter/s, 6.25596s/100 iter), loss = 0.128527
I0122 17:12:35.767707 64218 solver.cpp:285]     Train net output #0: loss = 0.128527 (* 1 = 0.128527 loss)
I0122 17:12:35.767714 64218 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 17:12:42.042912 64218 solver.cpp:266] Iteration 11500 (15.9363 iter/s, 6.27496s/100 iter), loss = 0.20788
I0122 17:12:42.042940 64218 solver.cpp:285]     Train net output #0: loss = 0.20788 (* 1 = 0.20788 loss)
I0122 17:12:42.042946 64218 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 17:12:48.322382 64218 solver.cpp:266] Iteration 11600 (15.9256 iter/s, 6.2792s/100 iter), loss = 0.139032
I0122 17:12:48.322412 64218 solver.cpp:285]     Train net output #0: loss = 0.139032 (* 1 = 0.139032 loss)
I0122 17:12:48.322417 64218 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 17:12:54.571236 64218 solver.cpp:266] Iteration 11700 (16.0036 iter/s, 6.24858s/100 iter), loss = 0.170852
I0122 17:12:54.571266 64218 solver.cpp:285]     Train net output #0: loss = 0.170852 (* 1 = 0.170852 loss)
I0122 17:12:54.571272 64218 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 17:13:00.829313 64218 solver.cpp:266] Iteration 11800 (15.98 iter/s, 6.2578s/100 iter), loss = 0.178797
I0122 17:13:00.829377 64218 solver.cpp:285]     Train net output #0: loss = 0.178797 (* 1 = 0.178797 loss)
I0122 17:13:00.829383 64218 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 17:13:07.088456 64218 solver.cpp:266] Iteration 11900 (15.9774 iter/s, 6.25884s/100 iter), loss = 0.155719
I0122 17:13:07.088495 64218 solver.cpp:285]     Train net output #0: loss = 0.155719 (* 1 = 0.155719 loss)
I0122 17:13:07.088501 64218 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 17:13:13.300796 64218 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 17:13:14.756661 64218 solver.cpp:517]     Test net output #0: accuracy = 0.667
I0122 17:13:14.756690 64218 solver.cpp:517]     Test net output #1: loss = 1.04871 (* 1 = 1.04871 loss)
I0122 17:13:14.756693 64218 solver.cpp:517]     Test net output #2: top-1 = 0.667
I0122 17:13:14.756697 64218 solver.cpp:517]     Test net output #3: top-5 = 0.933889
I0122 17:13:14.819502 64218 solver.cpp:266] Iteration 12000 (12.9354 iter/s, 7.73071s/100 iter), loss = 0.110507
I0122 17:13:14.819533 64218 solver.cpp:285]     Train net output #0: loss = 0.110507 (* 1 = 0.110507 loss)
I0122 17:13:14.819540 64218 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 17:13:21.069730 64218 solver.cpp:266] Iteration 12100 (16.0001 iter/s, 6.24996s/100 iter), loss = 0.0896993
I0122 17:13:21.069759 64218 solver.cpp:285]     Train net output #0: loss = 0.0896993 (* 1 = 0.0896993 loss)
I0122 17:13:21.069764 64218 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 17:13:27.348721 64218 solver.cpp:266] Iteration 12200 (15.9268 iter/s, 6.27872s/100 iter), loss = 0.147041
I0122 17:13:27.348749 64218 solver.cpp:285]     Train net output #0: loss = 0.147041 (* 1 = 0.147041 loss)
I0122 17:13:27.348755 64218 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 17:13:33.629935 64218 solver.cpp:266] Iteration 12300 (15.9212 iter/s, 6.28094s/100 iter), loss = 0.124082
I0122 17:13:33.630017 64218 solver.cpp:285]     Train net output #0: loss = 0.124082 (* 1 = 0.124082 loss)
I0122 17:13:33.630024 64218 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 17:13:39.893853 64218 solver.cpp:266] Iteration 12400 (15.9653 iter/s, 6.2636s/100 iter), loss = 0.1989
I0122 17:13:39.893896 64218 solver.cpp:285]     Train net output #0: loss = 0.1989 (* 1 = 0.1989 loss)
I0122 17:13:39.893906 64218 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 17:13:46.149581 64218 solver.cpp:266] Iteration 12500 (15.9861 iter/s, 6.25544s/100 iter), loss = 0.137989
I0122 17:13:46.149612 64218 solver.cpp:285]     Train net output #0: loss = 0.137989 (* 1 = 0.137989 loss)
I0122 17:13:46.149618 64218 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 17:13:52.403448 64218 solver.cpp:266] Iteration 12600 (15.9908 iter/s, 6.25359s/100 iter), loss = 0.1242
I0122 17:13:52.403479 64218 solver.cpp:285]     Train net output #0: loss = 0.124199 (* 1 = 0.124199 loss)
I0122 17:13:52.403486 64218 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 17:13:58.671766 64218 solver.cpp:266] Iteration 12700 (15.9539 iter/s, 6.26804s/100 iter), loss = 0.131932
I0122 17:13:58.671797 64218 solver.cpp:285]     Train net output #0: loss = 0.131932 (* 1 = 0.131932 loss)
I0122 17:13:58.671802 64218 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 17:14:04.960724 64218 solver.cpp:266] Iteration 12800 (15.9016 iter/s, 6.28868s/100 iter), loss = 0.201801
I0122 17:14:04.960789 64218 solver.cpp:285]     Train net output #0: loss = 0.201801 (* 1 = 0.201801 loss)
I0122 17:14:04.960796 64218 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 17:14:11.208737 64218 solver.cpp:266] Iteration 12900 (16.0059 iter/s, 6.24771s/100 iter), loss = 0.0404426
I0122 17:14:11.208770 64218 solver.cpp:285]     Train net output #0: loss = 0.0404426 (* 1 = 0.0404426 loss)
I0122 17:14:11.208775 64218 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 17:14:17.400668 64218 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 17:14:18.855540 64218 solver.cpp:517]     Test net output #0: accuracy = 0.599556
I0122 17:14:18.855567 64218 solver.cpp:517]     Test net output #1: loss = 1.22786 (* 1 = 1.22786 loss)
I0122 17:14:18.855571 64218 solver.cpp:517]     Test net output #2: top-1 = 0.599556
I0122 17:14:18.855576 64218 solver.cpp:517]     Test net output #3: top-5 = 0.927667
I0122 17:14:18.917548 64218 solver.cpp:266] Iteration 13000 (12.9727 iter/s, 7.70849s/100 iter), loss = 0.0955092
I0122 17:14:18.917569 64218 solver.cpp:285]     Train net output #0: loss = 0.0955092 (* 1 = 0.0955092 loss)
I0122 17:14:18.917575 64218 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 17:14:25.176697 64218 solver.cpp:266] Iteration 13100 (15.9773 iter/s, 6.25889s/100 iter), loss = 0.124461
I0122 17:14:25.176726 64218 solver.cpp:285]     Train net output #0: loss = 0.124461 (* 1 = 0.124461 loss)
I0122 17:14:25.176731 64218 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 17:14:31.460906 64218 solver.cpp:266] Iteration 13200 (15.9136 iter/s, 6.28394s/100 iter), loss = 0.13432
I0122 17:14:31.460935 64218 solver.cpp:285]     Train net output #0: loss = 0.13432 (* 1 = 0.13432 loss)
I0122 17:14:31.460942 64218 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 17:14:37.743028 64218 solver.cpp:266] Iteration 13300 (15.9189 iter/s, 6.28185s/100 iter), loss = 0.15012
I0122 17:14:37.743203 64218 solver.cpp:285]     Train net output #0: loss = 0.15012 (* 1 = 0.15012 loss)
I0122 17:14:37.743224 64218 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 17:14:44.026334 64218 solver.cpp:266] Iteration 13400 (15.9162 iter/s, 6.2829s/100 iter), loss = 0.128189
I0122 17:14:44.026374 64218 solver.cpp:285]     Train net output #0: loss = 0.128189 (* 1 = 0.128189 loss)
I0122 17:14:44.026381 64218 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 17:14:50.306200 64218 solver.cpp:266] Iteration 13500 (15.9246 iter/s, 6.27958s/100 iter), loss = 0.0957963
I0122 17:14:50.306227 64218 solver.cpp:285]     Train net output #0: loss = 0.0957963 (* 1 = 0.0957963 loss)
I0122 17:14:50.306232 64218 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 17:14:56.560322 64218 solver.cpp:266] Iteration 13600 (15.9901 iter/s, 6.25385s/100 iter), loss = 0.0520561
I0122 17:14:56.560353 64218 solver.cpp:285]     Train net output #0: loss = 0.0520561 (* 1 = 0.0520561 loss)
I0122 17:14:56.560359 64218 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 17:15:02.838423 64218 solver.cpp:266] Iteration 13700 (15.9291 iter/s, 6.27783s/100 iter), loss = 0.0683967
I0122 17:15:02.838454 64218 solver.cpp:285]     Train net output #0: loss = 0.0683966 (* 1 = 0.0683966 loss)
I0122 17:15:02.838459 64218 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 17:15:09.123982 64218 solver.cpp:266] Iteration 13800 (15.9102 iter/s, 6.28529s/100 iter), loss = 0.114632
I0122 17:15:09.124049 64218 solver.cpp:285]     Train net output #0: loss = 0.114632 (* 1 = 0.114632 loss)
I0122 17:15:09.124056 64218 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 17:15:15.386554 64218 solver.cpp:266] Iteration 13900 (15.9687 iter/s, 6.26226s/100 iter), loss = 0.0744611
I0122 17:15:15.386584 64218 solver.cpp:285]     Train net output #0: loss = 0.0744611 (* 1 = 0.0744611 loss)
I0122 17:15:15.386590 64218 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 17:15:21.601747 64218 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 17:15:23.065255 64218 solver.cpp:517]     Test net output #0: accuracy = 0.688444
I0122 17:15:23.065282 64218 solver.cpp:517]     Test net output #1: loss = 0.989285 (* 1 = 0.989285 loss)
I0122 17:15:23.065287 64218 solver.cpp:517]     Test net output #2: top-1 = 0.688444
I0122 17:15:23.065290 64218 solver.cpp:517]     Test net output #3: top-5 = 0.938222
I0122 17:15:23.127012 64218 solver.cpp:266] Iteration 14000 (12.9197 iter/s, 7.74013s/100 iter), loss = 0.0543464
I0122 17:15:23.127043 64218 solver.cpp:285]     Train net output #0: loss = 0.0543464 (* 1 = 0.0543464 loss)
I0122 17:15:23.127050 64218 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 17:15:29.396584 64218 solver.cpp:266] Iteration 14100 (15.9507 iter/s, 6.2693s/100 iter), loss = 0.102429
I0122 17:15:29.396615 64218 solver.cpp:285]     Train net output #0: loss = 0.102429 (* 1 = 0.102429 loss)
I0122 17:15:29.396621 64218 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 17:15:35.642151 64218 solver.cpp:266] Iteration 14200 (16.0121 iter/s, 6.2453s/100 iter), loss = 0.069733
I0122 17:15:35.642181 64218 solver.cpp:285]     Train net output #0: loss = 0.069733 (* 1 = 0.069733 loss)
I0122 17:15:35.642187 64218 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 17:15:41.918179 64218 solver.cpp:266] Iteration 14300 (15.9343 iter/s, 6.27575s/100 iter), loss = 0.0909426
I0122 17:15:41.918282 64218 solver.cpp:285]     Train net output #0: loss = 0.0909426 (* 1 = 0.0909426 loss)
I0122 17:15:41.918288 64218 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 17:15:48.176841 64218 solver.cpp:266] Iteration 14400 (15.9787 iter/s, 6.25832s/100 iter), loss = 0.072023
I0122 17:15:48.176872 64218 solver.cpp:285]     Train net output #0: loss = 0.072023 (* 1 = 0.072023 loss)
I0122 17:15:48.176877 64218 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 17:15:54.453248 64218 solver.cpp:266] Iteration 14500 (15.9334 iter/s, 6.27613s/100 iter), loss = 0.110764
I0122 17:15:54.453277 64218 solver.cpp:285]     Train net output #0: loss = 0.110764 (* 1 = 0.110764 loss)
I0122 17:15:54.453284 64218 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 17:16:00.733183 64218 solver.cpp:266] Iteration 14600 (15.9244 iter/s, 6.27966s/100 iter), loss = 0.140075
I0122 17:16:00.733212 64218 solver.cpp:285]     Train net output #0: loss = 0.140075 (* 1 = 0.140075 loss)
I0122 17:16:00.733217 64218 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 17:16:06.995154 64218 solver.cpp:266] Iteration 14700 (15.9701 iter/s, 6.2617s/100 iter), loss = 0.0661887
I0122 17:16:06.995185 64218 solver.cpp:285]     Train net output #0: loss = 0.0661887 (* 1 = 0.0661887 loss)
I0122 17:16:06.995191 64218 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 17:16:13.244534 64218 solver.cpp:266] Iteration 14800 (16.0023 iter/s, 6.24911s/100 iter), loss = 0.11678
I0122 17:16:13.244617 64218 solver.cpp:285]     Train net output #0: loss = 0.11678 (* 1 = 0.11678 loss)
I0122 17:16:13.244624 64218 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 17:16:19.521631 64218 solver.cpp:266] Iteration 14900 (15.9318 iter/s, 6.27677s/100 iter), loss = 0.0707194
I0122 17:16:19.521670 64218 solver.cpp:285]     Train net output #0: loss = 0.0707193 (* 1 = 0.0707193 loss)
I0122 17:16:19.521677 64218 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 17:16:25.718194 64218 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 17:16:27.185252 64218 solver.cpp:517]     Test net output #0: accuracy = 0.694889
I0122 17:16:27.185289 64218 solver.cpp:517]     Test net output #1: loss = 0.959884 (* 1 = 0.959884 loss)
I0122 17:16:27.185294 64218 solver.cpp:517]     Test net output #2: top-1 = 0.694889
I0122 17:16:27.185297 64218 solver.cpp:517]     Test net output #3: top-5 = 0.971889
I0122 17:16:27.249061 64218 solver.cpp:266] Iteration 15000 (12.9415 iter/s, 7.7271s/100 iter), loss = 0.0406867
I0122 17:16:27.249092 64218 solver.cpp:285]     Train net output #0: loss = 0.0406867 (* 1 = 0.0406867 loss)
I0122 17:16:27.249099 64218 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 17:16:33.499583 64218 solver.cpp:266] Iteration 15100 (15.9993 iter/s, 6.25026s/100 iter), loss = 0.0428607
I0122 17:16:33.499613 64218 solver.cpp:285]     Train net output #0: loss = 0.0428607 (* 1 = 0.0428607 loss)
I0122 17:16:33.499617 64218 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 17:16:39.771982 64218 solver.cpp:266] Iteration 15200 (15.9436 iter/s, 6.27213s/100 iter), loss = 0.182874
I0122 17:16:39.772012 64218 solver.cpp:285]     Train net output #0: loss = 0.182874 (* 1 = 0.182874 loss)
I0122 17:16:39.772018 64218 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 17:16:46.037919 64218 solver.cpp:266] Iteration 15300 (15.96 iter/s, 6.26567s/100 iter), loss = 0.126047
I0122 17:16:46.038020 64218 solver.cpp:285]     Train net output #0: loss = 0.126047 (* 1 = 0.126047 loss)
I0122 17:16:46.038027 64218 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 17:16:52.297401 64218 solver.cpp:266] Iteration 15400 (15.9766 iter/s, 6.25914s/100 iter), loss = 0.126433
I0122 17:16:52.297430 64218 solver.cpp:285]     Train net output #0: loss = 0.126433 (* 1 = 0.126433 loss)
I0122 17:16:52.297436 64218 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 17:16:58.567685 64218 solver.cpp:266] Iteration 15500 (15.9489 iter/s, 6.27001s/100 iter), loss = 0.093863
I0122 17:16:58.567726 64218 solver.cpp:285]     Train net output #0: loss = 0.093863 (* 1 = 0.093863 loss)
I0122 17:16:58.567732 64218 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 17:17:04.817373 64218 solver.cpp:266] Iteration 15600 (16.0015 iter/s, 6.24941s/100 iter), loss = 0.0703308
I0122 17:17:04.817404 64218 solver.cpp:285]     Train net output #0: loss = 0.0703308 (* 1 = 0.0703308 loss)
I0122 17:17:04.817409 64218 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 17:17:11.081634 64218 solver.cpp:266] Iteration 15700 (15.9643 iter/s, 6.26399s/100 iter), loss = 0.132121
I0122 17:17:11.081665 64218 solver.cpp:285]     Train net output #0: loss = 0.132121 (* 1 = 0.132121 loss)
I0122 17:17:11.081671 64218 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 17:17:17.351608 64218 solver.cpp:266] Iteration 15800 (15.9497 iter/s, 6.2697s/100 iter), loss = 0.0710229
I0122 17:17:17.351732 64218 solver.cpp:285]     Train net output #0: loss = 0.0710229 (* 1 = 0.0710229 loss)
I0122 17:17:17.351740 64218 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 17:17:23.613402 64218 solver.cpp:266] Iteration 15900 (15.9708 iter/s, 6.26143s/100 iter), loss = 0.115421
I0122 17:17:23.613443 64218 solver.cpp:285]     Train net output #0: loss = 0.115421 (* 1 = 0.115421 loss)
I0122 17:17:23.613449 64218 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 17:17:29.823173 64218 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 17:17:31.283668 64218 solver.cpp:517]     Test net output #0: accuracy = 0.811333
I0122 17:17:31.283694 64218 solver.cpp:517]     Test net output #1: loss = 0.580165 (* 1 = 0.580165 loss)
I0122 17:17:31.283699 64218 solver.cpp:517]     Test net output #2: top-1 = 0.811333
I0122 17:17:31.283704 64218 solver.cpp:517]     Test net output #3: top-5 = 0.985222
I0122 17:17:31.346287 64218 solver.cpp:266] Iteration 16000 (12.9323 iter/s, 7.73255s/100 iter), loss = 0.0508728
I0122 17:17:31.346307 64218 solver.cpp:285]     Train net output #0: loss = 0.0508728 (* 1 = 0.0508728 loss)
I0122 17:17:31.346313 64218 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 17:17:37.584010 64218 solver.cpp:266] Iteration 16100 (16.0322 iter/s, 6.23746s/100 iter), loss = 0.150211
I0122 17:17:37.584040 64218 solver.cpp:285]     Train net output #0: loss = 0.150211 (* 1 = 0.150211 loss)
I0122 17:17:37.584046 64218 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 17:17:43.868631 64218 solver.cpp:266] Iteration 16200 (15.9125 iter/s, 6.28435s/100 iter), loss = 0.0640948
I0122 17:17:43.868661 64218 solver.cpp:285]     Train net output #0: loss = 0.0640948 (* 1 = 0.0640948 loss)
I0122 17:17:43.868667 64218 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 17:17:50.140395 64218 solver.cpp:266] Iteration 16300 (15.9452 iter/s, 6.27149s/100 iter), loss = 0.170144
I0122 17:17:50.140460 64218 solver.cpp:285]     Train net output #0: loss = 0.170144 (* 1 = 0.170144 loss)
I0122 17:17:50.140466 64218 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 17:17:56.392280 64218 solver.cpp:266] Iteration 16400 (15.996 iter/s, 6.25158s/100 iter), loss = 0.0424423
I0122 17:17:56.392320 64218 solver.cpp:285]     Train net output #0: loss = 0.0424423 (* 1 = 0.0424423 loss)
I0122 17:17:56.392328 64218 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 17:18:02.642910 64218 solver.cpp:266] Iteration 16500 (15.9991 iter/s, 6.25035s/100 iter), loss = 0.0652235
I0122 17:18:02.642948 64218 solver.cpp:285]     Train net output #0: loss = 0.0652235 (* 1 = 0.0652235 loss)
I0122 17:18:02.642954 64218 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 17:18:08.919570 64218 solver.cpp:266] Iteration 16600 (15.9328 iter/s, 6.27638s/100 iter), loss = 0.0652025
I0122 17:18:08.919600 64218 solver.cpp:285]     Train net output #0: loss = 0.0652025 (* 1 = 0.0652025 loss)
I0122 17:18:08.919606 64218 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 17:18:15.187209 64218 solver.cpp:266] Iteration 16700 (15.9557 iter/s, 6.26737s/100 iter), loss = 0.126824
I0122 17:18:15.187238 64218 solver.cpp:285]     Train net output #0: loss = 0.126824 (* 1 = 0.126824 loss)
I0122 17:18:15.187245 64218 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 17:18:21.437155 64218 solver.cpp:266] Iteration 16800 (16.0008 iter/s, 6.24968s/100 iter), loss = 0.107433
I0122 17:18:21.437227 64218 solver.cpp:285]     Train net output #0: loss = 0.107433 (* 1 = 0.107433 loss)
I0122 17:18:21.437233 64218 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 17:18:27.693341 64218 solver.cpp:266] Iteration 16900 (15.985 iter/s, 6.25587s/100 iter), loss = 0.174938
I0122 17:18:27.693382 64218 solver.cpp:285]     Train net output #0: loss = 0.174938 (* 1 = 0.174938 loss)
I0122 17:18:27.693387 64218 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 17:18:33.912693 64218 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 17:18:35.379014 64218 solver.cpp:517]     Test net output #0: accuracy = 0.824555
I0122 17:18:35.379040 64218 solver.cpp:517]     Test net output #1: loss = 0.538081 (* 1 = 0.538081 loss)
I0122 17:18:35.379043 64218 solver.cpp:517]     Test net output #2: top-1 = 0.824555
I0122 17:18:35.379047 64218 solver.cpp:517]     Test net output #3: top-5 = 0.991445
I0122 17:18:35.441232 64218 solver.cpp:266] Iteration 17000 (12.9073 iter/s, 7.74756s/100 iter), loss = 0.0896869
I0122 17:18:35.441252 64218 solver.cpp:285]     Train net output #0: loss = 0.0896869 (* 1 = 0.0896869 loss)
I0122 17:18:35.441258 64218 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 17:18:41.717098 64218 solver.cpp:266] Iteration 17100 (15.9347 iter/s, 6.2756s/100 iter), loss = 0.0877546
I0122 17:18:41.717129 64218 solver.cpp:285]     Train net output #0: loss = 0.0877546 (* 1 = 0.0877546 loss)
I0122 17:18:41.717135 64218 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 17:18:47.982172 64218 solver.cpp:266] Iteration 17200 (15.9622 iter/s, 6.2648s/100 iter), loss = 0.119453
I0122 17:18:47.982201 64218 solver.cpp:285]     Train net output #0: loss = 0.119453 (* 1 = 0.119453 loss)
I0122 17:18:47.982208 64218 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 17:18:54.241348 64218 solver.cpp:266] Iteration 17300 (15.9772 iter/s, 6.25891s/100 iter), loss = 0.13167
I0122 17:18:54.241431 64218 solver.cpp:285]     Train net output #0: loss = 0.13167 (* 1 = 0.13167 loss)
I0122 17:18:54.241438 64218 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 17:19:00.503950 64218 solver.cpp:266] Iteration 17400 (15.9686 iter/s, 6.26228s/100 iter), loss = 0.165236
I0122 17:19:00.503989 64218 solver.cpp:285]     Train net output #0: loss = 0.165236 (* 1 = 0.165236 loss)
I0122 17:19:00.503995 64218 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 17:19:06.779741 64218 solver.cpp:266] Iteration 17500 (15.935 iter/s, 6.27551s/100 iter), loss = 0.11758
I0122 17:19:06.779772 64218 solver.cpp:285]     Train net output #0: loss = 0.11758 (* 1 = 0.11758 loss)
I0122 17:19:06.779778 64218 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 17:19:13.075115 64218 solver.cpp:266] Iteration 17600 (15.8854 iter/s, 6.2951s/100 iter), loss = 0.0586217
I0122 17:19:13.075158 64218 solver.cpp:285]     Train net output #0: loss = 0.0586217 (* 1 = 0.0586217 loss)
I0122 17:19:13.075165 64218 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 17:19:19.325656 64218 solver.cpp:266] Iteration 17700 (15.9993 iter/s, 6.25026s/100 iter), loss = 0.140459
I0122 17:19:19.325686 64218 solver.cpp:285]     Train net output #0: loss = 0.140459 (* 1 = 0.140459 loss)
I0122 17:19:19.325691 64218 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 17:19:25.576395 64218 solver.cpp:266] Iteration 17800 (15.9988 iter/s, 6.25047s/100 iter), loss = 0.114873
I0122 17:19:25.576459 64218 solver.cpp:285]     Train net output #0: loss = 0.114873 (* 1 = 0.114873 loss)
I0122 17:19:25.576467 64218 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 17:19:31.857674 64218 solver.cpp:266] Iteration 17900 (15.9211 iter/s, 6.28097s/100 iter), loss = 0.069155
I0122 17:19:31.857705 64218 solver.cpp:285]     Train net output #0: loss = 0.069155 (* 1 = 0.069155 loss)
I0122 17:19:31.857712 64218 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 17:19:38.078428 64218 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 17:19:39.548941 64218 solver.cpp:517]     Test net output #0: accuracy = 0.820222
I0122 17:19:39.548969 64218 solver.cpp:517]     Test net output #1: loss = 0.607669 (* 1 = 0.607669 loss)
I0122 17:19:39.548972 64218 solver.cpp:517]     Test net output #2: top-1 = 0.820222
I0122 17:19:39.548976 64218 solver.cpp:517]     Test net output #3: top-5 = 0.989667
I0122 17:19:39.612906 64218 solver.cpp:266] Iteration 18000 (12.8951 iter/s, 7.75491s/100 iter), loss = 0.0680041
I0122 17:19:39.612926 64218 solver.cpp:285]     Train net output #0: loss = 0.0680041 (* 1 = 0.0680041 loss)
I0122 17:19:39.612931 64218 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 17:19:45.858721 64218 solver.cpp:266] Iteration 18100 (16.0114 iter/s, 6.24556s/100 iter), loss = 0.161474
I0122 17:19:45.858748 64218 solver.cpp:285]     Train net output #0: loss = 0.161474 (* 1 = 0.161474 loss)
I0122 17:19:45.858753 64218 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 17:19:52.131618 64218 solver.cpp:266] Iteration 18200 (15.9423 iter/s, 6.27263s/100 iter), loss = 0.0325364
I0122 17:19:52.131647 64218 solver.cpp:285]     Train net output #0: loss = 0.0325364 (* 1 = 0.0325364 loss)
I0122 17:19:52.131654 64218 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 17:19:58.400857 64218 solver.cpp:266] Iteration 18300 (15.9516 iter/s, 6.26897s/100 iter), loss = 0.151864
I0122 17:19:58.400951 64218 solver.cpp:285]     Train net output #0: loss = 0.151864 (* 1 = 0.151864 loss)
I0122 17:19:58.400959 64218 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 17:20:04.663712 64218 solver.cpp:266] Iteration 18400 (15.968 iter/s, 6.26252s/100 iter), loss = 0.0875673
I0122 17:20:04.663743 64218 solver.cpp:285]     Train net output #0: loss = 0.0875673 (* 1 = 0.0875673 loss)
I0122 17:20:04.663748 64218 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 17:20:10.920352 64218 solver.cpp:266] Iteration 18500 (15.9837 iter/s, 6.25637s/100 iter), loss = 0.111194
I0122 17:20:10.920382 64218 solver.cpp:285]     Train net output #0: loss = 0.111194 (* 1 = 0.111194 loss)
I0122 17:20:10.920388 64218 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 17:20:17.200429 64218 solver.cpp:266] Iteration 18600 (15.9241 iter/s, 6.27981s/100 iter), loss = 0.131505
I0122 17:20:17.200457 64218 solver.cpp:285]     Train net output #0: loss = 0.131505 (* 1 = 0.131505 loss)
I0122 17:20:17.200464 64218 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 17:20:23.470499 64218 solver.cpp:266] Iteration 18700 (15.9495 iter/s, 6.2698s/100 iter), loss = 0.0598872
I0122 17:20:23.470541 64218 solver.cpp:285]     Train net output #0: loss = 0.0598871 (* 1 = 0.0598871 loss)
I0122 17:20:23.470547 64218 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 17:20:29.732687 64218 solver.cpp:266] Iteration 18800 (15.9696 iter/s, 6.26191s/100 iter), loss = 0.0793546
I0122 17:20:29.732750 64218 solver.cpp:285]     Train net output #0: loss = 0.0793545 (* 1 = 0.0793545 loss)
I0122 17:20:29.732756 64218 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 17:20:36.009912 64218 solver.cpp:266] Iteration 18900 (15.9314 iter/s, 6.27692s/100 iter), loss = 0.0775995
I0122 17:20:36.009943 64218 solver.cpp:285]     Train net output #0: loss = 0.0775995 (* 1 = 0.0775995 loss)
I0122 17:20:36.009949 64218 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 17:20:42.210656 64218 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 17:20:43.673355 64218 solver.cpp:517]     Test net output #0: accuracy = 0.836667
I0122 17:20:43.673380 64218 solver.cpp:517]     Test net output #1: loss = 0.527093 (* 1 = 0.527093 loss)
I0122 17:20:43.673385 64218 solver.cpp:517]     Test net output #2: top-1 = 0.836667
I0122 17:20:43.673389 64218 solver.cpp:517]     Test net output #3: top-5 = 0.992111
I0122 17:20:43.737213 64218 solver.cpp:266] Iteration 19000 (12.9417 iter/s, 7.72698s/100 iter), loss = 0.0936135
I0122 17:20:43.737233 64218 solver.cpp:285]     Train net output #0: loss = 0.0936134 (* 1 = 0.0936134 loss)
I0122 17:20:43.737241 64218 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 17:20:50.029285 64218 solver.cpp:266] Iteration 19100 (15.8937 iter/s, 6.29181s/100 iter), loss = 0.134625
I0122 17:20:50.029314 64218 solver.cpp:285]     Train net output #0: loss = 0.134625 (* 1 = 0.134625 loss)
I0122 17:20:50.029320 64218 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 17:20:56.304391 64218 solver.cpp:266] Iteration 19200 (15.9367 iter/s, 6.27483s/100 iter), loss = 0.0911594
I0122 17:20:56.304421 64218 solver.cpp:285]     Train net output #0: loss = 0.0911593 (* 1 = 0.0911593 loss)
I0122 17:20:56.304426 64218 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 17:21:02.675509 64218 solver.cpp:266] Iteration 19300 (15.6965 iter/s, 6.37084s/100 iter), loss = 0.054451
I0122 17:21:02.675606 64218 solver.cpp:285]     Train net output #0: loss = 0.0544509 (* 1 = 0.0544509 loss)
I0122 17:21:02.675613 64218 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 17:21:09.037307 64218 solver.cpp:266] Iteration 19400 (15.7197 iter/s, 6.36146s/100 iter), loss = 0.061913
I0122 17:21:09.037336 64218 solver.cpp:285]     Train net output #0: loss = 0.0619129 (* 1 = 0.0619129 loss)
I0122 17:21:09.037343 64218 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 17:21:15.321949 64218 solver.cpp:266] Iteration 19500 (15.9125 iter/s, 6.28437s/100 iter), loss = 0.0533869
I0122 17:21:15.321980 64218 solver.cpp:285]     Train net output #0: loss = 0.0533868 (* 1 = 0.0533868 loss)
I0122 17:21:15.321986 64218 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 17:21:21.580121 64218 solver.cpp:266] Iteration 19600 (15.9798 iter/s, 6.2579s/100 iter), loss = 0.131535
I0122 17:21:21.580152 64218 solver.cpp:285]     Train net output #0: loss = 0.131535 (* 1 = 0.131535 loss)
I0122 17:21:21.580157 64218 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 17:21:27.895766 64218 solver.cpp:266] Iteration 19700 (15.8344 iter/s, 6.31537s/100 iter), loss = 0.108643
I0122 17:21:27.895808 64218 solver.cpp:285]     Train net output #0: loss = 0.108643 (* 1 = 0.108643 loss)
I0122 17:21:27.895814 64218 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 17:21:34.235096 64218 solver.cpp:266] Iteration 19800 (15.7752 iter/s, 6.33905s/100 iter), loss = 0.0936802
I0122 17:21:34.235229 64218 solver.cpp:285]     Train net output #0: loss = 0.0936801 (* 1 = 0.0936801 loss)
I0122 17:21:34.235236 64218 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 17:21:40.599962 64218 solver.cpp:266] Iteration 19900 (15.7122 iter/s, 6.36449s/100 iter), loss = 0.110356
I0122 17:21:40.600004 64218 solver.cpp:285]     Train net output #0: loss = 0.110356 (* 1 = 0.110356 loss)
I0122 17:21:40.600010 64218 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 17:21:46.858891 64218 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_20000.caffemodel
I0122 17:21:46.912647 64218 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_20000.solverstate
I0122 17:21:46.920990 64218 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 17:21:48.389123 64218 solver.cpp:517]     Test net output #0: accuracy = 0.783222
I0122 17:21:48.389151 64218 solver.cpp:517]     Test net output #1: loss = 0.810611 (* 1 = 0.810611 loss)
I0122 17:21:48.389155 64218 solver.cpp:517]     Test net output #2: top-1 = 0.783222
I0122 17:21:48.389159 64218 solver.cpp:517]     Test net output #3: top-5 = 0.989889
I0122 17:21:48.453270 64218 solver.cpp:266] Iteration 20000 (12.734 iter/s, 7.85297s/100 iter), loss = 0.0895783
I0122 17:21:48.453292 64218 solver.cpp:285]     Train net output #0: loss = 0.0895782 (* 1 = 0.0895782 loss)
I0122 17:21:48.453299 64218 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 17:21:54.766280 64218 solver.cpp:266] Iteration 20100 (15.841 iter/s, 6.31274s/100 iter), loss = 0.0705072
I0122 17:21:54.766310 64218 solver.cpp:285]     Train net output #0: loss = 0.0705071 (* 1 = 0.0705071 loss)
I0122 17:21:54.766316 64218 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 17:22:01.048208 64218 solver.cpp:266] Iteration 20200 (15.9194 iter/s, 6.28166s/100 iter), loss = 0.0802972
I0122 17:22:01.048239 64218 solver.cpp:285]     Train net output #0: loss = 0.0802971 (* 1 = 0.0802971 loss)
I0122 17:22:01.048244 64218 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 17:22:07.313750 64218 solver.cpp:266] Iteration 20300 (15.961 iter/s, 6.26527s/100 iter), loss = 0.0277703
I0122 17:22:07.313880 64218 solver.cpp:285]     Train net output #0: loss = 0.0277702 (* 1 = 0.0277702 loss)
I0122 17:22:07.313889 64218 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 17:22:13.588203 64218 solver.cpp:266] Iteration 20400 (15.9386 iter/s, 6.27408s/100 iter), loss = 0.0723343
I0122 17:22:13.588234 64218 solver.cpp:285]     Train net output #0: loss = 0.0723342 (* 1 = 0.0723342 loss)
I0122 17:22:13.588240 64218 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 17:22:22.085868 64218 solver.cpp:266] Iteration 20500 (11.7684 iter/s, 8.49731s/100 iter), loss = 0.026555
I0122 17:22:22.085901 64218 solver.cpp:285]     Train net output #0: loss = 0.0265549 (* 1 = 0.0265549 loss)
I0122 17:22:22.085911 64218 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 17:22:31.938289 64218 solver.cpp:266] Iteration 20600 (10.1502 iter/s, 9.85201s/100 iter), loss = 0.0393766
I0122 17:22:31.938321 64218 solver.cpp:285]     Train net output #0: loss = 0.0393765 (* 1 = 0.0393765 loss)
I0122 17:22:31.938328 64218 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 17:22:41.809422 64218 solver.cpp:266] Iteration 20700 (10.131 iter/s, 9.87072s/100 iter), loss = 0.0242083
I0122 17:22:41.809568 64218 solver.cpp:285]     Train net output #0: loss = 0.0242083 (* 1 = 0.0242083 loss)
I0122 17:22:41.809576 64218 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 17:22:51.739517 64218 solver.cpp:266] Iteration 20800 (10.0709 iter/s, 9.92957s/100 iter), loss = 0.0218761
I0122 17:22:51.739562 64218 solver.cpp:285]     Train net output #0: loss = 0.0218761 (* 1 = 0.0218761 loss)
I0122 17:22:51.739568 64218 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 17:23:01.719857 64218 solver.cpp:266] Iteration 20900 (10.0201 iter/s, 9.97991s/100 iter), loss = 0.00860927
I0122 17:23:01.719900 64218 solver.cpp:285]     Train net output #0: loss = 0.00860919 (* 1 = 0.00860919 loss)
I0122 17:23:01.719908 64218 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 17:23:11.583801 64218 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 17:23:13.832592 64218 solver.cpp:517]     Test net output #0: accuracy = 0.893777
I0122 17:23:13.832664 64218 solver.cpp:517]     Test net output #1: loss = 0.350566 (* 1 = 0.350566 loss)
I0122 17:23:13.832669 64218 solver.cpp:517]     Test net output #2: top-1 = 0.893777
I0122 17:23:13.832674 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 17:23:13.926604 64218 solver.cpp:266] Iteration 21000 (8.19253 iter/s, 12.2062s/100 iter), loss = 0.0312746
I0122 17:23:13.926630 64218 solver.cpp:285]     Train net output #0: loss = 0.0312745 (* 1 = 0.0312745 loss)
I0122 17:23:13.926636 64218 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 17:23:23.785913 64218 solver.cpp:266] Iteration 21100 (10.1431 iter/s, 9.8589s/100 iter), loss = 0.012168
I0122 17:23:23.785945 64218 solver.cpp:285]     Train net output #0: loss = 0.0121679 (* 1 = 0.0121679 loss)
I0122 17:23:23.785951 64218 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 17:23:33.624428 64218 solver.cpp:266] Iteration 21200 (10.1646 iter/s, 9.8381s/100 iter), loss = 0.0209534
I0122 17:23:33.624459 64218 solver.cpp:285]     Train net output #0: loss = 0.0209533 (* 1 = 0.0209533 loss)
I0122 17:23:33.624466 64218 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 17:23:43.469619 64218 solver.cpp:266] Iteration 21300 (10.1577 iter/s, 9.84478s/100 iter), loss = 0.0321422
I0122 17:23:43.469650 64218 solver.cpp:285]     Train net output #0: loss = 0.0321422 (* 1 = 0.0321422 loss)
I0122 17:23:43.469656 64218 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 17:23:53.403038 64218 solver.cpp:266] Iteration 21400 (10.0674 iter/s, 9.93301s/100 iter), loss = 0.0168502
I0122 17:23:53.403098 64218 solver.cpp:285]     Train net output #0: loss = 0.0168501 (* 1 = 0.0168501 loss)
I0122 17:23:53.403105 64218 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 17:24:02.767534 64218 solver.cpp:266] Iteration 21500 (10.6791 iter/s, 9.36407s/100 iter), loss = 0.0153653
I0122 17:24:02.767576 64218 solver.cpp:285]     Train net output #0: loss = 0.0153652 (* 1 = 0.0153652 loss)
I0122 17:24:02.767585 64218 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 17:24:12.623286 64218 solver.cpp:266] Iteration 21600 (10.1468 iter/s, 9.85533s/100 iter), loss = 0.0236997
I0122 17:24:12.623319 64218 solver.cpp:285]     Train net output #0: loss = 0.0236996 (* 1 = 0.0236996 loss)
I0122 17:24:12.623327 64218 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 17:24:22.523579 64218 solver.cpp:266] Iteration 21700 (10.1011 iter/s, 9.89988s/100 iter), loss = 0.0230963
I0122 17:24:22.523622 64218 solver.cpp:285]     Train net output #0: loss = 0.0230962 (* 1 = 0.0230962 loss)
I0122 17:24:22.523628 64218 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 17:24:32.421003 64218 solver.cpp:266] Iteration 21800 (10.1041 iter/s, 9.897s/100 iter), loss = 0.00948939
I0122 17:24:32.421138 64218 solver.cpp:285]     Train net output #0: loss = 0.0094893 (* 1 = 0.0094893 loss)
I0122 17:24:32.421146 64218 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 17:24:42.279552 64218 solver.cpp:266] Iteration 21900 (10.144 iter/s, 9.85804s/100 iter), loss = 0.0225419
I0122 17:24:42.279584 64218 solver.cpp:285]     Train net output #0: loss = 0.0225418 (* 1 = 0.0225418 loss)
I0122 17:24:42.279592 64218 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 17:24:52.073527 64218 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 17:24:54.396829 64218 solver.cpp:517]     Test net output #0: accuracy = 0.892778
I0122 17:24:54.396859 64218 solver.cpp:517]     Test net output #1: loss = 0.354708 (* 1 = 0.354708 loss)
I0122 17:24:54.396863 64218 solver.cpp:517]     Test net output #2: top-1 = 0.892778
I0122 17:24:54.396867 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 17:24:54.496299 64218 solver.cpp:266] Iteration 22000 (8.18582 iter/s, 12.2162s/100 iter), loss = 0.0130559
I0122 17:24:54.496325 64218 solver.cpp:285]     Train net output #0: loss = 0.0130558 (* 1 = 0.0130558 loss)
I0122 17:24:54.496331 64218 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 17:25:04.336956 64218 solver.cpp:266] Iteration 22100 (10.1623 iter/s, 9.84025s/100 iter), loss = 0.0149498
I0122 17:25:04.337024 64218 solver.cpp:285]     Train net output #0: loss = 0.0149497 (* 1 = 0.0149497 loss)
I0122 17:25:04.337031 64218 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 17:25:14.179242 64218 solver.cpp:266] Iteration 22200 (10.1607 iter/s, 9.84184s/100 iter), loss = 0.0103902
I0122 17:25:14.179277 64218 solver.cpp:285]     Train net output #0: loss = 0.0103901 (* 1 = 0.0103901 loss)
I0122 17:25:14.179284 64218 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 17:25:24.023208 64218 solver.cpp:266] Iteration 22300 (10.1589 iter/s, 9.84356s/100 iter), loss = 0.00857387
I0122 17:25:24.023241 64218 solver.cpp:285]     Train net output #0: loss = 0.00857379 (* 1 = 0.00857379 loss)
I0122 17:25:24.023247 64218 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 17:25:33.936695 64218 solver.cpp:266] Iteration 22400 (10.0877 iter/s, 9.91307s/100 iter), loss = 0.0176951
I0122 17:25:33.936728 64218 solver.cpp:285]     Train net output #0: loss = 0.017695 (* 1 = 0.017695 loss)
I0122 17:25:33.936734 64218 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 17:25:43.154533 64218 solver.cpp:266] Iteration 22500 (10.849 iter/s, 9.21745s/100 iter), loss = 0.0152429
I0122 17:25:43.154642 64218 solver.cpp:285]     Train net output #0: loss = 0.0152429 (* 1 = 0.0152429 loss)
I0122 17:25:43.154650 64218 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 17:25:52.771865 64218 solver.cpp:266] Iteration 22600 (10.3984 iter/s, 9.61686s/100 iter), loss = 0.0103471
I0122 17:25:52.771908 64218 solver.cpp:285]     Train net output #0: loss = 0.0103471 (* 1 = 0.0103471 loss)
I0122 17:25:52.771915 64218 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 17:26:02.242219 64218 solver.cpp:266] Iteration 22700 (10.5597 iter/s, 9.46995s/100 iter), loss = 0.0137601
I0122 17:26:02.242254 64218 solver.cpp:285]     Train net output #0: loss = 0.01376 (* 1 = 0.01376 loss)
I0122 17:26:02.242261 64218 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 17:26:11.799558 64218 solver.cpp:266] Iteration 22800 (10.4636 iter/s, 9.55694s/100 iter), loss = 0.0193159
I0122 17:26:11.799589 64218 solver.cpp:285]     Train net output #0: loss = 0.0193158 (* 1 = 0.0193158 loss)
I0122 17:26:11.799595 64218 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 17:26:21.275095 64218 solver.cpp:266] Iteration 22900 (10.5539 iter/s, 9.47514s/100 iter), loss = 0.0108496
I0122 17:26:21.275264 64218 solver.cpp:285]     Train net output #0: loss = 0.0108495 (* 1 = 0.0108495 loss)
I0122 17:26:21.277355 64218 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 17:26:30.671635 64218 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 17:26:32.946171 64218 solver.cpp:517]     Test net output #0: accuracy = 0.894
I0122 17:26:32.946200 64218 solver.cpp:517]     Test net output #1: loss = 0.351559 (* 1 = 0.351559 loss)
I0122 17:26:32.946205 64218 solver.cpp:517]     Test net output #2: top-1 = 0.894
I0122 17:26:32.946208 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:26:33.041000 64218 solver.cpp:266] Iteration 23000 (8.50109 iter/s, 11.7632s/100 iter), loss = 0.0136623
I0122 17:26:33.041028 64218 solver.cpp:285]     Train net output #0: loss = 0.0136623 (* 1 = 0.0136623 loss)
I0122 17:26:33.041033 64218 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 17:26:42.467784 64218 solver.cpp:266] Iteration 23100 (10.6085 iter/s, 9.4264s/100 iter), loss = 0.00856657
I0122 17:26:42.467816 64218 solver.cpp:285]     Train net output #0: loss = 0.00856648 (* 1 = 0.00856648 loss)
I0122 17:26:42.467823 64218 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 17:26:52.026271 64218 solver.cpp:266] Iteration 23200 (10.4623 iter/s, 9.55809s/100 iter), loss = 0.0153593
I0122 17:26:52.027081 64218 solver.cpp:285]     Train net output #0: loss = 0.0153592 (* 1 = 0.0153592 loss)
I0122 17:26:52.028511 64218 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 17:27:01.498332 64218 solver.cpp:266] Iteration 23300 (10.5603 iter/s, 9.46946s/100 iter), loss = 0.00725933
I0122 17:27:01.498366 64218 solver.cpp:285]     Train net output #0: loss = 0.00725924 (* 1 = 0.00725924 loss)
I0122 17:27:01.498412 64218 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 17:27:11.019632 64218 solver.cpp:266] Iteration 23400 (10.5033 iter/s, 9.52086s/100 iter), loss = 0.0161987
I0122 17:27:11.019665 64218 solver.cpp:285]     Train net output #0: loss = 0.0161986 (* 1 = 0.0161986 loss)
I0122 17:27:11.019671 64218 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 17:27:20.109447 64218 solver.cpp:266] Iteration 23500 (11.0018 iter/s, 9.08944s/100 iter), loss = 0.0099356
I0122 17:27:20.109479 64218 solver.cpp:285]     Train net output #0: loss = 0.00993551 (* 1 = 0.00993551 loss)
I0122 17:27:20.109486 64218 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 17:27:29.619145 64218 solver.cpp:266] Iteration 23600 (10.516 iter/s, 9.5093s/100 iter), loss = 0.00901636
I0122 17:27:29.619199 64218 solver.cpp:285]     Train net output #0: loss = 0.00901627 (* 1 = 0.00901627 loss)
I0122 17:27:29.621387 64218 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 17:27:39.061956 64218 solver.cpp:266] Iteration 23700 (10.593 iter/s, 9.44021s/100 iter), loss = 0.00834609
I0122 17:27:39.061997 64218 solver.cpp:285]     Train net output #0: loss = 0.008346 (* 1 = 0.008346 loss)
I0122 17:27:39.062005 64218 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 17:27:48.525399 64218 solver.cpp:266] Iteration 23800 (10.5674 iter/s, 9.46304s/100 iter), loss = 0.00853977
I0122 17:27:48.525432 64218 solver.cpp:285]     Train net output #0: loss = 0.00853968 (* 1 = 0.00853968 loss)
I0122 17:27:48.525439 64218 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 17:27:57.995517 64218 solver.cpp:266] Iteration 23900 (10.56 iter/s, 9.46972s/100 iter), loss = 0.00932777
I0122 17:27:57.995549 64218 solver.cpp:285]     Train net output #0: loss = 0.00932767 (* 1 = 0.00932767 loss)
I0122 17:27:57.995555 64218 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 17:28:07.356365 64218 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 17:28:09.620587 64218 solver.cpp:517]     Test net output #0: accuracy = 0.892667
I0122 17:28:09.620620 64218 solver.cpp:517]     Test net output #1: loss = 0.363296 (* 1 = 0.363296 loss)
I0122 17:28:09.620623 64218 solver.cpp:517]     Test net output #2: top-1 = 0.892667
I0122 17:28:09.620627 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:28:09.713033 64218 solver.cpp:266] Iteration 24000 (8.53458 iter/s, 11.717s/100 iter), loss = 0.0185081
I0122 17:28:09.713059 64218 solver.cpp:285]     Train net output #0: loss = 0.018508 (* 1 = 0.018508 loss)
I0122 17:28:09.713066 64218 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 17:28:19.223393 64218 solver.cpp:266] Iteration 24100 (10.5153 iter/s, 9.50997s/100 iter), loss = 0.00847753
I0122 17:28:19.223426 64218 solver.cpp:285]     Train net output #0: loss = 0.00847743 (* 1 = 0.00847743 loss)
I0122 17:28:19.223433 64218 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 17:28:28.665503 64218 solver.cpp:266] Iteration 24200 (10.5913 iter/s, 9.44172s/100 iter), loss = 0.010031
I0122 17:28:28.665535 64218 solver.cpp:285]     Train net output #0: loss = 0.0100309 (* 1 = 0.0100309 loss)
I0122 17:28:28.665542 64218 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 17:28:38.122105 64218 solver.cpp:266] Iteration 24300 (10.5751 iter/s, 9.45621s/100 iter), loss = 0.0182092
I0122 17:28:38.122213 64218 solver.cpp:285]     Train net output #0: loss = 0.0182091 (* 1 = 0.0182091 loss)
I0122 17:28:38.122222 64218 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 17:28:48.037245 64218 solver.cpp:266] Iteration 24400 (10.0861 iter/s, 9.91465s/100 iter), loss = 0.0113657
I0122 17:28:48.037276 64218 solver.cpp:285]     Train net output #0: loss = 0.0113656 (* 1 = 0.0113656 loss)
I0122 17:28:48.037281 64218 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 17:28:57.905539 64218 solver.cpp:266] Iteration 24500 (10.1339 iter/s, 9.86789s/100 iter), loss = 0.0111817
I0122 17:28:57.905571 64218 solver.cpp:285]     Train net output #0: loss = 0.0111816 (* 1 = 0.0111816 loss)
I0122 17:28:57.905580 64218 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 17:29:07.408926 64218 solver.cpp:266] Iteration 24600 (10.523 iter/s, 9.50299s/100 iter), loss = 0.00636365
I0122 17:29:07.408957 64218 solver.cpp:285]     Train net output #0: loss = 0.00636356 (* 1 = 0.00636356 loss)
I0122 17:29:07.408965 64218 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 17:29:17.241626 64218 solver.cpp:266] Iteration 24700 (10.1706 iter/s, 9.83229s/100 iter), loss = 0.0294782
I0122 17:29:17.241749 64218 solver.cpp:285]     Train net output #0: loss = 0.0294781 (* 1 = 0.0294781 loss)
I0122 17:29:17.241755 64218 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 17:29:27.103489 64218 solver.cpp:266] Iteration 24800 (10.1406 iter/s, 9.86137s/100 iter), loss = 0.0161856
I0122 17:29:27.103523 64218 solver.cpp:285]     Train net output #0: loss = 0.0161855 (* 1 = 0.0161855 loss)
I0122 17:29:27.103529 64218 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 17:29:36.983777 64218 solver.cpp:266] Iteration 24900 (10.1216 iter/s, 9.87988s/100 iter), loss = 0.00764838
I0122 17:29:36.983819 64218 solver.cpp:285]     Train net output #0: loss = 0.00764829 (* 1 = 0.00764829 loss)
I0122 17:29:36.983917 64218 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 17:29:46.762446 64218 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 17:29:49.106209 64218 solver.cpp:517]     Test net output #0: accuracy = 0.894556
I0122 17:29:49.106271 64218 solver.cpp:517]     Test net output #1: loss = 0.357556 (* 1 = 0.357556 loss)
I0122 17:29:49.106277 64218 solver.cpp:517]     Test net output #2: top-1 = 0.894556
I0122 17:29:49.106281 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:29:49.198865 64218 solver.cpp:266] Iteration 25000 (8.187 iter/s, 12.2145s/100 iter), loss = 0.00865492
I0122 17:29:49.198890 64218 solver.cpp:285]     Train net output #0: loss = 0.00865483 (* 1 = 0.00865483 loss)
I0122 17:29:49.198897 64218 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 17:29:59.072440 64218 solver.cpp:266] Iteration 25100 (10.1285 iter/s, 9.87317s/100 iter), loss = 0.0102705
I0122 17:29:59.072474 64218 solver.cpp:285]     Train net output #0: loss = 0.0102704 (* 1 = 0.0102704 loss)
I0122 17:29:59.072480 64218 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 17:30:08.963999 64218 solver.cpp:266] Iteration 25200 (10.1101 iter/s, 9.89114s/100 iter), loss = 0.0291133
I0122 17:30:08.964032 64218 solver.cpp:285]     Train net output #0: loss = 0.0291132 (* 1 = 0.0291132 loss)
I0122 17:30:08.964038 64218 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 17:30:18.885812 64218 solver.cpp:266] Iteration 25300 (10.0792 iter/s, 9.9214s/100 iter), loss = 0.0144092
I0122 17:30:18.885845 64218 solver.cpp:285]     Train net output #0: loss = 0.0144091 (* 1 = 0.0144091 loss)
I0122 17:30:18.885851 64218 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 17:30:28.800712 64218 solver.cpp:266] Iteration 25400 (10.0863 iter/s, 9.91448s/100 iter), loss = 0.00745859
I0122 17:30:28.800848 64218 solver.cpp:285]     Train net output #0: loss = 0.0074585 (* 1 = 0.0074585 loss)
I0122 17:30:28.800858 64218 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 17:30:38.723143 64218 solver.cpp:266] Iteration 25500 (10.0787 iter/s, 9.92192s/100 iter), loss = 0.00797322
I0122 17:30:38.723177 64218 solver.cpp:285]     Train net output #0: loss = 0.00797313 (* 1 = 0.00797313 loss)
I0122 17:30:38.723183 64218 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 17:30:48.069788 64218 solver.cpp:266] Iteration 25600 (10.6995 iter/s, 9.34625s/100 iter), loss = 0.0120727
I0122 17:30:48.069833 64218 solver.cpp:285]     Train net output #0: loss = 0.0120726 (* 1 = 0.0120726 loss)
I0122 17:30:48.069839 64218 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 17:30:57.901309 64218 solver.cpp:266] Iteration 25700 (10.1718 iter/s, 9.8311s/100 iter), loss = 0.0147665
I0122 17:30:57.901342 64218 solver.cpp:285]     Train net output #0: loss = 0.0147664 (* 1 = 0.0147664 loss)
I0122 17:30:57.901350 64218 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 17:31:07.823842 64218 solver.cpp:266] Iteration 25800 (10.0785 iter/s, 9.92212s/100 iter), loss = 0.00874868
I0122 17:31:07.823916 64218 solver.cpp:285]     Train net output #0: loss = 0.00874859 (* 1 = 0.00874859 loss)
I0122 17:31:07.823925 64218 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 17:31:17.770407 64218 solver.cpp:266] Iteration 25900 (10.0542 iter/s, 9.94611s/100 iter), loss = 0.0170399
I0122 17:31:17.770439 64218 solver.cpp:285]     Train net output #0: loss = 0.0170398 (* 1 = 0.0170398 loss)
I0122 17:31:17.770445 64218 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 17:31:27.523380 64218 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 17:31:29.858376 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895555
I0122 17:31:29.858404 64218 solver.cpp:517]     Test net output #1: loss = 0.362615 (* 1 = 0.362615 loss)
I0122 17:31:29.858409 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895555
I0122 17:31:29.858413 64218 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 17:31:29.952046 64218 solver.cpp:266] Iteration 26000 (8.20941 iter/s, 12.1811s/100 iter), loss = 0.00747546
I0122 17:31:29.952071 64218 solver.cpp:285]     Train net output #0: loss = 0.00747537 (* 1 = 0.00747537 loss)
I0122 17:31:29.952078 64218 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 17:31:39.771251 64218 solver.cpp:266] Iteration 26100 (10.1845 iter/s, 9.8188s/100 iter), loss = 0.00983977
I0122 17:31:39.771358 64218 solver.cpp:285]     Train net output #0: loss = 0.00983968 (* 1 = 0.00983968 loss)
I0122 17:31:39.771366 64218 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 17:31:49.683799 64218 solver.cpp:266] Iteration 26200 (10.0887 iter/s, 9.91206s/100 iter), loss = 0.00787884
I0122 17:31:49.683840 64218 solver.cpp:285]     Train net output #0: loss = 0.00787875 (* 1 = 0.00787875 loss)
I0122 17:31:49.683847 64218 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 17:31:59.562892 64218 solver.cpp:266] Iteration 26300 (10.1228 iter/s, 9.87867s/100 iter), loss = 0.00685245
I0122 17:31:59.562924 64218 solver.cpp:285]     Train net output #0: loss = 0.00685236 (* 1 = 0.00685236 loss)
I0122 17:31:59.562932 64218 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 17:32:09.475682 64218 solver.cpp:266] Iteration 26400 (10.0884 iter/s, 9.91238s/100 iter), loss = 0.015489
I0122 17:32:09.475711 64218 solver.cpp:285]     Train net output #0: loss = 0.0154889 (* 1 = 0.0154889 loss)
I0122 17:32:09.475718 64218 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 17:32:19.277266 64218 solver.cpp:266] Iteration 26500 (10.2029 iter/s, 9.80118s/100 iter), loss = 0.00745083
I0122 17:32:19.277349 64218 solver.cpp:285]     Train net output #0: loss = 0.00745074 (* 1 = 0.00745074 loss)
I0122 17:32:19.277385 64218 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 17:32:28.738623 64218 solver.cpp:266] Iteration 26600 (10.5698 iter/s, 9.46088s/100 iter), loss = 0.012619
I0122 17:32:28.738656 64218 solver.cpp:285]     Train net output #0: loss = 0.0126189 (* 1 = 0.0126189 loss)
I0122 17:32:28.738677 64218 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 17:32:38.542158 64218 solver.cpp:266] Iteration 26700 (10.2008 iter/s, 9.80313s/100 iter), loss = 0.00401938
I0122 17:32:38.542191 64218 solver.cpp:285]     Train net output #0: loss = 0.00401929 (* 1 = 0.00401929 loss)
I0122 17:32:38.542197 64218 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 17:32:48.453547 64218 solver.cpp:266] Iteration 26800 (10.0898 iter/s, 9.91097s/100 iter), loss = 0.00643009
I0122 17:32:48.453577 64218 solver.cpp:285]     Train net output #0: loss = 0.00643 (* 1 = 0.00643 loss)
I0122 17:32:48.453599 64218 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 17:32:58.305537 64218 solver.cpp:266] Iteration 26900 (10.1507 iter/s, 9.85158s/100 iter), loss = 0.0077434
I0122 17:32:58.305691 64218 solver.cpp:285]     Train net output #0: loss = 0.00774332 (* 1 = 0.00774332 loss)
I0122 17:32:58.305698 64218 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 17:33:07.993903 64218 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 17:33:10.484037 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895111
I0122 17:33:10.484066 64218 solver.cpp:517]     Test net output #1: loss = 0.366317 (* 1 = 0.366317 loss)
I0122 17:33:10.484071 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895111
I0122 17:33:10.484074 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 17:33:10.583617 64218 solver.cpp:266] Iteration 27000 (8.14501 iter/s, 12.2775s/100 iter), loss = 0.00924124
I0122 17:33:10.583643 64218 solver.cpp:285]     Train net output #0: loss = 0.00924116 (* 1 = 0.00924116 loss)
I0122 17:33:10.583650 64218 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 17:33:20.446852 64218 solver.cpp:266] Iteration 27100 (10.1391 iter/s, 9.86283s/100 iter), loss = 0.00707752
I0122 17:33:20.446885 64218 solver.cpp:285]     Train net output #0: loss = 0.00707744 (* 1 = 0.00707744 loss)
I0122 17:33:20.446892 64218 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 17:33:30.488523 64218 solver.cpp:266] Iteration 27200 (9.95892 iter/s, 10.0413s/100 iter), loss = 0.00428541
I0122 17:33:30.488658 64218 solver.cpp:285]     Train net output #0: loss = 0.00428533 (* 1 = 0.00428533 loss)
I0122 17:33:30.490768 64218 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 17:33:40.426187 64218 solver.cpp:266] Iteration 27300 (10.0654 iter/s, 9.93504s/100 iter), loss = 0.00509873
I0122 17:33:40.426218 64218 solver.cpp:285]     Train net output #0: loss = 0.00509865 (* 1 = 0.00509865 loss)
I0122 17:33:40.428225 64218 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 17:33:50.332041 64218 solver.cpp:266] Iteration 27400 (10.0975 iter/s, 9.90344s/100 iter), loss = 0.00760954
I0122 17:33:50.332070 64218 solver.cpp:285]     Train net output #0: loss = 0.00760946 (* 1 = 0.00760946 loss)
I0122 17:33:50.332113 64218 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 17:33:59.765888 64218 solver.cpp:266] Iteration 27500 (10.6006 iter/s, 9.43342s/100 iter), loss = 0.00616053
I0122 17:33:59.765923 64218 solver.cpp:285]     Train net output #0: loss = 0.00616045 (* 1 = 0.00616045 loss)
I0122 17:33:59.765930 64218 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 17:34:09.611433 64218 solver.cpp:266] Iteration 27600 (10.1573 iter/s, 9.84513s/100 iter), loss = 0.006358
I0122 17:34:09.611589 64218 solver.cpp:285]     Train net output #0: loss = 0.00635791 (* 1 = 0.00635791 loss)
I0122 17:34:09.611598 64218 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 17:34:19.478410 64218 solver.cpp:266] Iteration 27700 (10.1354 iter/s, 9.86645s/100 iter), loss = 0.00634097
I0122 17:34:19.478440 64218 solver.cpp:285]     Train net output #0: loss = 0.00634088 (* 1 = 0.00634088 loss)
I0122 17:34:19.478444 64218 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 17:34:29.318902 64218 solver.cpp:266] Iteration 27800 (10.1625 iter/s, 9.84009s/100 iter), loss = 0.0129647
I0122 17:34:29.318931 64218 solver.cpp:285]     Train net output #0: loss = 0.0129646 (* 1 = 0.0129646 loss)
I0122 17:34:29.318938 64218 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 17:34:39.185335 64218 solver.cpp:266] Iteration 27900 (10.1358 iter/s, 9.86603s/100 iter), loss = 0.00761588
I0122 17:34:39.185369 64218 solver.cpp:285]     Train net output #0: loss = 0.0076158 (* 1 = 0.0076158 loss)
I0122 17:34:39.185375 64218 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 17:34:48.918845 64218 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 17:34:51.179358 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895777
I0122 17:34:51.179388 64218 solver.cpp:517]     Test net output #1: loss = 0.367031 (* 1 = 0.367031 loss)
I0122 17:34:51.179392 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895777
I0122 17:34:51.179395 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:34:51.274184 64218 solver.cpp:266] Iteration 28000 (8.27246 iter/s, 12.0883s/100 iter), loss = 0.00489061
I0122 17:34:51.274214 64218 solver.cpp:285]     Train net output #0: loss = 0.00489053 (* 1 = 0.00489053 loss)
I0122 17:34:51.274219 64218 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 17:35:01.123569 64218 solver.cpp:266] Iteration 28100 (10.1534 iter/s, 9.84893s/100 iter), loss = 0.00620548
I0122 17:35:01.123602 64218 solver.cpp:285]     Train net output #0: loss = 0.0062054 (* 1 = 0.0062054 loss)
I0122 17:35:01.123610 64218 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 17:35:10.988703 64218 solver.cpp:266] Iteration 28200 (10.1372 iter/s, 9.86468s/100 iter), loss = 0.00535825
I0122 17:35:10.988735 64218 solver.cpp:285]     Train net output #0: loss = 0.00535817 (* 1 = 0.00535817 loss)
I0122 17:35:10.988742 64218 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 17:35:20.787478 64218 solver.cpp:266] Iteration 28300 (10.2058 iter/s, 9.79833s/100 iter), loss = 0.00614073
I0122 17:35:20.787530 64218 solver.cpp:285]     Train net output #0: loss = 0.00614065 (* 1 = 0.00614065 loss)
I0122 17:35:20.787537 64218 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 17:35:30.582304 64218 solver.cpp:266] Iteration 28400 (10.21 iter/s, 9.79436s/100 iter), loss = 0.00995618
I0122 17:35:30.582337 64218 solver.cpp:285]     Train net output #0: loss = 0.0099561 (* 1 = 0.0099561 loss)
I0122 17:35:30.582345 64218 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 17:35:39.967053 64218 solver.cpp:266] Iteration 28500 (10.6561 iter/s, 9.38431s/100 iter), loss = 0.00835746
I0122 17:35:39.967084 64218 solver.cpp:285]     Train net output #0: loss = 0.00835738 (* 1 = 0.00835738 loss)
I0122 17:35:39.967092 64218 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 17:35:49.843523 64218 solver.cpp:266] Iteration 28600 (10.1255 iter/s, 9.87602s/100 iter), loss = 0.0170534
I0122 17:35:49.843554 64218 solver.cpp:285]     Train net output #0: loss = 0.0170533 (* 1 = 0.0170533 loss)
I0122 17:35:49.843561 64218 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 17:35:59.742553 64218 solver.cpp:266] Iteration 28700 (10.1025 iter/s, 9.89858s/100 iter), loss = 0.0063661
I0122 17:35:59.742656 64218 solver.cpp:285]     Train net output #0: loss = 0.00636602 (* 1 = 0.00636602 loss)
I0122 17:35:59.742662 64218 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 17:36:09.603875 64218 solver.cpp:266] Iteration 28800 (10.1412 iter/s, 9.86081s/100 iter), loss = 0.00611679
I0122 17:36:09.603907 64218 solver.cpp:285]     Train net output #0: loss = 0.00611671 (* 1 = 0.00611671 loss)
I0122 17:36:09.603915 64218 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 17:36:19.472947 64218 solver.cpp:266] Iteration 28900 (10.1331 iter/s, 9.86862s/100 iter), loss = 0.00696091
I0122 17:36:19.472980 64218 solver.cpp:285]     Train net output #0: loss = 0.00696083 (* 1 = 0.00696083 loss)
I0122 17:36:19.472986 64218 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 17:36:29.225545 64218 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 17:36:31.481717 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895222
I0122 17:36:31.481815 64218 solver.cpp:517]     Test net output #1: loss = 0.371315 (* 1 = 0.371315 loss)
I0122 17:36:31.481822 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895222
I0122 17:36:31.481825 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 17:36:31.575024 64218 solver.cpp:266] Iteration 29000 (8.26341 iter/s, 12.1015s/100 iter), loss = 0.00582122
I0122 17:36:31.575062 64218 solver.cpp:285]     Train net output #0: loss = 0.00582113 (* 1 = 0.00582113 loss)
I0122 17:36:31.575085 64218 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 17:36:41.416263 64218 solver.cpp:266] Iteration 29100 (10.1618 iter/s, 9.84079s/100 iter), loss = 0.00461417
I0122 17:36:41.416296 64218 solver.cpp:285]     Train net output #0: loss = 0.00461408 (* 1 = 0.00461408 loss)
I0122 17:36:41.416301 64218 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 17:36:51.285481 64218 solver.cpp:266] Iteration 29200 (10.133 iter/s, 9.86877s/100 iter), loss = 0.00623521
I0122 17:36:51.285513 64218 solver.cpp:285]     Train net output #0: loss = 0.00623512 (* 1 = 0.00623512 loss)
I0122 17:36:51.285521 64218 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 17:37:01.169911 64218 solver.cpp:266] Iteration 29300 (10.1174 iter/s, 9.88398s/100 iter), loss = 0.00430684
I0122 17:37:01.169953 64218 solver.cpp:285]     Train net output #0: loss = 0.00430676 (* 1 = 0.00430676 loss)
I0122 17:37:01.169961 64218 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 17:37:11.071982 64218 solver.cpp:266] Iteration 29400 (10.0994 iter/s, 9.90161s/100 iter), loss = 0.0309371
I0122 17:37:11.072124 64218 solver.cpp:285]     Train net output #0: loss = 0.030937 (* 1 = 0.030937 loss)
I0122 17:37:11.072132 64218 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 17:37:20.433365 64218 solver.cpp:266] Iteration 29500 (10.6828 iter/s, 9.36085s/100 iter), loss = 0.00673283
I0122 17:37:20.433395 64218 solver.cpp:285]     Train net output #0: loss = 0.00673275 (* 1 = 0.00673275 loss)
I0122 17:37:20.433403 64218 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 17:37:30.242866 64218 solver.cpp:266] Iteration 29600 (10.1947 iter/s, 9.80906s/100 iter), loss = 0.00532359
I0122 17:37:30.242898 64218 solver.cpp:285]     Train net output #0: loss = 0.0053235 (* 1 = 0.0053235 loss)
I0122 17:37:30.243162 64218 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 17:37:40.149806 64218 solver.cpp:266] Iteration 29700 (10.0947 iter/s, 9.90623s/100 iter), loss = 0.0122378
I0122 17:37:40.149838 64218 solver.cpp:285]     Train net output #0: loss = 0.0122377 (* 1 = 0.0122377 loss)
I0122 17:37:40.149844 64218 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 17:37:50.033828 64218 solver.cpp:266] Iteration 29800 (10.1178 iter/s, 9.88358s/100 iter), loss = 0.00477893
I0122 17:37:50.033948 64218 solver.cpp:285]     Train net output #0: loss = 0.00477885 (* 1 = 0.00477885 loss)
I0122 17:37:50.033957 64218 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 17:37:59.913045 64218 solver.cpp:266] Iteration 29900 (10.1228 iter/s, 9.87868s/100 iter), loss = 0.00843585
I0122 17:37:59.913086 64218 solver.cpp:285]     Train net output #0: loss = 0.00843576 (* 1 = 0.00843576 loss)
I0122 17:37:59.913094 64218 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 17:38:07.113236 64218 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 17:38:08.624822 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895666
I0122 17:38:08.624848 64218 solver.cpp:517]     Test net output #1: loss = 0.370352 (* 1 = 0.370352 loss)
I0122 17:38:08.624852 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895666
I0122 17:38:08.624856 64218 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 17:38:08.688968 64218 solver.cpp:266] Iteration 30000 (11.3953 iter/s, 8.77553s/100 iter), loss = 0.00580949
I0122 17:38:08.689003 64218 solver.cpp:285]     Train net output #0: loss = 0.0058094 (* 1 = 0.0058094 loss)
I0122 17:38:08.689010 64218 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 17:38:15.089350 64218 solver.cpp:266] Iteration 30100 (15.6248 iter/s, 6.40008s/100 iter), loss = 0.00747158
I0122 17:38:15.089381 64218 solver.cpp:285]     Train net output #0: loss = 0.00747149 (* 1 = 0.00747149 loss)
I0122 17:38:15.089387 64218 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 17:38:21.459105 64218 solver.cpp:266] Iteration 30200 (15.6999 iter/s, 6.36946s/100 iter), loss = 0.0156194
I0122 17:38:21.459239 64218 solver.cpp:285]     Train net output #0: loss = 0.0156193 (* 1 = 0.0156193 loss)
I0122 17:38:21.459246 64218 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 17:38:27.799275 64218 solver.cpp:266] Iteration 30300 (15.7734 iter/s, 6.33978s/100 iter), loss = 0.00409591
I0122 17:38:27.799305 64218 solver.cpp:285]     Train net output #0: loss = 0.00409583 (* 1 = 0.00409583 loss)
I0122 17:38:27.799311 64218 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 17:38:34.124797 64218 solver.cpp:266] Iteration 30400 (15.8097 iter/s, 6.32523s/100 iter), loss = 0.00470565
I0122 17:38:34.124826 64218 solver.cpp:285]     Train net output #0: loss = 0.00470557 (* 1 = 0.00470557 loss)
I0122 17:38:34.124832 64218 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 17:38:40.403228 64218 solver.cpp:266] Iteration 30500 (15.9283 iter/s, 6.27814s/100 iter), loss = 0.0073408
I0122 17:38:40.403268 64218 solver.cpp:285]     Train net output #0: loss = 0.00734071 (* 1 = 0.00734071 loss)
I0122 17:38:40.403275 64218 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 17:38:46.675881 64218 solver.cpp:266] Iteration 30600 (15.943 iter/s, 6.27235s/100 iter), loss = 0.00427621
I0122 17:38:46.675923 64218 solver.cpp:285]     Train net output #0: loss = 0.00427612 (* 1 = 0.00427612 loss)
I0122 17:38:46.675930 64218 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 17:38:52.930784 64218 solver.cpp:266] Iteration 30700 (15.9882 iter/s, 6.2546s/100 iter), loss = 0.0031986
I0122 17:38:52.930908 64218 solver.cpp:285]     Train net output #0: loss = 0.00319851 (* 1 = 0.00319851 loss)
I0122 17:38:52.930917 64218 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 17:38:59.242975 64218 solver.cpp:266] Iteration 30800 (15.8433 iter/s, 6.31181s/100 iter), loss = 0.00691445
I0122 17:38:59.243005 64218 solver.cpp:285]     Train net output #0: loss = 0.00691437 (* 1 = 0.00691437 loss)
I0122 17:38:59.243011 64218 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 17:39:05.519839 64218 solver.cpp:266] Iteration 30900 (15.9323 iter/s, 6.27657s/100 iter), loss = 0.00589808
I0122 17:39:05.519879 64218 solver.cpp:285]     Train net output #0: loss = 0.005898 (* 1 = 0.005898 loss)
I0122 17:39:05.519886 64218 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 17:39:11.761674 64218 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 17:39:13.231596 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895888
I0122 17:39:13.231627 64218 solver.cpp:517]     Test net output #1: loss = 0.370912 (* 1 = 0.370912 loss)
I0122 17:39:13.231631 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895888
I0122 17:39:13.231636 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:39:13.295687 64218 solver.cpp:266] Iteration 31000 (12.8609 iter/s, 7.77549s/100 iter), loss = 0.00471151
I0122 17:39:13.295722 64218 solver.cpp:285]     Train net output #0: loss = 0.00471143 (* 1 = 0.00471143 loss)
I0122 17:39:13.295729 64218 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 17:39:19.625793 64218 solver.cpp:266] Iteration 31100 (15.7983 iter/s, 6.32981s/100 iter), loss = 0.00416513
I0122 17:39:19.625823 64218 solver.cpp:285]     Train net output #0: loss = 0.00416505 (* 1 = 0.00416505 loss)
I0122 17:39:19.625828 64218 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 17:39:25.930932 64218 solver.cpp:266] Iteration 31200 (15.8608 iter/s, 6.30485s/100 iter), loss = 0.00646361
I0122 17:39:25.931063 64218 solver.cpp:285]     Train net output #0: loss = 0.00646353 (* 1 = 0.00646353 loss)
I0122 17:39:25.931072 64218 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 17:39:32.251461 64218 solver.cpp:266] Iteration 31300 (15.8224 iter/s, 6.32014s/100 iter), loss = 0.00209865
I0122 17:39:32.251502 64218 solver.cpp:285]     Train net output #0: loss = 0.00209857 (* 1 = 0.00209857 loss)
I0122 17:39:32.251508 64218 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 17:39:38.586081 64218 solver.cpp:266] Iteration 31400 (15.787 iter/s, 6.33432s/100 iter), loss = 0.0101286
I0122 17:39:38.586123 64218 solver.cpp:285]     Train net output #0: loss = 0.0101286 (* 1 = 0.0101286 loss)
I0122 17:39:38.586130 64218 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 17:39:44.929929 64218 solver.cpp:266] Iteration 31500 (15.7641 iter/s, 6.34354s/100 iter), loss = 0.00700731
I0122 17:39:44.929958 64218 solver.cpp:285]     Train net output #0: loss = 0.00700723 (* 1 = 0.00700723 loss)
I0122 17:39:44.929965 64218 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 17:39:51.265735 64218 solver.cpp:266] Iteration 31600 (15.784 iter/s, 6.33551s/100 iter), loss = 0.00808502
I0122 17:39:51.265766 64218 solver.cpp:285]     Train net output #0: loss = 0.00808494 (* 1 = 0.00808494 loss)
I0122 17:39:51.265774 64218 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 17:39:57.622493 64218 solver.cpp:266] Iteration 31700 (15.732 iter/s, 6.35646s/100 iter), loss = 0.00443353
I0122 17:39:57.622594 64218 solver.cpp:285]     Train net output #0: loss = 0.00443345 (* 1 = 0.00443345 loss)
I0122 17:39:57.622601 64218 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 17:40:03.937547 64218 solver.cpp:266] Iteration 31800 (15.8361 iter/s, 6.31469s/100 iter), loss = 0.00486467
I0122 17:40:03.937587 64218 solver.cpp:285]     Train net output #0: loss = 0.00486459 (* 1 = 0.00486459 loss)
I0122 17:40:03.937594 64218 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 17:40:10.212348 64218 solver.cpp:266] Iteration 31900 (15.9375 iter/s, 6.2745s/100 iter), loss = 0.00323142
I0122 17:40:10.212378 64218 solver.cpp:285]     Train net output #0: loss = 0.00323134 (* 1 = 0.00323134 loss)
I0122 17:40:10.212383 64218 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 17:40:16.434783 64218 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 17:40:17.916738 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895555
I0122 17:40:17.916765 64218 solver.cpp:517]     Test net output #1: loss = 0.372623 (* 1 = 0.372623 loss)
I0122 17:40:17.916769 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895555
I0122 17:40:17.916774 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:40:17.979749 64218 solver.cpp:266] Iteration 32000 (12.8749 iter/s, 7.76706s/100 iter), loss = 0.00285488
I0122 17:40:17.979770 64218 solver.cpp:285]     Train net output #0: loss = 0.0028548 (* 1 = 0.0028548 loss)
I0122 17:40:17.979776 64218 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 17:40:24.238095 64218 solver.cpp:266] Iteration 32100 (15.9794 iter/s, 6.25807s/100 iter), loss = 0.0108251
I0122 17:40:24.238124 64218 solver.cpp:285]     Train net output #0: loss = 0.0108251 (* 1 = 0.0108251 loss)
I0122 17:40:24.238131 64218 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 17:40:30.541872 64218 solver.cpp:266] Iteration 32200 (15.8642 iter/s, 6.30349s/100 iter), loss = 0.00331257
I0122 17:40:30.542006 64218 solver.cpp:285]     Train net output #0: loss = 0.00331248 (* 1 = 0.00331248 loss)
I0122 17:40:30.542012 64218 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 17:40:36.833050 64218 solver.cpp:266] Iteration 32300 (15.8963 iter/s, 6.29079s/100 iter), loss = 0.00503825
I0122 17:40:36.833078 64218 solver.cpp:285]     Train net output #0: loss = 0.00503817 (* 1 = 0.00503817 loss)
I0122 17:40:36.833084 64218 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 17:40:43.124055 64218 solver.cpp:266] Iteration 32400 (15.8964 iter/s, 6.29072s/100 iter), loss = 0.00521051
I0122 17:40:43.124086 64218 solver.cpp:285]     Train net output #0: loss = 0.00521043 (* 1 = 0.00521043 loss)
I0122 17:40:43.124092 64218 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 17:40:49.413791 64218 solver.cpp:266] Iteration 32500 (15.8997 iter/s, 6.28945s/100 iter), loss = 0.00716515
I0122 17:40:49.413820 64218 solver.cpp:285]     Train net output #0: loss = 0.00716507 (* 1 = 0.00716507 loss)
I0122 17:40:49.413826 64218 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 17:40:55.690212 64218 solver.cpp:266] Iteration 32600 (15.9334 iter/s, 6.27614s/100 iter), loss = 0.00598994
I0122 17:40:55.690239 64218 solver.cpp:285]     Train net output #0: loss = 0.00598985 (* 1 = 0.00598985 loss)
I0122 17:40:55.690245 64218 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 17:41:01.976739 64218 solver.cpp:266] Iteration 32700 (15.9078 iter/s, 6.28624s/100 iter), loss = 0.00290997
I0122 17:41:01.976830 64218 solver.cpp:285]     Train net output #0: loss = 0.00290989 (* 1 = 0.00290989 loss)
I0122 17:41:01.976836 64218 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 17:41:08.287428 64218 solver.cpp:266] Iteration 32800 (15.847 iter/s, 6.31034s/100 iter), loss = 0.00616393
I0122 17:41:08.287456 64218 solver.cpp:285]     Train net output #0: loss = 0.00616384 (* 1 = 0.00616384 loss)
I0122 17:41:08.287462 64218 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 17:41:14.593955 64218 solver.cpp:266] Iteration 32900 (15.8573 iter/s, 6.30624s/100 iter), loss = 0.00322639
I0122 17:41:14.593992 64218 solver.cpp:285]     Train net output #0: loss = 0.0032263 (* 1 = 0.0032263 loss)
I0122 17:41:14.593998 64218 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 17:41:20.802704 64218 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 17:41:22.275285 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895888
I0122 17:41:22.275321 64218 solver.cpp:517]     Test net output #1: loss = 0.373277 (* 1 = 0.373277 loss)
I0122 17:41:22.275326 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895888
I0122 17:41:22.275328 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:41:22.338315 64218 solver.cpp:266] Iteration 33000 (12.9132 iter/s, 7.74401s/100 iter), loss = 0.00726023
I0122 17:41:22.338337 64218 solver.cpp:285]     Train net output #0: loss = 0.00726015 (* 1 = 0.00726015 loss)
I0122 17:41:22.338344 64218 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 17:41:28.642271 64218 solver.cpp:266] Iteration 33100 (15.8638 iter/s, 6.30367s/100 iter), loss = 0.0049676
I0122 17:41:28.642300 64218 solver.cpp:285]     Train net output #0: loss = 0.00496751 (* 1 = 0.00496751 loss)
I0122 17:41:28.642307 64218 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 17:41:34.941118 64218 solver.cpp:266] Iteration 33200 (15.8766 iter/s, 6.29856s/100 iter), loss = 0.00518801
I0122 17:41:34.941239 64218 solver.cpp:285]     Train net output #0: loss = 0.00518793 (* 1 = 0.00518793 loss)
I0122 17:41:34.941246 64218 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 17:41:41.385727 64218 solver.cpp:266] Iteration 33300 (15.5178 iter/s, 6.44423s/100 iter), loss = 0.00412217
I0122 17:41:41.385759 64218 solver.cpp:285]     Train net output #0: loss = 0.00412208 (* 1 = 0.00412208 loss)
I0122 17:41:41.385764 64218 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 17:41:47.823135 64218 solver.cpp:266] Iteration 33400 (15.5349 iter/s, 6.43711s/100 iter), loss = 0.00310175
I0122 17:41:47.823165 64218 solver.cpp:285]     Train net output #0: loss = 0.00310166 (* 1 = 0.00310166 loss)
I0122 17:41:47.823171 64218 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 17:41:54.199769 64218 solver.cpp:266] Iteration 33500 (15.683 iter/s, 6.37634s/100 iter), loss = 0.00633338
I0122 17:41:54.199800 64218 solver.cpp:285]     Train net output #0: loss = 0.0063333 (* 1 = 0.0063333 loss)
I0122 17:41:54.199806 64218 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 17:42:00.465888 64218 solver.cpp:266] Iteration 33600 (15.9596 iter/s, 6.26583s/100 iter), loss = 0.00363548
I0122 17:42:00.465920 64218 solver.cpp:285]     Train net output #0: loss = 0.0036354 (* 1 = 0.0036354 loss)
I0122 17:42:00.465941 64218 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 17:42:06.755487 64218 solver.cpp:266] Iteration 33700 (15.9 iter/s, 6.28931s/100 iter), loss = 0.00639126
I0122 17:42:06.755581 64218 solver.cpp:285]     Train net output #0: loss = 0.00639118 (* 1 = 0.00639118 loss)
I0122 17:42:06.755589 64218 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 17:42:13.019476 64218 solver.cpp:266] Iteration 33800 (15.9652 iter/s, 6.26364s/100 iter), loss = 0.00653344
I0122 17:42:13.019505 64218 solver.cpp:285]     Train net output #0: loss = 0.00653335 (* 1 = 0.00653335 loss)
I0122 17:42:13.019511 64218 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 17:42:19.304144 64218 solver.cpp:266] Iteration 33900 (15.9125 iter/s, 6.28438s/100 iter), loss = 0.00696642
I0122 17:42:19.304174 64218 solver.cpp:285]     Train net output #0: loss = 0.00696633 (* 1 = 0.00696633 loss)
I0122 17:42:19.304180 64218 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 17:42:25.501112 64218 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 17:42:26.997270 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895222
I0122 17:42:26.997297 64218 solver.cpp:517]     Test net output #1: loss = 0.373709 (* 1 = 0.373709 loss)
I0122 17:42:26.997301 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895222
I0122 17:42:26.997305 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:42:27.066712 64218 solver.cpp:266] Iteration 34000 (12.8829 iter/s, 7.76223s/100 iter), loss = 0.00412645
I0122 17:42:27.066733 64218 solver.cpp:285]     Train net output #0: loss = 0.00412637 (* 1 = 0.00412637 loss)
I0122 17:42:27.066740 64218 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 17:42:33.373386 64218 solver.cpp:266] Iteration 34100 (15.8569 iter/s, 6.3064s/100 iter), loss = 0.00405047
I0122 17:42:33.373417 64218 solver.cpp:285]     Train net output #0: loss = 0.00405039 (* 1 = 0.00405039 loss)
I0122 17:42:33.373423 64218 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 17:42:39.669921 64218 solver.cpp:266] Iteration 34200 (15.8825 iter/s, 6.29625s/100 iter), loss = 0.00506066
I0122 17:42:39.670006 64218 solver.cpp:285]     Train net output #0: loss = 0.00506057 (* 1 = 0.00506057 loss)
I0122 17:42:39.670013 64218 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 17:42:45.953400 64218 solver.cpp:266] Iteration 34300 (15.9156 iter/s, 6.28314s/100 iter), loss = 0.00563428
I0122 17:42:45.953430 64218 solver.cpp:285]     Train net output #0: loss = 0.00563419 (* 1 = 0.00563419 loss)
I0122 17:42:45.953436 64218 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 17:42:52.228969 64218 solver.cpp:266] Iteration 34400 (15.9355 iter/s, 6.27528s/100 iter), loss = 0.0107926
I0122 17:42:52.228997 64218 solver.cpp:285]     Train net output #0: loss = 0.0107925 (* 1 = 0.0107925 loss)
I0122 17:42:52.229002 64218 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 17:42:58.499763 64218 solver.cpp:266] Iteration 34500 (15.9477 iter/s, 6.27051s/100 iter), loss = 0.00228857
I0122 17:42:58.499804 64218 solver.cpp:285]     Train net output #0: loss = 0.00228848 (* 1 = 0.00228848 loss)
I0122 17:42:58.499810 64218 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 17:43:04.745559 64218 solver.cpp:266] Iteration 34600 (16.0115 iter/s, 6.2455s/100 iter), loss = 0.0042284
I0122 17:43:04.745589 64218 solver.cpp:285]     Train net output #0: loss = 0.00422831 (* 1 = 0.00422831 loss)
I0122 17:43:04.745595 64218 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 17:43:11.024549 64218 solver.cpp:266] Iteration 34700 (15.9269 iter/s, 6.2787s/100 iter), loss = 0.004485
I0122 17:43:11.024641 64218 solver.cpp:285]     Train net output #0: loss = 0.00448491 (* 1 = 0.00448491 loss)
I0122 17:43:11.024648 64218 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 17:43:17.291630 64218 solver.cpp:266] Iteration 34800 (15.9573 iter/s, 6.26674s/100 iter), loss = 0.0034133
I0122 17:43:17.291659 64218 solver.cpp:285]     Train net output #0: loss = 0.00341321 (* 1 = 0.00341321 loss)
I0122 17:43:17.291666 64218 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 17:43:23.568832 64218 solver.cpp:266] Iteration 34900 (15.9314 iter/s, 6.27692s/100 iter), loss = 0.0120055
I0122 17:43:23.568861 64218 solver.cpp:285]     Train net output #0: loss = 0.0120054 (* 1 = 0.0120054 loss)
I0122 17:43:23.568867 64218 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 17:43:29.815894 64218 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 17:43:31.286686 64218 solver.cpp:517]     Test net output #0: accuracy = 0.896222
I0122 17:43:31.286713 64218 solver.cpp:517]     Test net output #1: loss = 0.373921 (* 1 = 0.373921 loss)
I0122 17:43:31.286717 64218 solver.cpp:517]     Test net output #2: top-1 = 0.896222
I0122 17:43:31.286721 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:43:31.349565 64218 solver.cpp:266] Iteration 35000 (12.8528 iter/s, 7.78039s/100 iter), loss = 0.00759784
I0122 17:43:31.349586 64218 solver.cpp:285]     Train net output #0: loss = 0.00759775 (* 1 = 0.00759775 loss)
I0122 17:43:31.349592 64218 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 17:43:37.622514 64218 solver.cpp:266] Iteration 35100 (15.9422 iter/s, 6.27267s/100 iter), loss = 0.00246872
I0122 17:43:37.622545 64218 solver.cpp:285]     Train net output #0: loss = 0.00246863 (* 1 = 0.00246863 loss)
I0122 17:43:37.622551 64218 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 17:43:43.914471 64218 solver.cpp:266] Iteration 35200 (15.894 iter/s, 6.29167s/100 iter), loss = 0.00851007
I0122 17:43:43.914579 64218 solver.cpp:285]     Train net output #0: loss = 0.00850998 (* 1 = 0.00850998 loss)
I0122 17:43:43.914587 64218 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 17:43:50.222123 64218 solver.cpp:266] Iteration 35300 (15.8547 iter/s, 6.30729s/100 iter), loss = 0.0067545
I0122 17:43:50.222152 64218 solver.cpp:285]     Train net output #0: loss = 0.00675441 (* 1 = 0.00675441 loss)
I0122 17:43:50.222157 64218 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 17:43:56.528334 64218 solver.cpp:266] Iteration 35400 (15.8581 iter/s, 6.30593s/100 iter), loss = 0.00489548
I0122 17:43:56.528363 64218 solver.cpp:285]     Train net output #0: loss = 0.00489539 (* 1 = 0.00489539 loss)
I0122 17:43:56.528368 64218 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 17:44:02.795557 64218 solver.cpp:266] Iteration 35500 (15.9567 iter/s, 6.26694s/100 iter), loss = 0.00781946
I0122 17:44:02.795586 64218 solver.cpp:285]     Train net output #0: loss = 0.00781937 (* 1 = 0.00781937 loss)
I0122 17:44:02.795593 64218 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 17:44:09.128751 64218 solver.cpp:266] Iteration 35600 (15.7905 iter/s, 6.33291s/100 iter), loss = 0.00565488
I0122 17:44:09.128782 64218 solver.cpp:285]     Train net output #0: loss = 0.00565479 (* 1 = 0.00565479 loss)
I0122 17:44:09.128787 64218 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 17:44:15.436264 64218 solver.cpp:266] Iteration 35700 (15.8548 iter/s, 6.30723s/100 iter), loss = 0.00546114
I0122 17:44:15.436390 64218 solver.cpp:285]     Train net output #0: loss = 0.00546105 (* 1 = 0.00546105 loss)
I0122 17:44:15.436396 64218 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 17:44:21.721313 64218 solver.cpp:266] Iteration 35800 (15.9117 iter/s, 6.28467s/100 iter), loss = 0.00676943
I0122 17:44:21.721341 64218 solver.cpp:285]     Train net output #0: loss = 0.00676934 (* 1 = 0.00676934 loss)
I0122 17:44:21.721348 64218 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 17:44:28.030558 64218 solver.cpp:266] Iteration 35900 (15.8505 iter/s, 6.30896s/100 iter), loss = 0.00272039
I0122 17:44:28.030601 64218 solver.cpp:285]     Train net output #0: loss = 0.0027203 (* 1 = 0.0027203 loss)
I0122 17:44:28.030606 64218 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 17:44:34.257710 64218 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 17:44:35.738508 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895444
I0122 17:44:35.738536 64218 solver.cpp:517]     Test net output #1: loss = 0.374471 (* 1 = 0.374471 loss)
I0122 17:44:35.738541 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895444
I0122 17:44:35.738544 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:44:35.802971 64218 solver.cpp:266] Iteration 36000 (12.8666 iter/s, 7.77206s/100 iter), loss = 0.00586163
I0122 17:44:35.802996 64218 solver.cpp:285]     Train net output #0: loss = 0.00586154 (* 1 = 0.00586154 loss)
I0122 17:44:35.803004 64218 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 17:44:42.093845 64218 solver.cpp:266] Iteration 36100 (15.8967 iter/s, 6.2906s/100 iter), loss = 0.00412684
I0122 17:44:42.093875 64218 solver.cpp:285]     Train net output #0: loss = 0.00412675 (* 1 = 0.00412675 loss)
I0122 17:44:42.093883 64218 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 17:44:48.406944 64218 solver.cpp:266] Iteration 36200 (15.8408 iter/s, 6.31281s/100 iter), loss = 0.00366496
I0122 17:44:48.407081 64218 solver.cpp:285]     Train net output #0: loss = 0.00366487 (* 1 = 0.00366487 loss)
I0122 17:44:48.407089 64218 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 17:44:54.673928 64218 solver.cpp:266] Iteration 36300 (15.9576 iter/s, 6.2666s/100 iter), loss = 0.00700542
I0122 17:44:54.673959 64218 solver.cpp:285]     Train net output #0: loss = 0.00700533 (* 1 = 0.00700533 loss)
I0122 17:44:54.673964 64218 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 17:45:00.940153 64218 solver.cpp:266] Iteration 36400 (15.9593 iter/s, 6.26594s/100 iter), loss = 0.00365558
I0122 17:45:00.940184 64218 solver.cpp:285]     Train net output #0: loss = 0.00365549 (* 1 = 0.00365549 loss)
I0122 17:45:00.940189 64218 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 17:45:07.192183 64218 solver.cpp:266] Iteration 36500 (15.9955 iter/s, 6.25175s/100 iter), loss = 0.00734094
I0122 17:45:07.192211 64218 solver.cpp:285]     Train net output #0: loss = 0.00734085 (* 1 = 0.00734085 loss)
I0122 17:45:07.192219 64218 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 17:45:13.465900 64218 solver.cpp:266] Iteration 36600 (15.9402 iter/s, 6.27344s/100 iter), loss = 0.0029221
I0122 17:45:13.465930 64218 solver.cpp:285]     Train net output #0: loss = 0.00292202 (* 1 = 0.00292202 loss)
I0122 17:45:13.465936 64218 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 17:45:19.721101 64218 solver.cpp:266] Iteration 36700 (15.9874 iter/s, 6.25492s/100 iter), loss = 0.00404088
I0122 17:45:19.721165 64218 solver.cpp:285]     Train net output #0: loss = 0.0040408 (* 1 = 0.0040408 loss)
I0122 17:45:19.721173 64218 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 17:45:25.976651 64218 solver.cpp:266] Iteration 36800 (15.9866 iter/s, 6.25524s/100 iter), loss = 0.00834045
I0122 17:45:25.976692 64218 solver.cpp:285]     Train net output #0: loss = 0.00834036 (* 1 = 0.00834036 loss)
I0122 17:45:25.976698 64218 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 17:45:32.236783 64218 solver.cpp:266] Iteration 36900 (15.9748 iter/s, 6.25984s/100 iter), loss = 0.00480485
I0122 17:45:32.236812 64218 solver.cpp:285]     Train net output #0: loss = 0.00480476 (* 1 = 0.00480476 loss)
I0122 17:45:32.236819 64218 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 17:45:38.432915 64218 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 17:45:39.890501 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895888
I0122 17:45:39.890528 64218 solver.cpp:517]     Test net output #1: loss = 0.373872 (* 1 = 0.373872 loss)
I0122 17:45:39.890533 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895888
I0122 17:45:39.890552 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:45:39.953660 64218 solver.cpp:266] Iteration 37000 (12.9592 iter/s, 7.71654s/100 iter), loss = 0.00989747
I0122 17:45:39.953681 64218 solver.cpp:285]     Train net output #0: loss = 0.00989738 (* 1 = 0.00989738 loss)
I0122 17:45:39.953688 64218 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 17:45:46.214447 64218 solver.cpp:266] Iteration 37100 (15.9731 iter/s, 6.26051s/100 iter), loss = 0.00357499
I0122 17:45:46.214488 64218 solver.cpp:285]     Train net output #0: loss = 0.00357491 (* 1 = 0.00357491 loss)
I0122 17:45:46.214494 64218 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 17:45:52.437415 64218 solver.cpp:266] Iteration 37200 (16.0702 iter/s, 6.22268s/100 iter), loss = 0.00550309
I0122 17:45:52.437506 64218 solver.cpp:285]     Train net output #0: loss = 0.005503 (* 1 = 0.005503 loss)
I0122 17:45:52.437515 64218 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 17:45:58.705982 64218 solver.cpp:266] Iteration 37300 (15.9535 iter/s, 6.26823s/100 iter), loss = 0.00598155
I0122 17:45:58.706010 64218 solver.cpp:285]     Train net output #0: loss = 0.00598146 (* 1 = 0.00598146 loss)
I0122 17:45:58.706017 64218 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 17:46:04.955891 64218 solver.cpp:266] Iteration 37400 (16.0009 iter/s, 6.24963s/100 iter), loss = 0.00245948
I0122 17:46:04.955920 64218 solver.cpp:285]     Train net output #0: loss = 0.00245939 (* 1 = 0.00245939 loss)
I0122 17:46:04.955927 64218 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 17:46:11.228956 64218 solver.cpp:266] Iteration 37500 (15.9419 iter/s, 6.27278s/100 iter), loss = 0.00690917
I0122 17:46:11.228983 64218 solver.cpp:285]     Train net output #0: loss = 0.00690908 (* 1 = 0.00690908 loss)
I0122 17:46:11.228989 64218 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 17:46:17.492491 64218 solver.cpp:266] Iteration 37600 (15.9661 iter/s, 6.26326s/100 iter), loss = 0.00325214
I0122 17:46:17.492521 64218 solver.cpp:285]     Train net output #0: loss = 0.00325205 (* 1 = 0.00325205 loss)
I0122 17:46:17.492527 64218 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 17:46:23.743377 64218 solver.cpp:266] Iteration 37700 (15.9984 iter/s, 6.25061s/100 iter), loss = 0.00952537
I0122 17:46:23.743439 64218 solver.cpp:285]     Train net output #0: loss = 0.00952528 (* 1 = 0.00952528 loss)
I0122 17:46:23.743446 64218 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 17:46:29.999392 64218 solver.cpp:266] Iteration 37800 (15.9854 iter/s, 6.2557s/100 iter), loss = 0.00570323
I0122 17:46:29.999431 64218 solver.cpp:285]     Train net output #0: loss = 0.00570315 (* 1 = 0.00570315 loss)
I0122 17:46:29.999439 64218 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 17:46:36.252794 64218 solver.cpp:266] Iteration 37900 (15.992 iter/s, 6.25311s/100 iter), loss = 0.00677969
I0122 17:46:36.252825 64218 solver.cpp:285]     Train net output #0: loss = 0.0067796 (* 1 = 0.0067796 loss)
I0122 17:46:36.252830 64218 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 17:46:42.438366 64218 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 17:46:43.895489 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895444
I0122 17:46:43.895514 64218 solver.cpp:517]     Test net output #1: loss = 0.373965 (* 1 = 0.373965 loss)
I0122 17:46:43.895517 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895444
I0122 17:46:43.895521 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:46:43.959228 64218 solver.cpp:266] Iteration 38000 (12.9767 iter/s, 7.7061s/100 iter), loss = 0.00439637
I0122 17:46:43.959246 64218 solver.cpp:285]     Train net output #0: loss = 0.00439628 (* 1 = 0.00439628 loss)
I0122 17:46:43.959254 64218 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 17:46:50.212147 64218 solver.cpp:266] Iteration 38100 (15.9932 iter/s, 6.25265s/100 iter), loss = 0.00554695
I0122 17:46:50.212175 64218 solver.cpp:285]     Train net output #0: loss = 0.00554686 (* 1 = 0.00554686 loss)
I0122 17:46:50.212180 64218 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 17:46:56.473008 64218 solver.cpp:266] Iteration 38200 (15.973 iter/s, 6.26058s/100 iter), loss = 0.00712834
I0122 17:46:56.473143 64218 solver.cpp:285]     Train net output #0: loss = 0.00712824 (* 1 = 0.00712824 loss)
I0122 17:46:56.473150 64218 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 17:47:02.720399 64218 solver.cpp:266] Iteration 38300 (16.0077 iter/s, 6.24701s/100 iter), loss = 0.00674534
I0122 17:47:02.720428 64218 solver.cpp:285]     Train net output #0: loss = 0.00674525 (* 1 = 0.00674525 loss)
I0122 17:47:02.720434 64218 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 17:47:09.000645 64218 solver.cpp:266] Iteration 38400 (15.9237 iter/s, 6.27997s/100 iter), loss = 0.0081917
I0122 17:47:09.000674 64218 solver.cpp:285]     Train net output #0: loss = 0.0081916 (* 1 = 0.0081916 loss)
I0122 17:47:09.000679 64218 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 17:47:15.267161 64218 solver.cpp:266] Iteration 38500 (15.9585 iter/s, 6.26624s/100 iter), loss = 0.00917292
I0122 17:47:15.267187 64218 solver.cpp:285]     Train net output #0: loss = 0.00917283 (* 1 = 0.00917283 loss)
I0122 17:47:15.267192 64218 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 17:47:21.532946 64218 solver.cpp:266] Iteration 38600 (15.9604 iter/s, 6.26551s/100 iter), loss = 0.00277375
I0122 17:47:21.532976 64218 solver.cpp:285]     Train net output #0: loss = 0.00277366 (* 1 = 0.00277366 loss)
I0122 17:47:21.532982 64218 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 17:47:27.794373 64218 solver.cpp:266] Iteration 38700 (15.9715 iter/s, 6.26115s/100 iter), loss = 0.00589407
I0122 17:47:27.794432 64218 solver.cpp:285]     Train net output #0: loss = 0.00589398 (* 1 = 0.00589398 loss)
I0122 17:47:27.794440 64218 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 17:47:34.050460 64218 solver.cpp:266] Iteration 38800 (15.9852 iter/s, 6.25578s/100 iter), loss = 0.0074406
I0122 17:47:34.050492 64218 solver.cpp:285]     Train net output #0: loss = 0.00744051 (* 1 = 0.00744051 loss)
I0122 17:47:34.050498 64218 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 17:47:40.304071 64218 solver.cpp:266] Iteration 38900 (15.9915 iter/s, 6.25333s/100 iter), loss = 0.00596343
I0122 17:47:40.304101 64218 solver.cpp:285]     Train net output #0: loss = 0.00596333 (* 1 = 0.00596333 loss)
I0122 17:47:40.304107 64218 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 17:47:46.487993 64218 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 17:47:47.960788 64218 solver.cpp:517]     Test net output #0: accuracy = 0.896222
I0122 17:47:47.960814 64218 solver.cpp:517]     Test net output #1: loss = 0.373637 (* 1 = 0.373637 loss)
I0122 17:47:47.960819 64218 solver.cpp:517]     Test net output #2: top-1 = 0.896222
I0122 17:47:47.960822 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:47:48.025765 64218 solver.cpp:266] Iteration 39000 (12.9511 iter/s, 7.72136s/100 iter), loss = 0.00453338
I0122 17:47:48.025786 64218 solver.cpp:285]     Train net output #0: loss = 0.00453329 (* 1 = 0.00453329 loss)
I0122 17:47:48.025794 64218 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 17:47:54.280653 64218 solver.cpp:266] Iteration 39100 (15.9882 iter/s, 6.25462s/100 iter), loss = 0.0323906
I0122 17:47:54.280683 64218 solver.cpp:285]     Train net output #0: loss = 0.0323905 (* 1 = 0.0323905 loss)
I0122 17:47:54.280689 64218 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 17:48:00.533414 64218 solver.cpp:266] Iteration 39200 (15.9936 iter/s, 6.25248s/100 iter), loss = 0.00485437
I0122 17:48:00.533471 64218 solver.cpp:285]     Train net output #0: loss = 0.00485428 (* 1 = 0.00485428 loss)
I0122 17:48:00.533478 64218 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 17:48:06.805066 64218 solver.cpp:266] Iteration 39300 (15.9455 iter/s, 6.27135s/100 iter), loss = 0.00626143
I0122 17:48:06.805096 64218 solver.cpp:285]     Train net output #0: loss = 0.00626134 (* 1 = 0.00626134 loss)
I0122 17:48:06.805102 64218 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 17:48:13.063447 64218 solver.cpp:266] Iteration 39400 (15.9793 iter/s, 6.2581s/100 iter), loss = 0.00646417
I0122 17:48:13.063477 64218 solver.cpp:285]     Train net output #0: loss = 0.00646408 (* 1 = 0.00646408 loss)
I0122 17:48:13.063482 64218 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 17:48:19.307777 64218 solver.cpp:266] Iteration 39500 (16.0152 iter/s, 6.24405s/100 iter), loss = 0.00390461
I0122 17:48:19.307807 64218 solver.cpp:285]     Train net output #0: loss = 0.00390452 (* 1 = 0.00390452 loss)
I0122 17:48:19.307813 64218 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 17:48:25.575251 64218 solver.cpp:266] Iteration 39600 (15.9561 iter/s, 6.26719s/100 iter), loss = 0.0205236
I0122 17:48:25.575291 64218 solver.cpp:285]     Train net output #0: loss = 0.0205235 (* 1 = 0.0205235 loss)
I0122 17:48:25.575299 64218 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 17:48:31.838977 64218 solver.cpp:266] Iteration 39700 (15.9657 iter/s, 6.26344s/100 iter), loss = 0.00355441
I0122 17:48:31.839056 64218 solver.cpp:285]     Train net output #0: loss = 0.00355432 (* 1 = 0.00355432 loss)
I0122 17:48:31.839063 64218 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 17:48:38.089114 64218 solver.cpp:266] Iteration 39800 (16.0005 iter/s, 6.24981s/100 iter), loss = 0.00953196
I0122 17:48:38.089144 64218 solver.cpp:285]     Train net output #0: loss = 0.00953187 (* 1 = 0.00953187 loss)
I0122 17:48:38.089150 64218 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 17:48:44.353148 64218 solver.cpp:266] Iteration 39900 (15.9649 iter/s, 6.26375s/100 iter), loss = 0.00342594
I0122 17:48:44.353178 64218 solver.cpp:285]     Train net output #0: loss = 0.00342585 (* 1 = 0.00342585 loss)
I0122 17:48:44.353184 64218 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 17:48:50.520723 64218 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_40000.caffemodel
I0122 17:48:50.564146 64218 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_40000.solverstate
I0122 17:48:50.594069 64218 solver.cpp:378] Iteration 40000, loss = 0.00367317
I0122 17:48:50.594101 64218 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 17:48:52.069146 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895555
I0122 17:48:52.069173 64218 solver.cpp:517]     Test net output #1: loss = 0.373944 (* 1 = 0.373944 loss)
I0122 17:48:52.069180 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895555
I0122 17:48:52.069182 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:48:52.069186 64218 solver.cpp:386] Optimization Done (13.4624 iter/s).
I0122 17:48:52.069191 64218 caffe_interface.cpp:530] Optimization Done.

# compression: first run
$PRUNE_ROOT/deephi_compress compress -config ${WORK_DIR}/config1.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_compress1_miniGoogleNet.txt
I0122 17:48:52.676797 65942 pruning_runner.cpp:190] Sens info found, use it.
I0122 17:48:52.712800 65942 pruning_runner.cpp:217] Start compressing, please wait...
I0122 17:48:54.117508 65942 pruning_runner.cpp:264] Compression complete 0.0692244%
I0122 17:48:54.750699 65942 pruning_runner.cpp:264] Compression complete 0.138353%
I0122 17:48:55.395267 65942 pruning_runner.cpp:264] Compression complete 0.276324%
I0122 17:48:56.052402 65942 pruning_runner.cpp:264] Compression complete 0.551124%
I0122 17:48:56.701149 65942 pruning_runner.cpp:264] Compression complete 50.2756%
I0122 17:48:57.352383 65942 pruning_runner.cpp:264] Compression complete 80.1758%
I0122 17:48:57.999213 65942 pruning_runner.cpp:264] Compression complete 97.522%
I0122 17:48:58.641589 65942 pruning_runner.cpp:264] Compression complete 99.6834%
I0122 17:48:59.295473 65942 pruning_runner.cpp:264] Compression complete 99.8417%
I0122 17:48:59.940431 65942 pruning_runner.cpp:264] Compression complete 99.9208%
I0122 17:49:00.587249 65942 caffe_interface.cpp:66] Use GPU with device ID 0
I0122 17:49:00.587538 65942 caffe_interface.cpp:70] GPU device name: Quadro P6000
I0122 17:49:00.588435 65942 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 17:49:00.589018 65942 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 17:49:00.589329 65942 layer_factory.hpp:77] Creating layer data
I0122 17:49:00.589365 65942 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 17:49:00.589728 65942 net.cpp:94] Creating Layer data
I0122 17:49:00.589735 65942 net.cpp:409] data -> data
I0122 17:49:00.589745 65942 net.cpp:409] data -> label
I0122 17:49:00.590836 66969 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 17:49:00.590865 66969 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 17:49:00.590955 65942 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 17:49:00.591035 65942 data_layer.cpp:83] output data size: 50,3,32,32
I0122 17:49:00.593654 65942 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 17:49:00.593699 65942 net.cpp:144] Setting up data
I0122 17:49:00.593705 65942 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 17:49:00.593710 65942 net.cpp:151] Top shape: 50 (50)
I0122 17:49:00.593713 65942 net.cpp:159] Memory required for data: 614600
I0122 17:49:00.593715 65942 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 17:49:00.593722 65942 net.cpp:94] Creating Layer label_data_1_split
I0122 17:49:00.593726 65942 net.cpp:435] label_data_1_split <- label
I0122 17:49:00.593731 65942 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 17:49:00.593739 65942 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 17:49:00.593745 65942 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 17:49:00.593753 65942 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 17:49:00.593827 65942 net.cpp:144] Setting up label_data_1_split
I0122 17:49:00.593832 65942 net.cpp:151] Top shape: 50 (50)
I0122 17:49:00.593835 65942 net.cpp:151] Top shape: 50 (50)
I0122 17:49:00.593839 65942 net.cpp:151] Top shape: 50 (50)
I0122 17:49:00.593842 65942 net.cpp:151] Top shape: 50 (50)
I0122 17:49:00.593845 65942 net.cpp:159] Memory required for data: 615400
I0122 17:49:00.593847 65942 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 17:49:00.593856 65942 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 17:49:00.593861 65942 net.cpp:435] conv1/3x3_s1 <- data
I0122 17:49:00.593866 65942 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 17:49:00.595356 65942 net.cpp:144] Setting up conv1/3x3_s1
I0122 17:49:00.595367 65942 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:00.595381 65942 net.cpp:159] Memory required for data: 20276200
I0122 17:49:00.595389 65942 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 17:49:00.595396 65942 net.cpp:94] Creating Layer conv1/bn1
I0122 17:49:00.595398 65942 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 17:49:00.595403 65942 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 17:49:00.595989 65942 net.cpp:144] Setting up conv1/bn1
I0122 17:49:00.595996 65942 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:00.596000 65942 net.cpp:159] Memory required for data: 39937000
I0122 17:49:00.596010 65942 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 17:49:00.596016 65942 net.cpp:94] Creating Layer conv1/relu1
I0122 17:49:00.596021 65942 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 17:49:00.596026 65942 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 17:49:00.596032 65942 net.cpp:144] Setting up conv1/relu1
I0122 17:49:00.596035 65942 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:00.596038 65942 net.cpp:159] Memory required for data: 59597800
I0122 17:49:00.596041 65942 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:00.596045 65942 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:00.596047 65942 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 17:49:00.596052 65942 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 17:49:00.596058 65942 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 17:49:00.596084 65942 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:00.596091 65942 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:00.596093 65942 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:00.596097 65942 net.cpp:159] Memory required for data: 98919400
I0122 17:49:00.596099 65942 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 17:49:00.596107 65942 net.cpp:94] Creating Layer inception_2a/1x1
I0122 17:49:00.596109 65942 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 17:49:00.596115 65942 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 17:49:00.596321 65942 net.cpp:144] Setting up inception_2a/1x1
I0122 17:49:00.596328 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.596330 65942 net.cpp:159] Memory required for data: 105473000
I0122 17:49:00.596338 65942 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 17:49:00.596356 65942 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 17:49:00.596359 65942 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 17:49:00.596364 65942 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 17:49:00.597106 65942 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 17:49:00.597113 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.597116 65942 net.cpp:159] Memory required for data: 112026600
I0122 17:49:00.597124 65942 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 17:49:00.597129 65942 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 17:49:00.597132 65942 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 17:49:00.597137 65942 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 17:49:00.597143 65942 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 17:49:00.597147 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.597149 65942 net.cpp:159] Memory required for data: 118580200
I0122 17:49:00.597152 65942 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 17:49:00.597159 65942 net.cpp:94] Creating Layer inception_2a/3x3
I0122 17:49:00.597164 65942 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 17:49:00.597169 65942 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 17:49:00.598199 65942 net.cpp:144] Setting up inception_2a/3x3
I0122 17:49:00.598210 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.598214 65942 net.cpp:159] Memory required for data: 125133800
I0122 17:49:00.598219 65942 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 17:49:00.598227 65942 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 17:49:00.598230 65942 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 17:49:00.598237 65942 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 17:49:00.598878 65942 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 17:49:00.598886 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.598888 65942 net.cpp:159] Memory required for data: 131687400
I0122 17:49:00.598901 65942 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 17:49:00.598907 65942 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 17:49:00.598911 65942 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 17:49:00.598917 65942 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 17:49:00.598922 65942 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 17:49:00.598927 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.598929 65942 net.cpp:159] Memory required for data: 138241000
I0122 17:49:00.598932 65942 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 17:49:00.598937 65942 net.cpp:94] Creating Layer inception_2a/output
I0122 17:49:00.598939 65942 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 17:49:00.598943 65942 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 17:49:00.598948 65942 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 17:49:00.598968 65942 net.cpp:144] Setting up inception_2a/output
I0122 17:49:00.598974 65942 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 17:49:00.598976 65942 net.cpp:159] Memory required for data: 151348200
I0122 17:49:00.598979 65942 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 17:49:00.598985 65942 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 17:49:00.598987 65942 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 17:49:00.598992 65942 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 17:49:00.598999 65942 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 17:49:00.599064 65942 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 17:49:00.599081 65942 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 17:49:00.599086 65942 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 17:49:00.599088 65942 net.cpp:159] Memory required for data: 177562600
I0122 17:49:00.599092 65942 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 17:49:00.599100 65942 net.cpp:94] Creating Layer inception_3a/1x1
I0122 17:49:00.599103 65942 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 17:49:00.599108 65942 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 17:49:00.599326 65942 net.cpp:144] Setting up inception_3a/1x1
I0122 17:49:00.599333 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.599336 65942 net.cpp:159] Memory required for data: 184116200
I0122 17:49:00.599341 65942 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 17:49:00.599349 65942 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 17:49:00.599351 65942 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 17:49:00.599356 65942 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 17:49:00.600008 65942 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 17:49:00.600014 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.600018 65942 net.cpp:159] Memory required for data: 190669800
I0122 17:49:00.600025 65942 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 17:49:00.600031 65942 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 17:49:00.600035 65942 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 17:49:00.600039 65942 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 17:49:00.600045 65942 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 17:49:00.600049 65942 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:00.600052 65942 net.cpp:159] Memory required for data: 197223400
I0122 17:49:00.600056 65942 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 17:49:00.600064 65942 net.cpp:94] Creating Layer inception_3a/3x3
I0122 17:49:00.600070 65942 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 17:49:00.600077 65942 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 17:49:00.600453 65942 net.cpp:144] Setting up inception_3a/3x3
I0122 17:49:00.600461 65942 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 17:49:00.600463 65942 net.cpp:159] Memory required for data: 207053800
I0122 17:49:00.600469 65942 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 17:49:00.600476 65942 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 17:49:00.600479 65942 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 17:49:00.600484 65942 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 17:49:00.601122 65942 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 17:49:00.601128 65942 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 17:49:00.601131 65942 net.cpp:159] Memory required for data: 216884200
I0122 17:49:00.601142 65942 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 17:49:00.601150 65942 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 17:49:00.601152 65942 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 17:49:00.601157 65942 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 17:49:00.601163 65942 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 17:49:00.601167 65942 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 17:49:00.601171 65942 net.cpp:159] Memory required for data: 226714600
I0122 17:49:00.601173 65942 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 17:49:00.601178 65942 net.cpp:94] Creating Layer inception_3a/output
I0122 17:49:00.601182 65942 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 17:49:00.601186 65942 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 17:49:00.601191 65942 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 17:49:00.601210 65942 net.cpp:144] Setting up inception_3a/output
I0122 17:49:00.601224 65942 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 17:49:00.601227 65942 net.cpp:159] Memory required for data: 243098600
I0122 17:49:00.601229 65942 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 17:49:00.601234 65942 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 17:49:00.601239 65942 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 17:49:00.601244 65942 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 17:49:00.601250 65942 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 17:49:00.601315 65942 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 17:49:00.601321 65942 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 17:49:00.601325 65942 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 17:49:00.601327 65942 net.cpp:159] Memory required for data: 275866600
I0122 17:49:00.601331 65942 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 17:49:00.601341 65942 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 17:49:00.601343 65942 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 17:49:00.601349 65942 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 17:49:00.601881 65942 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 17:49:00.601889 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.601893 65942 net.cpp:159] Memory required for data: 279962600
I0122 17:49:00.601898 65942 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 17:49:00.601922 65942 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 17:49:00.601927 65942 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 17:49:00.601933 65942 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 17:49:00.602653 65942 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 17:49:00.602660 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.602663 65942 net.cpp:159] Memory required for data: 284058600
I0122 17:49:00.602671 65942 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 17:49:00.602677 65942 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 17:49:00.602680 65942 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 17:49:00.602686 65942 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 17:49:00.602691 65942 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 17:49:00.602695 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.602699 65942 net.cpp:159] Memory required for data: 288154600
I0122 17:49:00.602701 65942 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 17:49:00.602706 65942 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 17:49:00.602710 65942 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 17:49:00.602715 65942 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 17:49:00.602754 65942 net.cpp:144] Setting up downsample_4/pool_s2
I0122 17:49:00.602759 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.602762 65942 net.cpp:159] Memory required for data: 292250600
I0122 17:49:00.602764 65942 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 17:49:00.602769 65942 net.cpp:94] Creating Layer downsample_4/output
I0122 17:49:00.602772 65942 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 17:49:00.602777 65942 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 17:49:00.602780 65942 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 17:49:00.602838 65942 net.cpp:144] Setting up downsample_4/output
I0122 17:49:00.602843 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.602846 65942 net.cpp:159] Memory required for data: 300442600
I0122 17:49:00.602856 65942 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 17:49:00.602862 65942 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 17:49:00.602865 65942 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 17:49:00.602870 65942 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 17:49:00.602876 65942 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 17:49:00.602906 65942 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 17:49:00.602911 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.602916 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.602917 65942 net.cpp:159] Memory required for data: 316826600
I0122 17:49:00.602921 65942 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 17:49:00.602928 65942 net.cpp:94] Creating Layer inception_5a/1x1
I0122 17:49:00.602932 65942 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 17:49:00.602936 65942 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 17:49:00.603257 65942 net.cpp:144] Setting up inception_5a/1x1
I0122 17:49:00.603265 65942 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 17:49:00.603267 65942 net.cpp:159] Memory required for data: 322561000
I0122 17:49:00.603273 65942 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 17:49:00.603281 65942 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 17:49:00.603283 65942 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 17:49:00.603288 65942 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 17:49:00.603988 65942 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 17:49:00.603996 65942 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 17:49:00.603998 65942 net.cpp:159] Memory required for data: 328295400
I0122 17:49:00.604007 65942 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 17:49:00.604010 65942 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 17:49:00.604014 65942 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 17:49:00.604018 65942 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 17:49:00.604024 65942 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 17:49:00.604030 65942 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 17:49:00.604033 65942 net.cpp:159] Memory required for data: 334029800
I0122 17:49:00.604035 65942 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 17:49:00.604043 65942 net.cpp:94] Creating Layer inception_5a/3x3
I0122 17:49:00.604048 65942 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 17:49:00.604053 65942 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 17:49:00.604673 65942 net.cpp:144] Setting up inception_5a/3x3
I0122 17:49:00.604681 65942 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:00.604684 65942 net.cpp:159] Memory required for data: 336487400
I0122 17:49:00.604689 65942 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 17:49:00.604698 65942 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 17:49:00.604702 65942 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 17:49:00.604707 65942 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 17:49:00.605387 65942 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 17:49:00.605393 65942 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:00.605396 65942 net.cpp:159] Memory required for data: 338945000
I0122 17:49:00.605404 65942 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 17:49:00.605409 65942 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 17:49:00.605412 65942 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 17:49:00.605417 65942 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 17:49:00.605432 65942 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 17:49:00.605437 65942 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:00.605439 65942 net.cpp:159] Memory required for data: 341402600
I0122 17:49:00.605443 65942 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 17:49:00.605448 65942 net.cpp:94] Creating Layer inception_5a/output
I0122 17:49:00.605451 65942 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 17:49:00.605455 65942 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 17:49:00.605460 65942 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 17:49:00.605480 65942 net.cpp:144] Setting up inception_5a/output
I0122 17:49:00.605486 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.605489 65942 net.cpp:159] Memory required for data: 349594600
I0122 17:49:00.605491 65942 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 17:49:00.605496 65942 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 17:49:00.605499 65942 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 17:49:00.605504 65942 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 17:49:00.605509 65942 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 17:49:00.605579 65942 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 17:49:00.605585 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.605589 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.605592 65942 net.cpp:159] Memory required for data: 365978600
I0122 17:49:00.605595 65942 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 17:49:00.605603 65942 net.cpp:94] Creating Layer inception_6a/1x1
I0122 17:49:00.605608 65942 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 17:49:00.605614 65942 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 17:49:00.606673 65942 net.cpp:144] Setting up inception_6a/1x1
I0122 17:49:00.606685 65942 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:00.606688 65942 net.cpp:159] Memory required for data: 370893800
I0122 17:49:00.606694 65942 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 17:49:00.606701 65942 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 17:49:00.606705 65942 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 17:49:00.606711 65942 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 17:49:00.607357 65942 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 17:49:00.607364 65942 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:00.607367 65942 net.cpp:159] Memory required for data: 375809000
I0122 17:49:00.607375 65942 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 17:49:00.607380 65942 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 17:49:00.607383 65942 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 17:49:00.607388 65942 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 17:49:00.607394 65942 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 17:49:00.607398 65942 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:00.607401 65942 net.cpp:159] Memory required for data: 380724200
I0122 17:49:00.607404 65942 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 17:49:00.607412 65942 net.cpp:94] Creating Layer inception_6a/3x3
I0122 17:49:00.607416 65942 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 17:49:00.607422 65942 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 17:49:00.608769 65942 net.cpp:144] Setting up inception_6a/3x3
I0122 17:49:00.608781 65942 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 17:49:00.608784 65942 net.cpp:159] Memory required for data: 384001000
I0122 17:49:00.608794 65942 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 17:49:00.608815 65942 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 17:49:00.608819 65942 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 17:49:00.608825 65942 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 17:49:00.609458 65942 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 17:49:00.609467 65942 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 17:49:00.609469 65942 net.cpp:159] Memory required for data: 387277800
I0122 17:49:00.609477 65942 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 17:49:00.609484 65942 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 17:49:00.609488 65942 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 17:49:00.609493 65942 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 17:49:00.609498 65942 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 17:49:00.609503 65942 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 17:49:00.609508 65942 net.cpp:159] Memory required for data: 390554600
I0122 17:49:00.609509 65942 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 17:49:00.609514 65942 net.cpp:94] Creating Layer inception_6a/output
I0122 17:49:00.609517 65942 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 17:49:00.609521 65942 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 17:49:00.609526 65942 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 17:49:00.609544 65942 net.cpp:144] Setting up inception_6a/output
I0122 17:49:00.609549 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.609552 65942 net.cpp:159] Memory required for data: 398746600
I0122 17:49:00.609555 65942 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 17:49:00.609560 65942 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 17:49:00.609562 65942 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 17:49:00.609567 65942 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 17:49:00.609575 65942 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 17:49:00.609602 65942 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 17:49:00.609608 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.609612 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.609614 65942 net.cpp:159] Memory required for data: 415130600
I0122 17:49:00.609617 65942 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 17:49:00.609624 65942 net.cpp:94] Creating Layer inception_7a/1x1
I0122 17:49:00.609629 65942 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 17:49:00.609634 65942 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 17:49:00.609939 65942 net.cpp:144] Setting up inception_7a/1x1
I0122 17:49:00.609946 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.609951 65942 net.cpp:159] Memory required for data: 419226600
I0122 17:49:00.609956 65942 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 17:49:00.609962 65942 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 17:49:00.609966 65942 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 17:49:00.609972 65942 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 17:49:00.610601 65942 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 17:49:00.610607 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.610610 65942 net.cpp:159] Memory required for data: 423322600
I0122 17:49:00.610620 65942 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 17:49:00.610623 65942 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 17:49:00.610626 65942 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 17:49:00.610631 65942 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 17:49:00.610647 65942 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 17:49:00.610651 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.610653 65942 net.cpp:159] Memory required for data: 427418600
I0122 17:49:00.610656 65942 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 17:49:00.610664 65942 net.cpp:94] Creating Layer inception_7a/3x3
I0122 17:49:00.610668 65942 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 17:49:00.610674 65942 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 17:49:00.611531 65942 net.cpp:144] Setting up inception_7a/3x3
I0122 17:49:00.611538 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.611541 65942 net.cpp:159] Memory required for data: 431514600
I0122 17:49:00.611546 65942 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 17:49:00.611553 65942 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 17:49:00.611557 65942 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 17:49:00.611562 65942 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 17:49:00.612190 65942 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 17:49:00.612197 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.612200 65942 net.cpp:159] Memory required for data: 435610600
I0122 17:49:00.612208 65942 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 17:49:00.612215 65942 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 17:49:00.612220 65942 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 17:49:00.612224 65942 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 17:49:00.612231 65942 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 17:49:00.612234 65942 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:00.612236 65942 net.cpp:159] Memory required for data: 439706600
I0122 17:49:00.612239 65942 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 17:49:00.612243 65942 net.cpp:94] Creating Layer inception_7a/output
I0122 17:49:00.612246 65942 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 17:49:00.612249 65942 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 17:49:00.612255 65942 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 17:49:00.612272 65942 net.cpp:144] Setting up inception_7a/output
I0122 17:49:00.612277 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.612280 65942 net.cpp:159] Memory required for data: 447898600
I0122 17:49:00.612283 65942 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 17:49:00.612288 65942 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 17:49:00.612290 65942 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 17:49:00.612295 65942 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 17:49:00.612303 65942 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 17:49:00.612329 65942 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 17:49:00.612334 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.612337 65942 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:00.612340 65942 net.cpp:159] Memory required for data: 464282600
I0122 17:49:00.612344 65942 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 17:49:00.612350 65942 net.cpp:94] Creating Layer inception_8a/1x1
I0122 17:49:00.612356 65942 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 17:49:00.612361 65942 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 17:49:00.612617 65942 net.cpp:144] Setting up inception_8a/1x1
I0122 17:49:00.612622 65942 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:00.612627 65942 net.cpp:159] Memory required for data: 466740200
I0122 17:49:00.612632 65942 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 17:49:00.612649 65942 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 17:49:00.612653 65942 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 17:49:00.612658 65942 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 17:49:00.613283 65942 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 17:49:00.613289 65942 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:00.613292 65942 net.cpp:159] Memory required for data: 469197800
I0122 17:49:00.613301 65942 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 17:49:00.613307 65942 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 17:49:00.613310 65942 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 17:49:00.613315 65942 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 17:49:00.613320 65942 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 17:49:00.613327 65942 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:00.613328 65942 net.cpp:159] Memory required for data: 471655400
I0122 17:49:00.613332 65942 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 17:49:00.613338 65942 net.cpp:94] Creating Layer inception_8a/3x3
I0122 17:49:00.613343 65942 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 17:49:00.613349 65942 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 17:49:00.614953 65942 net.cpp:144] Setting up inception_8a/3x3
I0122 17:49:00.614964 65942 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:00.614967 65942 net.cpp:159] Memory required for data: 476570600
I0122 17:49:00.614974 65942 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 17:49:00.614980 65942 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 17:49:00.614984 65942 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 17:49:00.614990 65942 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 17:49:00.615639 65942 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 17:49:00.615646 65942 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:00.615650 65942 net.cpp:159] Memory required for data: 481485800
I0122 17:49:00.615658 65942 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 17:49:00.615664 65942 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 17:49:00.615666 65942 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 17:49:00.615670 65942 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 17:49:00.615677 65942 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 17:49:00.615681 65942 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:00.615684 65942 net.cpp:159] Memory required for data: 486401000
I0122 17:49:00.615686 65942 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 17:49:00.615691 65942 net.cpp:94] Creating Layer inception_8a/output
I0122 17:49:00.615694 65942 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 17:49:00.615697 65942 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 17:49:00.615702 65942 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 17:49:00.615723 65942 net.cpp:144] Setting up inception_8a/output
I0122 17:49:00.615728 65942 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 17:49:00.615731 65942 net.cpp:159] Memory required for data: 493773800
I0122 17:49:00.615733 65942 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 17:49:00.615738 65942 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 17:49:00.615741 65942 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 17:49:00.615746 65942 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 17:49:00.615752 65942 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 17:49:00.615779 65942 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 17:49:00.615793 65942 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 17:49:00.615798 65942 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 17:49:00.615800 65942 net.cpp:159] Memory required for data: 508519400
I0122 17:49:00.615803 65942 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 17:49:00.615811 65942 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 17:49:00.615816 65942 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 17:49:00.615823 65942 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 17:49:00.617352 65942 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 17:49:00.617363 65942 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 17:49:00.617367 65942 net.cpp:159] Memory required for data: 509748200
I0122 17:49:00.617372 65942 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 17:49:00.617395 65942 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 17:49:00.617399 65942 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 17:49:00.617404 65942 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 17:49:00.618067 65942 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 17:49:00.618075 65942 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 17:49:00.618078 65942 net.cpp:159] Memory required for data: 510977000
I0122 17:49:00.618086 65942 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 17:49:00.618091 65942 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 17:49:00.618095 65942 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 17:49:00.618100 65942 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 17:49:00.618108 65942 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 17:49:00.618110 65942 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 17:49:00.618113 65942 net.cpp:159] Memory required for data: 512205800
I0122 17:49:00.618116 65942 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 17:49:00.618121 65942 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 17:49:00.618125 65942 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 17:49:00.618130 65942 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 17:49:00.618158 65942 net.cpp:144] Setting up downsample_9/pool_s2
I0122 17:49:00.618163 65942 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 17:49:00.618166 65942 net.cpp:159] Memory required for data: 514049000
I0122 17:49:00.618170 65942 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 17:49:00.618176 65942 net.cpp:94] Creating Layer downsample_9/output
I0122 17:49:00.618181 65942 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 17:49:00.618185 65942 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 17:49:00.618191 65942 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 17:49:00.618207 65942 net.cpp:144] Setting up downsample_9/output
I0122 17:49:00.618212 65942 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 17:49:00.618216 65942 net.cpp:159] Memory required for data: 517121000
I0122 17:49:00.618219 65942 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 17:49:00.618223 65942 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 17:49:00.618227 65942 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 17:49:00.618230 65942 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 17:49:00.618237 65942 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 17:49:00.618263 65942 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 17:49:00.618268 65942 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 17:49:00.618271 65942 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 17:49:00.618284 65942 net.cpp:159] Memory required for data: 523265000
I0122 17:49:00.618288 65942 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 17:49:00.618294 65942 net.cpp:94] Creating Layer inception_10a/1x1
I0122 17:49:00.618297 65942 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 17:49:00.618304 65942 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 17:49:00.618767 65942 net.cpp:144] Setting up inception_10a/1x1
I0122 17:49:00.618774 65942 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:00.618777 65942 net.cpp:159] Memory required for data: 525517800
I0122 17:49:00.618783 65942 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 17:49:00.618789 65942 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 17:49:00.618793 65942 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 17:49:00.618798 65942 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 17:49:00.619417 65942 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 17:49:00.619424 65942 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:00.619427 65942 net.cpp:159] Memory required for data: 527770600
I0122 17:49:00.619434 65942 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 17:49:00.619439 65942 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 17:49:00.619442 65942 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 17:49:00.619446 65942 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 17:49:00.619452 65942 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 17:49:00.619457 65942 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:00.619459 65942 net.cpp:159] Memory required for data: 530023400
I0122 17:49:00.619462 65942 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 17:49:00.619469 65942 net.cpp:94] Creating Layer inception_10a/3x3
I0122 17:49:00.619475 65942 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 17:49:00.619480 65942 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 17:49:00.621801 65942 net.cpp:144] Setting up inception_10a/3x3
I0122 17:49:00.621811 65942 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:00.621814 65942 net.cpp:159] Memory required for data: 532071400
I0122 17:49:00.621819 65942 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 17:49:00.621840 65942 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 17:49:00.621845 65942 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 17:49:00.621860 65942 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 17:49:00.622494 65942 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 17:49:00.622501 65942 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:00.622504 65942 net.cpp:159] Memory required for data: 534119400
I0122 17:49:00.622514 65942 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 17:49:00.622519 65942 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 17:49:00.622521 65942 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 17:49:00.622525 65942 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 17:49:00.622532 65942 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 17:49:00.622539 65942 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:00.622540 65942 net.cpp:159] Memory required for data: 536167400
I0122 17:49:00.622543 65942 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 17:49:00.622548 65942 net.cpp:94] Creating Layer inception_10a/output
I0122 17:49:00.622550 65942 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 17:49:00.622555 65942 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 17:49:00.622558 65942 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 17:49:00.622577 65942 net.cpp:144] Setting up inception_10a/output
I0122 17:49:00.622582 65942 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:00.622584 65942 net.cpp:159] Memory required for data: 540468200
I0122 17:49:00.622596 65942 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 17:49:00.622601 65942 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 17:49:00.622604 65942 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 17:49:00.622608 65942 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 17:49:00.622614 65942 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 17:49:00.622642 65942 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 17:49:00.622648 65942 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:00.622651 65942 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:00.622653 65942 net.cpp:159] Memory required for data: 549069800
I0122 17:49:00.622656 65942 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 17:49:00.622664 65942 net.cpp:94] Creating Layer inception_11a/1x1
I0122 17:49:00.622666 65942 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 17:49:00.622671 65942 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 17:49:00.623217 65942 net.cpp:144] Setting up inception_11a/1x1
I0122 17:49:00.623224 65942 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:00.623227 65942 net.cpp:159] Memory required for data: 551322600
I0122 17:49:00.623232 65942 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 17:49:00.623239 65942 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 17:49:00.623244 65942 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 17:49:00.623248 65942 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 17:49:00.623870 65942 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 17:49:00.623878 65942 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:00.623880 65942 net.cpp:159] Memory required for data: 553575400
I0122 17:49:00.623888 65942 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 17:49:00.623893 65942 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 17:49:00.623896 65942 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 17:49:00.623900 65942 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 17:49:00.623906 65942 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 17:49:00.623909 65942 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:00.623912 65942 net.cpp:159] Memory required for data: 555828200
I0122 17:49:00.623915 65942 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 17:49:00.623922 65942 net.cpp:94] Creating Layer inception_11a/3x3
I0122 17:49:00.623925 65942 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 17:49:00.623931 65942 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 17:49:00.627311 65942 net.cpp:144] Setting up inception_11a/3x3
I0122 17:49:00.627322 65942 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:00.627324 65942 net.cpp:159] Memory required for data: 557876200
I0122 17:49:00.627329 65942 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 17:49:00.627336 65942 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 17:49:00.627338 65942 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 17:49:00.627342 65942 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 17:49:00.627981 65942 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 17:49:00.627988 65942 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:00.627992 65942 net.cpp:159] Memory required for data: 559924200
I0122 17:49:00.628005 65942 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 17:49:00.628013 65942 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 17:49:00.628016 65942 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 17:49:00.628031 65942 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 17:49:00.628037 65942 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 17:49:00.628041 65942 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:00.628043 65942 net.cpp:159] Memory required for data: 561972200
I0122 17:49:00.628046 65942 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 17:49:00.628051 65942 net.cpp:94] Creating Layer inception_11a/output
I0122 17:49:00.628054 65942 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 17:49:00.628057 65942 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 17:49:00.628062 65942 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 17:49:00.628079 65942 net.cpp:144] Setting up inception_11a/output
I0122 17:49:00.628085 65942 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:00.628088 65942 net.cpp:159] Memory required for data: 566273000
I0122 17:49:00.628090 65942 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 17:49:00.628095 65942 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 17:49:00.628098 65942 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 17:49:00.628103 65942 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 17:49:00.628123 65942 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 17:49:00.628127 65942 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 17:49:00.628130 65942 net.cpp:159] Memory required for data: 566340200
I0122 17:49:00.628134 65942 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 17:49:00.628137 65942 net.cpp:94] Creating Layer drop_8x8_s1
I0122 17:49:00.628140 65942 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 17:49:00.628145 65942 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 17:49:00.628161 65942 net.cpp:144] Setting up drop_8x8_s1
I0122 17:49:00.628165 65942 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 17:49:00.628168 65942 net.cpp:159] Memory required for data: 566407400
I0122 17:49:00.628171 65942 layer_factory.hpp:77] Creating layer loss/classifier
I0122 17:49:00.628177 65942 net.cpp:94] Creating Layer loss/classifier
I0122 17:49:00.628180 65942 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 17:49:00.628185 65942 net.cpp:409] loss/classifier -> loss/classifier
I0122 17:49:00.628314 65942 net.cpp:144] Setting up loss/classifier
I0122 17:49:00.628319 65942 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:00.628322 65942 net.cpp:159] Memory required for data: 566409400
I0122 17:49:00.628326 65942 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 17:49:00.628332 65942 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 17:49:00.628337 65942 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 17:49:00.628342 65942 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 17:49:00.628348 65942 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 17:49:00.628355 65942 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 17:49:00.628360 65942 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 17:49:00.628407 65942 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 17:49:00.628412 65942 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:00.628417 65942 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:00.628419 65942 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:00.628422 65942 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:00.628424 65942 net.cpp:159] Memory required for data: 566417400
I0122 17:49:00.628428 65942 layer_factory.hpp:77] Creating layer loss
I0122 17:49:00.628432 65942 net.cpp:94] Creating Layer loss
I0122 17:49:00.628435 65942 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 17:49:00.628439 65942 net.cpp:435] loss <- label_data_1_split_0
I0122 17:49:00.628444 65942 net.cpp:409] loss -> loss
I0122 17:49:00.628458 65942 layer_factory.hpp:77] Creating layer loss
I0122 17:49:00.628530 65942 net.cpp:144] Setting up loss
I0122 17:49:00.628535 65942 net.cpp:151] Top shape: (1)
I0122 17:49:00.628538 65942 net.cpp:154]     with loss weight 1
I0122 17:49:00.628546 65942 net.cpp:159] Memory required for data: 566417404
I0122 17:49:00.628548 65942 layer_factory.hpp:77] Creating layer accuracy
I0122 17:49:00.628553 65942 net.cpp:94] Creating Layer accuracy
I0122 17:49:00.628557 65942 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 17:49:00.628561 65942 net.cpp:435] accuracy <- label_data_1_split_1
I0122 17:49:00.628566 65942 net.cpp:409] accuracy -> accuracy
I0122 17:49:00.628574 65942 net.cpp:144] Setting up accuracy
I0122 17:49:00.628581 65942 net.cpp:151] Top shape: (1)
I0122 17:49:00.628582 65942 net.cpp:159] Memory required for data: 566417408
I0122 17:49:00.628584 65942 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 17:49:00.628588 65942 net.cpp:94] Creating Layer accuracy-top1
I0122 17:49:00.628592 65942 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 17:49:00.628595 65942 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 17:49:00.628599 65942 net.cpp:409] accuracy-top1 -> top-1
I0122 17:49:00.628604 65942 net.cpp:144] Setting up accuracy-top1
I0122 17:49:00.628610 65942 net.cpp:151] Top shape: (1)
I0122 17:49:00.628613 65942 net.cpp:159] Memory required for data: 566417412
I0122 17:49:00.628615 65942 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 17:49:00.628619 65942 net.cpp:94] Creating Layer accuracy-top5
I0122 17:49:00.628623 65942 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 17:49:00.628626 65942 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 17:49:00.628630 65942 net.cpp:409] accuracy-top5 -> top-5
I0122 17:49:00.628636 65942 net.cpp:144] Setting up accuracy-top5
I0122 17:49:00.628639 65942 net.cpp:151] Top shape: (1)
I0122 17:49:00.628643 65942 net.cpp:159] Memory required for data: 566417416
I0122 17:49:00.628644 65942 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 17:49:00.628648 65942 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 17:49:00.628651 65942 net.cpp:222] accuracy does not need backward computation.
I0122 17:49:00.628654 65942 net.cpp:220] loss needs backward computation.
I0122 17:49:00.628659 65942 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 17:49:00.628661 65942 net.cpp:220] loss/classifier needs backward computation.
I0122 17:49:00.628665 65942 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 17:49:00.628667 65942 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 17:49:00.628670 65942 net.cpp:220] inception_11a/output needs backward computation.
I0122 17:49:00.628674 65942 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 17:49:00.628677 65942 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 17:49:00.628679 65942 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 17:49:00.628682 65942 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 17:49:00.628685 65942 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 17:49:00.628688 65942 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 17:49:00.628691 65942 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 17:49:00.628695 65942 net.cpp:220] inception_10a/output needs backward computation.
I0122 17:49:00.628698 65942 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 17:49:00.628701 65942 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 17:49:00.628705 65942 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 17:49:00.628707 65942 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 17:49:00.628710 65942 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 17:49:00.628713 65942 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 17:49:00.628722 65942 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 17:49:00.628726 65942 net.cpp:220] downsample_9/output needs backward computation.
I0122 17:49:00.628729 65942 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 17:49:00.628733 65942 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 17:49:00.628736 65942 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 17:49:00.628738 65942 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 17:49:00.628741 65942 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 17:49:00.628746 65942 net.cpp:220] inception_8a/output needs backward computation.
I0122 17:49:00.628748 65942 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 17:49:00.628751 65942 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 17:49:00.628754 65942 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 17:49:00.628758 65942 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 17:49:00.628762 65942 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 17:49:00.628764 65942 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 17:49:00.628767 65942 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 17:49:00.628772 65942 net.cpp:220] inception_7a/output needs backward computation.
I0122 17:49:00.628774 65942 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 17:49:00.628777 65942 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 17:49:00.628780 65942 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 17:49:00.628783 65942 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 17:49:00.628787 65942 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 17:49:00.628789 65942 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 17:49:00.628793 65942 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 17:49:00.628796 65942 net.cpp:220] inception_6a/output needs backward computation.
I0122 17:49:00.628799 65942 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 17:49:00.628803 65942 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 17:49:00.628804 65942 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 17:49:00.628808 65942 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 17:49:00.628811 65942 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 17:49:00.628813 65942 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 17:49:00.628816 65942 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 17:49:00.628821 65942 net.cpp:220] inception_5a/output needs backward computation.
I0122 17:49:00.628824 65942 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 17:49:00.628828 65942 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 17:49:00.628830 65942 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 17:49:00.628834 65942 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 17:49:00.628837 65942 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 17:49:00.628839 65942 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 17:49:00.628844 65942 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 17:49:00.628847 65942 net.cpp:220] downsample_4/output needs backward computation.
I0122 17:49:00.628851 65942 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 17:49:00.628855 65942 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 17:49:00.628859 65942 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 17:49:00.628867 65942 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 17:49:00.628871 65942 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 17:49:00.628875 65942 net.cpp:220] inception_3a/output needs backward computation.
I0122 17:49:00.628877 65942 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 17:49:00.628880 65942 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 17:49:00.628883 65942 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 17:49:00.628886 65942 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 17:49:00.628890 65942 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 17:49:00.628892 65942 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 17:49:00.628895 65942 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 17:49:00.628899 65942 net.cpp:220] inception_2a/output needs backward computation.
I0122 17:49:00.628902 65942 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 17:49:00.628906 65942 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 17:49:00.628908 65942 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 17:49:00.628911 65942 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 17:49:00.628914 65942 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 17:49:00.628917 65942 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 17:49:00.628921 65942 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 17:49:00.628923 65942 net.cpp:220] conv1/relu1 needs backward computation.
I0122 17:49:00.628926 65942 net.cpp:220] conv1/bn1 needs backward computation.
I0122 17:49:00.628931 65942 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 17:49:00.628934 65942 net.cpp:222] label_data_1_split does not need backward computation.
I0122 17:49:00.628938 65942 net.cpp:222] data does not need backward computation.
I0122 17:49:00.628940 65942 net.cpp:264] This network produces output accuracy
I0122 17:49:00.628944 65942 net.cpp:264] This network produces output loss
I0122 17:49:00.628947 65942 net.cpp:264] This network produces output top-1
I0122 17:49:00.628950 65942 net.cpp:264] This network produces output top-5
I0122 17:49:00.629014 65942 net.cpp:284] Network initialization done.
I0122 17:49:00.631669 65942 caffe_interface.cpp:363] Running for 180 iterations.
I0122 17:49:00.655463 65942 caffe_interface.cpp:125] Batch 0, accuracy = 0.94
I0122 17:49:00.655481 65942 caffe_interface.cpp:125] Batch 0, loss = 0.217846
I0122 17:49:00.655486 65942 caffe_interface.cpp:125] Batch 0, top-1 = 0.94
I0122 17:49:00.655490 65942 caffe_interface.cpp:125] Batch 0, top-5 = 0.98
I0122 17:49:00.665884 65942 caffe_interface.cpp:125] Batch 1, accuracy = 0.92
I0122 17:49:00.665895 65942 caffe_interface.cpp:125] Batch 1, loss = 0.273439
I0122 17:49:00.665899 65942 caffe_interface.cpp:125] Batch 1, top-1 = 0.92
I0122 17:49:00.665906 65942 caffe_interface.cpp:125] Batch 1, top-5 = 1
I0122 17:49:00.674314 65942 caffe_interface.cpp:125] Batch 2, accuracy = 0.92
I0122 17:49:00.674324 65942 caffe_interface.cpp:125] Batch 2, loss = 0.287761
I0122 17:49:00.674326 65942 caffe_interface.cpp:125] Batch 2, top-1 = 0.92
I0122 17:49:00.674329 65942 caffe_interface.cpp:125] Batch 2, top-5 = 1
I0122 17:49:00.682720 65942 caffe_interface.cpp:125] Batch 3, accuracy = 0.88
I0122 17:49:00.682729 65942 caffe_interface.cpp:125] Batch 3, loss = 1.1222
I0122 17:49:00.682731 65942 caffe_interface.cpp:125] Batch 3, top-1 = 0.88
I0122 17:49:00.682745 65942 caffe_interface.cpp:125] Batch 3, top-5 = 0.98
I0122 17:49:00.691150 65942 caffe_interface.cpp:125] Batch 4, accuracy = 0.86
I0122 17:49:00.691159 65942 caffe_interface.cpp:125] Batch 4, loss = 0.311285
I0122 17:49:00.691162 65942 caffe_interface.cpp:125] Batch 4, top-1 = 0.86
I0122 17:49:00.691175 65942 caffe_interface.cpp:125] Batch 4, top-5 = 1
I0122 17:49:00.701150 65942 caffe_interface.cpp:125] Batch 5, accuracy = 0.9
I0122 17:49:00.701169 65942 caffe_interface.cpp:125] Batch 5, loss = 0.215803
I0122 17:49:00.701172 65942 caffe_interface.cpp:125] Batch 5, top-1 = 0.9
I0122 17:49:00.701176 65942 caffe_interface.cpp:125] Batch 5, top-5 = 1
I0122 17:49:00.709574 65942 caffe_interface.cpp:125] Batch 6, accuracy = 0.9
I0122 17:49:00.709583 65942 caffe_interface.cpp:125] Batch 6, loss = 0.327353
I0122 17:49:00.709586 65942 caffe_interface.cpp:125] Batch 6, top-1 = 0.9
I0122 17:49:00.709589 65942 caffe_interface.cpp:125] Batch 6, top-5 = 1
I0122 17:49:00.718004 65942 caffe_interface.cpp:125] Batch 7, accuracy = 0.92
I0122 17:49:00.718014 65942 caffe_interface.cpp:125] Batch 7, loss = 0.191924
I0122 17:49:00.718017 65942 caffe_interface.cpp:125] Batch 7, top-1 = 0.92
I0122 17:49:00.718020 65942 caffe_interface.cpp:125] Batch 7, top-5 = 1
I0122 17:49:00.727636 65942 caffe_interface.cpp:125] Batch 8, accuracy = 0.94
I0122 17:49:00.727645 65942 caffe_interface.cpp:125] Batch 8, loss = 0.266792
I0122 17:49:00.727648 65942 caffe_interface.cpp:125] Batch 8, top-1 = 0.94
I0122 17:49:00.727651 65942 caffe_interface.cpp:125] Batch 8, top-5 = 1
I0122 17:49:00.736254 65942 caffe_interface.cpp:125] Batch 9, accuracy = 0.86
I0122 17:49:00.736263 65942 caffe_interface.cpp:125] Batch 9, loss = 0.531119
I0122 17:49:00.736265 65942 caffe_interface.cpp:125] Batch 9, top-1 = 0.86
I0122 17:49:00.736268 65942 caffe_interface.cpp:125] Batch 9, top-5 = 0.98
I0122 17:49:00.744678 65942 caffe_interface.cpp:125] Batch 10, accuracy = 0.88
I0122 17:49:00.744686 65942 caffe_interface.cpp:125] Batch 10, loss = 0.411316
I0122 17:49:00.744689 65942 caffe_interface.cpp:125] Batch 10, top-1 = 0.88
I0122 17:49:00.744693 65942 caffe_interface.cpp:125] Batch 10, top-5 = 0.98
I0122 17:49:00.752678 65942 caffe_interface.cpp:125] Batch 11, accuracy = 0.88
I0122 17:49:00.752687 65942 caffe_interface.cpp:125] Batch 11, loss = 0.319531
I0122 17:49:00.752691 65942 caffe_interface.cpp:125] Batch 11, top-1 = 0.88
I0122 17:49:00.752696 65942 caffe_interface.cpp:125] Batch 11, top-5 = 0.98
I0122 17:49:00.762008 65942 caffe_interface.cpp:125] Batch 12, accuracy = 0.9
I0122 17:49:00.762018 65942 caffe_interface.cpp:125] Batch 12, loss = 0.266414
I0122 17:49:00.762022 65942 caffe_interface.cpp:125] Batch 12, top-1 = 0.9
I0122 17:49:00.762024 65942 caffe_interface.cpp:125] Batch 12, top-5 = 1
I0122 17:49:00.769989 65942 caffe_interface.cpp:125] Batch 13, accuracy = 0.94
I0122 17:49:00.769997 65942 caffe_interface.cpp:125] Batch 13, loss = 0.283494
I0122 17:49:00.770000 65942 caffe_interface.cpp:125] Batch 13, top-1 = 0.94
I0122 17:49:00.770004 65942 caffe_interface.cpp:125] Batch 13, top-5 = 1
I0122 17:49:00.777952 65942 caffe_interface.cpp:125] Batch 14, accuracy = 0.96
I0122 17:49:00.777961 65942 caffe_interface.cpp:125] Batch 14, loss = 0.206305
I0122 17:49:00.777963 65942 caffe_interface.cpp:125] Batch 14, top-1 = 0.96
I0122 17:49:00.777966 65942 caffe_interface.cpp:125] Batch 14, top-5 = 1
I0122 17:49:00.785887 65942 caffe_interface.cpp:125] Batch 15, accuracy = 0.9
I0122 17:49:00.785897 65942 caffe_interface.cpp:125] Batch 15, loss = 0.425111
I0122 17:49:00.785898 65942 caffe_interface.cpp:125] Batch 15, top-1 = 0.9
I0122 17:49:00.785902 65942 caffe_interface.cpp:125] Batch 15, top-5 = 1
I0122 17:49:00.795228 65942 caffe_interface.cpp:125] Batch 16, accuracy = 0.9
I0122 17:49:00.795236 65942 caffe_interface.cpp:125] Batch 16, loss = 0.29937
I0122 17:49:00.795239 65942 caffe_interface.cpp:125] Batch 16, top-1 = 0.9
I0122 17:49:00.795243 65942 caffe_interface.cpp:125] Batch 16, top-5 = 1
I0122 17:49:00.803251 65942 caffe_interface.cpp:125] Batch 17, accuracy = 0.94
I0122 17:49:00.803261 65942 caffe_interface.cpp:125] Batch 17, loss = 0.236713
I0122 17:49:00.803264 65942 caffe_interface.cpp:125] Batch 17, top-1 = 0.94
I0122 17:49:00.803268 65942 caffe_interface.cpp:125] Batch 17, top-5 = 1
I0122 17:49:00.811204 65942 caffe_interface.cpp:125] Batch 18, accuracy = 0.88
I0122 17:49:00.811214 65942 caffe_interface.cpp:125] Batch 18, loss = 0.404031
I0122 17:49:00.811228 65942 caffe_interface.cpp:125] Batch 18, top-1 = 0.88
I0122 17:49:00.811231 65942 caffe_interface.cpp:125] Batch 18, top-5 = 0.98
I0122 17:49:00.819172 65942 caffe_interface.cpp:125] Batch 19, accuracy = 0.9
I0122 17:49:00.819181 65942 caffe_interface.cpp:125] Batch 19, loss = 0.394355
I0122 17:49:00.819185 65942 caffe_interface.cpp:125] Batch 19, top-1 = 0.9
I0122 17:49:00.819190 65942 caffe_interface.cpp:125] Batch 19, top-5 = 1
I0122 17:49:00.828577 65942 caffe_interface.cpp:125] Batch 20, accuracy = 0.88
I0122 17:49:00.828586 65942 caffe_interface.cpp:125] Batch 20, loss = 0.497438
I0122 17:49:00.828590 65942 caffe_interface.cpp:125] Batch 20, top-1 = 0.88
I0122 17:49:00.828593 65942 caffe_interface.cpp:125] Batch 20, top-5 = 1
I0122 17:49:00.836602 65942 caffe_interface.cpp:125] Batch 21, accuracy = 0.82
I0122 17:49:00.836611 65942 caffe_interface.cpp:125] Batch 21, loss = 0.749807
I0122 17:49:00.836616 65942 caffe_interface.cpp:125] Batch 21, top-1 = 0.82
I0122 17:49:00.836619 65942 caffe_interface.cpp:125] Batch 21, top-5 = 1
I0122 17:49:00.844557 65942 caffe_interface.cpp:125] Batch 22, accuracy = 0.94
I0122 17:49:00.844565 65942 caffe_interface.cpp:125] Batch 22, loss = 0.120333
I0122 17:49:00.844569 65942 caffe_interface.cpp:125] Batch 22, top-1 = 0.94
I0122 17:49:00.844573 65942 caffe_interface.cpp:125] Batch 22, top-5 = 1
I0122 17:49:00.852526 65942 caffe_interface.cpp:125] Batch 23, accuracy = 0.96
I0122 17:49:00.852535 65942 caffe_interface.cpp:125] Batch 23, loss = 0.224317
I0122 17:49:00.852540 65942 caffe_interface.cpp:125] Batch 23, top-1 = 0.96
I0122 17:49:00.852542 65942 caffe_interface.cpp:125] Batch 23, top-5 = 1
I0122 17:49:00.861753 65942 caffe_interface.cpp:125] Batch 24, accuracy = 0.92
I0122 17:49:00.861763 65942 caffe_interface.cpp:125] Batch 24, loss = 0.312607
I0122 17:49:00.861766 65942 caffe_interface.cpp:125] Batch 24, top-1 = 0.92
I0122 17:49:00.861770 65942 caffe_interface.cpp:125] Batch 24, top-5 = 1
I0122 17:49:00.869742 65942 caffe_interface.cpp:125] Batch 25, accuracy = 0.96
I0122 17:49:00.869752 65942 caffe_interface.cpp:125] Batch 25, loss = 0.310033
I0122 17:49:00.869755 65942 caffe_interface.cpp:125] Batch 25, top-1 = 0.96
I0122 17:49:00.869760 65942 caffe_interface.cpp:125] Batch 25, top-5 = 0.96
I0122 17:49:00.877724 65942 caffe_interface.cpp:125] Batch 26, accuracy = 0.86
I0122 17:49:00.877733 65942 caffe_interface.cpp:125] Batch 26, loss = 0.403025
I0122 17:49:00.877737 65942 caffe_interface.cpp:125] Batch 26, top-1 = 0.86
I0122 17:49:00.877740 65942 caffe_interface.cpp:125] Batch 26, top-5 = 1
I0122 17:49:00.885673 65942 caffe_interface.cpp:125] Batch 27, accuracy = 0.92
I0122 17:49:00.885681 65942 caffe_interface.cpp:125] Batch 27, loss = 0.222031
I0122 17:49:00.885684 65942 caffe_interface.cpp:125] Batch 27, top-1 = 0.92
I0122 17:49:00.885689 65942 caffe_interface.cpp:125] Batch 27, top-5 = 1
I0122 17:49:00.894950 65942 caffe_interface.cpp:125] Batch 28, accuracy = 0.92
I0122 17:49:00.894958 65942 caffe_interface.cpp:125] Batch 28, loss = 0.286518
I0122 17:49:00.894961 65942 caffe_interface.cpp:125] Batch 28, top-1 = 0.92
I0122 17:49:00.894965 65942 caffe_interface.cpp:125] Batch 28, top-5 = 1
I0122 17:49:00.903076 65942 caffe_interface.cpp:125] Batch 29, accuracy = 0.94
I0122 17:49:00.903085 65942 caffe_interface.cpp:125] Batch 29, loss = 0.341722
I0122 17:49:00.903090 65942 caffe_interface.cpp:125] Batch 29, top-1 = 0.94
I0122 17:49:00.903093 65942 caffe_interface.cpp:125] Batch 29, top-5 = 1
I0122 17:49:00.911051 65942 caffe_interface.cpp:125] Batch 30, accuracy = 0.92
I0122 17:49:00.911061 65942 caffe_interface.cpp:125] Batch 30, loss = 0.146471
I0122 17:49:00.911064 65942 caffe_interface.cpp:125] Batch 30, top-1 = 0.92
I0122 17:49:00.911067 65942 caffe_interface.cpp:125] Batch 30, top-5 = 1
I0122 17:49:00.918998 65942 caffe_interface.cpp:125] Batch 31, accuracy = 0.96
I0122 17:49:00.919008 65942 caffe_interface.cpp:125] Batch 31, loss = 0.10323
I0122 17:49:00.919010 65942 caffe_interface.cpp:125] Batch 31, top-1 = 0.96
I0122 17:49:00.919014 65942 caffe_interface.cpp:125] Batch 31, top-5 = 1
I0122 17:49:00.928167 65942 caffe_interface.cpp:125] Batch 32, accuracy = 0.9
I0122 17:49:00.928177 65942 caffe_interface.cpp:125] Batch 32, loss = 0.464169
I0122 17:49:00.928181 65942 caffe_interface.cpp:125] Batch 32, top-1 = 0.9
I0122 17:49:00.928184 65942 caffe_interface.cpp:125] Batch 32, top-5 = 1
I0122 17:49:00.936297 65942 caffe_interface.cpp:125] Batch 33, accuracy = 0.86
I0122 17:49:00.936306 65942 caffe_interface.cpp:125] Batch 33, loss = 0.628369
I0122 17:49:00.936311 65942 caffe_interface.cpp:125] Batch 33, top-1 = 0.86
I0122 17:49:00.936314 65942 caffe_interface.cpp:125] Batch 33, top-5 = 0.98
I0122 17:49:00.944254 65942 caffe_interface.cpp:125] Batch 34, accuracy = 0.92
I0122 17:49:00.944263 65942 caffe_interface.cpp:125] Batch 34, loss = 0.203706
I0122 17:49:00.944267 65942 caffe_interface.cpp:125] Batch 34, top-1 = 0.92
I0122 17:49:00.944272 65942 caffe_interface.cpp:125] Batch 34, top-5 = 1
I0122 17:49:00.952225 65942 caffe_interface.cpp:125] Batch 35, accuracy = 0.9
I0122 17:49:00.952234 65942 caffe_interface.cpp:125] Batch 35, loss = 0.3827
I0122 17:49:00.952239 65942 caffe_interface.cpp:125] Batch 35, top-1 = 0.9
I0122 17:49:00.952242 65942 caffe_interface.cpp:125] Batch 35, top-5 = 1
I0122 17:49:00.961410 65942 caffe_interface.cpp:125] Batch 36, accuracy = 0.94
I0122 17:49:00.961421 65942 caffe_interface.cpp:125] Batch 36, loss = 0.142877
I0122 17:49:00.961423 65942 caffe_interface.cpp:125] Batch 36, top-1 = 0.94
I0122 17:49:00.961427 65942 caffe_interface.cpp:125] Batch 36, top-5 = 1
I0122 17:49:00.969568 65942 caffe_interface.cpp:125] Batch 37, accuracy = 0.9
I0122 17:49:00.969578 65942 caffe_interface.cpp:125] Batch 37, loss = 0.269911
I0122 17:49:00.969581 65942 caffe_interface.cpp:125] Batch 37, top-1 = 0.9
I0122 17:49:00.969584 65942 caffe_interface.cpp:125] Batch 37, top-5 = 1
I0122 17:49:00.977522 65942 caffe_interface.cpp:125] Batch 38, accuracy = 0.84
I0122 17:49:00.977532 65942 caffe_interface.cpp:125] Batch 38, loss = 0.603168
I0122 17:49:00.977535 65942 caffe_interface.cpp:125] Batch 38, top-1 = 0.84
I0122 17:49:00.977538 65942 caffe_interface.cpp:125] Batch 38, top-5 = 0.98
I0122 17:49:00.985471 65942 caffe_interface.cpp:125] Batch 39, accuracy = 0.92
I0122 17:49:00.985481 65942 caffe_interface.cpp:125] Batch 39, loss = 0.272701
I0122 17:49:00.985484 65942 caffe_interface.cpp:125] Batch 39, top-1 = 0.92
I0122 17:49:00.985487 65942 caffe_interface.cpp:125] Batch 39, top-5 = 0.98
I0122 17:49:00.994594 65942 caffe_interface.cpp:125] Batch 40, accuracy = 0.96
I0122 17:49:00.994602 65942 caffe_interface.cpp:125] Batch 40, loss = 0.134542
I0122 17:49:00.994606 65942 caffe_interface.cpp:125] Batch 40, top-1 = 0.96
I0122 17:49:00.994608 65942 caffe_interface.cpp:125] Batch 40, top-5 = 1
I0122 17:49:01.002753 65942 caffe_interface.cpp:125] Batch 41, accuracy = 0.86
I0122 17:49:01.002761 65942 caffe_interface.cpp:125] Batch 41, loss = 0.652822
I0122 17:49:01.002765 65942 caffe_interface.cpp:125] Batch 41, top-1 = 0.86
I0122 17:49:01.002769 65942 caffe_interface.cpp:125] Batch 41, top-5 = 1
I0122 17:49:01.010713 65942 caffe_interface.cpp:125] Batch 42, accuracy = 0.88
I0122 17:49:01.010722 65942 caffe_interface.cpp:125] Batch 42, loss = 0.47894
I0122 17:49:01.010726 65942 caffe_interface.cpp:125] Batch 42, top-1 = 0.88
I0122 17:49:01.010730 65942 caffe_interface.cpp:125] Batch 42, top-5 = 0.98
I0122 17:49:01.018680 65942 caffe_interface.cpp:125] Batch 43, accuracy = 0.9
I0122 17:49:01.018689 65942 caffe_interface.cpp:125] Batch 43, loss = 0.285353
I0122 17:49:01.018693 65942 caffe_interface.cpp:125] Batch 43, top-1 = 0.9
I0122 17:49:01.018697 65942 caffe_interface.cpp:125] Batch 43, top-5 = 1
I0122 17:49:01.027726 65942 caffe_interface.cpp:125] Batch 44, accuracy = 0.92
I0122 17:49:01.027734 65942 caffe_interface.cpp:125] Batch 44, loss = 0.203896
I0122 17:49:01.027737 65942 caffe_interface.cpp:125] Batch 44, top-1 = 0.92
I0122 17:49:01.027741 65942 caffe_interface.cpp:125] Batch 44, top-5 = 1
I0122 17:49:01.035972 65942 caffe_interface.cpp:125] Batch 45, accuracy = 0.96
I0122 17:49:01.035989 65942 caffe_interface.cpp:125] Batch 45, loss = 0.199962
I0122 17:49:01.035993 65942 caffe_interface.cpp:125] Batch 45, top-1 = 0.96
I0122 17:49:01.035996 65942 caffe_interface.cpp:125] Batch 45, top-5 = 1
I0122 17:49:01.043984 65942 caffe_interface.cpp:125] Batch 46, accuracy = 0.96
I0122 17:49:01.043994 65942 caffe_interface.cpp:125] Batch 46, loss = 0.20051
I0122 17:49:01.043998 65942 caffe_interface.cpp:125] Batch 46, top-1 = 0.96
I0122 17:49:01.044001 65942 caffe_interface.cpp:125] Batch 46, top-5 = 1
I0122 17:49:01.052150 65942 caffe_interface.cpp:125] Batch 47, accuracy = 0.9
I0122 17:49:01.052157 65942 caffe_interface.cpp:125] Batch 47, loss = 0.309739
I0122 17:49:01.052160 65942 caffe_interface.cpp:125] Batch 47, top-1 = 0.9
I0122 17:49:01.052163 65942 caffe_interface.cpp:125] Batch 47, top-5 = 1
I0122 17:49:01.061127 65942 caffe_interface.cpp:125] Batch 48, accuracy = 0.9
I0122 17:49:01.061136 65942 caffe_interface.cpp:125] Batch 48, loss = 0.357959
I0122 17:49:01.061139 65942 caffe_interface.cpp:125] Batch 48, top-1 = 0.9
I0122 17:49:01.061143 65942 caffe_interface.cpp:125] Batch 48, top-5 = 1
I0122 17:49:01.069443 65942 caffe_interface.cpp:125] Batch 49, accuracy = 0.84
I0122 17:49:01.069453 65942 caffe_interface.cpp:125] Batch 49, loss = 0.56098
I0122 17:49:01.069456 65942 caffe_interface.cpp:125] Batch 49, top-1 = 0.84
I0122 17:49:01.069460 65942 caffe_interface.cpp:125] Batch 49, top-5 = 1
I0122 17:49:01.077409 65942 caffe_interface.cpp:125] Batch 50, accuracy = 0.88
I0122 17:49:01.077417 65942 caffe_interface.cpp:125] Batch 50, loss = 0.426775
I0122 17:49:01.077421 65942 caffe_interface.cpp:125] Batch 50, top-1 = 0.88
I0122 17:49:01.077425 65942 caffe_interface.cpp:125] Batch 50, top-5 = 1
I0122 17:49:01.085606 65942 caffe_interface.cpp:125] Batch 51, accuracy = 0.88
I0122 17:49:01.085615 65942 caffe_interface.cpp:125] Batch 51, loss = 0.186707
I0122 17:49:01.085619 65942 caffe_interface.cpp:125] Batch 51, top-1 = 0.88
I0122 17:49:01.085623 65942 caffe_interface.cpp:125] Batch 51, top-5 = 1
I0122 17:49:01.093529 65942 caffe_interface.cpp:125] Batch 52, accuracy = 0.86
I0122 17:49:01.093538 65942 caffe_interface.cpp:125] Batch 52, loss = 0.365909
I0122 17:49:01.093541 65942 caffe_interface.cpp:125] Batch 52, top-1 = 0.86
I0122 17:49:01.093545 65942 caffe_interface.cpp:125] Batch 52, top-5 = 1
I0122 17:49:01.102859 65942 caffe_interface.cpp:125] Batch 53, accuracy = 0.88
I0122 17:49:01.102867 65942 caffe_interface.cpp:125] Batch 53, loss = 0.415325
I0122 17:49:01.102871 65942 caffe_interface.cpp:125] Batch 53, top-1 = 0.88
I0122 17:49:01.102875 65942 caffe_interface.cpp:125] Batch 53, top-5 = 1
I0122 17:49:01.110841 65942 caffe_interface.cpp:125] Batch 54, accuracy = 0.88
I0122 17:49:01.110850 65942 caffe_interface.cpp:125] Batch 54, loss = 0.455044
I0122 17:49:01.110854 65942 caffe_interface.cpp:125] Batch 54, top-1 = 0.88
I0122 17:49:01.110857 65942 caffe_interface.cpp:125] Batch 54, top-5 = 0.98
I0122 17:49:01.119047 65942 caffe_interface.cpp:125] Batch 55, accuracy = 0.94
I0122 17:49:01.119056 65942 caffe_interface.cpp:125] Batch 55, loss = 0.223705
I0122 17:49:01.119060 65942 caffe_interface.cpp:125] Batch 55, top-1 = 0.94
I0122 17:49:01.119072 65942 caffe_interface.cpp:125] Batch 55, top-5 = 1
I0122 17:49:01.127018 65942 caffe_interface.cpp:125] Batch 56, accuracy = 0.9
I0122 17:49:01.127027 65942 caffe_interface.cpp:125] Batch 56, loss = 0.456877
I0122 17:49:01.127032 65942 caffe_interface.cpp:125] Batch 56, top-1 = 0.9
I0122 17:49:01.127035 65942 caffe_interface.cpp:125] Batch 56, top-5 = 1
I0122 17:49:01.136340 65942 caffe_interface.cpp:125] Batch 57, accuracy = 0.9
I0122 17:49:01.136348 65942 caffe_interface.cpp:125] Batch 57, loss = 0.281462
I0122 17:49:01.136351 65942 caffe_interface.cpp:125] Batch 57, top-1 = 0.9
I0122 17:49:01.136354 65942 caffe_interface.cpp:125] Batch 57, top-5 = 1
I0122 17:49:01.144299 65942 caffe_interface.cpp:125] Batch 58, accuracy = 0.92
I0122 17:49:01.144307 65942 caffe_interface.cpp:125] Batch 58, loss = 0.255128
I0122 17:49:01.144321 65942 caffe_interface.cpp:125] Batch 58, top-1 = 0.92
I0122 17:49:01.144325 65942 caffe_interface.cpp:125] Batch 58, top-5 = 1
I0122 17:49:01.152518 65942 caffe_interface.cpp:125] Batch 59, accuracy = 0.8
I0122 17:49:01.152528 65942 caffe_interface.cpp:125] Batch 59, loss = 0.4646
I0122 17:49:01.152531 65942 caffe_interface.cpp:125] Batch 59, top-1 = 0.8
I0122 17:49:01.152535 65942 caffe_interface.cpp:125] Batch 59, top-5 = 1
I0122 17:49:01.160475 65942 caffe_interface.cpp:125] Batch 60, accuracy = 0.94
I0122 17:49:01.160485 65942 caffe_interface.cpp:125] Batch 60, loss = 0.151484
I0122 17:49:01.160487 65942 caffe_interface.cpp:125] Batch 60, top-1 = 0.94
I0122 17:49:01.160491 65942 caffe_interface.cpp:125] Batch 60, top-5 = 1
I0122 17:49:01.169854 65942 caffe_interface.cpp:125] Batch 61, accuracy = 0.86
I0122 17:49:01.169863 65942 caffe_interface.cpp:125] Batch 61, loss = 0.504031
I0122 17:49:01.169867 65942 caffe_interface.cpp:125] Batch 61, top-1 = 0.86
I0122 17:49:01.169870 65942 caffe_interface.cpp:125] Batch 61, top-5 = 1
I0122 17:49:01.177820 65942 caffe_interface.cpp:125] Batch 62, accuracy = 0.86
I0122 17:49:01.177829 65942 caffe_interface.cpp:125] Batch 62, loss = 0.471872
I0122 17:49:01.177832 65942 caffe_interface.cpp:125] Batch 62, top-1 = 0.86
I0122 17:49:01.177836 65942 caffe_interface.cpp:125] Batch 62, top-5 = 1
I0122 17:49:01.186040 65942 caffe_interface.cpp:125] Batch 63, accuracy = 0.94
I0122 17:49:01.186050 65942 caffe_interface.cpp:125] Batch 63, loss = 0.300668
I0122 17:49:01.186053 65942 caffe_interface.cpp:125] Batch 63, top-1 = 0.94
I0122 17:49:01.186058 65942 caffe_interface.cpp:125] Batch 63, top-5 = 1
I0122 17:49:01.194002 65942 caffe_interface.cpp:125] Batch 64, accuracy = 0.86
I0122 17:49:01.194012 65942 caffe_interface.cpp:125] Batch 64, loss = 0.515449
I0122 17:49:01.194016 65942 caffe_interface.cpp:125] Batch 64, top-1 = 0.86
I0122 17:49:01.194020 65942 caffe_interface.cpp:125] Batch 64, top-5 = 1
I0122 17:49:01.203315 65942 caffe_interface.cpp:125] Batch 65, accuracy = 0.92
I0122 17:49:01.203322 65942 caffe_interface.cpp:125] Batch 65, loss = 0.303745
I0122 17:49:01.203325 65942 caffe_interface.cpp:125] Batch 65, top-1 = 0.92
I0122 17:49:01.203328 65942 caffe_interface.cpp:125] Batch 65, top-5 = 1
I0122 17:49:01.211292 65942 caffe_interface.cpp:125] Batch 66, accuracy = 0.96
I0122 17:49:01.211302 65942 caffe_interface.cpp:125] Batch 66, loss = 0.179071
I0122 17:49:01.211307 65942 caffe_interface.cpp:125] Batch 66, top-1 = 0.96
I0122 17:49:01.211310 65942 caffe_interface.cpp:125] Batch 66, top-5 = 1
I0122 17:49:01.219350 65942 caffe_interface.cpp:125] Batch 67, accuracy = 0.88
I0122 17:49:01.219360 65942 caffe_interface.cpp:125] Batch 67, loss = 0.522464
I0122 17:49:01.219364 65942 caffe_interface.cpp:125] Batch 67, top-1 = 0.88
I0122 17:49:01.219367 65942 caffe_interface.cpp:125] Batch 67, top-5 = 1
I0122 17:49:01.227329 65942 caffe_interface.cpp:125] Batch 68, accuracy = 0.88
I0122 17:49:01.227339 65942 caffe_interface.cpp:125] Batch 68, loss = 0.477357
I0122 17:49:01.227342 65942 caffe_interface.cpp:125] Batch 68, top-1 = 0.88
I0122 17:49:01.227345 65942 caffe_interface.cpp:125] Batch 68, top-5 = 1
I0122 17:49:01.236682 65942 caffe_interface.cpp:125] Batch 69, accuracy = 0.94
I0122 17:49:01.236691 65942 caffe_interface.cpp:125] Batch 69, loss = 0.190315
I0122 17:49:01.236694 65942 caffe_interface.cpp:125] Batch 69, top-1 = 0.94
I0122 17:49:01.236697 65942 caffe_interface.cpp:125] Batch 69, top-5 = 1
I0122 17:49:01.244666 65942 caffe_interface.cpp:125] Batch 70, accuracy = 0.9
I0122 17:49:01.244676 65942 caffe_interface.cpp:125] Batch 70, loss = 0.429717
I0122 17:49:01.244680 65942 caffe_interface.cpp:125] Batch 70, top-1 = 0.9
I0122 17:49:01.244683 65942 caffe_interface.cpp:125] Batch 70, top-5 = 1
I0122 17:49:01.252712 65942 caffe_interface.cpp:125] Batch 71, accuracy = 0.92
I0122 17:49:01.252722 65942 caffe_interface.cpp:125] Batch 71, loss = 0.405751
I0122 17:49:01.252725 65942 caffe_interface.cpp:125] Batch 71, top-1 = 0.92
I0122 17:49:01.252728 65942 caffe_interface.cpp:125] Batch 71, top-5 = 1
I0122 17:49:01.260681 65942 caffe_interface.cpp:125] Batch 72, accuracy = 0.86
I0122 17:49:01.260690 65942 caffe_interface.cpp:125] Batch 72, loss = 0.428969
I0122 17:49:01.260694 65942 caffe_interface.cpp:125] Batch 72, top-1 = 0.86
I0122 17:49:01.260699 65942 caffe_interface.cpp:125] Batch 72, top-5 = 0.98
I0122 17:49:01.270020 65942 caffe_interface.cpp:125] Batch 73, accuracy = 0.88
I0122 17:49:01.270030 65942 caffe_interface.cpp:125] Batch 73, loss = 0.51498
I0122 17:49:01.270032 65942 caffe_interface.cpp:125] Batch 73, top-1 = 0.88
I0122 17:49:01.270035 65942 caffe_interface.cpp:125] Batch 73, top-5 = 0.98
I0122 17:49:01.277999 65942 caffe_interface.cpp:125] Batch 74, accuracy = 0.86
I0122 17:49:01.278008 65942 caffe_interface.cpp:125] Batch 74, loss = 0.561554
I0122 17:49:01.278010 65942 caffe_interface.cpp:125] Batch 74, top-1 = 0.86
I0122 17:49:01.278013 65942 caffe_interface.cpp:125] Batch 74, top-5 = 1
I0122 17:49:01.286172 65942 caffe_interface.cpp:125] Batch 75, accuracy = 0.88
I0122 17:49:01.286181 65942 caffe_interface.cpp:125] Batch 75, loss = 0.5941
I0122 17:49:01.286183 65942 caffe_interface.cpp:125] Batch 75, top-1 = 0.88
I0122 17:49:01.286187 65942 caffe_interface.cpp:125] Batch 75, top-5 = 0.98
I0122 17:49:01.294136 65942 caffe_interface.cpp:125] Batch 76, accuracy = 0.92
I0122 17:49:01.294144 65942 caffe_interface.cpp:125] Batch 76, loss = 0.332542
I0122 17:49:01.294147 65942 caffe_interface.cpp:125] Batch 76, top-1 = 0.92
I0122 17:49:01.294150 65942 caffe_interface.cpp:125] Batch 76, top-5 = 0.98
I0122 17:49:01.303596 65942 caffe_interface.cpp:125] Batch 77, accuracy = 0.94
I0122 17:49:01.303606 65942 caffe_interface.cpp:125] Batch 77, loss = 0.325255
I0122 17:49:01.303609 65942 caffe_interface.cpp:125] Batch 77, top-1 = 0.94
I0122 17:49:01.303612 65942 caffe_interface.cpp:125] Batch 77, top-5 = 1
I0122 17:49:01.311576 65942 caffe_interface.cpp:125] Batch 78, accuracy = 0.94
I0122 17:49:01.311585 65942 caffe_interface.cpp:125] Batch 78, loss = 0.166344
I0122 17:49:01.311589 65942 caffe_interface.cpp:125] Batch 78, top-1 = 0.94
I0122 17:49:01.311594 65942 caffe_interface.cpp:125] Batch 78, top-5 = 1
I0122 17:49:01.319723 65942 caffe_interface.cpp:125] Batch 79, accuracy = 0.92
I0122 17:49:01.319731 65942 caffe_interface.cpp:125] Batch 79, loss = 0.150323
I0122 17:49:01.319733 65942 caffe_interface.cpp:125] Batch 79, top-1 = 0.92
I0122 17:49:01.319737 65942 caffe_interface.cpp:125] Batch 79, top-5 = 1
I0122 17:49:01.327649 65942 caffe_interface.cpp:125] Batch 80, accuracy = 0.96
I0122 17:49:01.327657 65942 caffe_interface.cpp:125] Batch 80, loss = 0.151007
I0122 17:49:01.327661 65942 caffe_interface.cpp:125] Batch 80, top-1 = 0.96
I0122 17:49:01.327663 65942 caffe_interface.cpp:125] Batch 80, top-5 = 1
I0122 17:49:01.337015 65942 caffe_interface.cpp:125] Batch 81, accuracy = 0.88
I0122 17:49:01.337024 65942 caffe_interface.cpp:125] Batch 81, loss = 0.411381
I0122 17:49:01.337026 65942 caffe_interface.cpp:125] Batch 81, top-1 = 0.88
I0122 17:49:01.337029 65942 caffe_interface.cpp:125] Batch 81, top-5 = 1
I0122 17:49:01.344977 65942 caffe_interface.cpp:125] Batch 82, accuracy = 0.9
I0122 17:49:01.344985 65942 caffe_interface.cpp:125] Batch 82, loss = 0.321371
I0122 17:49:01.344990 65942 caffe_interface.cpp:125] Batch 82, top-1 = 0.9
I0122 17:49:01.344992 65942 caffe_interface.cpp:125] Batch 82, top-5 = 0.98
I0122 17:49:01.353135 65942 caffe_interface.cpp:125] Batch 83, accuracy = 0.86
I0122 17:49:01.353143 65942 caffe_interface.cpp:125] Batch 83, loss = 0.366084
I0122 17:49:01.353147 65942 caffe_interface.cpp:125] Batch 83, top-1 = 0.86
I0122 17:49:01.353149 65942 caffe_interface.cpp:125] Batch 83, top-5 = 1
I0122 17:49:01.361112 65942 caffe_interface.cpp:125] Batch 84, accuracy = 0.84
I0122 17:49:01.361122 65942 caffe_interface.cpp:125] Batch 84, loss = 0.878563
I0122 17:49:01.361126 65942 caffe_interface.cpp:125] Batch 84, top-1 = 0.84
I0122 17:49:01.361129 65942 caffe_interface.cpp:125] Batch 84, top-5 = 0.96
I0122 17:49:01.370446 65942 caffe_interface.cpp:125] Batch 85, accuracy = 0.9
I0122 17:49:01.370462 65942 caffe_interface.cpp:125] Batch 85, loss = 0.403023
I0122 17:49:01.370465 65942 caffe_interface.cpp:125] Batch 85, top-1 = 0.9
I0122 17:49:01.370468 65942 caffe_interface.cpp:125] Batch 85, top-5 = 1
I0122 17:49:01.378437 65942 caffe_interface.cpp:125] Batch 86, accuracy = 0.96
I0122 17:49:01.378446 65942 caffe_interface.cpp:125] Batch 86, loss = 0.0924446
I0122 17:49:01.378450 65942 caffe_interface.cpp:125] Batch 86, top-1 = 0.96
I0122 17:49:01.378454 65942 caffe_interface.cpp:125] Batch 86, top-5 = 1
I0122 17:49:01.386587 65942 caffe_interface.cpp:125] Batch 87, accuracy = 0.9
I0122 17:49:01.386595 65942 caffe_interface.cpp:125] Batch 87, loss = 0.311068
I0122 17:49:01.386598 65942 caffe_interface.cpp:125] Batch 87, top-1 = 0.9
I0122 17:49:01.386601 65942 caffe_interface.cpp:125] Batch 87, top-5 = 0.98
I0122 17:49:01.394498 65942 caffe_interface.cpp:125] Batch 88, accuracy = 0.88
I0122 17:49:01.394507 65942 caffe_interface.cpp:125] Batch 88, loss = 0.3479
I0122 17:49:01.394510 65942 caffe_interface.cpp:125] Batch 88, top-1 = 0.88
I0122 17:49:01.394523 65942 caffe_interface.cpp:125] Batch 88, top-5 = 1
I0122 17:49:01.403872 65942 caffe_interface.cpp:125] Batch 89, accuracy = 0.92
I0122 17:49:01.403879 65942 caffe_interface.cpp:125] Batch 89, loss = 0.265134
I0122 17:49:01.403882 65942 caffe_interface.cpp:125] Batch 89, top-1 = 0.92
I0122 17:49:01.403885 65942 caffe_interface.cpp:125] Batch 89, top-5 = 1
I0122 17:49:01.411833 65942 caffe_interface.cpp:125] Batch 90, accuracy = 0.86
I0122 17:49:01.411841 65942 caffe_interface.cpp:125] Batch 90, loss = 0.751044
I0122 17:49:01.411845 65942 caffe_interface.cpp:125] Batch 90, top-1 = 0.86
I0122 17:49:01.411849 65942 caffe_interface.cpp:125] Batch 90, top-5 = 0.98
I0122 17:49:01.420035 65942 caffe_interface.cpp:125] Batch 91, accuracy = 0.82
I0122 17:49:01.420044 65942 caffe_interface.cpp:125] Batch 91, loss = 0.370616
I0122 17:49:01.420048 65942 caffe_interface.cpp:125] Batch 91, top-1 = 0.82
I0122 17:49:01.420051 65942 caffe_interface.cpp:125] Batch 91, top-5 = 1
I0122 17:49:01.427995 65942 caffe_interface.cpp:125] Batch 92, accuracy = 0.92
I0122 17:49:01.428004 65942 caffe_interface.cpp:125] Batch 92, loss = 0.410459
I0122 17:49:01.428009 65942 caffe_interface.cpp:125] Batch 92, top-1 = 0.92
I0122 17:49:01.428012 65942 caffe_interface.cpp:125] Batch 92, top-5 = 0.96
I0122 17:49:01.437350 65942 caffe_interface.cpp:125] Batch 93, accuracy = 0.9
I0122 17:49:01.437361 65942 caffe_interface.cpp:125] Batch 93, loss = 0.241307
I0122 17:49:01.437364 65942 caffe_interface.cpp:125] Batch 93, top-1 = 0.9
I0122 17:49:01.437367 65942 caffe_interface.cpp:125] Batch 93, top-5 = 1
I0122 17:49:01.445324 65942 caffe_interface.cpp:125] Batch 94, accuracy = 0.8
I0122 17:49:01.445333 65942 caffe_interface.cpp:125] Batch 94, loss = 0.680699
I0122 17:49:01.445338 65942 caffe_interface.cpp:125] Batch 94, top-1 = 0.8
I0122 17:49:01.445341 65942 caffe_interface.cpp:125] Batch 94, top-5 = 1
I0122 17:49:01.453513 65942 caffe_interface.cpp:125] Batch 95, accuracy = 0.96
I0122 17:49:01.453521 65942 caffe_interface.cpp:125] Batch 95, loss = 0.100861
I0122 17:49:01.453526 65942 caffe_interface.cpp:125] Batch 95, top-1 = 0.96
I0122 17:49:01.453528 65942 caffe_interface.cpp:125] Batch 95, top-5 = 1
I0122 17:49:01.461488 65942 caffe_interface.cpp:125] Batch 96, accuracy = 0.84
I0122 17:49:01.461498 65942 caffe_interface.cpp:125] Batch 96, loss = 0.696168
I0122 17:49:01.461501 65942 caffe_interface.cpp:125] Batch 96, top-1 = 0.84
I0122 17:49:01.461505 65942 caffe_interface.cpp:125] Batch 96, top-5 = 1
I0122 17:49:01.470871 65942 caffe_interface.cpp:125] Batch 97, accuracy = 0.9
I0122 17:49:01.470880 65942 caffe_interface.cpp:125] Batch 97, loss = 0.423592
I0122 17:49:01.470885 65942 caffe_interface.cpp:125] Batch 97, top-1 = 0.9
I0122 17:49:01.470888 65942 caffe_interface.cpp:125] Batch 97, top-5 = 1
I0122 17:49:01.478845 65942 caffe_interface.cpp:125] Batch 98, accuracy = 0.9
I0122 17:49:01.478855 65942 caffe_interface.cpp:125] Batch 98, loss = 0.364162
I0122 17:49:01.478868 65942 caffe_interface.cpp:125] Batch 98, top-1 = 0.9
I0122 17:49:01.478871 65942 caffe_interface.cpp:125] Batch 98, top-5 = 1
I0122 17:49:01.487071 65942 caffe_interface.cpp:125] Batch 99, accuracy = 0.88
I0122 17:49:01.487080 65942 caffe_interface.cpp:125] Batch 99, loss = 0.581427
I0122 17:49:01.487084 65942 caffe_interface.cpp:125] Batch 99, top-1 = 0.88
I0122 17:49:01.487088 65942 caffe_interface.cpp:125] Batch 99, top-5 = 1
I0122 17:49:01.495023 65942 caffe_interface.cpp:125] Batch 100, accuracy = 0.96
I0122 17:49:01.495033 65942 caffe_interface.cpp:125] Batch 100, loss = 0.162925
I0122 17:49:01.495035 65942 caffe_interface.cpp:125] Batch 100, top-1 = 0.96
I0122 17:49:01.495038 65942 caffe_interface.cpp:125] Batch 100, top-5 = 1
I0122 17:49:01.504428 65942 caffe_interface.cpp:125] Batch 101, accuracy = 0.84
I0122 17:49:01.504437 65942 caffe_interface.cpp:125] Batch 101, loss = 0.446259
I0122 17:49:01.504441 65942 caffe_interface.cpp:125] Batch 101, top-1 = 0.84
I0122 17:49:01.504444 65942 caffe_interface.cpp:125] Batch 101, top-5 = 1
I0122 17:49:01.512401 65942 caffe_interface.cpp:125] Batch 102, accuracy = 0.84
I0122 17:49:01.512410 65942 caffe_interface.cpp:125] Batch 102, loss = 0.645454
I0122 17:49:01.512413 65942 caffe_interface.cpp:125] Batch 102, top-1 = 0.84
I0122 17:49:01.512418 65942 caffe_interface.cpp:125] Batch 102, top-5 = 1
I0122 17:49:01.520555 65942 caffe_interface.cpp:125] Batch 103, accuracy = 0.92
I0122 17:49:01.520563 65942 caffe_interface.cpp:125] Batch 103, loss = 0.188827
I0122 17:49:01.520566 65942 caffe_interface.cpp:125] Batch 103, top-1 = 0.92
I0122 17:49:01.520570 65942 caffe_interface.cpp:125] Batch 103, top-5 = 1
I0122 17:49:01.528497 65942 caffe_interface.cpp:125] Batch 104, accuracy = 0.96
I0122 17:49:01.528507 65942 caffe_interface.cpp:125] Batch 104, loss = 0.200938
I0122 17:49:01.528512 65942 caffe_interface.cpp:125] Batch 104, top-1 = 0.96
I0122 17:49:01.528515 65942 caffe_interface.cpp:125] Batch 104, top-5 = 1
I0122 17:49:01.537844 65942 caffe_interface.cpp:125] Batch 105, accuracy = 0.88
I0122 17:49:01.537853 65942 caffe_interface.cpp:125] Batch 105, loss = 0.295111
I0122 17:49:01.537855 65942 caffe_interface.cpp:125] Batch 105, top-1 = 0.88
I0122 17:49:01.537858 65942 caffe_interface.cpp:125] Batch 105, top-5 = 1
I0122 17:49:01.545838 65942 caffe_interface.cpp:125] Batch 106, accuracy = 0.9
I0122 17:49:01.545848 65942 caffe_interface.cpp:125] Batch 106, loss = 0.538785
I0122 17:49:01.545852 65942 caffe_interface.cpp:125] Batch 106, top-1 = 0.9
I0122 17:49:01.545856 65942 caffe_interface.cpp:125] Batch 106, top-5 = 1
I0122 17:49:01.554021 65942 caffe_interface.cpp:125] Batch 107, accuracy = 0.84
I0122 17:49:01.554029 65942 caffe_interface.cpp:125] Batch 107, loss = 0.776244
I0122 17:49:01.554033 65942 caffe_interface.cpp:125] Batch 107, top-1 = 0.84
I0122 17:49:01.554045 65942 caffe_interface.cpp:125] Batch 107, top-5 = 0.98
I0122 17:49:01.561986 65942 caffe_interface.cpp:125] Batch 108, accuracy = 0.88
I0122 17:49:01.561996 65942 caffe_interface.cpp:125] Batch 108, loss = 0.745615
I0122 17:49:01.562000 65942 caffe_interface.cpp:125] Batch 108, top-1 = 0.88
I0122 17:49:01.562002 65942 caffe_interface.cpp:125] Batch 108, top-5 = 0.98
I0122 17:49:01.571303 65942 caffe_interface.cpp:125] Batch 109, accuracy = 0.9
I0122 17:49:01.571311 65942 caffe_interface.cpp:125] Batch 109, loss = 0.420744
I0122 17:49:01.571314 65942 caffe_interface.cpp:125] Batch 109, top-1 = 0.9
I0122 17:49:01.571317 65942 caffe_interface.cpp:125] Batch 109, top-5 = 1
I0122 17:49:01.579231 65942 caffe_interface.cpp:125] Batch 110, accuracy = 0.88
I0122 17:49:01.579238 65942 caffe_interface.cpp:125] Batch 110, loss = 0.382592
I0122 17:49:01.579241 65942 caffe_interface.cpp:125] Batch 110, top-1 = 0.88
I0122 17:49:01.579244 65942 caffe_interface.cpp:125] Batch 110, top-5 = 1
I0122 17:49:01.587414 65942 caffe_interface.cpp:125] Batch 111, accuracy = 0.9
I0122 17:49:01.587422 65942 caffe_interface.cpp:125] Batch 111, loss = 0.437219
I0122 17:49:01.587424 65942 caffe_interface.cpp:125] Batch 111, top-1 = 0.9
I0122 17:49:01.587436 65942 caffe_interface.cpp:125] Batch 111, top-5 = 0.98
I0122 17:49:01.595384 65942 caffe_interface.cpp:125] Batch 112, accuracy = 0.9
I0122 17:49:01.595393 65942 caffe_interface.cpp:125] Batch 112, loss = 0.285263
I0122 17:49:01.595397 65942 caffe_interface.cpp:125] Batch 112, top-1 = 0.9
I0122 17:49:01.595402 65942 caffe_interface.cpp:125] Batch 112, top-5 = 1
I0122 17:49:01.604708 65942 caffe_interface.cpp:125] Batch 113, accuracy = 0.84
I0122 17:49:01.604717 65942 caffe_interface.cpp:125] Batch 113, loss = 0.391911
I0122 17:49:01.604719 65942 caffe_interface.cpp:125] Batch 113, top-1 = 0.84
I0122 17:49:01.604732 65942 caffe_interface.cpp:125] Batch 113, top-5 = 1
I0122 17:49:01.612673 65942 caffe_interface.cpp:125] Batch 114, accuracy = 0.88
I0122 17:49:01.612684 65942 caffe_interface.cpp:125] Batch 114, loss = 0.365984
I0122 17:49:01.612687 65942 caffe_interface.cpp:125] Batch 114, top-1 = 0.88
I0122 17:49:01.612690 65942 caffe_interface.cpp:125] Batch 114, top-5 = 1
I0122 17:49:01.620874 65942 caffe_interface.cpp:125] Batch 115, accuracy = 0.98
I0122 17:49:01.620883 65942 caffe_interface.cpp:125] Batch 115, loss = 0.0817875
I0122 17:49:01.620887 65942 caffe_interface.cpp:125] Batch 115, top-1 = 0.98
I0122 17:49:01.620890 65942 caffe_interface.cpp:125] Batch 115, top-5 = 1
I0122 17:49:01.628809 65942 caffe_interface.cpp:125] Batch 116, accuracy = 0.92
I0122 17:49:01.628818 65942 caffe_interface.cpp:125] Batch 116, loss = 0.377232
I0122 17:49:01.628821 65942 caffe_interface.cpp:125] Batch 116, top-1 = 0.92
I0122 17:49:01.628824 65942 caffe_interface.cpp:125] Batch 116, top-5 = 1
I0122 17:49:01.638126 65942 caffe_interface.cpp:125] Batch 117, accuracy = 0.84
I0122 17:49:01.638135 65942 caffe_interface.cpp:125] Batch 117, loss = 0.462163
I0122 17:49:01.638137 65942 caffe_interface.cpp:125] Batch 117, top-1 = 0.84
I0122 17:49:01.638140 65942 caffe_interface.cpp:125] Batch 117, top-5 = 1
I0122 17:49:01.646092 65942 caffe_interface.cpp:125] Batch 118, accuracy = 0.92
I0122 17:49:01.646100 65942 caffe_interface.cpp:125] Batch 118, loss = 0.273839
I0122 17:49:01.646103 65942 caffe_interface.cpp:125] Batch 118, top-1 = 0.92
I0122 17:49:01.646107 65942 caffe_interface.cpp:125] Batch 118, top-5 = 1
I0122 17:49:01.654271 65942 caffe_interface.cpp:125] Batch 119, accuracy = 0.88
I0122 17:49:01.654279 65942 caffe_interface.cpp:125] Batch 119, loss = 0.492549
I0122 17:49:01.654283 65942 caffe_interface.cpp:125] Batch 119, top-1 = 0.88
I0122 17:49:01.654285 65942 caffe_interface.cpp:125] Batch 119, top-5 = 0.98
I0122 17:49:01.662209 65942 caffe_interface.cpp:125] Batch 120, accuracy = 0.88
I0122 17:49:01.662217 65942 caffe_interface.cpp:125] Batch 120, loss = 0.456158
I0122 17:49:01.662220 65942 caffe_interface.cpp:125] Batch 120, top-1 = 0.88
I0122 17:49:01.662223 65942 caffe_interface.cpp:125] Batch 120, top-5 = 1
I0122 17:49:01.671551 65942 caffe_interface.cpp:125] Batch 121, accuracy = 0.82
I0122 17:49:01.671561 65942 caffe_interface.cpp:125] Batch 121, loss = 0.607135
I0122 17:49:01.671562 65942 caffe_interface.cpp:125] Batch 121, top-1 = 0.82
I0122 17:49:01.671566 65942 caffe_interface.cpp:125] Batch 121, top-5 = 0.98
I0122 17:49:01.679476 65942 caffe_interface.cpp:125] Batch 122, accuracy = 0.96
I0122 17:49:01.679484 65942 caffe_interface.cpp:125] Batch 122, loss = 0.159126
I0122 17:49:01.679487 65942 caffe_interface.cpp:125] Batch 122, top-1 = 0.96
I0122 17:49:01.679500 65942 caffe_interface.cpp:125] Batch 122, top-5 = 1
I0122 17:49:01.687678 65942 caffe_interface.cpp:125] Batch 123, accuracy = 0.88
I0122 17:49:01.687687 65942 caffe_interface.cpp:125] Batch 123, loss = 0.42328
I0122 17:49:01.687690 65942 caffe_interface.cpp:125] Batch 123, top-1 = 0.88
I0122 17:49:01.687692 65942 caffe_interface.cpp:125] Batch 123, top-5 = 0.98
I0122 17:49:01.695585 65942 caffe_interface.cpp:125] Batch 124, accuracy = 0.92
I0122 17:49:01.695592 65942 caffe_interface.cpp:125] Batch 124, loss = 0.203536
I0122 17:49:01.695595 65942 caffe_interface.cpp:125] Batch 124, top-1 = 0.92
I0122 17:49:01.695598 65942 caffe_interface.cpp:125] Batch 124, top-5 = 1
I0122 17:49:01.704996 65942 caffe_interface.cpp:125] Batch 125, accuracy = 0.9
I0122 17:49:01.705004 65942 caffe_interface.cpp:125] Batch 125, loss = 0.285719
I0122 17:49:01.705008 65942 caffe_interface.cpp:125] Batch 125, top-1 = 0.9
I0122 17:49:01.705010 65942 caffe_interface.cpp:125] Batch 125, top-5 = 1
I0122 17:49:01.712935 65942 caffe_interface.cpp:125] Batch 126, accuracy = 0.86
I0122 17:49:01.712944 65942 caffe_interface.cpp:125] Batch 126, loss = 0.495734
I0122 17:49:01.712946 65942 caffe_interface.cpp:125] Batch 126, top-1 = 0.86
I0122 17:49:01.712949 65942 caffe_interface.cpp:125] Batch 126, top-5 = 1
I0122 17:49:01.720929 65942 caffe_interface.cpp:125] Batch 127, accuracy = 0.9
I0122 17:49:01.720937 65942 caffe_interface.cpp:125] Batch 127, loss = 0.297593
I0122 17:49:01.720939 65942 caffe_interface.cpp:125] Batch 127, top-1 = 0.9
I0122 17:49:01.720952 65942 caffe_interface.cpp:125] Batch 127, top-5 = 1
I0122 17:49:01.728916 65942 caffe_interface.cpp:125] Batch 128, accuracy = 0.88
I0122 17:49:01.728926 65942 caffe_interface.cpp:125] Batch 128, loss = 0.252981
I0122 17:49:01.728930 65942 caffe_interface.cpp:125] Batch 128, top-1 = 0.88
I0122 17:49:01.728933 65942 caffe_interface.cpp:125] Batch 128, top-5 = 1
I0122 17:49:01.738245 65942 caffe_interface.cpp:125] Batch 129, accuracy = 0.78
I0122 17:49:01.738255 65942 caffe_interface.cpp:125] Batch 129, loss = 0.61036
I0122 17:49:01.738258 65942 caffe_interface.cpp:125] Batch 129, top-1 = 0.78
I0122 17:49:01.738261 65942 caffe_interface.cpp:125] Batch 129, top-5 = 1
I0122 17:49:01.746212 65942 caffe_interface.cpp:125] Batch 130, accuracy = 0.88
I0122 17:49:01.746222 65942 caffe_interface.cpp:125] Batch 130, loss = 0.372831
I0122 17:49:01.746225 65942 caffe_interface.cpp:125] Batch 130, top-1 = 0.88
I0122 17:49:01.746229 65942 caffe_interface.cpp:125] Batch 130, top-5 = 1
I0122 17:49:01.754444 65942 caffe_interface.cpp:125] Batch 131, accuracy = 0.9
I0122 17:49:01.754454 65942 caffe_interface.cpp:125] Batch 131, loss = 0.434598
I0122 17:49:01.754457 65942 caffe_interface.cpp:125] Batch 131, top-1 = 0.9
I0122 17:49:01.754460 65942 caffe_interface.cpp:125] Batch 131, top-5 = 1
I0122 17:49:01.762411 65942 caffe_interface.cpp:125] Batch 132, accuracy = 0.86
I0122 17:49:01.762420 65942 caffe_interface.cpp:125] Batch 132, loss = 0.644196
I0122 17:49:01.762424 65942 caffe_interface.cpp:125] Batch 132, top-1 = 0.86
I0122 17:49:01.762428 65942 caffe_interface.cpp:125] Batch 132, top-5 = 0.98
I0122 17:49:01.771721 65942 caffe_interface.cpp:125] Batch 133, accuracy = 0.88
I0122 17:49:01.771730 65942 caffe_interface.cpp:125] Batch 133, loss = 0.297228
I0122 17:49:01.771733 65942 caffe_interface.cpp:125] Batch 133, top-1 = 0.88
I0122 17:49:01.771736 65942 caffe_interface.cpp:125] Batch 133, top-5 = 1
I0122 17:49:01.779716 65942 caffe_interface.cpp:125] Batch 134, accuracy = 0.84
I0122 17:49:01.779724 65942 caffe_interface.cpp:125] Batch 134, loss = 0.834322
I0122 17:49:01.779728 65942 caffe_interface.cpp:125] Batch 134, top-1 = 0.84
I0122 17:49:01.779731 65942 caffe_interface.cpp:125] Batch 134, top-5 = 1
I0122 17:49:01.787917 65942 caffe_interface.cpp:125] Batch 135, accuracy = 0.86
I0122 17:49:01.787926 65942 caffe_interface.cpp:125] Batch 135, loss = 0.614172
I0122 17:49:01.787930 65942 caffe_interface.cpp:125] Batch 135, top-1 = 0.86
I0122 17:49:01.787933 65942 caffe_interface.cpp:125] Batch 135, top-5 = 1
I0122 17:49:01.795866 65942 caffe_interface.cpp:125] Batch 136, accuracy = 0.94
I0122 17:49:01.795876 65942 caffe_interface.cpp:125] Batch 136, loss = 0.176399
I0122 17:49:01.795879 65942 caffe_interface.cpp:125] Batch 136, top-1 = 0.94
I0122 17:49:01.795882 65942 caffe_interface.cpp:125] Batch 136, top-5 = 1
I0122 17:49:01.805177 65942 caffe_interface.cpp:125] Batch 137, accuracy = 0.9
I0122 17:49:01.805186 65942 caffe_interface.cpp:125] Batch 137, loss = 0.38774
I0122 17:49:01.805188 65942 caffe_interface.cpp:125] Batch 137, top-1 = 0.9
I0122 17:49:01.805202 65942 caffe_interface.cpp:125] Batch 137, top-5 = 1
I0122 17:49:01.813148 65942 caffe_interface.cpp:125] Batch 138, accuracy = 0.86
I0122 17:49:01.813168 65942 caffe_interface.cpp:125] Batch 138, loss = 0.522923
I0122 17:49:01.813171 65942 caffe_interface.cpp:125] Batch 138, top-1 = 0.86
I0122 17:49:01.813175 65942 caffe_interface.cpp:125] Batch 138, top-5 = 1
I0122 17:49:01.821386 65942 caffe_interface.cpp:125] Batch 139, accuracy = 0.82
I0122 17:49:01.821396 65942 caffe_interface.cpp:125] Batch 139, loss = 0.688354
I0122 17:49:01.821400 65942 caffe_interface.cpp:125] Batch 139, top-1 = 0.82
I0122 17:49:01.821403 65942 caffe_interface.cpp:125] Batch 139, top-5 = 1
I0122 17:49:01.829340 65942 caffe_interface.cpp:125] Batch 140, accuracy = 0.88
I0122 17:49:01.829349 65942 caffe_interface.cpp:125] Batch 140, loss = 0.598675
I0122 17:49:01.829354 65942 caffe_interface.cpp:125] Batch 140, top-1 = 0.88
I0122 17:49:01.829356 65942 caffe_interface.cpp:125] Batch 140, top-5 = 1
I0122 17:49:01.838690 65942 caffe_interface.cpp:125] Batch 141, accuracy = 0.92
I0122 17:49:01.838698 65942 caffe_interface.cpp:125] Batch 141, loss = 0.399386
I0122 17:49:01.838701 65942 caffe_interface.cpp:125] Batch 141, top-1 = 0.92
I0122 17:49:01.838706 65942 caffe_interface.cpp:125] Batch 141, top-5 = 1
I0122 17:49:01.846649 65942 caffe_interface.cpp:125] Batch 142, accuracy = 0.92
I0122 17:49:01.846658 65942 caffe_interface.cpp:125] Batch 142, loss = 0.229844
I0122 17:49:01.846662 65942 caffe_interface.cpp:125] Batch 142, top-1 = 0.92
I0122 17:49:01.846665 65942 caffe_interface.cpp:125] Batch 142, top-5 = 1
I0122 17:49:01.854663 65942 caffe_interface.cpp:125] Batch 143, accuracy = 0.9
I0122 17:49:01.854672 65942 caffe_interface.cpp:125] Batch 143, loss = 0.422608
I0122 17:49:01.854676 65942 caffe_interface.cpp:125] Batch 143, top-1 = 0.9
I0122 17:49:01.854681 65942 caffe_interface.cpp:125] Batch 143, top-5 = 1
I0122 17:49:01.862639 65942 caffe_interface.cpp:125] Batch 144, accuracy = 0.9
I0122 17:49:01.862649 65942 caffe_interface.cpp:125] Batch 144, loss = 0.484465
I0122 17:49:01.862653 65942 caffe_interface.cpp:125] Batch 144, top-1 = 0.9
I0122 17:49:01.862656 65942 caffe_interface.cpp:125] Batch 144, top-5 = 1
I0122 17:49:01.871979 65942 caffe_interface.cpp:125] Batch 145, accuracy = 0.86
I0122 17:49:01.871987 65942 caffe_interface.cpp:125] Batch 145, loss = 0.320717
I0122 17:49:01.871990 65942 caffe_interface.cpp:125] Batch 145, top-1 = 0.86
I0122 17:49:01.871994 65942 caffe_interface.cpp:125] Batch 145, top-5 = 1
I0122 17:49:01.879948 65942 caffe_interface.cpp:125] Batch 146, accuracy = 0.86
I0122 17:49:01.879958 65942 caffe_interface.cpp:125] Batch 146, loss = 0.722747
I0122 17:49:01.879961 65942 caffe_interface.cpp:125] Batch 146, top-1 = 0.86
I0122 17:49:01.879966 65942 caffe_interface.cpp:125] Batch 146, top-5 = 1
I0122 17:49:01.888010 65942 caffe_interface.cpp:125] Batch 147, accuracy = 0.9
I0122 17:49:01.888020 65942 caffe_interface.cpp:125] Batch 147, loss = 0.24458
I0122 17:49:01.888023 65942 caffe_interface.cpp:125] Batch 147, top-1 = 0.9
I0122 17:49:01.888026 65942 caffe_interface.cpp:125] Batch 147, top-5 = 1
I0122 17:49:01.895954 65942 caffe_interface.cpp:125] Batch 148, accuracy = 0.9
I0122 17:49:01.895964 65942 caffe_interface.cpp:125] Batch 148, loss = 0.499481
I0122 17:49:01.895968 65942 caffe_interface.cpp:125] Batch 148, top-1 = 0.9
I0122 17:49:01.895972 65942 caffe_interface.cpp:125] Batch 148, top-5 = 1
I0122 17:49:01.905279 65942 caffe_interface.cpp:125] Batch 149, accuracy = 0.94
I0122 17:49:01.905287 65942 caffe_interface.cpp:125] Batch 149, loss = 0.110697
I0122 17:49:01.905292 65942 caffe_interface.cpp:125] Batch 149, top-1 = 0.94
I0122 17:49:01.905294 65942 caffe_interface.cpp:125] Batch 149, top-5 = 1
I0122 17:49:01.913221 65942 caffe_interface.cpp:125] Batch 150, accuracy = 0.94
I0122 17:49:01.913230 65942 caffe_interface.cpp:125] Batch 150, loss = 0.130066
I0122 17:49:01.913233 65942 caffe_interface.cpp:125] Batch 150, top-1 = 0.94
I0122 17:49:01.913236 65942 caffe_interface.cpp:125] Batch 150, top-5 = 1
I0122 17:49:01.921417 65942 caffe_interface.cpp:125] Batch 151, accuracy = 0.84
I0122 17:49:01.921437 65942 caffe_interface.cpp:125] Batch 151, loss = 0.471706
I0122 17:49:01.921442 65942 caffe_interface.cpp:125] Batch 151, top-1 = 0.84
I0122 17:49:01.921444 65942 caffe_interface.cpp:125] Batch 151, top-5 = 1
I0122 17:49:01.929392 65942 caffe_interface.cpp:125] Batch 152, accuracy = 0.86
I0122 17:49:01.929402 65942 caffe_interface.cpp:125] Batch 152, loss = 0.300242
I0122 17:49:01.929406 65942 caffe_interface.cpp:125] Batch 152, top-1 = 0.86
I0122 17:49:01.929409 65942 caffe_interface.cpp:125] Batch 152, top-5 = 1
I0122 17:49:01.938725 65942 caffe_interface.cpp:125] Batch 153, accuracy = 0.92
I0122 17:49:01.938733 65942 caffe_interface.cpp:125] Batch 153, loss = 0.233642
I0122 17:49:01.938735 65942 caffe_interface.cpp:125] Batch 153, top-1 = 0.92
I0122 17:49:01.938740 65942 caffe_interface.cpp:125] Batch 153, top-5 = 1
I0122 17:49:01.946686 65942 caffe_interface.cpp:125] Batch 154, accuracy = 0.9
I0122 17:49:01.946696 65942 caffe_interface.cpp:125] Batch 154, loss = 0.231092
I0122 17:49:01.946698 65942 caffe_interface.cpp:125] Batch 154, top-1 = 0.9
I0122 17:49:01.946702 65942 caffe_interface.cpp:125] Batch 154, top-5 = 1
I0122 17:49:01.954744 65942 caffe_interface.cpp:125] Batch 155, accuracy = 0.96
I0122 17:49:01.954753 65942 caffe_interface.cpp:125] Batch 155, loss = 0.148646
I0122 17:49:01.954757 65942 caffe_interface.cpp:125] Batch 155, top-1 = 0.96
I0122 17:49:01.954761 65942 caffe_interface.cpp:125] Batch 155, top-5 = 1
I0122 17:49:01.962736 65942 caffe_interface.cpp:125] Batch 156, accuracy = 0.9
I0122 17:49:01.962745 65942 caffe_interface.cpp:125] Batch 156, loss = 0.268249
I0122 17:49:01.962749 65942 caffe_interface.cpp:125] Batch 156, top-1 = 0.9
I0122 17:49:01.962752 65942 caffe_interface.cpp:125] Batch 156, top-5 = 1
I0122 17:49:01.972082 65942 caffe_interface.cpp:125] Batch 157, accuracy = 0.94
I0122 17:49:01.972091 65942 caffe_interface.cpp:125] Batch 157, loss = 0.245319
I0122 17:49:01.972095 65942 caffe_interface.cpp:125] Batch 157, top-1 = 0.94
I0122 17:49:01.972097 65942 caffe_interface.cpp:125] Batch 157, top-5 = 1
I0122 17:49:01.980017 65942 caffe_interface.cpp:125] Batch 158, accuracy = 0.9
I0122 17:49:01.980026 65942 caffe_interface.cpp:125] Batch 158, loss = 0.510567
I0122 17:49:01.980028 65942 caffe_interface.cpp:125] Batch 158, top-1 = 0.9
I0122 17:49:01.980031 65942 caffe_interface.cpp:125] Batch 158, top-5 = 1
I0122 17:49:01.988212 65942 caffe_interface.cpp:125] Batch 159, accuracy = 0.88
I0122 17:49:01.988221 65942 caffe_interface.cpp:125] Batch 159, loss = 0.516111
I0122 17:49:01.988225 65942 caffe_interface.cpp:125] Batch 159, top-1 = 0.88
I0122 17:49:01.988229 65942 caffe_interface.cpp:125] Batch 159, top-5 = 1
I0122 17:49:01.996163 65942 caffe_interface.cpp:125] Batch 160, accuracy = 0.92
I0122 17:49:01.996172 65942 caffe_interface.cpp:125] Batch 160, loss = 0.354749
I0122 17:49:01.996176 65942 caffe_interface.cpp:125] Batch 160, top-1 = 0.92
I0122 17:49:01.996179 65942 caffe_interface.cpp:125] Batch 160, top-5 = 1
I0122 17:49:02.005506 65942 caffe_interface.cpp:125] Batch 161, accuracy = 0.92
I0122 17:49:02.005514 65942 caffe_interface.cpp:125] Batch 161, loss = 0.215946
I0122 17:49:02.005517 65942 caffe_interface.cpp:125] Batch 161, top-1 = 0.92
I0122 17:49:02.005519 65942 caffe_interface.cpp:125] Batch 161, top-5 = 1
I0122 17:49:02.013417 65942 caffe_interface.cpp:125] Batch 162, accuracy = 0.84
I0122 17:49:02.013425 65942 caffe_interface.cpp:125] Batch 162, loss = 0.438572
I0122 17:49:02.013428 65942 caffe_interface.cpp:125] Batch 162, top-1 = 0.84
I0122 17:49:02.013432 65942 caffe_interface.cpp:125] Batch 162, top-5 = 1
I0122 17:49:02.021466 65942 caffe_interface.cpp:125] Batch 163, accuracy = 0.96
I0122 17:49:02.021476 65942 caffe_interface.cpp:125] Batch 163, loss = 0.274304
I0122 17:49:02.021478 65942 caffe_interface.cpp:125] Batch 163, top-1 = 0.96
I0122 17:49:02.021482 65942 caffe_interface.cpp:125] Batch 163, top-5 = 1
I0122 17:49:02.029433 65942 caffe_interface.cpp:125] Batch 164, accuracy = 0.84
I0122 17:49:02.029443 65942 caffe_interface.cpp:125] Batch 164, loss = 0.363142
I0122 17:49:02.029455 65942 caffe_interface.cpp:125] Batch 164, top-1 = 0.84
I0122 17:49:02.029459 65942 caffe_interface.cpp:125] Batch 164, top-5 = 1
I0122 17:49:02.038746 65942 caffe_interface.cpp:125] Batch 165, accuracy = 0.92
I0122 17:49:02.038754 65942 caffe_interface.cpp:125] Batch 165, loss = 0.35515
I0122 17:49:02.038758 65942 caffe_interface.cpp:125] Batch 165, top-1 = 0.92
I0122 17:49:02.038760 65942 caffe_interface.cpp:125] Batch 165, top-5 = 1
I0122 17:49:02.046689 65942 caffe_interface.cpp:125] Batch 166, accuracy = 0.94
I0122 17:49:02.046697 65942 caffe_interface.cpp:125] Batch 166, loss = 0.178978
I0122 17:49:02.046701 65942 caffe_interface.cpp:125] Batch 166, top-1 = 0.94
I0122 17:49:02.046705 65942 caffe_interface.cpp:125] Batch 166, top-5 = 0.98
I0122 17:49:02.054857 65942 caffe_interface.cpp:125] Batch 167, accuracy = 0.88
I0122 17:49:02.054865 65942 caffe_interface.cpp:125] Batch 167, loss = 0.426291
I0122 17:49:02.054867 65942 caffe_interface.cpp:125] Batch 167, top-1 = 0.88
I0122 17:49:02.054870 65942 caffe_interface.cpp:125] Batch 167, top-5 = 0.98
I0122 17:49:02.062788 65942 caffe_interface.cpp:125] Batch 168, accuracy = 0.92
I0122 17:49:02.062795 65942 caffe_interface.cpp:125] Batch 168, loss = 0.15589
I0122 17:49:02.062798 65942 caffe_interface.cpp:125] Batch 168, top-1 = 0.92
I0122 17:49:02.062800 65942 caffe_interface.cpp:125] Batch 168, top-5 = 1
I0122 17:49:02.072085 65942 caffe_interface.cpp:125] Batch 169, accuracy = 0.9
I0122 17:49:02.072093 65942 caffe_interface.cpp:125] Batch 169, loss = 0.297143
I0122 17:49:02.072095 65942 caffe_interface.cpp:125] Batch 169, top-1 = 0.9
I0122 17:49:02.072098 65942 caffe_interface.cpp:125] Batch 169, top-5 = 1
I0122 17:49:02.080057 65942 caffe_interface.cpp:125] Batch 170, accuracy = 0.94
I0122 17:49:02.080066 65942 caffe_interface.cpp:125] Batch 170, loss = 0.194909
I0122 17:49:02.080070 65942 caffe_interface.cpp:125] Batch 170, top-1 = 0.94
I0122 17:49:02.080075 65942 caffe_interface.cpp:125] Batch 170, top-5 = 1
I0122 17:49:02.088250 65942 caffe_interface.cpp:125] Batch 171, accuracy = 0.92
I0122 17:49:02.088260 65942 caffe_interface.cpp:125] Batch 171, loss = 0.285247
I0122 17:49:02.088264 65942 caffe_interface.cpp:125] Batch 171, top-1 = 0.92
I0122 17:49:02.088268 65942 caffe_interface.cpp:125] Batch 171, top-5 = 1
I0122 17:49:02.096222 65942 caffe_interface.cpp:125] Batch 172, accuracy = 0.88
I0122 17:49:02.096231 65942 caffe_interface.cpp:125] Batch 172, loss = 0.424375
I0122 17:49:02.096235 65942 caffe_interface.cpp:125] Batch 172, top-1 = 0.88
I0122 17:49:02.096238 65942 caffe_interface.cpp:125] Batch 172, top-5 = 0.98
I0122 17:49:02.105584 65942 caffe_interface.cpp:125] Batch 173, accuracy = 0.88
I0122 17:49:02.105592 65942 caffe_interface.cpp:125] Batch 173, loss = 0.368414
I0122 17:49:02.105595 65942 caffe_interface.cpp:125] Batch 173, top-1 = 0.88
I0122 17:49:02.105598 65942 caffe_interface.cpp:125] Batch 173, top-5 = 1
I0122 17:49:02.113557 65942 caffe_interface.cpp:125] Batch 174, accuracy = 0.9
I0122 17:49:02.113566 65942 caffe_interface.cpp:125] Batch 174, loss = 0.312735
I0122 17:49:02.113570 65942 caffe_interface.cpp:125] Batch 174, top-1 = 0.9
I0122 17:49:02.113574 65942 caffe_interface.cpp:125] Batch 174, top-5 = 1
I0122 17:49:02.121567 65942 caffe_interface.cpp:125] Batch 175, accuracy = 0.84
I0122 17:49:02.121575 65942 caffe_interface.cpp:125] Batch 175, loss = 0.544057
I0122 17:49:02.121578 65942 caffe_interface.cpp:125] Batch 175, top-1 = 0.84
I0122 17:49:02.121582 65942 caffe_interface.cpp:125] Batch 175, top-5 = 1
I0122 17:49:02.129508 65942 caffe_interface.cpp:125] Batch 176, accuracy = 0.84
I0122 17:49:02.129515 65942 caffe_interface.cpp:125] Batch 176, loss = 0.87636
I0122 17:49:02.129518 65942 caffe_interface.cpp:125] Batch 176, top-1 = 0.84
I0122 17:49:02.129523 65942 caffe_interface.cpp:125] Batch 176, top-5 = 0.98
I0122 17:49:02.138988 65942 caffe_interface.cpp:125] Batch 177, accuracy = 0.82
I0122 17:49:02.138996 65942 caffe_interface.cpp:125] Batch 177, loss = 0.529536
I0122 17:49:02.138998 65942 caffe_interface.cpp:125] Batch 177, top-1 = 0.82
I0122 17:49:02.139010 65942 caffe_interface.cpp:125] Batch 177, top-5 = 1
I0122 17:49:02.146930 65942 caffe_interface.cpp:125] Batch 178, accuracy = 0.96
I0122 17:49:02.146939 65942 caffe_interface.cpp:125] Batch 178, loss = 0.118293
I0122 17:49:02.146941 65942 caffe_interface.cpp:125] Batch 178, top-1 = 0.96
I0122 17:49:02.146944 65942 caffe_interface.cpp:125] Batch 178, top-5 = 1
I0122 17:49:02.154954 65942 caffe_interface.cpp:125] Batch 179, accuracy = 0.86
I0122 17:49:02.154964 65942 caffe_interface.cpp:125] Batch 179, loss = 0.398241
I0122 17:49:02.154968 65942 caffe_interface.cpp:125] Batch 179, top-1 = 0.86
I0122 17:49:02.154973 65942 caffe_interface.cpp:125] Batch 179, top-5 = 0.98
I0122 17:49:02.154975 65942 caffe_interface.cpp:130] Loss: 0.373471
I0122 17:49:02.154978 65942 caffe_interface.cpp:142] accuracy = 0.896333
I0122 17:49:02.154985 65942 caffe_interface.cpp:142] loss = 0.373471 (* 1 = 0.373471 loss)
I0122 17:49:02.154990 65942 caffe_interface.cpp:142] top-1 = 0.896333
I0122 17:49:02.154994 65942 caffe_interface.cpp:142] top-5 = 0.996
I0122 17:49:02.318181 65942 pruning_runner.cpp:306] pruning done, output model: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/sparse.caffemodel
I0122 17:49:02.318199 65942 pruning_runner.cpp:320] summary of REGULAR compression with rate 0.1:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.897777736    | 0.89633286     | -0.00144487619 |
+-------------------------------------------------------------------+
| Weights        | 1652899        | 1472719        | -10.9008493%   |
+-------------------------------------------------------------------+
| Operations     | 533938176      | 479801856      | -10.13906%     |
+-------------------------------------------------------------------+
To fine-tune the compressed model, please run:
deephi_compress finetune -config cifar10/deephi/miniGoogleNet/pruning/config1.prototxt
# fine-tuning: first run
$PRUNE_ROOT/deephi_compress finetune -config ${WORK_DIR}/config1.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_finetune1_miniGoogleNet.txt
I0122 17:49:02.560602 67000 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/net_finetune.prototxt
I0122 17:49:02.741058 67000 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 17:49:02.741569 67000 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24861540352, dev_info[0]: total=25620447232 free=24861540352
I0122 17:49:02.741580 67000 caffe_interface.cpp:493] Using GPUs 0
I0122 17:49:02.741832 67000 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 17:49:03.332623 67000 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/net_finetune.prototxt"
type: "SGD"
I0122 17:49:03.332718 67000 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/net_finetune.prototxt
I0122 17:49:03.333307 67000 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 17:49:03.333335 67000 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 17:49:03.333339 67000 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 17:49:03.333341 67000 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 17:49:03.333845 67000 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 17:49:03.334175 67000 layer_factory.hpp:77] Creating layer data
I0122 17:49:03.334273 67000 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 17:49:03.335219 67000 net.cpp:94] Creating Layer data
I0122 17:49:03.335232 67000 net.cpp:409] data -> data
I0122 17:49:03.335242 67000 net.cpp:409] data -> label
I0122 17:49:03.336545 67039 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 17:49:03.336606 67039 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 17:49:03.336697 67000 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 17:49:03.336782 67000 data_layer.cpp:83] output data size: 128,3,32,32
I0122 17:49:03.344223 67000 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 17:49:03.344266 67000 net.cpp:144] Setting up data
I0122 17:49:03.344275 67000 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 17:49:03.344280 67000 net.cpp:151] Top shape: 128 (128)
I0122 17:49:03.344281 67000 net.cpp:159] Memory required for data: 1573376
I0122 17:49:03.344285 67000 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 17:49:03.344300 67000 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 17:49:03.344305 67000 net.cpp:435] conv1/3x3_s1 <- data
I0122 17:49:03.344316 67000 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 17:49:03.345916 67000 net.cpp:144] Setting up conv1/3x3_s1
I0122 17:49:03.345929 67000 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 17:49:03.345932 67000 net.cpp:159] Memory required for data: 51905024
I0122 17:49:03.345945 67000 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 17:49:03.345955 67000 net.cpp:94] Creating Layer conv1/bn1
I0122 17:49:03.345958 67000 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 17:49:03.345964 67000 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 17:49:03.346576 67000 net.cpp:144] Setting up conv1/bn1
I0122 17:49:03.346585 67000 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 17:49:03.346587 67000 net.cpp:159] Memory required for data: 102236672
I0122 17:49:03.346597 67000 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 17:49:03.346606 67000 net.cpp:94] Creating Layer conv1/relu1
I0122 17:49:03.346608 67000 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 17:49:03.346613 67000 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 17:49:03.346623 67000 net.cpp:144] Setting up conv1/relu1
I0122 17:49:03.346639 67000 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 17:49:03.346642 67000 net.cpp:159] Memory required for data: 152568320
I0122 17:49:03.346644 67000 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:03.346652 67000 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:03.346655 67000 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 17:49:03.346660 67000 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 17:49:03.346668 67000 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 17:49:03.346696 67000 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:03.346702 67000 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 17:49:03.346705 67000 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 17:49:03.346709 67000 net.cpp:159] Memory required for data: 253231616
I0122 17:49:03.346711 67000 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 17:49:03.346721 67000 net.cpp:94] Creating Layer inception_2a/1x1
I0122 17:49:03.346725 67000 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 17:49:03.346732 67000 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 17:49:03.346966 67000 net.cpp:144] Setting up inception_2a/1x1
I0122 17:49:03.346972 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.346976 67000 net.cpp:159] Memory required for data: 270008832
I0122 17:49:03.346982 67000 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 17:49:03.346990 67000 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 17:49:03.346995 67000 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 17:49:03.346999 67000 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 17:49:03.348309 67000 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 17:49:03.348315 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.348317 67000 net.cpp:159] Memory required for data: 286786048
I0122 17:49:03.348325 67000 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 17:49:03.348328 67000 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 17:49:03.348331 67000 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 17:49:03.348336 67000 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 17:49:03.348341 67000 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 17:49:03.348345 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.348346 67000 net.cpp:159] Memory required for data: 303563264
I0122 17:49:03.348348 67000 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 17:49:03.348356 67000 net.cpp:94] Creating Layer inception_2a/3x3
I0122 17:49:03.348358 67000 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 17:49:03.348366 67000 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 17:49:03.349608 67000 net.cpp:144] Setting up inception_2a/3x3
I0122 17:49:03.349627 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.349630 67000 net.cpp:159] Memory required for data: 320340480
I0122 17:49:03.349637 67000 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 17:49:03.349659 67000 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 17:49:03.349663 67000 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 17:49:03.349669 67000 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 17:49:03.350373 67000 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 17:49:03.350380 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.350383 67000 net.cpp:159] Memory required for data: 337117696
I0122 17:49:03.350395 67000 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 17:49:03.350401 67000 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 17:49:03.350404 67000 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 17:49:03.350411 67000 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 17:49:03.350440 67000 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 17:49:03.350446 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.350448 67000 net.cpp:159] Memory required for data: 353894912
I0122 17:49:03.350451 67000 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 17:49:03.350456 67000 net.cpp:94] Creating Layer inception_2a/output
I0122 17:49:03.350459 67000 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 17:49:03.350463 67000 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 17:49:03.350469 67000 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 17:49:03.350487 67000 net.cpp:144] Setting up inception_2a/output
I0122 17:49:03.350493 67000 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 17:49:03.350497 67000 net.cpp:159] Memory required for data: 387449344
I0122 17:49:03.350498 67000 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 17:49:03.350513 67000 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 17:49:03.350519 67000 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 17:49:03.350524 67000 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 17:49:03.350533 67000 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 17:49:03.350564 67000 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 17:49:03.350570 67000 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 17:49:03.350575 67000 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 17:49:03.350579 67000 net.cpp:159] Memory required for data: 454558208
I0122 17:49:03.350580 67000 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 17:49:03.350589 67000 net.cpp:94] Creating Layer inception_3a/1x1
I0122 17:49:03.350594 67000 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 17:49:03.350600 67000 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 17:49:03.350839 67000 net.cpp:144] Setting up inception_3a/1x1
I0122 17:49:03.350847 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.350849 67000 net.cpp:159] Memory required for data: 471335424
I0122 17:49:03.350854 67000 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 17:49:03.350868 67000 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 17:49:03.350872 67000 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 17:49:03.350879 67000 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 17:49:03.351521 67000 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 17:49:03.351526 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.351531 67000 net.cpp:159] Memory required for data: 488112640
I0122 17:49:03.351537 67000 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 17:49:03.351542 67000 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 17:49:03.351546 67000 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 17:49:03.351552 67000 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 17:49:03.351558 67000 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 17:49:03.351564 67000 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 17:49:03.351567 67000 net.cpp:159] Memory required for data: 504889856
I0122 17:49:03.351570 67000 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 17:49:03.351581 67000 net.cpp:94] Creating Layer inception_3a/3x3
I0122 17:49:03.351586 67000 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 17:49:03.351591 67000 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 17:49:03.352006 67000 net.cpp:144] Setting up inception_3a/3x3
I0122 17:49:03.352013 67000 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 17:49:03.352016 67000 net.cpp:159] Memory required for data: 530055680
I0122 17:49:03.352030 67000 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 17:49:03.352038 67000 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 17:49:03.352044 67000 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 17:49:03.352051 67000 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 17:49:03.352933 67000 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 17:49:03.352942 67000 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 17:49:03.352946 67000 net.cpp:159] Memory required for data: 555221504
I0122 17:49:03.352957 67000 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 17:49:03.352965 67000 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 17:49:03.352969 67000 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 17:49:03.352975 67000 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 17:49:03.352982 67000 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 17:49:03.352984 67000 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 17:49:03.352988 67000 net.cpp:159] Memory required for data: 580387328
I0122 17:49:03.352990 67000 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 17:49:03.352994 67000 net.cpp:94] Creating Layer inception_3a/output
I0122 17:49:03.352998 67000 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 17:49:03.353001 67000 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 17:49:03.353006 67000 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 17:49:03.353031 67000 net.cpp:144] Setting up inception_3a/output
I0122 17:49:03.353037 67000 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 17:49:03.353049 67000 net.cpp:159] Memory required for data: 622330368
I0122 17:49:03.353052 67000 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 17:49:03.353056 67000 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 17:49:03.353060 67000 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 17:49:03.353065 67000 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 17:49:03.353071 67000 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 17:49:03.353098 67000 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 17:49:03.353104 67000 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 17:49:03.353109 67000 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 17:49:03.353112 67000 net.cpp:159] Memory required for data: 706216448
I0122 17:49:03.353114 67000 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 17:49:03.353126 67000 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 17:49:03.353130 67000 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 17:49:03.353137 67000 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 17:49:03.353688 67000 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 17:49:03.353694 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.353698 67000 net.cpp:159] Memory required for data: 716702208
I0122 17:49:03.353703 67000 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 17:49:03.353710 67000 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 17:49:03.353715 67000 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 17:49:03.353724 67000 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 17:49:03.354374 67000 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 17:49:03.354382 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.354384 67000 net.cpp:159] Memory required for data: 727187968
I0122 17:49:03.354393 67000 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 17:49:03.354398 67000 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 17:49:03.354400 67000 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 17:49:03.354418 67000 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 17:49:03.354424 67000 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 17:49:03.354430 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.354434 67000 net.cpp:159] Memory required for data: 737673728
I0122 17:49:03.354436 67000 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 17:49:03.354444 67000 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 17:49:03.354446 67000 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 17:49:03.354452 67000 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 17:49:03.354491 67000 net.cpp:144] Setting up downsample_4/pool_s2
I0122 17:49:03.354498 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.354501 67000 net.cpp:159] Memory required for data: 748159488
I0122 17:49:03.354503 67000 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 17:49:03.354508 67000 net.cpp:94] Creating Layer downsample_4/output
I0122 17:49:03.354511 67000 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 17:49:03.354514 67000 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 17:49:03.354521 67000 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 17:49:03.354539 67000 net.cpp:144] Setting up downsample_4/output
I0122 17:49:03.354547 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.354549 67000 net.cpp:159] Memory required for data: 769131008
I0122 17:49:03.354552 67000 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 17:49:03.354557 67000 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 17:49:03.354559 67000 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 17:49:03.354566 67000 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 17:49:03.354571 67000 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 17:49:03.354604 67000 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 17:49:03.354609 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.354614 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.354616 67000 net.cpp:159] Memory required for data: 811074048
I0122 17:49:03.354619 67000 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 17:49:03.354627 67000 net.cpp:94] Creating Layer inception_5a/1x1
I0122 17:49:03.354630 67000 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 17:49:03.354636 67000 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 17:49:03.354995 67000 net.cpp:144] Setting up inception_5a/1x1
I0122 17:49:03.355002 67000 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 17:49:03.355005 67000 net.cpp:159] Memory required for data: 825754112
I0122 17:49:03.355010 67000 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 17:49:03.355020 67000 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 17:49:03.355024 67000 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 17:49:03.355031 67000 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 17:49:03.355935 67000 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 17:49:03.355942 67000 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 17:49:03.355945 67000 net.cpp:159] Memory required for data: 840434176
I0122 17:49:03.355953 67000 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 17:49:03.355962 67000 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 17:49:03.355964 67000 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 17:49:03.355969 67000 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 17:49:03.355975 67000 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 17:49:03.355984 67000 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 17:49:03.355998 67000 net.cpp:159] Memory required for data: 855114240
I0122 17:49:03.356001 67000 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 17:49:03.356019 67000 net.cpp:94] Creating Layer inception_5a/3x3
I0122 17:49:03.356030 67000 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 17:49:03.356037 67000 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 17:49:03.356667 67000 net.cpp:144] Setting up inception_5a/3x3
I0122 17:49:03.356675 67000 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 17:49:03.356678 67000 net.cpp:159] Memory required for data: 861405696
I0122 17:49:03.356683 67000 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 17:49:03.356691 67000 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 17:49:03.356695 67000 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 17:49:03.356703 67000 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 17:49:03.357364 67000 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 17:49:03.357372 67000 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 17:49:03.357376 67000 net.cpp:159] Memory required for data: 867697152
I0122 17:49:03.357383 67000 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 17:49:03.357395 67000 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 17:49:03.357400 67000 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 17:49:03.357405 67000 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 17:49:03.357411 67000 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 17:49:03.357417 67000 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 17:49:03.357420 67000 net.cpp:159] Memory required for data: 873988608
I0122 17:49:03.357424 67000 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 17:49:03.357427 67000 net.cpp:94] Creating Layer inception_5a/output
I0122 17:49:03.357430 67000 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 17:49:03.357434 67000 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 17:49:03.357439 67000 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 17:49:03.357460 67000 net.cpp:144] Setting up inception_5a/output
I0122 17:49:03.357465 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.357470 67000 net.cpp:159] Memory required for data: 894960128
I0122 17:49:03.357471 67000 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 17:49:03.357476 67000 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 17:49:03.357480 67000 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 17:49:03.357486 67000 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 17:49:03.357493 67000 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 17:49:03.357523 67000 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 17:49:03.357528 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.357532 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.357535 67000 net.cpp:159] Memory required for data: 936903168
I0122 17:49:03.357538 67000 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 17:49:03.357547 67000 net.cpp:94] Creating Layer inception_6a/1x1
I0122 17:49:03.357553 67000 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 17:49:03.357558 67000 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 17:49:03.358590 67000 net.cpp:144] Setting up inception_6a/1x1
I0122 17:49:03.358602 67000 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 17:49:03.358604 67000 net.cpp:159] Memory required for data: 949486080
I0122 17:49:03.358610 67000 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 17:49:03.358619 67000 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 17:49:03.358633 67000 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 17:49:03.358641 67000 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 17:49:03.359524 67000 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 17:49:03.359531 67000 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 17:49:03.359534 67000 net.cpp:159] Memory required for data: 962068992
I0122 17:49:03.359544 67000 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 17:49:03.359552 67000 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 17:49:03.359556 67000 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 17:49:03.359562 67000 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 17:49:03.359570 67000 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 17:49:03.359575 67000 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 17:49:03.359578 67000 net.cpp:159] Memory required for data: 974651904
I0122 17:49:03.359581 67000 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 17:49:03.359591 67000 net.cpp:94] Creating Layer inception_6a/3x3
I0122 17:49:03.359594 67000 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 17:49:03.359601 67000 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 17:49:03.360373 67000 net.cpp:144] Setting up inception_6a/3x3
I0122 17:49:03.360381 67000 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 17:49:03.360384 67000 net.cpp:159] Memory required for data: 983040512
I0122 17:49:03.360396 67000 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 17:49:03.360406 67000 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 17:49:03.360412 67000 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 17:49:03.360419 67000 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 17:49:03.361083 67000 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 17:49:03.361090 67000 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 17:49:03.361093 67000 net.cpp:159] Memory required for data: 991429120
I0122 17:49:03.361101 67000 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 17:49:03.361109 67000 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 17:49:03.361111 67000 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 17:49:03.361117 67000 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 17:49:03.361124 67000 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 17:49:03.361129 67000 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 17:49:03.361131 67000 net.cpp:159] Memory required for data: 999817728
I0122 17:49:03.361135 67000 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 17:49:03.361140 67000 net.cpp:94] Creating Layer inception_6a/output
I0122 17:49:03.361141 67000 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 17:49:03.361145 67000 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 17:49:03.361151 67000 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 17:49:03.361169 67000 net.cpp:144] Setting up inception_6a/output
I0122 17:49:03.361176 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.361178 67000 net.cpp:159] Memory required for data: 1020789248
I0122 17:49:03.361181 67000 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 17:49:03.361188 67000 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 17:49:03.361191 67000 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 17:49:03.361196 67000 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 17:49:03.361204 67000 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 17:49:03.361243 67000 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 17:49:03.361248 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.361263 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.361266 67000 net.cpp:159] Memory required for data: 1062732288
I0122 17:49:03.361269 67000 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 17:49:03.361279 67000 net.cpp:94] Creating Layer inception_7a/1x1
I0122 17:49:03.361284 67000 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 17:49:03.361290 67000 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 17:49:03.361723 67000 net.cpp:144] Setting up inception_7a/1x1
I0122 17:49:03.361730 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.361733 67000 net.cpp:159] Memory required for data: 1073218048
I0122 17:49:03.361739 67000 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 17:49:03.361747 67000 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 17:49:03.361749 67000 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 17:49:03.361755 67000 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 17:49:03.362432 67000 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 17:49:03.362440 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.362443 67000 net.cpp:159] Memory required for data: 1083703808
I0122 17:49:03.362452 67000 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 17:49:03.362457 67000 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 17:49:03.362463 67000 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 17:49:03.362468 67000 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 17:49:03.362476 67000 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 17:49:03.362480 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.362483 67000 net.cpp:159] Memory required for data: 1094189568
I0122 17:49:03.362486 67000 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 17:49:03.362495 67000 net.cpp:94] Creating Layer inception_7a/3x3
I0122 17:49:03.362500 67000 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 17:49:03.362507 67000 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 17:49:03.363436 67000 net.cpp:144] Setting up inception_7a/3x3
I0122 17:49:03.363445 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.363448 67000 net.cpp:159] Memory required for data: 1104675328
I0122 17:49:03.363454 67000 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 17:49:03.363463 67000 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 17:49:03.363467 67000 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 17:49:03.363476 67000 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 17:49:03.364372 67000 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 17:49:03.364378 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.364382 67000 net.cpp:159] Memory required for data: 1115161088
I0122 17:49:03.364392 67000 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 17:49:03.364400 67000 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 17:49:03.364403 67000 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 17:49:03.364409 67000 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 17:49:03.364416 67000 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 17:49:03.364423 67000 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 17:49:03.364424 67000 net.cpp:159] Memory required for data: 1125646848
I0122 17:49:03.364428 67000 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 17:49:03.364432 67000 net.cpp:94] Creating Layer inception_7a/output
I0122 17:49:03.364442 67000 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 17:49:03.364446 67000 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 17:49:03.364452 67000 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 17:49:03.364473 67000 net.cpp:144] Setting up inception_7a/output
I0122 17:49:03.364480 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.364491 67000 net.cpp:159] Memory required for data: 1146618368
I0122 17:49:03.364495 67000 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 17:49:03.364500 67000 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 17:49:03.364503 67000 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 17:49:03.364509 67000 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 17:49:03.364516 67000 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 17:49:03.364547 67000 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 17:49:03.364552 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.364557 67000 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 17:49:03.364558 67000 net.cpp:159] Memory required for data: 1188561408
I0122 17:49:03.364562 67000 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 17:49:03.364572 67000 net.cpp:94] Creating Layer inception_8a/1x1
I0122 17:49:03.364576 67000 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 17:49:03.364583 67000 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 17:49:03.364866 67000 net.cpp:144] Setting up inception_8a/1x1
I0122 17:49:03.364871 67000 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 17:49:03.364874 67000 net.cpp:159] Memory required for data: 1194852864
I0122 17:49:03.364878 67000 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 17:49:03.364887 67000 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 17:49:03.364890 67000 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 17:49:03.364897 67000 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 17:49:03.365566 67000 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 17:49:03.365573 67000 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 17:49:03.365576 67000 net.cpp:159] Memory required for data: 1201144320
I0122 17:49:03.365584 67000 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 17:49:03.365588 67000 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 17:49:03.365592 67000 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 17:49:03.365598 67000 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 17:49:03.365604 67000 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 17:49:03.365610 67000 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 17:49:03.365613 67000 net.cpp:159] Memory required for data: 1207435776
I0122 17:49:03.365617 67000 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 17:49:03.365624 67000 net.cpp:94] Creating Layer inception_8a/3x3
I0122 17:49:03.365629 67000 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 17:49:03.365638 67000 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 17:49:03.367328 67000 net.cpp:144] Setting up inception_8a/3x3
I0122 17:49:03.367341 67000 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 17:49:03.367343 67000 net.cpp:159] Memory required for data: 1220018688
I0122 17:49:03.367349 67000 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 17:49:03.367357 67000 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 17:49:03.367359 67000 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 17:49:03.367365 67000 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 17:49:03.368011 67000 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 17:49:03.368021 67000 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 17:49:03.368022 67000 net.cpp:159] Memory required for data: 1232601600
I0122 17:49:03.368031 67000 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 17:49:03.368036 67000 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 17:49:03.368039 67000 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 17:49:03.368054 67000 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 17:49:03.368060 67000 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 17:49:03.368067 67000 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 17:49:03.368070 67000 net.cpp:159] Memory required for data: 1245184512
I0122 17:49:03.368073 67000 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 17:49:03.368080 67000 net.cpp:94] Creating Layer inception_8a/output
I0122 17:49:03.368084 67000 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 17:49:03.368088 67000 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 17:49:03.368093 67000 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 17:49:03.368114 67000 net.cpp:144] Setting up inception_8a/output
I0122 17:49:03.368120 67000 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 17:49:03.368124 67000 net.cpp:159] Memory required for data: 1264058880
I0122 17:49:03.368126 67000 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 17:49:03.368131 67000 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 17:49:03.368135 67000 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 17:49:03.368141 67000 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 17:49:03.368149 67000 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 17:49:03.368180 67000 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 17:49:03.368186 67000 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 17:49:03.368191 67000 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 17:49:03.368193 67000 net.cpp:159] Memory required for data: 1301807616
I0122 17:49:03.368196 67000 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 17:49:03.368207 67000 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 17:49:03.368212 67000 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 17:49:03.368218 67000 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 17:49:03.369153 67000 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 17:49:03.369163 67000 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 17:49:03.369165 67000 net.cpp:159] Memory required for data: 1304953344
I0122 17:49:03.369171 67000 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 17:49:03.369180 67000 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 17:49:03.369186 67000 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 17:49:03.369194 67000 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 17:49:03.369897 67000 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 17:49:03.369915 67000 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 17:49:03.369918 67000 net.cpp:159] Memory required for data: 1308099072
I0122 17:49:03.369926 67000 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 17:49:03.369931 67000 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 17:49:03.369935 67000 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 17:49:03.369940 67000 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 17:49:03.369947 67000 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 17:49:03.369953 67000 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 17:49:03.369956 67000 net.cpp:159] Memory required for data: 1311244800
I0122 17:49:03.369959 67000 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 17:49:03.369966 67000 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 17:49:03.369971 67000 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 17:49:03.369976 67000 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 17:49:03.370010 67000 net.cpp:144] Setting up downsample_9/pool_s2
I0122 17:49:03.370024 67000 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 17:49:03.370028 67000 net.cpp:159] Memory required for data: 1315963392
I0122 17:49:03.370031 67000 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 17:49:03.370038 67000 net.cpp:94] Creating Layer downsample_9/output
I0122 17:49:03.370040 67000 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 17:49:03.370043 67000 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 17:49:03.370049 67000 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 17:49:03.370070 67000 net.cpp:144] Setting up downsample_9/output
I0122 17:49:03.370075 67000 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 17:49:03.370079 67000 net.cpp:159] Memory required for data: 1323827712
I0122 17:49:03.370081 67000 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 17:49:03.370093 67000 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 17:49:03.370098 67000 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 17:49:03.370103 67000 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 17:49:03.370110 67000 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 17:49:03.370138 67000 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 17:49:03.370146 67000 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 17:49:03.370149 67000 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 17:49:03.370151 67000 net.cpp:159] Memory required for data: 1339556352
I0122 17:49:03.370155 67000 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 17:49:03.370163 67000 net.cpp:94] Creating Layer inception_10a/1x1
I0122 17:49:03.370168 67000 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 17:49:03.370173 67000 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 17:49:03.370651 67000 net.cpp:144] Setting up inception_10a/1x1
I0122 17:49:03.370657 67000 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 17:49:03.370661 67000 net.cpp:159] Memory required for data: 1345323520
I0122 17:49:03.370666 67000 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 17:49:03.370673 67000 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 17:49:03.370676 67000 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 17:49:03.370682 67000 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 17:49:03.371359 67000 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 17:49:03.371377 67000 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 17:49:03.371381 67000 net.cpp:159] Memory required for data: 1351090688
I0122 17:49:03.371387 67000 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 17:49:03.371394 67000 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 17:49:03.371398 67000 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 17:49:03.371402 67000 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 17:49:03.371408 67000 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 17:49:03.371412 67000 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 17:49:03.371415 67000 net.cpp:159] Memory required for data: 1356857856
I0122 17:49:03.371418 67000 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 17:49:03.371428 67000 net.cpp:94] Creating Layer inception_10a/3x3
I0122 17:49:03.371433 67000 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 17:49:03.371438 67000 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 17:49:03.374640 67000 net.cpp:144] Setting up inception_10a/3x3
I0122 17:49:03.374652 67000 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 17:49:03.374655 67000 net.cpp:159] Memory required for data: 1362100736
I0122 17:49:03.374660 67000 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 17:49:03.374680 67000 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 17:49:03.374683 67000 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 17:49:03.374691 67000 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 17:49:03.375377 67000 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 17:49:03.375385 67000 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 17:49:03.375387 67000 net.cpp:159] Memory required for data: 1367343616
I0122 17:49:03.375396 67000 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 17:49:03.375401 67000 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 17:49:03.375403 67000 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 17:49:03.375409 67000 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 17:49:03.375416 67000 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 17:49:03.375422 67000 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 17:49:03.375424 67000 net.cpp:159] Memory required for data: 1372586496
I0122 17:49:03.375427 67000 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 17:49:03.375432 67000 net.cpp:94] Creating Layer inception_10a/output
I0122 17:49:03.375435 67000 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 17:49:03.375438 67000 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 17:49:03.375443 67000 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 17:49:03.375463 67000 net.cpp:144] Setting up inception_10a/output
I0122 17:49:03.375470 67000 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 17:49:03.375473 67000 net.cpp:159] Memory required for data: 1383596544
I0122 17:49:03.375475 67000 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 17:49:03.375480 67000 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 17:49:03.375484 67000 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 17:49:03.375488 67000 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 17:49:03.375495 67000 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 17:49:03.375524 67000 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 17:49:03.375530 67000 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 17:49:03.375533 67000 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 17:49:03.375535 67000 net.cpp:159] Memory required for data: 1405616640
I0122 17:49:03.375538 67000 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 17:49:03.375548 67000 net.cpp:94] Creating Layer inception_11a/1x1
I0122 17:49:03.375553 67000 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 17:49:03.375560 67000 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 17:49:03.376128 67000 net.cpp:144] Setting up inception_11a/1x1
I0122 17:49:03.376137 67000 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 17:49:03.376138 67000 net.cpp:159] Memory required for data: 1411383808
I0122 17:49:03.376143 67000 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 17:49:03.376152 67000 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 17:49:03.376157 67000 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 17:49:03.376164 67000 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 17:49:03.376845 67000 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 17:49:03.376852 67000 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 17:49:03.376857 67000 net.cpp:159] Memory required for data: 1417150976
I0122 17:49:03.376863 67000 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 17:49:03.376870 67000 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 17:49:03.376875 67000 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 17:49:03.376888 67000 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 17:49:03.376894 67000 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 17:49:03.376899 67000 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 17:49:03.376900 67000 net.cpp:159] Memory required for data: 1422918144
I0122 17:49:03.376904 67000 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 17:49:03.376912 67000 net.cpp:94] Creating Layer inception_11a/3x3
I0122 17:49:03.376917 67000 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 17:49:03.376924 67000 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 17:49:03.380662 67000 net.cpp:144] Setting up inception_11a/3x3
I0122 17:49:03.380674 67000 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 17:49:03.380676 67000 net.cpp:159] Memory required for data: 1428161024
I0122 17:49:03.380681 67000 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 17:49:03.380707 67000 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 17:49:03.380709 67000 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 17:49:03.380715 67000 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 17:49:03.381377 67000 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 17:49:03.381386 67000 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 17:49:03.381389 67000 net.cpp:159] Memory required for data: 1433403904
I0122 17:49:03.381409 67000 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 17:49:03.381415 67000 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 17:49:03.381419 67000 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 17:49:03.381424 67000 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 17:49:03.381430 67000 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 17:49:03.381434 67000 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 17:49:03.381438 67000 net.cpp:159] Memory required for data: 1438646784
I0122 17:49:03.381440 67000 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 17:49:03.381444 67000 net.cpp:94] Creating Layer inception_11a/output
I0122 17:49:03.381448 67000 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 17:49:03.381453 67000 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 17:49:03.381458 67000 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 17:49:03.381479 67000 net.cpp:144] Setting up inception_11a/output
I0122 17:49:03.381484 67000 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 17:49:03.381487 67000 net.cpp:159] Memory required for data: 1449656832
I0122 17:49:03.381489 67000 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 17:49:03.381495 67000 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 17:49:03.381498 67000 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 17:49:03.381505 67000 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 17:49:03.381530 67000 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 17:49:03.381534 67000 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 17:49:03.381537 67000 net.cpp:159] Memory required for data: 1449828864
I0122 17:49:03.381541 67000 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 17:49:03.381546 67000 net.cpp:94] Creating Layer drop_8x8_s1
I0122 17:49:03.381548 67000 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 17:49:03.381553 67000 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 17:49:03.381572 67000 net.cpp:144] Setting up drop_8x8_s1
I0122 17:49:03.381577 67000 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 17:49:03.381580 67000 net.cpp:159] Memory required for data: 1450000896
I0122 17:49:03.381582 67000 layer_factory.hpp:77] Creating layer loss/classifier
I0122 17:49:03.381589 67000 net.cpp:94] Creating Layer loss/classifier
I0122 17:49:03.381592 67000 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 17:49:03.381598 67000 net.cpp:409] loss/classifier -> loss/classifier
I0122 17:49:03.381738 67000 net.cpp:144] Setting up loss/classifier
I0122 17:49:03.381754 67000 net.cpp:151] Top shape: 128 10 (1280)
I0122 17:49:03.381757 67000 net.cpp:159] Memory required for data: 1450006016
I0122 17:49:03.381762 67000 layer_factory.hpp:77] Creating layer loss
I0122 17:49:03.381768 67000 net.cpp:94] Creating Layer loss
I0122 17:49:03.381774 67000 net.cpp:435] loss <- loss/classifier
I0122 17:49:03.381778 67000 net.cpp:435] loss <- label
I0122 17:49:03.381783 67000 net.cpp:409] loss -> loss
I0122 17:49:03.381789 67000 layer_factory.hpp:77] Creating layer loss
I0122 17:49:03.381866 67000 net.cpp:144] Setting up loss
I0122 17:49:03.381871 67000 net.cpp:151] Top shape: (1)
I0122 17:49:03.381875 67000 net.cpp:154]     with loss weight 1
I0122 17:49:03.381883 67000 net.cpp:159] Memory required for data: 1450006020
I0122 17:49:03.381887 67000 net.cpp:220] loss needs backward computation.
I0122 17:49:03.381896 67000 net.cpp:220] loss/classifier needs backward computation.
I0122 17:49:03.381899 67000 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 17:49:03.381901 67000 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 17:49:03.381914 67000 net.cpp:220] inception_11a/output needs backward computation.
I0122 17:49:03.381918 67000 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 17:49:03.381920 67000 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 17:49:03.381923 67000 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 17:49:03.381927 67000 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 17:49:03.381929 67000 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 17:49:03.381932 67000 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 17:49:03.381935 67000 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 17:49:03.381939 67000 net.cpp:220] inception_10a/output needs backward computation.
I0122 17:49:03.381942 67000 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 17:49:03.381945 67000 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 17:49:03.381948 67000 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 17:49:03.381952 67000 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 17:49:03.381954 67000 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 17:49:03.381958 67000 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 17:49:03.381960 67000 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 17:49:03.381964 67000 net.cpp:220] downsample_9/output needs backward computation.
I0122 17:49:03.381968 67000 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 17:49:03.381971 67000 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 17:49:03.381973 67000 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 17:49:03.381978 67000 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 17:49:03.381980 67000 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 17:49:03.381983 67000 net.cpp:220] inception_8a/output needs backward computation.
I0122 17:49:03.381986 67000 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 17:49:03.381990 67000 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 17:49:03.381994 67000 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 17:49:03.381996 67000 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 17:49:03.381999 67000 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 17:49:03.382002 67000 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 17:49:03.382005 67000 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 17:49:03.382009 67000 net.cpp:220] inception_7a/output needs backward computation.
I0122 17:49:03.382014 67000 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 17:49:03.382023 67000 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 17:49:03.382026 67000 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 17:49:03.382030 67000 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 17:49:03.382033 67000 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 17:49:03.382037 67000 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 17:49:03.382040 67000 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 17:49:03.382043 67000 net.cpp:220] inception_6a/output needs backward computation.
I0122 17:49:03.382047 67000 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 17:49:03.382050 67000 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 17:49:03.382053 67000 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 17:49:03.382056 67000 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 17:49:03.382059 67000 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 17:49:03.382063 67000 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 17:49:03.382066 67000 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 17:49:03.382069 67000 net.cpp:220] inception_5a/output needs backward computation.
I0122 17:49:03.382073 67000 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 17:49:03.382076 67000 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 17:49:03.382079 67000 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 17:49:03.382082 67000 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 17:49:03.382086 67000 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 17:49:03.382088 67000 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 17:49:03.382091 67000 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 17:49:03.382095 67000 net.cpp:220] downsample_4/output needs backward computation.
I0122 17:49:03.382100 67000 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 17:49:03.382104 67000 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 17:49:03.382107 67000 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 17:49:03.382110 67000 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 17:49:03.382113 67000 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 17:49:03.382117 67000 net.cpp:220] inception_3a/output needs backward computation.
I0122 17:49:03.382122 67000 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 17:49:03.382124 67000 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 17:49:03.382127 67000 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 17:49:03.382130 67000 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 17:49:03.382133 67000 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 17:49:03.382135 67000 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 17:49:03.382139 67000 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 17:49:03.382143 67000 net.cpp:220] inception_2a/output needs backward computation.
I0122 17:49:03.382146 67000 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 17:49:03.382149 67000 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 17:49:03.382151 67000 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 17:49:03.382155 67000 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 17:49:03.382158 67000 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 17:49:03.382161 67000 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 17:49:03.382164 67000 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 17:49:03.382177 67000 net.cpp:220] conv1/relu1 needs backward computation.
I0122 17:49:03.382181 67000 net.cpp:220] conv1/bn1 needs backward computation.
I0122 17:49:03.382184 67000 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 17:49:03.382187 67000 net.cpp:222] data does not need backward computation.
I0122 17:49:03.382191 67000 net.cpp:264] This network produces output loss
I0122 17:49:03.382264 67000 net.cpp:284] Network initialization done.
I0122 17:49:03.383193 67000 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/net_finetune.prototxt
I0122 17:49:03.383277 67000 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 17:49:03.383927 67000 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 17:49:03.384249 67000 layer_factory.hpp:77] Creating layer data
I0122 17:49:03.384290 67000 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 17:49:03.385013 67000 net.cpp:94] Creating Layer data
I0122 17:49:03.385023 67000 net.cpp:409] data -> data
I0122 17:49:03.385031 67000 net.cpp:409] data -> label
I0122 17:49:03.386175 67069 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 17:49:03.386209 67069 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 17:49:03.386294 67000 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 17:49:03.386380 67000 data_layer.cpp:83] output data size: 50,3,32,32
I0122 17:49:03.389449 67000 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 17:49:03.389505 67000 net.cpp:144] Setting up data
I0122 17:49:03.389513 67000 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 17:49:03.389518 67000 net.cpp:151] Top shape: 50 (50)
I0122 17:49:03.389519 67000 net.cpp:159] Memory required for data: 614600
I0122 17:49:03.389523 67000 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 17:49:03.389552 67000 net.cpp:94] Creating Layer label_data_1_split
I0122 17:49:03.389559 67000 net.cpp:435] label_data_1_split <- label
I0122 17:49:03.389566 67000 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 17:49:03.389575 67000 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 17:49:03.389582 67000 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 17:49:03.389588 67000 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 17:49:03.389701 67000 net.cpp:144] Setting up label_data_1_split
I0122 17:49:03.389708 67000 net.cpp:151] Top shape: 50 (50)
I0122 17:49:03.389711 67000 net.cpp:151] Top shape: 50 (50)
I0122 17:49:03.389715 67000 net.cpp:151] Top shape: 50 (50)
I0122 17:49:03.389719 67000 net.cpp:151] Top shape: 50 (50)
I0122 17:49:03.389720 67000 net.cpp:159] Memory required for data: 615400
I0122 17:49:03.389724 67000 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 17:49:03.389734 67000 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 17:49:03.389737 67000 net.cpp:435] conv1/3x3_s1 <- data
I0122 17:49:03.389744 67000 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 17:49:03.390105 67000 net.cpp:144] Setting up conv1/3x3_s1
I0122 17:49:03.390112 67000 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:03.390115 67000 net.cpp:159] Memory required for data: 20276200
I0122 17:49:03.390125 67000 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 17:49:03.390131 67000 net.cpp:94] Creating Layer conv1/bn1
I0122 17:49:03.390134 67000 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 17:49:03.390151 67000 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 17:49:03.390867 67000 net.cpp:144] Setting up conv1/bn1
I0122 17:49:03.390875 67000 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:03.390878 67000 net.cpp:159] Memory required for data: 39937000
I0122 17:49:03.390888 67000 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 17:49:03.390895 67000 net.cpp:94] Creating Layer conv1/relu1
I0122 17:49:03.390898 67000 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 17:49:03.390904 67000 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 17:49:03.390910 67000 net.cpp:144] Setting up conv1/relu1
I0122 17:49:03.390913 67000 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:03.390918 67000 net.cpp:159] Memory required for data: 59597800
I0122 17:49:03.390919 67000 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:03.390923 67000 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:03.390926 67000 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 17:49:03.390933 67000 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 17:49:03.390938 67000 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 17:49:03.390970 67000 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 17:49:03.390976 67000 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:03.390980 67000 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 17:49:03.390983 67000 net.cpp:159] Memory required for data: 98919400
I0122 17:49:03.390985 67000 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 17:49:03.390995 67000 net.cpp:94] Creating Layer inception_2a/1x1
I0122 17:49:03.391000 67000 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 17:49:03.391005 67000 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 17:49:03.391618 67000 net.cpp:144] Setting up inception_2a/1x1
I0122 17:49:03.391625 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.391628 67000 net.cpp:159] Memory required for data: 105473000
I0122 17:49:03.391635 67000 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 17:49:03.391644 67000 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 17:49:03.391649 67000 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 17:49:03.391655 67000 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 17:49:03.392489 67000 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 17:49:03.392496 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.392499 67000 net.cpp:159] Memory required for data: 112026600
I0122 17:49:03.392508 67000 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 17:49:03.392515 67000 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 17:49:03.392519 67000 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 17:49:03.392524 67000 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 17:49:03.392532 67000 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 17:49:03.392536 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.392539 67000 net.cpp:159] Memory required for data: 118580200
I0122 17:49:03.392541 67000 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 17:49:03.392551 67000 net.cpp:94] Creating Layer inception_2a/3x3
I0122 17:49:03.392555 67000 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 17:49:03.392562 67000 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 17:49:03.393026 67000 net.cpp:144] Setting up inception_2a/3x3
I0122 17:49:03.393034 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.393038 67000 net.cpp:159] Memory required for data: 125133800
I0122 17:49:03.393043 67000 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 17:49:03.393050 67000 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 17:49:03.393056 67000 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 17:49:03.393070 67000 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 17:49:03.393818 67000 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 17:49:03.393826 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.393828 67000 net.cpp:159] Memory required for data: 131687400
I0122 17:49:03.393841 67000 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 17:49:03.393848 67000 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 17:49:03.393851 67000 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 17:49:03.393857 67000 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 17:49:03.393862 67000 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 17:49:03.393868 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.393870 67000 net.cpp:159] Memory required for data: 138241000
I0122 17:49:03.393874 67000 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 17:49:03.393880 67000 net.cpp:94] Creating Layer inception_2a/output
I0122 17:49:03.393883 67000 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 17:49:03.393887 67000 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 17:49:03.393893 67000 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 17:49:03.393923 67000 net.cpp:144] Setting up inception_2a/output
I0122 17:49:03.393929 67000 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 17:49:03.393932 67000 net.cpp:159] Memory required for data: 151348200
I0122 17:49:03.393935 67000 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 17:49:03.393939 67000 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 17:49:03.393942 67000 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 17:49:03.393949 67000 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 17:49:03.393956 67000 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 17:49:03.394048 67000 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 17:49:03.394054 67000 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 17:49:03.394057 67000 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 17:49:03.394062 67000 net.cpp:159] Memory required for data: 177562600
I0122 17:49:03.394065 67000 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 17:49:03.394083 67000 net.cpp:94] Creating Layer inception_3a/1x1
I0122 17:49:03.394088 67000 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 17:49:03.394098 67000 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 17:49:03.394394 67000 net.cpp:144] Setting up inception_3a/1x1
I0122 17:49:03.394402 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.394404 67000 net.cpp:159] Memory required for data: 184116200
I0122 17:49:03.394410 67000 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 17:49:03.394418 67000 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 17:49:03.394421 67000 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 17:49:03.394428 67000 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 17:49:03.395223 67000 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 17:49:03.395231 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.395234 67000 net.cpp:159] Memory required for data: 190669800
I0122 17:49:03.395242 67000 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 17:49:03.395252 67000 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 17:49:03.395258 67000 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 17:49:03.395264 67000 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 17:49:03.395272 67000 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 17:49:03.395288 67000 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 17:49:03.395293 67000 net.cpp:159] Memory required for data: 197223400
I0122 17:49:03.395308 67000 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 17:49:03.395319 67000 net.cpp:94] Creating Layer inception_3a/3x3
I0122 17:49:03.395326 67000 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 17:49:03.395335 67000 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 17:49:03.396891 67000 net.cpp:144] Setting up inception_3a/3x3
I0122 17:49:03.396906 67000 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 17:49:03.396912 67000 net.cpp:159] Memory required for data: 207053800
I0122 17:49:03.396921 67000 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 17:49:03.396935 67000 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 17:49:03.396942 67000 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 17:49:03.396952 67000 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 17:49:03.398094 67000 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 17:49:03.398105 67000 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 17:49:03.398109 67000 net.cpp:159] Memory required for data: 216884200
I0122 17:49:03.398130 67000 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 17:49:03.398140 67000 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 17:49:03.398145 67000 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 17:49:03.398154 67000 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 17:49:03.398167 67000 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 17:49:03.398175 67000 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 17:49:03.398178 67000 net.cpp:159] Memory required for data: 226714600
I0122 17:49:03.398183 67000 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 17:49:03.398193 67000 net.cpp:94] Creating Layer inception_3a/output
I0122 17:49:03.398198 67000 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 17:49:03.398203 67000 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 17:49:03.398212 67000 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 17:49:03.398247 67000 net.cpp:144] Setting up inception_3a/output
I0122 17:49:03.398254 67000 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 17:49:03.398258 67000 net.cpp:159] Memory required for data: 243098600
I0122 17:49:03.398262 67000 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 17:49:03.398270 67000 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 17:49:03.398274 67000 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 17:49:03.398283 67000 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 17:49:03.398293 67000 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 17:49:03.398347 67000 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 17:49:03.398356 67000 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 17:49:03.398362 67000 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 17:49:03.398366 67000 net.cpp:159] Memory required for data: 275866600
I0122 17:49:03.398371 67000 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 17:49:03.398385 67000 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 17:49:03.398391 67000 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 17:49:03.398402 67000 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 17:49:03.399353 67000 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 17:49:03.399368 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.399371 67000 net.cpp:159] Memory required for data: 279962600
I0122 17:49:03.399379 67000 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 17:49:03.399391 67000 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 17:49:03.399396 67000 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 17:49:03.399422 67000 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 17:49:03.400534 67000 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 17:49:03.400547 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.400550 67000 net.cpp:159] Memory required for data: 284058600
I0122 17:49:03.400563 67000 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 17:49:03.400574 67000 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 17:49:03.400580 67000 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 17:49:03.400588 67000 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 17:49:03.400597 67000 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 17:49:03.400604 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.400609 67000 net.cpp:159] Memory required for data: 288154600
I0122 17:49:03.400614 67000 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 17:49:03.400624 67000 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 17:49:03.400631 67000 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 17:49:03.400641 67000 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 17:49:03.400717 67000 net.cpp:144] Setting up downsample_4/pool_s2
I0122 17:49:03.400728 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.400732 67000 net.cpp:159] Memory required for data: 292250600
I0122 17:49:03.400738 67000 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 17:49:03.400745 67000 net.cpp:94] Creating Layer downsample_4/output
I0122 17:49:03.400753 67000 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 17:49:03.400758 67000 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 17:49:03.400766 67000 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 17:49:03.400805 67000 net.cpp:144] Setting up downsample_4/output
I0122 17:49:03.400812 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.400816 67000 net.cpp:159] Memory required for data: 300442600
I0122 17:49:03.400821 67000 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 17:49:03.400830 67000 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 17:49:03.400838 67000 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 17:49:03.400846 67000 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 17:49:03.400861 67000 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 17:49:03.400902 67000 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 17:49:03.400909 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.400914 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.400919 67000 net.cpp:159] Memory required for data: 316826600
I0122 17:49:03.400924 67000 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 17:49:03.400938 67000 net.cpp:94] Creating Layer inception_5a/1x1
I0122 17:49:03.400943 67000 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 17:49:03.400954 67000 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 17:49:03.401506 67000 net.cpp:144] Setting up inception_5a/1x1
I0122 17:49:03.401517 67000 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 17:49:03.401521 67000 net.cpp:159] Memory required for data: 322561000
I0122 17:49:03.401530 67000 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 17:49:03.401546 67000 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 17:49:03.401553 67000 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 17:49:03.401563 67000 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 17:49:03.402676 67000 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 17:49:03.402698 67000 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 17:49:03.402703 67000 net.cpp:159] Memory required for data: 328295400
I0122 17:49:03.402714 67000 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 17:49:03.402726 67000 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 17:49:03.402730 67000 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 17:49:03.402740 67000 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 17:49:03.402750 67000 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 17:49:03.402758 67000 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 17:49:03.402762 67000 net.cpp:159] Memory required for data: 334029800
I0122 17:49:03.402766 67000 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 17:49:03.402779 67000 net.cpp:94] Creating Layer inception_5a/3x3
I0122 17:49:03.402786 67000 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 17:49:03.402796 67000 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 17:49:03.403885 67000 net.cpp:144] Setting up inception_5a/3x3
I0122 17:49:03.403898 67000 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:03.403903 67000 net.cpp:159] Memory required for data: 336487400
I0122 17:49:03.403911 67000 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 17:49:03.403928 67000 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 17:49:03.403934 67000 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 17:49:03.403944 67000 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 17:49:03.404912 67000 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 17:49:03.404928 67000 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:03.404935 67000 net.cpp:159] Memory required for data: 338945000
I0122 17:49:03.404949 67000 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 17:49:03.404959 67000 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 17:49:03.404964 67000 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 17:49:03.404971 67000 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 17:49:03.404983 67000 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 17:49:03.404992 67000 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:03.404996 67000 net.cpp:159] Memory required for data: 341402600
I0122 17:49:03.405000 67000 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 17:49:03.405009 67000 net.cpp:94] Creating Layer inception_5a/output
I0122 17:49:03.405015 67000 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 17:49:03.405020 67000 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 17:49:03.405028 67000 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 17:49:03.405061 67000 net.cpp:144] Setting up inception_5a/output
I0122 17:49:03.405068 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.405072 67000 net.cpp:159] Memory required for data: 349594600
I0122 17:49:03.405077 67000 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 17:49:03.405084 67000 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 17:49:03.405089 67000 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 17:49:03.405097 67000 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 17:49:03.405107 67000 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 17:49:03.405151 67000 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 17:49:03.405158 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.405164 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.405167 67000 net.cpp:159] Memory required for data: 365978600
I0122 17:49:03.405172 67000 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 17:49:03.405195 67000 net.cpp:94] Creating Layer inception_6a/1x1
I0122 17:49:03.405201 67000 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 17:49:03.405211 67000 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 17:49:03.405678 67000 net.cpp:144] Setting up inception_6a/1x1
I0122 17:49:03.405691 67000 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:03.405695 67000 net.cpp:159] Memory required for data: 370893800
I0122 17:49:03.405704 67000 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 17:49:03.405720 67000 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 17:49:03.405727 67000 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 17:49:03.405737 67000 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 17:49:03.406580 67000 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 17:49:03.406591 67000 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:03.406594 67000 net.cpp:159] Memory required for data: 375809000
I0122 17:49:03.406602 67000 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 17:49:03.406610 67000 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 17:49:03.406613 67000 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 17:49:03.406620 67000 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 17:49:03.406627 67000 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 17:49:03.406632 67000 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:03.406635 67000 net.cpp:159] Memory required for data: 380724200
I0122 17:49:03.406638 67000 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 17:49:03.406647 67000 net.cpp:94] Creating Layer inception_6a/3x3
I0122 17:49:03.406651 67000 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 17:49:03.406659 67000 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 17:49:03.408080 67000 net.cpp:144] Setting up inception_6a/3x3
I0122 17:49:03.408092 67000 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 17:49:03.408094 67000 net.cpp:159] Memory required for data: 384001000
I0122 17:49:03.408107 67000 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 17:49:03.408115 67000 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 17:49:03.408119 67000 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 17:49:03.408126 67000 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 17:49:03.408819 67000 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 17:49:03.408826 67000 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 17:49:03.408829 67000 net.cpp:159] Memory required for data: 387277800
I0122 17:49:03.408838 67000 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 17:49:03.408843 67000 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 17:49:03.408848 67000 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 17:49:03.408851 67000 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 17:49:03.408860 67000 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 17:49:03.408869 67000 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 17:49:03.408872 67000 net.cpp:159] Memory required for data: 390554600
I0122 17:49:03.408875 67000 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 17:49:03.408882 67000 net.cpp:94] Creating Layer inception_6a/output
I0122 17:49:03.408887 67000 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 17:49:03.408892 67000 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 17:49:03.408900 67000 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 17:49:03.408931 67000 net.cpp:144] Setting up inception_6a/output
I0122 17:49:03.408937 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.408941 67000 net.cpp:159] Memory required for data: 398746600
I0122 17:49:03.408944 67000 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 17:49:03.408951 67000 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 17:49:03.408969 67000 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 17:49:03.408977 67000 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 17:49:03.408989 67000 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 17:49:03.409029 67000 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 17:49:03.409036 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.409040 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.409042 67000 net.cpp:159] Memory required for data: 415130600
I0122 17:49:03.409045 67000 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 17:49:03.409054 67000 net.cpp:94] Creating Layer inception_7a/1x1
I0122 17:49:03.409059 67000 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 17:49:03.409066 67000 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 17:49:03.409386 67000 net.cpp:144] Setting up inception_7a/1x1
I0122 17:49:03.409394 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.409396 67000 net.cpp:159] Memory required for data: 419226600
I0122 17:49:03.409401 67000 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 17:49:03.409409 67000 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 17:49:03.409413 67000 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 17:49:03.409422 67000 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 17:49:03.410121 67000 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 17:49:03.410130 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.410132 67000 net.cpp:159] Memory required for data: 423322600
I0122 17:49:03.410140 67000 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 17:49:03.410146 67000 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 17:49:03.410151 67000 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 17:49:03.410157 67000 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 17:49:03.410166 67000 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 17:49:03.410171 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.410174 67000 net.cpp:159] Memory required for data: 427418600
I0122 17:49:03.410178 67000 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 17:49:03.410192 67000 net.cpp:94] Creating Layer inception_7a/3x3
I0122 17:49:03.410197 67000 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 17:49:03.410205 67000 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 17:49:03.411118 67000 net.cpp:144] Setting up inception_7a/3x3
I0122 17:49:03.411128 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.411131 67000 net.cpp:159] Memory required for data: 431514600
I0122 17:49:03.411136 67000 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 17:49:03.411146 67000 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 17:49:03.411151 67000 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 17:49:03.411161 67000 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 17:49:03.411875 67000 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 17:49:03.411882 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.411885 67000 net.cpp:159] Memory required for data: 435610600
I0122 17:49:03.411892 67000 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 17:49:03.411897 67000 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 17:49:03.411901 67000 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 17:49:03.411907 67000 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 17:49:03.411916 67000 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 17:49:03.411922 67000 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 17:49:03.411926 67000 net.cpp:159] Memory required for data: 439706600
I0122 17:49:03.411944 67000 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 17:49:03.411950 67000 net.cpp:94] Creating Layer inception_7a/output
I0122 17:49:03.411954 67000 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 17:49:03.411960 67000 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 17:49:03.411968 67000 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 17:49:03.411996 67000 net.cpp:144] Setting up inception_7a/output
I0122 17:49:03.412003 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.412009 67000 net.cpp:159] Memory required for data: 447898600
I0122 17:49:03.412012 67000 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 17:49:03.412019 67000 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 17:49:03.412022 67000 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 17:49:03.412029 67000 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 17:49:03.412039 67000 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 17:49:03.412078 67000 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 17:49:03.412084 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.412089 67000 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 17:49:03.412091 67000 net.cpp:159] Memory required for data: 464282600
I0122 17:49:03.412093 67000 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 17:49:03.412101 67000 net.cpp:94] Creating Layer inception_8a/1x1
I0122 17:49:03.412106 67000 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 17:49:03.412114 67000 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 17:49:03.412401 67000 net.cpp:144] Setting up inception_8a/1x1
I0122 17:49:03.412408 67000 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:03.412411 67000 net.cpp:159] Memory required for data: 466740200
I0122 17:49:03.412416 67000 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 17:49:03.412423 67000 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 17:49:03.412426 67000 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 17:49:03.412433 67000 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 17:49:03.413123 67000 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 17:49:03.413131 67000 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:03.413134 67000 net.cpp:159] Memory required for data: 469197800
I0122 17:49:03.413142 67000 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 17:49:03.413149 67000 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 17:49:03.413152 67000 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 17:49:03.413157 67000 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 17:49:03.413166 67000 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 17:49:03.413173 67000 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 17:49:03.413177 67000 net.cpp:159] Memory required for data: 471655400
I0122 17:49:03.413180 67000 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 17:49:03.413194 67000 net.cpp:94] Creating Layer inception_8a/3x3
I0122 17:49:03.413202 67000 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 17:49:03.413209 67000 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 17:49:03.414830 67000 net.cpp:144] Setting up inception_8a/3x3
I0122 17:49:03.414844 67000 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:03.414846 67000 net.cpp:159] Memory required for data: 476570600
I0122 17:49:03.414852 67000 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 17:49:03.414860 67000 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 17:49:03.414865 67000 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 17:49:03.414880 67000 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 17:49:03.415571 67000 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 17:49:03.415580 67000 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:03.415582 67000 net.cpp:159] Memory required for data: 481485800
I0122 17:49:03.415591 67000 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 17:49:03.415596 67000 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 17:49:03.415598 67000 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 17:49:03.415606 67000 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 17:49:03.415616 67000 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 17:49:03.415621 67000 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 17:49:03.415624 67000 net.cpp:159] Memory required for data: 486401000
I0122 17:49:03.415628 67000 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 17:49:03.415634 67000 net.cpp:94] Creating Layer inception_8a/output
I0122 17:49:03.415638 67000 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 17:49:03.415643 67000 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 17:49:03.415652 67000 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 17:49:03.415683 67000 net.cpp:144] Setting up inception_8a/output
I0122 17:49:03.415689 67000 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 17:49:03.415693 67000 net.cpp:159] Memory required for data: 493773800
I0122 17:49:03.415699 67000 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 17:49:03.415704 67000 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 17:49:03.415707 67000 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 17:49:03.415712 67000 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 17:49:03.415721 67000 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 17:49:03.415763 67000 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 17:49:03.415769 67000 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 17:49:03.415773 67000 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 17:49:03.415776 67000 net.cpp:159] Memory required for data: 508519400
I0122 17:49:03.415778 67000 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 17:49:03.415787 67000 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 17:49:03.415791 67000 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 17:49:03.415801 67000 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 17:49:03.417332 67000 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 17:49:03.417346 67000 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 17:49:03.417348 67000 net.cpp:159] Memory required for data: 509748200
I0122 17:49:03.417356 67000 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 17:49:03.417363 67000 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 17:49:03.417368 67000 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 17:49:03.417376 67000 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 17:49:03.418089 67000 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 17:49:03.418097 67000 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 17:49:03.418100 67000 net.cpp:159] Memory required for data: 510977000
I0122 17:49:03.418107 67000 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 17:49:03.418113 67000 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 17:49:03.418117 67000 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 17:49:03.418121 67000 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 17:49:03.418128 67000 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 17:49:03.418146 67000 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 17:49:03.418150 67000 net.cpp:159] Memory required for data: 512205800
I0122 17:49:03.418154 67000 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 17:49:03.418164 67000 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 17:49:03.418171 67000 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 17:49:03.418179 67000 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 17:49:03.418223 67000 net.cpp:144] Setting up downsample_9/pool_s2
I0122 17:49:03.418229 67000 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 17:49:03.418232 67000 net.cpp:159] Memory required for data: 514049000
I0122 17:49:03.418236 67000 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 17:49:03.418246 67000 net.cpp:94] Creating Layer downsample_9/output
I0122 17:49:03.418251 67000 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 17:49:03.418256 67000 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 17:49:03.418262 67000 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 17:49:03.418289 67000 net.cpp:144] Setting up downsample_9/output
I0122 17:49:03.418295 67000 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 17:49:03.418299 67000 net.cpp:159] Memory required for data: 517121000
I0122 17:49:03.418303 67000 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 17:49:03.418310 67000 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 17:49:03.418316 67000 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 17:49:03.418325 67000 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 17:49:03.418334 67000 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 17:49:03.418371 67000 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 17:49:03.418380 67000 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 17:49:03.418385 67000 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 17:49:03.418388 67000 net.cpp:159] Memory required for data: 523265000
I0122 17:49:03.418391 67000 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 17:49:03.418401 67000 net.cpp:94] Creating Layer inception_10a/1x1
I0122 17:49:03.418408 67000 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 17:49:03.418417 67000 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 17:49:03.418896 67000 net.cpp:144] Setting up inception_10a/1x1
I0122 17:49:03.418905 67000 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:03.418907 67000 net.cpp:159] Memory required for data: 525517800
I0122 17:49:03.418912 67000 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 17:49:03.418920 67000 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 17:49:03.418926 67000 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 17:49:03.418936 67000 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 17:49:03.419633 67000 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 17:49:03.419641 67000 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:03.419643 67000 net.cpp:159] Memory required for data: 527770600
I0122 17:49:03.419651 67000 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 17:49:03.419658 67000 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 17:49:03.419662 67000 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 17:49:03.419670 67000 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 17:49:03.419679 67000 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 17:49:03.419687 67000 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:03.419690 67000 net.cpp:159] Memory required for data: 530023400
I0122 17:49:03.419694 67000 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 17:49:03.419718 67000 net.cpp:94] Creating Layer inception_10a/3x3
I0122 17:49:03.419723 67000 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 17:49:03.419734 67000 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 17:49:03.422250 67000 net.cpp:144] Setting up inception_10a/3x3
I0122 17:49:03.422263 67000 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:03.422266 67000 net.cpp:159] Memory required for data: 532071400
I0122 17:49:03.422272 67000 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 17:49:03.422281 67000 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 17:49:03.422288 67000 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 17:49:03.422296 67000 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 17:49:03.423000 67000 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 17:49:03.423008 67000 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:03.423012 67000 net.cpp:159] Memory required for data: 534119400
I0122 17:49:03.423019 67000 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 17:49:03.423027 67000 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 17:49:03.423032 67000 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 17:49:03.423039 67000 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 17:49:03.423049 67000 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 17:49:03.423056 67000 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:03.423060 67000 net.cpp:159] Memory required for data: 536167400
I0122 17:49:03.423065 67000 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 17:49:03.423071 67000 net.cpp:94] Creating Layer inception_10a/output
I0122 17:49:03.423077 67000 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 17:49:03.423082 67000 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 17:49:03.423091 67000 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 17:49:03.423122 67000 net.cpp:144] Setting up inception_10a/output
I0122 17:49:03.423130 67000 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:03.423135 67000 net.cpp:159] Memory required for data: 540468200
I0122 17:49:03.423138 67000 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 17:49:03.423143 67000 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 17:49:03.423146 67000 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 17:49:03.423152 67000 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 17:49:03.423163 67000 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 17:49:03.423203 67000 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 17:49:03.423210 67000 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:03.423213 67000 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:03.423216 67000 net.cpp:159] Memory required for data: 549069800
I0122 17:49:03.423219 67000 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 17:49:03.423228 67000 net.cpp:94] Creating Layer inception_11a/1x1
I0122 17:49:03.423233 67000 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 17:49:03.423241 67000 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 17:49:03.423813 67000 net.cpp:144] Setting up inception_11a/1x1
I0122 17:49:03.423821 67000 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:03.423825 67000 net.cpp:159] Memory required for data: 551322600
I0122 17:49:03.423830 67000 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 17:49:03.423838 67000 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 17:49:03.423843 67000 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 17:49:03.423851 67000 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 17:49:03.424566 67000 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 17:49:03.424574 67000 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:03.424577 67000 net.cpp:159] Memory required for data: 553575400
I0122 17:49:03.424584 67000 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 17:49:03.424593 67000 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 17:49:03.424597 67000 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 17:49:03.424603 67000 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 17:49:03.424615 67000 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 17:49:03.424623 67000 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 17:49:03.424628 67000 net.cpp:159] Memory required for data: 555828200
I0122 17:49:03.424633 67000 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 17:49:03.424644 67000 net.cpp:94] Creating Layer inception_11a/3x3
I0122 17:49:03.424651 67000 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 17:49:03.424660 67000 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 17:49:03.428431 67000 net.cpp:144] Setting up inception_11a/3x3
I0122 17:49:03.428442 67000 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:03.428445 67000 net.cpp:159] Memory required for data: 557876200
I0122 17:49:03.428450 67000 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 17:49:03.428457 67000 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 17:49:03.428463 67000 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 17:49:03.428472 67000 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 17:49:03.429172 67000 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 17:49:03.429180 67000 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:03.429183 67000 net.cpp:159] Memory required for data: 559924200
I0122 17:49:03.429201 67000 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 17:49:03.429210 67000 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 17:49:03.429215 67000 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 17:49:03.429224 67000 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 17:49:03.429235 67000 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 17:49:03.429244 67000 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 17:49:03.429247 67000 net.cpp:159] Memory required for data: 561972200
I0122 17:49:03.429251 67000 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 17:49:03.429258 67000 net.cpp:94] Creating Layer inception_11a/output
I0122 17:49:03.429262 67000 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 17:49:03.429267 67000 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 17:49:03.429275 67000 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 17:49:03.429302 67000 net.cpp:144] Setting up inception_11a/output
I0122 17:49:03.429309 67000 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 17:49:03.429313 67000 net.cpp:159] Memory required for data: 566273000
I0122 17:49:03.429317 67000 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 17:49:03.429329 67000 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 17:49:03.429335 67000 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 17:49:03.429343 67000 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 17:49:03.429371 67000 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 17:49:03.429379 67000 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 17:49:03.429383 67000 net.cpp:159] Memory required for data: 566340200
I0122 17:49:03.429385 67000 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 17:49:03.429389 67000 net.cpp:94] Creating Layer drop_8x8_s1
I0122 17:49:03.429394 67000 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 17:49:03.429399 67000 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 17:49:03.429424 67000 net.cpp:144] Setting up drop_8x8_s1
I0122 17:49:03.429430 67000 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 17:49:03.429446 67000 net.cpp:159] Memory required for data: 566407400
I0122 17:49:03.429450 67000 layer_factory.hpp:77] Creating layer loss/classifier
I0122 17:49:03.429460 67000 net.cpp:94] Creating Layer loss/classifier
I0122 17:49:03.429466 67000 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 17:49:03.429474 67000 net.cpp:409] loss/classifier -> loss/classifier
I0122 17:49:03.429631 67000 net.cpp:144] Setting up loss/classifier
I0122 17:49:03.429637 67000 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:03.429641 67000 net.cpp:159] Memory required for data: 566409400
I0122 17:49:03.429646 67000 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 17:49:03.429651 67000 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 17:49:03.429653 67000 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 17:49:03.429661 67000 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 17:49:03.429673 67000 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 17:49:03.429682 67000 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 17:49:03.429690 67000 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 17:49:03.429752 67000 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 17:49:03.429759 67000 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:03.429762 67000 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:03.429765 67000 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:03.429769 67000 net.cpp:151] Top shape: 50 10 (500)
I0122 17:49:03.429771 67000 net.cpp:159] Memory required for data: 566417400
I0122 17:49:03.429774 67000 layer_factory.hpp:77] Creating layer loss
I0122 17:49:03.429780 67000 net.cpp:94] Creating Layer loss
I0122 17:49:03.429783 67000 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 17:49:03.429790 67000 net.cpp:435] loss <- label_data_1_split_0
I0122 17:49:03.429795 67000 net.cpp:409] loss -> loss
I0122 17:49:03.429808 67000 layer_factory.hpp:77] Creating layer loss
I0122 17:49:03.429909 67000 net.cpp:144] Setting up loss
I0122 17:49:03.429916 67000 net.cpp:151] Top shape: (1)
I0122 17:49:03.429919 67000 net.cpp:154]     with loss weight 1
I0122 17:49:03.429927 67000 net.cpp:159] Memory required for data: 566417404
I0122 17:49:03.429930 67000 layer_factory.hpp:77] Creating layer accuracy
I0122 17:49:03.429940 67000 net.cpp:94] Creating Layer accuracy
I0122 17:49:03.429947 67000 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 17:49:03.429952 67000 net.cpp:435] accuracy <- label_data_1_split_1
I0122 17:49:03.429960 67000 net.cpp:409] accuracy -> accuracy
I0122 17:49:03.429975 67000 net.cpp:144] Setting up accuracy
I0122 17:49:03.429982 67000 net.cpp:151] Top shape: (1)
I0122 17:49:03.429986 67000 net.cpp:159] Memory required for data: 566417408
I0122 17:49:03.429991 67000 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 17:49:03.429996 67000 net.cpp:94] Creating Layer accuracy-top1
I0122 17:49:03.429999 67000 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 17:49:03.430003 67000 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 17:49:03.430011 67000 net.cpp:409] accuracy-top1 -> top-1
I0122 17:49:03.430021 67000 net.cpp:144] Setting up accuracy-top1
I0122 17:49:03.430025 67000 net.cpp:151] Top shape: (1)
I0122 17:49:03.430029 67000 net.cpp:159] Memory required for data: 566417412
I0122 17:49:03.430032 67000 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 17:49:03.430042 67000 net.cpp:94] Creating Layer accuracy-top5
I0122 17:49:03.430047 67000 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 17:49:03.430052 67000 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 17:49:03.430059 67000 net.cpp:409] accuracy-top5 -> top-5
I0122 17:49:03.430080 67000 net.cpp:144] Setting up accuracy-top5
I0122 17:49:03.430085 67000 net.cpp:151] Top shape: (1)
I0122 17:49:03.430091 67000 net.cpp:159] Memory required for data: 566417416
I0122 17:49:03.430095 67000 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 17:49:03.430099 67000 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 17:49:03.430104 67000 net.cpp:222] accuracy does not need backward computation.
I0122 17:49:03.430109 67000 net.cpp:220] loss needs backward computation.
I0122 17:49:03.430114 67000 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 17:49:03.430119 67000 net.cpp:220] loss/classifier needs backward computation.
I0122 17:49:03.430124 67000 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 17:49:03.430127 67000 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 17:49:03.430131 67000 net.cpp:220] inception_11a/output needs backward computation.
I0122 17:49:03.430138 67000 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 17:49:03.430142 67000 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 17:49:03.430146 67000 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 17:49:03.430150 67000 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 17:49:03.430155 67000 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 17:49:03.430158 67000 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 17:49:03.430162 67000 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 17:49:03.430167 67000 net.cpp:220] inception_10a/output needs backward computation.
I0122 17:49:03.430172 67000 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 17:49:03.430176 67000 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 17:49:03.430181 67000 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 17:49:03.430184 67000 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 17:49:03.430188 67000 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 17:49:03.430192 67000 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 17:49:03.430197 67000 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 17:49:03.430200 67000 net.cpp:220] downsample_9/output needs backward computation.
I0122 17:49:03.430205 67000 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 17:49:03.430210 67000 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 17:49:03.430214 67000 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 17:49:03.430217 67000 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 17:49:03.430222 67000 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 17:49:03.430227 67000 net.cpp:220] inception_8a/output needs backward computation.
I0122 17:49:03.430232 67000 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 17:49:03.430235 67000 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 17:49:03.430240 67000 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 17:49:03.430243 67000 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 17:49:03.430248 67000 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 17:49:03.430251 67000 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 17:49:03.430258 67000 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 17:49:03.430263 67000 net.cpp:220] inception_7a/output needs backward computation.
I0122 17:49:03.430267 67000 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 17:49:03.430271 67000 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 17:49:03.430275 67000 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 17:49:03.430280 67000 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 17:49:03.430292 67000 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 17:49:03.430296 67000 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 17:49:03.430301 67000 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 17:49:03.430305 67000 net.cpp:220] inception_6a/output needs backward computation.
I0122 17:49:03.430310 67000 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 17:49:03.430315 67000 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 17:49:03.430320 67000 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 17:49:03.430323 67000 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 17:49:03.430327 67000 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 17:49:03.430331 67000 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 17:49:03.430336 67000 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 17:49:03.430341 67000 net.cpp:220] inception_5a/output needs backward computation.
I0122 17:49:03.430346 67000 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 17:49:03.430349 67000 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 17:49:03.430353 67000 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 17:49:03.430375 67000 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 17:49:03.430379 67000 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 17:49:03.430383 67000 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 17:49:03.430389 67000 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 17:49:03.430392 67000 net.cpp:220] downsample_4/output needs backward computation.
I0122 17:49:03.430397 67000 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 17:49:03.430400 67000 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 17:49:03.430405 67000 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 17:49:03.430409 67000 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 17:49:03.430414 67000 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 17:49:03.430419 67000 net.cpp:220] inception_3a/output needs backward computation.
I0122 17:49:03.430424 67000 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 17:49:03.430428 67000 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 17:49:03.430433 67000 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 17:49:03.430436 67000 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 17:49:03.430441 67000 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 17:49:03.430445 67000 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 17:49:03.430450 67000 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 17:49:03.430455 67000 net.cpp:220] inception_2a/output needs backward computation.
I0122 17:49:03.430461 67000 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 17:49:03.430465 67000 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 17:49:03.430469 67000 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 17:49:03.430474 67000 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 17:49:03.430478 67000 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 17:49:03.430481 67000 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 17:49:03.430486 67000 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 17:49:03.430491 67000 net.cpp:220] conv1/relu1 needs backward computation.
I0122 17:49:03.430496 67000 net.cpp:220] conv1/bn1 needs backward computation.
I0122 17:49:03.430500 67000 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 17:49:03.430513 67000 net.cpp:222] label_data_1_split does not need backward computation.
I0122 17:49:03.430521 67000 net.cpp:222] data does not need backward computation.
I0122 17:49:03.430533 67000 net.cpp:264] This network produces output accuracy
I0122 17:49:03.430537 67000 net.cpp:264] This network produces output loss
I0122 17:49:03.430541 67000 net.cpp:264] This network produces output top-1
I0122 17:49:03.430546 67000 net.cpp:264] This network produces output top-5
I0122 17:49:03.430626 67000 net.cpp:284] Network initialization done.
I0122 17:49:03.430991 67000 solver.cpp:63] Solver scaffolding done.
I0122 17:49:03.435449 67000 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/sparse.caffemodel
I0122 17:49:03.478711 67000 caffe_interface.cpp:527] Starting Optimization
I0122 17:49:03.478730 67000 solver.cpp:335] Solving 
I0122 17:49:03.478732 67000 solver.cpp:336] Learning Rate Policy: step
I0122 17:49:03.481335 67000 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 17:49:04.934401 67000 solver.cpp:517]     Test net output #0: accuracy = 0.896333
I0122 17:49:04.934427 67000 solver.cpp:517]     Test net output #1: loss = 0.373471 (* 1 = 0.373471 loss)
I0122 17:49:04.934432 67000 solver.cpp:517]     Test net output #2: top-1 = 0.896333
I0122 17:49:04.934435 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:49:05.014597 67000 solver.cpp:266] Iteration 0 (0 iter/s, 1.53576s/100 iter), loss = 0.0036129
I0122 17:49:05.014631 67000 solver.cpp:285]     Train net output #0: loss = 0.0036129 (* 1 = 0.0036129 loss)
I0122 17:49:05.014647 67000 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 17:49:11.103190 67000 solver.cpp:266] Iteration 100 (16.4249 iter/s, 6.08832s/100 iter), loss = 1.06813
I0122 17:49:11.103217 67000 solver.cpp:285]     Train net output #0: loss = 1.06813 (* 1 = 1.06813 loss)
I0122 17:49:11.103224 67000 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 17:49:17.188376 67000 solver.cpp:266] Iteration 200 (16.4341 iter/s, 6.08492s/100 iter), loss = 1.2249
I0122 17:49:17.188416 67000 solver.cpp:285]     Train net output #0: loss = 1.2249 (* 1 = 1.2249 loss)
I0122 17:49:17.188422 67000 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 17:49:23.273597 67000 solver.cpp:266] Iteration 300 (16.434 iter/s, 6.08494s/100 iter), loss = 0.867712
I0122 17:49:23.273627 67000 solver.cpp:285]     Train net output #0: loss = 0.867712 (* 1 = 0.867712 loss)
I0122 17:49:23.273633 67000 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 17:49:29.371392 67000 solver.cpp:266] Iteration 400 (16.4001 iter/s, 6.09752s/100 iter), loss = 0.708463
I0122 17:49:29.371423 67000 solver.cpp:285]     Train net output #0: loss = 0.708463 (* 1 = 0.708463 loss)
I0122 17:49:29.371428 67000 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 17:49:35.487942 67000 solver.cpp:266] Iteration 500 (16.3498 iter/s, 6.11628s/100 iter), loss = 0.815876
I0122 17:49:35.488031 67000 solver.cpp:285]     Train net output #0: loss = 0.815876 (* 1 = 0.815876 loss)
I0122 17:49:35.488039 67000 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 17:49:41.673245 67000 solver.cpp:266] Iteration 600 (16.1682 iter/s, 6.18497s/100 iter), loss = 0.581639
I0122 17:49:41.673272 67000 solver.cpp:285]     Train net output #0: loss = 0.581639 (* 1 = 0.581639 loss)
I0122 17:49:41.673279 67000 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 17:49:48.201035 67000 solver.cpp:266] Iteration 700 (15.3198 iter/s, 6.5275s/100 iter), loss = 0.803266
I0122 17:49:48.201063 67000 solver.cpp:285]     Train net output #0: loss = 0.803266 (* 1 = 0.803266 loss)
I0122 17:49:48.201069 67000 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 17:49:54.714347 67000 solver.cpp:266] Iteration 800 (15.3538 iter/s, 6.51302s/100 iter), loss = 0.753258
I0122 17:49:54.714377 67000 solver.cpp:285]     Train net output #0: loss = 0.753258 (* 1 = 0.753258 loss)
I0122 17:49:54.714383 67000 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 17:50:00.965061 67000 solver.cpp:266] Iteration 900 (15.9989 iter/s, 6.25043s/100 iter), loss = 0.576853
I0122 17:50:00.965090 67000 solver.cpp:285]     Train net output #0: loss = 0.576853 (* 1 = 0.576853 loss)
I0122 17:50:00.965095 67000 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 17:50:07.168912 67000 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 17:50:08.635308 67000 solver.cpp:517]     Test net output #0: accuracy = 0.385222
I0122 17:50:08.635334 67000 solver.cpp:517]     Test net output #1: loss = 5.53538 (* 1 = 5.53538 loss)
I0122 17:50:08.635339 67000 solver.cpp:517]     Test net output #2: top-1 = 0.385222
I0122 17:50:08.635344 67000 solver.cpp:517]     Test net output #3: top-5 = 0.823666
I0122 17:50:08.697618 67000 solver.cpp:266] Iteration 1000 (12.9329 iter/s, 7.73223s/100 iter), loss = 0.64754
I0122 17:50:08.697638 67000 solver.cpp:285]     Train net output #0: loss = 0.64754 (* 1 = 0.64754 loss)
I0122 17:50:08.697645 67000 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 17:50:14.947604 67000 solver.cpp:266] Iteration 1100 (16.0007 iter/s, 6.24972s/100 iter), loss = 0.689707
I0122 17:50:14.947633 67000 solver.cpp:285]     Train net output #0: loss = 0.689707 (* 1 = 0.689707 loss)
I0122 17:50:14.947638 67000 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 17:50:21.202461 67000 solver.cpp:266] Iteration 1200 (15.9883 iter/s, 6.25458s/100 iter), loss = 0.616072
I0122 17:50:21.202491 67000 solver.cpp:285]     Train net output #0: loss = 0.616072 (* 1 = 0.616072 loss)
I0122 17:50:21.202495 67000 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 17:50:27.482991 67000 solver.cpp:266] Iteration 1300 (15.9229 iter/s, 6.28025s/100 iter), loss = 0.551452
I0122 17:50:27.483021 67000 solver.cpp:285]     Train net output #0: loss = 0.551452 (* 1 = 0.551452 loss)
I0122 17:50:27.483026 67000 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 17:50:33.754881 67000 solver.cpp:266] Iteration 1400 (15.9449 iter/s, 6.27161s/100 iter), loss = 0.583858
I0122 17:50:33.754909 67000 solver.cpp:285]     Train net output #0: loss = 0.583858 (* 1 = 0.583858 loss)
I0122 17:50:33.754932 67000 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 17:50:40.028793 67000 solver.cpp:266] Iteration 1500 (15.9397 iter/s, 6.27363s/100 iter), loss = 0.535927
I0122 17:50:40.028898 67000 solver.cpp:285]     Train net output #0: loss = 0.535927 (* 1 = 0.535927 loss)
I0122 17:50:40.028905 67000 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 17:50:46.265841 67000 solver.cpp:266] Iteration 1600 (16.0341 iter/s, 6.2367s/100 iter), loss = 0.675342
I0122 17:50:46.265872 67000 solver.cpp:285]     Train net output #0: loss = 0.675342 (* 1 = 0.675342 loss)
I0122 17:50:46.265878 67000 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 17:50:52.535861 67000 solver.cpp:266] Iteration 1700 (15.9496 iter/s, 6.26974s/100 iter), loss = 0.503962
I0122 17:50:52.535892 67000 solver.cpp:285]     Train net output #0: loss = 0.503962 (* 1 = 0.503962 loss)
I0122 17:50:52.535898 67000 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 17:50:58.797190 67000 solver.cpp:266] Iteration 1800 (15.9718 iter/s, 6.26105s/100 iter), loss = 0.52812
I0122 17:50:58.797231 67000 solver.cpp:285]     Train net output #0: loss = 0.52812 (* 1 = 0.52812 loss)
I0122 17:50:58.797238 67000 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 17:51:05.053560 67000 solver.cpp:266] Iteration 1900 (15.9844 iter/s, 6.25608s/100 iter), loss = 0.5637
I0122 17:51:05.053588 67000 solver.cpp:285]     Train net output #0: loss = 0.5637 (* 1 = 0.5637 loss)
I0122 17:51:05.053593 67000 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 17:51:11.258424 67000 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 17:51:12.713114 67000 solver.cpp:517]     Test net output #0: accuracy = 0.554222
I0122 17:51:12.713140 67000 solver.cpp:517]     Test net output #1: loss = 1.2892 (* 1 = 1.2892 loss)
I0122 17:51:12.713145 67000 solver.cpp:517]     Test net output #2: top-1 = 0.554222
I0122 17:51:12.713148 67000 solver.cpp:517]     Test net output #3: top-5 = 0.964222
I0122 17:51:12.777422 67000 solver.cpp:266] Iteration 2000 (12.9474 iter/s, 7.72353s/100 iter), loss = 0.510022
I0122 17:51:12.777444 67000 solver.cpp:285]     Train net output #0: loss = 0.510022 (* 1 = 0.510022 loss)
I0122 17:51:12.777451 67000 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 17:51:19.039333 67000 solver.cpp:266] Iteration 2100 (15.9703 iter/s, 6.26164s/100 iter), loss = 0.719217
I0122 17:51:19.039362 67000 solver.cpp:285]     Train net output #0: loss = 0.719217 (* 1 = 0.719217 loss)
I0122 17:51:19.039368 67000 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 17:51:25.296947 67000 solver.cpp:266] Iteration 2200 (15.9812 iter/s, 6.25734s/100 iter), loss = 0.44596
I0122 17:51:25.296988 67000 solver.cpp:285]     Train net output #0: loss = 0.44596 (* 1 = 0.44596 loss)
I0122 17:51:25.296993 67000 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 17:51:31.548974 67000 solver.cpp:266] Iteration 2300 (15.9955 iter/s, 6.25174s/100 iter), loss = 0.591583
I0122 17:51:31.549002 67000 solver.cpp:285]     Train net output #0: loss = 0.591583 (* 1 = 0.591583 loss)
I0122 17:51:31.549008 67000 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 17:51:37.821781 67000 solver.cpp:266] Iteration 2400 (15.9425 iter/s, 6.27253s/100 iter), loss = 0.477382
I0122 17:51:37.821812 67000 solver.cpp:285]     Train net output #0: loss = 0.477382 (* 1 = 0.477382 loss)
I0122 17:51:37.821817 67000 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 17:51:44.075460 67000 solver.cpp:266] Iteration 2500 (15.9913 iter/s, 6.2534s/100 iter), loss = 0.485471
I0122 17:51:44.075542 67000 solver.cpp:285]     Train net output #0: loss = 0.485471 (* 1 = 0.485471 loss)
I0122 17:51:44.075549 67000 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 17:51:50.337930 67000 solver.cpp:266] Iteration 2600 (15.969 iter/s, 6.26214s/100 iter), loss = 0.415165
I0122 17:51:50.337960 67000 solver.cpp:285]     Train net output #0: loss = 0.415165 (* 1 = 0.415165 loss)
I0122 17:51:50.337965 67000 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 17:51:56.605607 67000 solver.cpp:266] Iteration 2700 (15.9556 iter/s, 6.2674s/100 iter), loss = 0.636157
I0122 17:51:56.605636 67000 solver.cpp:285]     Train net output #0: loss = 0.636157 (* 1 = 0.636157 loss)
I0122 17:51:56.605643 67000 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 17:52:02.857725 67000 solver.cpp:266] Iteration 2800 (15.9953 iter/s, 6.25184s/100 iter), loss = 0.541431
I0122 17:52:02.857754 67000 solver.cpp:285]     Train net output #0: loss = 0.541431 (* 1 = 0.541431 loss)
I0122 17:52:02.857760 67000 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 17:52:09.111620 67000 solver.cpp:266] Iteration 2900 (15.9907 iter/s, 6.25362s/100 iter), loss = 0.478457
I0122 17:52:09.111649 67000 solver.cpp:285]     Train net output #0: loss = 0.478457 (* 1 = 0.478457 loss)
I0122 17:52:09.111655 67000 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 17:52:15.307149 67000 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 17:52:16.766904 67000 solver.cpp:517]     Test net output #0: accuracy = 0.501333
I0122 17:52:16.766929 67000 solver.cpp:517]     Test net output #1: loss = 1.65603 (* 1 = 1.65603 loss)
I0122 17:52:16.766934 67000 solver.cpp:517]     Test net output #2: top-1 = 0.501333
I0122 17:52:16.766938 67000 solver.cpp:517]     Test net output #3: top-5 = 0.884555
I0122 17:52:16.829051 67000 solver.cpp:266] Iteration 3000 (12.9582 iter/s, 7.7171s/100 iter), loss = 0.443658
I0122 17:52:16.829071 67000 solver.cpp:285]     Train net output #0: loss = 0.443658 (* 1 = 0.443658 loss)
I0122 17:52:16.829077 67000 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 17:52:23.079068 67000 solver.cpp:266] Iteration 3100 (16.0006 iter/s, 6.24975s/100 iter), loss = 0.421106
I0122 17:52:23.079098 67000 solver.cpp:285]     Train net output #0: loss = 0.421106 (* 1 = 0.421106 loss)
I0122 17:52:23.079103 67000 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 17:52:29.343606 67000 solver.cpp:266] Iteration 3200 (15.9636 iter/s, 6.26426s/100 iter), loss = 0.571617
I0122 17:52:29.343634 67000 solver.cpp:285]     Train net output #0: loss = 0.571617 (* 1 = 0.571617 loss)
I0122 17:52:29.343641 67000 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 17:52:35.602155 67000 solver.cpp:266] Iteration 3300 (15.9788 iter/s, 6.25827s/100 iter), loss = 0.453319
I0122 17:52:35.602185 67000 solver.cpp:285]     Train net output #0: loss = 0.453319 (* 1 = 0.453319 loss)
I0122 17:52:35.602190 67000 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 17:52:41.862730 67000 solver.cpp:266] Iteration 3400 (15.9737 iter/s, 6.2603s/100 iter), loss = 0.599955
I0122 17:52:41.862759 67000 solver.cpp:285]     Train net output #0: loss = 0.599955 (* 1 = 0.599955 loss)
I0122 17:52:41.862766 67000 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 17:52:48.123227 67000 solver.cpp:266] Iteration 3500 (15.9739 iter/s, 6.26022s/100 iter), loss = 0.520706
I0122 17:52:48.123309 67000 solver.cpp:285]     Train net output #0: loss = 0.520706 (* 1 = 0.520706 loss)
I0122 17:52:48.123317 67000 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 17:52:54.392453 67000 solver.cpp:266] Iteration 3600 (15.9518 iter/s, 6.2689s/100 iter), loss = 0.562325
I0122 17:52:54.392482 67000 solver.cpp:285]     Train net output #0: loss = 0.562325 (* 1 = 0.562325 loss)
I0122 17:52:54.392488 67000 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 17:53:00.648259 67000 solver.cpp:266] Iteration 3700 (15.9859 iter/s, 6.25553s/100 iter), loss = 0.486622
I0122 17:53:00.648299 67000 solver.cpp:285]     Train net output #0: loss = 0.486622 (* 1 = 0.486622 loss)
I0122 17:53:00.648305 67000 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 17:53:06.884344 67000 solver.cpp:266] Iteration 3800 (16.0364 iter/s, 6.2358s/100 iter), loss = 0.482109
I0122 17:53:06.884384 67000 solver.cpp:285]     Train net output #0: loss = 0.482109 (* 1 = 0.482109 loss)
I0122 17:53:06.884390 67000 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 17:53:13.138353 67000 solver.cpp:266] Iteration 3900 (15.9905 iter/s, 6.25372s/100 iter), loss = 0.426343
I0122 17:53:13.138383 67000 solver.cpp:285]     Train net output #0: loss = 0.426343 (* 1 = 0.426343 loss)
I0122 17:53:13.138388 67000 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 17:53:19.318472 67000 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 17:53:20.779670 67000 solver.cpp:517]     Test net output #0: accuracy = 0.488667
I0122 17:53:20.779696 67000 solver.cpp:517]     Test net output #1: loss = 2.02278 (* 1 = 2.02278 loss)
I0122 17:53:20.779700 67000 solver.cpp:517]     Test net output #2: top-1 = 0.488667
I0122 17:53:20.779705 67000 solver.cpp:517]     Test net output #3: top-5 = 0.950334
I0122 17:53:20.841558 67000 solver.cpp:266] Iteration 4000 (12.9822 iter/s, 7.70287s/100 iter), loss = 0.58083
I0122 17:53:20.841580 67000 solver.cpp:285]     Train net output #0: loss = 0.58083 (* 1 = 0.58083 loss)
I0122 17:53:20.841586 67000 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 17:53:27.081431 67000 solver.cpp:266] Iteration 4100 (16.0267 iter/s, 6.2396s/100 iter), loss = 0.429942
I0122 17:53:27.081460 67000 solver.cpp:285]     Train net output #0: loss = 0.429942 (* 1 = 0.429942 loss)
I0122 17:53:27.081466 67000 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 17:53:33.341138 67000 solver.cpp:266] Iteration 4200 (15.9759 iter/s, 6.25943s/100 iter), loss = 0.528212
I0122 17:53:33.341166 67000 solver.cpp:285]     Train net output #0: loss = 0.528212 (* 1 = 0.528212 loss)
I0122 17:53:33.341171 67000 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 17:53:39.607529 67000 solver.cpp:266] Iteration 4300 (15.9588 iter/s, 6.26612s/100 iter), loss = 0.501942
I0122 17:53:39.607570 67000 solver.cpp:285]     Train net output #0: loss = 0.501942 (* 1 = 0.501942 loss)
I0122 17:53:39.607594 67000 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 17:53:45.865173 67000 solver.cpp:266] Iteration 4400 (15.9812 iter/s, 6.25736s/100 iter), loss = 0.59796
I0122 17:53:45.865203 67000 solver.cpp:285]     Train net output #0: loss = 0.59796 (* 1 = 0.59796 loss)
I0122 17:53:45.865208 67000 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 17:53:52.111621 67000 solver.cpp:266] Iteration 4500 (16.0098 iter/s, 6.24617s/100 iter), loss = 0.42738
I0122 17:53:52.111704 67000 solver.cpp:285]     Train net output #0: loss = 0.42738 (* 1 = 0.42738 loss)
I0122 17:53:52.111712 67000 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 17:53:58.377095 67000 solver.cpp:266] Iteration 4600 (15.9613 iter/s, 6.26515s/100 iter), loss = 0.535687
I0122 17:53:58.377125 67000 solver.cpp:285]     Train net output #0: loss = 0.535687 (* 1 = 0.535687 loss)
I0122 17:53:58.377130 67000 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 17:54:04.642640 67000 solver.cpp:266] Iteration 4700 (15.961 iter/s, 6.26527s/100 iter), loss = 0.68542
I0122 17:54:04.642669 67000 solver.cpp:285]     Train net output #0: loss = 0.68542 (* 1 = 0.68542 loss)
I0122 17:54:04.642674 67000 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 17:54:10.907714 67000 solver.cpp:266] Iteration 4800 (15.9622 iter/s, 6.2648s/100 iter), loss = 0.515629
I0122 17:54:10.907742 67000 solver.cpp:285]     Train net output #0: loss = 0.515629 (* 1 = 0.515629 loss)
I0122 17:54:10.907748 67000 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 17:54:17.161378 67000 solver.cpp:266] Iteration 4900 (15.9913 iter/s, 6.25339s/100 iter), loss = 0.619493
I0122 17:54:17.161406 67000 solver.cpp:285]     Train net output #0: loss = 0.619493 (* 1 = 0.619493 loss)
I0122 17:54:17.161412 67000 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 17:54:23.343647 67000 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 17:54:24.807252 67000 solver.cpp:517]     Test net output #0: accuracy = 0.431555
I0122 17:54:24.807277 67000 solver.cpp:517]     Test net output #1: loss = 1.87209 (* 1 = 1.87209 loss)
I0122 17:54:24.807282 67000 solver.cpp:517]     Test net output #2: top-1 = 0.431555
I0122 17:54:24.807286 67000 solver.cpp:517]     Test net output #3: top-5 = 0.904333
I0122 17:54:24.868639 67000 solver.cpp:266] Iteration 5000 (12.9753 iter/s, 7.70693s/100 iter), loss = 0.537531
I0122 17:54:24.868660 67000 solver.cpp:285]     Train net output #0: loss = 0.537531 (* 1 = 0.537531 loss)
I0122 17:54:24.868666 67000 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 17:54:31.134251 67000 solver.cpp:266] Iteration 5100 (15.9608 iter/s, 6.26534s/100 iter), loss = 0.455493
I0122 17:54:31.134279 67000 solver.cpp:285]     Train net output #0: loss = 0.455493 (* 1 = 0.455493 loss)
I0122 17:54:31.134285 67000 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 17:54:37.405704 67000 solver.cpp:266] Iteration 5200 (15.946 iter/s, 6.27118s/100 iter), loss = 0.629076
I0122 17:54:37.405732 67000 solver.cpp:285]     Train net output #0: loss = 0.629076 (* 1 = 0.629076 loss)
I0122 17:54:37.405738 67000 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 17:54:43.661773 67000 solver.cpp:266] Iteration 5300 (15.9852 iter/s, 6.25579s/100 iter), loss = 0.39921
I0122 17:54:43.661803 67000 solver.cpp:285]     Train net output #0: loss = 0.39921 (* 1 = 0.39921 loss)
I0122 17:54:43.661808 67000 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 17:54:49.913535 67000 solver.cpp:266] Iteration 5400 (15.9962 iter/s, 6.25149s/100 iter), loss = 0.550173
I0122 17:54:49.913563 67000 solver.cpp:285]     Train net output #0: loss = 0.550173 (* 1 = 0.550173 loss)
I0122 17:54:49.913569 67000 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 17:54:56.179721 67000 solver.cpp:266] Iteration 5500 (15.9594 iter/s, 6.26591s/100 iter), loss = 0.541314
I0122 17:54:56.179781 67000 solver.cpp:285]     Train net output #0: loss = 0.541314 (* 1 = 0.541314 loss)
I0122 17:54:56.179787 67000 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 17:55:02.454915 67000 solver.cpp:266] Iteration 5600 (15.9365 iter/s, 6.27489s/100 iter), loss = 0.547335
I0122 17:55:02.454943 67000 solver.cpp:285]     Train net output #0: loss = 0.547335 (* 1 = 0.547335 loss)
I0122 17:55:02.454949 67000 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 17:55:08.691908 67000 solver.cpp:266] Iteration 5700 (16.0341 iter/s, 6.23672s/100 iter), loss = 0.39465
I0122 17:55:08.691939 67000 solver.cpp:285]     Train net output #0: loss = 0.39465 (* 1 = 0.39465 loss)
I0122 17:55:08.691946 67000 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 17:55:14.936661 67000 solver.cpp:266] Iteration 5800 (16.0142 iter/s, 6.24448s/100 iter), loss = 0.549838
I0122 17:55:14.936691 67000 solver.cpp:285]     Train net output #0: loss = 0.549838 (* 1 = 0.549838 loss)
I0122 17:55:14.936695 67000 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 17:55:21.193789 67000 solver.cpp:266] Iteration 5900 (15.9825 iter/s, 6.25685s/100 iter), loss = 0.609488
I0122 17:55:21.193817 67000 solver.cpp:285]     Train net output #0: loss = 0.609488 (* 1 = 0.609488 loss)
I0122 17:55:21.193822 67000 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 17:55:27.391077 67000 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 17:55:28.854560 67000 solver.cpp:517]     Test net output #0: accuracy = 0.526889
I0122 17:55:28.854586 67000 solver.cpp:517]     Test net output #1: loss = 1.71782 (* 1 = 1.71782 loss)
I0122 17:55:28.854590 67000 solver.cpp:517]     Test net output #2: top-1 = 0.526889
I0122 17:55:28.854594 67000 solver.cpp:517]     Test net output #3: top-5 = 0.955334
I0122 17:55:28.916235 67000 solver.cpp:266] Iteration 6000 (12.9498 iter/s, 7.72212s/100 iter), loss = 0.485402
I0122 17:55:28.916255 67000 solver.cpp:285]     Train net output #0: loss = 0.485402 (* 1 = 0.485402 loss)
I0122 17:55:28.916261 67000 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 17:55:35.170423 67000 solver.cpp:266] Iteration 6100 (15.99 iter/s, 6.25392s/100 iter), loss = 0.46815
I0122 17:55:35.170449 67000 solver.cpp:285]     Train net output #0: loss = 0.46815 (* 1 = 0.46815 loss)
I0122 17:55:35.170454 67000 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 17:55:41.419195 67000 solver.cpp:266] Iteration 6200 (16.0038 iter/s, 6.2485s/100 iter), loss = 0.426122
I0122 17:55:41.419224 67000 solver.cpp:285]     Train net output #0: loss = 0.426122 (* 1 = 0.426122 loss)
I0122 17:55:41.419229 67000 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 17:55:47.688036 67000 solver.cpp:266] Iteration 6300 (15.9526 iter/s, 6.26856s/100 iter), loss = 0.421832
I0122 17:55:47.688064 67000 solver.cpp:285]     Train net output #0: loss = 0.421832 (* 1 = 0.421832 loss)
I0122 17:55:47.688071 67000 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 17:55:53.946986 67000 solver.cpp:266] Iteration 6400 (15.9778 iter/s, 6.25868s/100 iter), loss = 0.582093
I0122 17:55:53.947015 67000 solver.cpp:285]     Train net output #0: loss = 0.582093 (* 1 = 0.582093 loss)
I0122 17:55:53.947021 67000 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 17:56:00.202667 67000 solver.cpp:266] Iteration 6500 (15.9862 iter/s, 6.25541s/100 iter), loss = 0.696501
I0122 17:56:00.202733 67000 solver.cpp:285]     Train net output #0: loss = 0.696501 (* 1 = 0.696501 loss)
I0122 17:56:00.202739 67000 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 17:56:06.446748 67000 solver.cpp:266] Iteration 6600 (16.016 iter/s, 6.24377s/100 iter), loss = 0.558634
I0122 17:56:06.446775 67000 solver.cpp:285]     Train net output #0: loss = 0.558634 (* 1 = 0.558634 loss)
I0122 17:56:06.446781 67000 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 17:56:12.715834 67000 solver.cpp:266] Iteration 6700 (15.952 iter/s, 6.26881s/100 iter), loss = 0.370974
I0122 17:56:12.715862 67000 solver.cpp:285]     Train net output #0: loss = 0.370974 (* 1 = 0.370974 loss)
I0122 17:56:12.715868 67000 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 17:56:18.961030 67000 solver.cpp:266] Iteration 6800 (16.013 iter/s, 6.24492s/100 iter), loss = 0.535553
I0122 17:56:18.961058 67000 solver.cpp:285]     Train net output #0: loss = 0.535553 (* 1 = 0.535553 loss)
I0122 17:56:18.961063 67000 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 17:56:25.207898 67000 solver.cpp:266] Iteration 6900 (16.0087 iter/s, 6.24659s/100 iter), loss = 0.476646
I0122 17:56:25.207938 67000 solver.cpp:285]     Train net output #0: loss = 0.476646 (* 1 = 0.476646 loss)
I0122 17:56:25.207944 67000 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 17:56:31.422610 67000 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 17:56:32.881839 67000 solver.cpp:517]     Test net output #0: accuracy = 0.61
I0122 17:56:32.881863 67000 solver.cpp:517]     Test net output #1: loss = 1.2948 (* 1 = 1.2948 loss)
I0122 17:56:32.881867 67000 solver.cpp:517]     Test net output #2: top-1 = 0.61
I0122 17:56:32.881870 67000 solver.cpp:517]     Test net output #3: top-5 = 0.934444
I0122 17:56:32.944378 67000 solver.cpp:266] Iteration 7000 (12.9263 iter/s, 7.73614s/100 iter), loss = 0.304156
I0122 17:56:32.944397 67000 solver.cpp:285]     Train net output #0: loss = 0.304156 (* 1 = 0.304156 loss)
I0122 17:56:32.944403 67000 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 17:56:39.183228 67000 solver.cpp:266] Iteration 7100 (16.0293 iter/s, 6.23858s/100 iter), loss = 0.584419
I0122 17:56:39.183269 67000 solver.cpp:285]     Train net output #0: loss = 0.584419 (* 1 = 0.584419 loss)
I0122 17:56:39.183274 67000 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 17:56:45.440987 67000 solver.cpp:266] Iteration 7200 (15.9809 iter/s, 6.25747s/100 iter), loss = 0.518724
I0122 17:56:45.441015 67000 solver.cpp:285]     Train net output #0: loss = 0.518724 (* 1 = 0.518724 loss)
I0122 17:56:45.441022 67000 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 17:56:51.687708 67000 solver.cpp:266] Iteration 7300 (16.0091 iter/s, 6.24645s/100 iter), loss = 0.594836
I0122 17:56:51.687736 67000 solver.cpp:285]     Train net output #0: loss = 0.594836 (* 1 = 0.594836 loss)
I0122 17:56:51.687742 67000 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 17:56:57.934679 67000 solver.cpp:266] Iteration 7400 (16.0085 iter/s, 6.2467s/100 iter), loss = 0.427538
I0122 17:56:57.934710 67000 solver.cpp:285]     Train net output #0: loss = 0.427538 (* 1 = 0.427538 loss)
I0122 17:56:57.934715 67000 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 17:57:04.189888 67000 solver.cpp:266] Iteration 7500 (15.9874 iter/s, 6.25493s/100 iter), loss = 0.487227
I0122 17:57:04.189993 67000 solver.cpp:285]     Train net output #0: loss = 0.487227 (* 1 = 0.487227 loss)
I0122 17:57:04.189999 67000 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 17:57:10.445196 67000 solver.cpp:266] Iteration 7600 (15.9873 iter/s, 6.25496s/100 iter), loss = 0.441015
I0122 17:57:10.445225 67000 solver.cpp:285]     Train net output #0: loss = 0.441015 (* 1 = 0.441015 loss)
I0122 17:57:10.445231 67000 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 17:57:16.707476 67000 solver.cpp:266] Iteration 7700 (15.9693 iter/s, 6.262s/100 iter), loss = 0.406018
I0122 17:57:16.707516 67000 solver.cpp:285]     Train net output #0: loss = 0.406018 (* 1 = 0.406018 loss)
I0122 17:57:16.707523 67000 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 17:57:22.956065 67000 solver.cpp:266] Iteration 7800 (16.0043 iter/s, 6.2483s/100 iter), loss = 0.486967
I0122 17:57:22.956104 67000 solver.cpp:285]     Train net output #0: loss = 0.486967 (* 1 = 0.486967 loss)
I0122 17:57:22.956110 67000 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 17:57:29.216809 67000 solver.cpp:266] Iteration 7900 (15.9733 iter/s, 6.26046s/100 iter), loss = 0.478947
I0122 17:57:29.216838 67000 solver.cpp:285]     Train net output #0: loss = 0.478947 (* 1 = 0.478947 loss)
I0122 17:57:29.216843 67000 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 17:57:35.400960 67000 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 17:57:36.860294 67000 solver.cpp:517]     Test net output #0: accuracy = 0.553778
I0122 17:57:36.860321 67000 solver.cpp:517]     Test net output #1: loss = 1.43355 (* 1 = 1.43355 loss)
I0122 17:57:36.860325 67000 solver.cpp:517]     Test net output #2: top-1 = 0.553778
I0122 17:57:36.860328 67000 solver.cpp:517]     Test net output #3: top-5 = 0.884222
I0122 17:57:36.921543 67000 solver.cpp:266] Iteration 8000 (12.9796 iter/s, 7.70441s/100 iter), loss = 0.432414
I0122 17:57:36.921563 67000 solver.cpp:285]     Train net output #0: loss = 0.432414 (* 1 = 0.432414 loss)
I0122 17:57:36.921569 67000 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 17:57:43.168206 67000 solver.cpp:266] Iteration 8100 (16.0092 iter/s, 6.2464s/100 iter), loss = 0.523517
I0122 17:57:43.168234 67000 solver.cpp:285]     Train net output #0: loss = 0.523517 (* 1 = 0.523517 loss)
I0122 17:57:43.168241 67000 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 17:57:49.409559 67000 solver.cpp:266] Iteration 8200 (16.0229 iter/s, 6.24108s/100 iter), loss = 0.493274
I0122 17:57:49.409588 67000 solver.cpp:285]     Train net output #0: loss = 0.493274 (* 1 = 0.493274 loss)
I0122 17:57:49.409595 67000 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 17:57:55.654104 67000 solver.cpp:266] Iteration 8300 (16.0147 iter/s, 6.24427s/100 iter), loss = 0.497814
I0122 17:57:55.654132 67000 solver.cpp:285]     Train net output #0: loss = 0.497814 (* 1 = 0.497814 loss)
I0122 17:57:55.654137 67000 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 17:58:01.907846 67000 solver.cpp:266] Iteration 8400 (15.9911 iter/s, 6.25347s/100 iter), loss = 0.31404
I0122 17:58:01.907873 67000 solver.cpp:285]     Train net output #0: loss = 0.31404 (* 1 = 0.31404 loss)
I0122 17:58:01.907879 67000 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 17:58:08.167898 67000 solver.cpp:266] Iteration 8500 (15.975 iter/s, 6.25978s/100 iter), loss = 0.55741
I0122 17:58:08.167982 67000 solver.cpp:285]     Train net output #0: loss = 0.55741 (* 1 = 0.55741 loss)
I0122 17:58:08.167989 67000 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 17:58:14.420399 67000 solver.cpp:266] Iteration 8600 (15.9944 iter/s, 6.25217s/100 iter), loss = 0.340646
I0122 17:58:14.420428 67000 solver.cpp:285]     Train net output #0: loss = 0.340646 (* 1 = 0.340646 loss)
I0122 17:58:14.420433 67000 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 17:58:20.682543 67000 solver.cpp:266] Iteration 8700 (15.9697 iter/s, 6.26187s/100 iter), loss = 0.476835
I0122 17:58:20.682570 67000 solver.cpp:285]     Train net output #0: loss = 0.476835 (* 1 = 0.476835 loss)
I0122 17:58:20.682576 67000 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 17:58:26.939831 67000 solver.cpp:266] Iteration 8800 (15.9821 iter/s, 6.25701s/100 iter), loss = 0.432733
I0122 17:58:26.939859 67000 solver.cpp:285]     Train net output #0: loss = 0.432733 (* 1 = 0.432733 loss)
I0122 17:58:26.939865 67000 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 17:58:33.204423 67000 solver.cpp:266] Iteration 8900 (15.9634 iter/s, 6.26432s/100 iter), loss = 0.586728
I0122 17:58:33.204452 67000 solver.cpp:285]     Train net output #0: loss = 0.586728 (* 1 = 0.586728 loss)
I0122 17:58:33.204459 67000 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 17:58:39.409787 67000 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 17:58:40.866905 67000 solver.cpp:517]     Test net output #0: accuracy = 0.565
I0122 17:58:40.866930 67000 solver.cpp:517]     Test net output #1: loss = 1.38527 (* 1 = 1.38527 loss)
I0122 17:58:40.866935 67000 solver.cpp:517]     Test net output #2: top-1 = 0.565
I0122 17:58:40.866940 67000 solver.cpp:517]     Test net output #3: top-5 = 0.922667
I0122 17:58:40.928612 67000 solver.cpp:266] Iteration 9000 (12.9469 iter/s, 7.72386s/100 iter), loss = 0.505333
I0122 17:58:40.928633 67000 solver.cpp:285]     Train net output #0: loss = 0.505333 (* 1 = 0.505333 loss)
I0122 17:58:40.928640 67000 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 17:58:47.163085 67000 solver.cpp:266] Iteration 9100 (16.0405 iter/s, 6.23421s/100 iter), loss = 0.349658
I0122 17:58:47.163125 67000 solver.cpp:285]     Train net output #0: loss = 0.349658 (* 1 = 0.349658 loss)
I0122 17:58:47.163131 67000 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 17:58:53.423785 67000 solver.cpp:266] Iteration 9200 (15.9734 iter/s, 6.26041s/100 iter), loss = 0.50528
I0122 17:58:53.423812 67000 solver.cpp:285]     Train net output #0: loss = 0.50528 (* 1 = 0.50528 loss)
I0122 17:58:53.423817 67000 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 17:58:59.712844 67000 solver.cpp:266] Iteration 9300 (15.9013 iter/s, 6.28878s/100 iter), loss = 0.350936
I0122 17:58:59.712877 67000 solver.cpp:285]     Train net output #0: loss = 0.350936 (* 1 = 0.350936 loss)
I0122 17:58:59.712884 67000 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 17:59:05.966540 67000 solver.cpp:266] Iteration 9400 (15.9913 iter/s, 6.25342s/100 iter), loss = 0.455955
I0122 17:59:05.966572 67000 solver.cpp:285]     Train net output #0: loss = 0.455955 (* 1 = 0.455955 loss)
I0122 17:59:05.966578 67000 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 17:59:12.229328 67000 solver.cpp:266] Iteration 9500 (15.968 iter/s, 6.26251s/100 iter), loss = 0.384397
I0122 17:59:12.229462 67000 solver.cpp:285]     Train net output #0: loss = 0.384397 (* 1 = 0.384397 loss)
I0122 17:59:12.229470 67000 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 17:59:18.479074 67000 solver.cpp:266] Iteration 9600 (16.0016 iter/s, 6.24937s/100 iter), loss = 0.54002
I0122 17:59:18.479102 67000 solver.cpp:285]     Train net output #0: loss = 0.54002 (* 1 = 0.54002 loss)
I0122 17:59:18.479109 67000 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 17:59:24.748891 67000 solver.cpp:266] Iteration 9700 (15.9501 iter/s, 6.26954s/100 iter), loss = 0.307139
I0122 17:59:24.748920 67000 solver.cpp:285]     Train net output #0: loss = 0.307139 (* 1 = 0.307139 loss)
I0122 17:59:24.748925 67000 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 17:59:31.002444 67000 solver.cpp:266] Iteration 9800 (15.9916 iter/s, 6.25328s/100 iter), loss = 0.405114
I0122 17:59:31.002485 67000 solver.cpp:285]     Train net output #0: loss = 0.405114 (* 1 = 0.405114 loss)
I0122 17:59:31.002491 67000 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 17:59:37.247627 67000 solver.cpp:266] Iteration 9900 (16.0131 iter/s, 6.2449s/100 iter), loss = 0.523505
I0122 17:59:37.247654 67000 solver.cpp:285]     Train net output #0: loss = 0.523505 (* 1 = 0.523505 loss)
I0122 17:59:37.247659 67000 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 17:59:43.447420 67000 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 17:59:44.909581 67000 solver.cpp:517]     Test net output #0: accuracy = 0.564222
I0122 17:59:44.909607 67000 solver.cpp:517]     Test net output #1: loss = 1.55542 (* 1 = 1.55542 loss)
I0122 17:59:44.909612 67000 solver.cpp:517]     Test net output #2: top-1 = 0.564222
I0122 17:59:44.909616 67000 solver.cpp:517]     Test net output #3: top-5 = 0.948
I0122 17:59:44.971274 67000 solver.cpp:266] Iteration 10000 (12.9478 iter/s, 7.72332s/100 iter), loss = 0.512937
I0122 17:59:44.971294 67000 solver.cpp:285]     Train net output #0: loss = 0.512937 (* 1 = 0.512937 loss)
I0122 17:59:44.971300 67000 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 17:59:51.204871 67000 solver.cpp:266] Iteration 10100 (16.0428 iter/s, 6.23333s/100 iter), loss = 0.388474
I0122 17:59:51.204901 67000 solver.cpp:285]     Train net output #0: loss = 0.388474 (* 1 = 0.388474 loss)
I0122 17:59:51.204907 67000 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 17:59:57.468551 67000 solver.cpp:266] Iteration 10200 (15.9658 iter/s, 6.2634s/100 iter), loss = 0.321552
I0122 17:59:57.468580 67000 solver.cpp:285]     Train net output #0: loss = 0.321552 (* 1 = 0.321552 loss)
I0122 17:59:57.468586 67000 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 18:00:03.732405 67000 solver.cpp:266] Iteration 10300 (15.9653 iter/s, 6.26358s/100 iter), loss = 0.214799
I0122 18:00:03.732434 67000 solver.cpp:285]     Train net output #0: loss = 0.214799 (* 1 = 0.214799 loss)
I0122 18:00:03.732439 67000 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 18:00:09.983814 67000 solver.cpp:266] Iteration 10400 (15.9971 iter/s, 6.25113s/100 iter), loss = 0.320813
I0122 18:00:09.983853 67000 solver.cpp:285]     Train net output #0: loss = 0.320813 (* 1 = 0.320813 loss)
I0122 18:00:09.983860 67000 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 18:00:16.268146 67000 solver.cpp:266] Iteration 10500 (15.9133 iter/s, 6.28405s/100 iter), loss = 0.255657
I0122 18:00:16.268204 67000 solver.cpp:285]     Train net output #0: loss = 0.255657 (* 1 = 0.255657 loss)
I0122 18:00:16.268210 67000 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 18:00:22.534483 67000 solver.cpp:266] Iteration 10600 (15.9591 iter/s, 6.26603s/100 iter), loss = 0.263824
I0122 18:00:22.534513 67000 solver.cpp:285]     Train net output #0: loss = 0.263824 (* 1 = 0.263824 loss)
I0122 18:00:22.534519 67000 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 18:00:28.789357 67000 solver.cpp:266] Iteration 10700 (15.9882 iter/s, 6.2546s/100 iter), loss = 0.246283
I0122 18:00:28.789386 67000 solver.cpp:285]     Train net output #0: loss = 0.246283 (* 1 = 0.246283 loss)
I0122 18:00:28.789391 67000 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 18:00:35.044960 67000 solver.cpp:266] Iteration 10800 (15.9864 iter/s, 6.25533s/100 iter), loss = 0.196667
I0122 18:00:35.044988 67000 solver.cpp:285]     Train net output #0: loss = 0.196667 (* 1 = 0.196667 loss)
I0122 18:00:35.044994 67000 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 18:00:41.309895 67000 solver.cpp:266] Iteration 10900 (15.9626 iter/s, 6.26466s/100 iter), loss = 0.224333
I0122 18:00:41.309926 67000 solver.cpp:285]     Train net output #0: loss = 0.224333 (* 1 = 0.224333 loss)
I0122 18:00:41.309931 67000 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 18:00:47.509650 67000 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 18:00:48.967315 67000 solver.cpp:517]     Test net output #0: accuracy = 0.802333
I0122 18:00:48.967341 67000 solver.cpp:517]     Test net output #1: loss = 0.614013 (* 1 = 0.614013 loss)
I0122 18:00:48.967345 67000 solver.cpp:517]     Test net output #2: top-1 = 0.802333
I0122 18:00:48.967350 67000 solver.cpp:517]     Test net output #3: top-5 = 0.979889
I0122 18:00:49.028986 67000 solver.cpp:266] Iteration 11000 (12.9554 iter/s, 7.71876s/100 iter), loss = 0.280002
I0122 18:00:49.029006 67000 solver.cpp:285]     Train net output #0: loss = 0.280002 (* 1 = 0.280002 loss)
I0122 18:00:49.029011 67000 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 18:00:55.279075 67000 solver.cpp:266] Iteration 11100 (16.0005 iter/s, 6.24982s/100 iter), loss = 0.143839
I0122 18:00:55.279104 67000 solver.cpp:285]     Train net output #0: loss = 0.143839 (* 1 = 0.143839 loss)
I0122 18:00:55.279110 67000 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 18:01:01.520126 67000 solver.cpp:266] Iteration 11200 (16.0236 iter/s, 6.24078s/100 iter), loss = 0.128557
I0122 18:01:01.520155 67000 solver.cpp:285]     Train net output #0: loss = 0.128557 (* 1 = 0.128557 loss)
I0122 18:01:01.520161 67000 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 18:01:07.766979 67000 solver.cpp:266] Iteration 11300 (16.0088 iter/s, 6.24658s/100 iter), loss = 0.118268
I0122 18:01:07.767006 67000 solver.cpp:285]     Train net output #0: loss = 0.118268 (* 1 = 0.118268 loss)
I0122 18:01:07.767012 67000 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 18:01:14.027076 67000 solver.cpp:266] Iteration 11400 (15.9749 iter/s, 6.25982s/100 iter), loss = 0.147828
I0122 18:01:14.027104 67000 solver.cpp:285]     Train net output #0: loss = 0.147828 (* 1 = 0.147828 loss)
I0122 18:01:14.027109 67000 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 18:01:20.272637 67000 solver.cpp:266] Iteration 11500 (16.0121 iter/s, 6.24529s/100 iter), loss = 0.15421
I0122 18:01:20.272712 67000 solver.cpp:285]     Train net output #0: loss = 0.15421 (* 1 = 0.15421 loss)
I0122 18:01:20.272718 67000 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 18:01:26.514078 67000 solver.cpp:266] Iteration 11600 (16.0228 iter/s, 6.24112s/100 iter), loss = 0.167842
I0122 18:01:26.514106 67000 solver.cpp:285]     Train net output #0: loss = 0.167842 (* 1 = 0.167842 loss)
I0122 18:01:26.514111 67000 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 18:01:32.778080 67000 solver.cpp:266] Iteration 11700 (15.9649 iter/s, 6.26373s/100 iter), loss = 0.124195
I0122 18:01:32.778107 67000 solver.cpp:285]     Train net output #0: loss = 0.124195 (* 1 = 0.124195 loss)
I0122 18:01:32.778113 67000 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 18:01:39.050346 67000 solver.cpp:266] Iteration 11800 (15.9439 iter/s, 6.27199s/100 iter), loss = 0.237859
I0122 18:01:39.050374 67000 solver.cpp:285]     Train net output #0: loss = 0.237859 (* 1 = 0.237859 loss)
I0122 18:01:39.050379 67000 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 18:01:45.310676 67000 solver.cpp:266] Iteration 11900 (15.9743 iter/s, 6.26006s/100 iter), loss = 0.142993
I0122 18:01:45.310703 67000 solver.cpp:285]     Train net output #0: loss = 0.142993 (* 1 = 0.142993 loss)
I0122 18:01:45.310708 67000 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 18:01:51.497651 67000 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 18:01:52.957068 67000 solver.cpp:517]     Test net output #0: accuracy = 0.756444
I0122 18:01:52.957094 67000 solver.cpp:517]     Test net output #1: loss = 0.784781 (* 1 = 0.784781 loss)
I0122 18:01:52.957099 67000 solver.cpp:517]     Test net output #2: top-1 = 0.756444
I0122 18:01:52.957118 67000 solver.cpp:517]     Test net output #3: top-5 = 0.965111
I0122 18:01:53.019824 67000 solver.cpp:266] Iteration 12000 (12.9721 iter/s, 7.70882s/100 iter), loss = 0.104305
I0122 18:01:53.019856 67000 solver.cpp:285]     Train net output #0: loss = 0.104305 (* 1 = 0.104305 loss)
I0122 18:01:53.019863 67000 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 18:01:59.272039 67000 solver.cpp:266] Iteration 12100 (15.995 iter/s, 6.25195s/100 iter), loss = 0.0944403
I0122 18:01:59.272066 67000 solver.cpp:285]     Train net output #0: loss = 0.0944403 (* 1 = 0.0944403 loss)
I0122 18:01:59.272073 67000 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 18:02:05.527773 67000 solver.cpp:266] Iteration 12200 (15.986 iter/s, 6.25546s/100 iter), loss = 0.154276
I0122 18:02:05.527802 67000 solver.cpp:285]     Train net output #0: loss = 0.154276 (* 1 = 0.154276 loss)
I0122 18:02:05.527807 67000 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 18:02:11.778314 67000 solver.cpp:266] Iteration 12300 (15.9993 iter/s, 6.25027s/100 iter), loss = 0.0952667
I0122 18:02:11.778342 67000 solver.cpp:285]     Train net output #0: loss = 0.0952667 (* 1 = 0.0952667 loss)
I0122 18:02:11.778347 67000 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 18:02:18.034683 67000 solver.cpp:266] Iteration 12400 (15.9844 iter/s, 6.2561s/100 iter), loss = 0.14167
I0122 18:02:18.034713 67000 solver.cpp:285]     Train net output #0: loss = 0.14167 (* 1 = 0.14167 loss)
I0122 18:02:18.034718 67000 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 18:02:24.295374 67000 solver.cpp:266] Iteration 12500 (15.9734 iter/s, 6.26042s/100 iter), loss = 0.0903532
I0122 18:02:24.295490 67000 solver.cpp:285]     Train net output #0: loss = 0.0903532 (* 1 = 0.0903532 loss)
I0122 18:02:24.295495 67000 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 18:02:30.548502 67000 solver.cpp:266] Iteration 12600 (15.9929 iter/s, 6.25277s/100 iter), loss = 0.130194
I0122 18:02:30.548532 67000 solver.cpp:285]     Train net output #0: loss = 0.130194 (* 1 = 0.130194 loss)
I0122 18:02:30.548537 67000 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 18:02:36.811615 67000 solver.cpp:266] Iteration 12700 (15.9672 iter/s, 6.26284s/100 iter), loss = 0.177161
I0122 18:02:36.811645 67000 solver.cpp:285]     Train net output #0: loss = 0.177161 (* 1 = 0.177161 loss)
I0122 18:02:36.811650 67000 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 18:02:43.069730 67000 solver.cpp:266] Iteration 12800 (15.98 iter/s, 6.25784s/100 iter), loss = 0.122659
I0122 18:02:43.069761 67000 solver.cpp:285]     Train net output #0: loss = 0.122659 (* 1 = 0.122659 loss)
I0122 18:02:43.069766 67000 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 18:02:49.315593 67000 solver.cpp:266] Iteration 12900 (16.0113 iter/s, 6.24559s/100 iter), loss = 0.0670384
I0122 18:02:49.315620 67000 solver.cpp:285]     Train net output #0: loss = 0.0670384 (* 1 = 0.0670384 loss)
I0122 18:02:49.315626 67000 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 18:02:55.527000 67000 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 18:02:56.986024 67000 solver.cpp:517]     Test net output #0: accuracy = 0.685556
I0122 18:02:56.986049 67000 solver.cpp:517]     Test net output #1: loss = 1.02377 (* 1 = 1.02377 loss)
I0122 18:02:56.986054 67000 solver.cpp:517]     Test net output #2: top-1 = 0.685556
I0122 18:02:56.986058 67000 solver.cpp:517]     Test net output #3: top-5 = 0.934333
I0122 18:02:57.047336 67000 solver.cpp:266] Iteration 13000 (12.9342 iter/s, 7.73142s/100 iter), loss = 0.110421
I0122 18:02:57.047355 67000 solver.cpp:285]     Train net output #0: loss = 0.110421 (* 1 = 0.110421 loss)
I0122 18:02:57.047361 67000 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 18:03:03.300201 67000 solver.cpp:266] Iteration 13100 (15.9933 iter/s, 6.2526s/100 iter), loss = 0.171349
I0122 18:03:03.300226 67000 solver.cpp:285]     Train net output #0: loss = 0.171349 (* 1 = 0.171349 loss)
I0122 18:03:03.300231 67000 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 18:03:09.549922 67000 solver.cpp:266] Iteration 13200 (16.0014 iter/s, 6.24945s/100 iter), loss = 0.177459
I0122 18:03:09.549950 67000 solver.cpp:285]     Train net output #0: loss = 0.177459 (* 1 = 0.177459 loss)
I0122 18:03:09.549955 67000 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 18:03:15.810566 67000 solver.cpp:266] Iteration 13300 (15.9735 iter/s, 6.26037s/100 iter), loss = 0.138211
I0122 18:03:15.810595 67000 solver.cpp:285]     Train net output #0: loss = 0.138211 (* 1 = 0.138211 loss)
I0122 18:03:15.810600 67000 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 18:03:22.073832 67000 solver.cpp:266] Iteration 13400 (15.9668 iter/s, 6.26299s/100 iter), loss = 0.111568
I0122 18:03:22.073858 67000 solver.cpp:285]     Train net output #0: loss = 0.111568 (* 1 = 0.111568 loss)
I0122 18:03:22.073865 67000 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 18:03:28.325541 67000 solver.cpp:266] Iteration 13500 (15.9963 iter/s, 6.25144s/100 iter), loss = 0.110517
I0122 18:03:28.325662 67000 solver.cpp:285]     Train net output #0: loss = 0.110517 (* 1 = 0.110517 loss)
I0122 18:03:28.325670 67000 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 18:03:34.584121 67000 solver.cpp:266] Iteration 13600 (15.979 iter/s, 6.25822s/100 iter), loss = 0.083038
I0122 18:03:34.584151 67000 solver.cpp:285]     Train net output #0: loss = 0.0830381 (* 1 = 0.0830381 loss)
I0122 18:03:34.584156 67000 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 18:03:40.826884 67000 solver.cpp:266] Iteration 13700 (16.0193 iter/s, 6.24249s/100 iter), loss = 0.0635623
I0122 18:03:40.826913 67000 solver.cpp:285]     Train net output #0: loss = 0.0635624 (* 1 = 0.0635624 loss)
I0122 18:03:40.826918 67000 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 18:03:47.069649 67000 solver.cpp:266] Iteration 13800 (16.0192 iter/s, 6.24249s/100 iter), loss = 0.108776
I0122 18:03:47.069676 67000 solver.cpp:285]     Train net output #0: loss = 0.108776 (* 1 = 0.108776 loss)
I0122 18:03:47.069682 67000 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 18:03:53.320327 67000 solver.cpp:266] Iteration 13900 (15.999 iter/s, 6.2504s/100 iter), loss = 0.0799952
I0122 18:03:53.320356 67000 solver.cpp:285]     Train net output #0: loss = 0.0799952 (* 1 = 0.0799952 loss)
I0122 18:03:53.320363 67000 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 18:03:59.518620 67000 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 18:04:00.981371 67000 solver.cpp:517]     Test net output #0: accuracy = 0.727778
I0122 18:04:00.981395 67000 solver.cpp:517]     Test net output #1: loss = 0.834927 (* 1 = 0.834927 loss)
I0122 18:04:00.981400 67000 solver.cpp:517]     Test net output #2: top-1 = 0.727778
I0122 18:04:00.981403 67000 solver.cpp:517]     Test net output #3: top-5 = 0.960334
I0122 18:04:01.043789 67000 solver.cpp:266] Iteration 14000 (12.9481 iter/s, 7.72313s/100 iter), loss = 0.0702466
I0122 18:04:01.043819 67000 solver.cpp:285]     Train net output #0: loss = 0.0702467 (* 1 = 0.0702467 loss)
I0122 18:04:01.043826 67000 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 18:04:07.298849 67000 solver.cpp:266] Iteration 14100 (15.9877 iter/s, 6.25479s/100 iter), loss = 0.157395
I0122 18:04:07.298877 67000 solver.cpp:285]     Train net output #0: loss = 0.157395 (* 1 = 0.157395 loss)
I0122 18:04:07.298882 67000 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 18:04:13.553799 67000 solver.cpp:266] Iteration 14200 (15.988 iter/s, 6.25468s/100 iter), loss = 0.0769296
I0122 18:04:13.553839 67000 solver.cpp:285]     Train net output #0: loss = 0.0769296 (* 1 = 0.0769296 loss)
I0122 18:04:13.553845 67000 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 18:04:19.799585 67000 solver.cpp:266] Iteration 14300 (16.0115 iter/s, 6.2455s/100 iter), loss = 0.0755702
I0122 18:04:19.799615 67000 solver.cpp:285]     Train net output #0: loss = 0.0755703 (* 1 = 0.0755703 loss)
I0122 18:04:19.799621 67000 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 18:04:26.037225 67000 solver.cpp:266] Iteration 14400 (16.0324 iter/s, 6.23737s/100 iter), loss = 0.0379191
I0122 18:04:26.037266 67000 solver.cpp:285]     Train net output #0: loss = 0.0379192 (* 1 = 0.0379192 loss)
I0122 18:04:26.037271 67000 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 18:04:32.312400 67000 solver.cpp:266] Iteration 14500 (15.9365 iter/s, 6.27489s/100 iter), loss = 0.0498191
I0122 18:04:32.312481 67000 solver.cpp:285]     Train net output #0: loss = 0.0498192 (* 1 = 0.0498192 loss)
I0122 18:04:32.312487 67000 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 18:04:38.572854 67000 solver.cpp:266] Iteration 14600 (15.9741 iter/s, 6.26013s/100 iter), loss = 0.0956655
I0122 18:04:38.572885 67000 solver.cpp:285]     Train net output #0: loss = 0.0956656 (* 1 = 0.0956656 loss)
I0122 18:04:38.572890 67000 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 18:04:44.842285 67000 solver.cpp:266] Iteration 14700 (15.9511 iter/s, 6.26916s/100 iter), loss = 0.104454
I0122 18:04:44.842315 67000 solver.cpp:285]     Train net output #0: loss = 0.104455 (* 1 = 0.104455 loss)
I0122 18:04:44.842321 67000 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 18:04:51.106088 67000 solver.cpp:266] Iteration 14800 (15.9654 iter/s, 6.26353s/100 iter), loss = 0.0605874
I0122 18:04:51.106117 67000 solver.cpp:285]     Train net output #0: loss = 0.0605875 (* 1 = 0.0605875 loss)
I0122 18:04:51.106122 67000 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 18:04:57.359302 67000 solver.cpp:266] Iteration 14900 (15.9925 iter/s, 6.25294s/100 iter), loss = 0.0498148
I0122 18:04:57.359330 67000 solver.cpp:285]     Train net output #0: loss = 0.0498149 (* 1 = 0.0498149 loss)
I0122 18:04:57.359336 67000 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 18:05:03.542384 67000 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 18:05:05.009025 67000 solver.cpp:517]     Test net output #0: accuracy = 0.778333
I0122 18:05:05.009050 67000 solver.cpp:517]     Test net output #1: loss = 0.686208 (* 1 = 0.686208 loss)
I0122 18:05:05.009055 67000 solver.cpp:517]     Test net output #2: top-1 = 0.778333
I0122 18:05:05.009059 67000 solver.cpp:517]     Test net output #3: top-5 = 0.98
I0122 18:05:05.071254 67000 solver.cpp:266] Iteration 15000 (12.9674 iter/s, 7.71163s/100 iter), loss = 0.0408896
I0122 18:05:05.071275 67000 solver.cpp:285]     Train net output #0: loss = 0.0408896 (* 1 = 0.0408896 loss)
I0122 18:05:05.071280 67000 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 18:05:11.307444 67000 solver.cpp:266] Iteration 15100 (16.0361 iter/s, 6.23593s/100 iter), loss = 0.032056
I0122 18:05:11.307476 67000 solver.cpp:285]     Train net output #0: loss = 0.032056 (* 1 = 0.032056 loss)
I0122 18:05:11.307482 67000 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 18:05:17.551199 67000 solver.cpp:266] Iteration 15200 (16.0167 iter/s, 6.24348s/100 iter), loss = 0.11041
I0122 18:05:17.551228 67000 solver.cpp:285]     Train net output #0: loss = 0.11041 (* 1 = 0.11041 loss)
I0122 18:05:17.551234 67000 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 18:05:23.810953 67000 solver.cpp:266] Iteration 15300 (15.9758 iter/s, 6.25948s/100 iter), loss = 0.103878
I0122 18:05:23.810981 67000 solver.cpp:285]     Train net output #0: loss = 0.103878 (* 1 = 0.103878 loss)
I0122 18:05:23.810987 67000 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 18:05:30.044070 67000 solver.cpp:266] Iteration 15400 (16.044 iter/s, 6.23285s/100 iter), loss = 0.0660308
I0122 18:05:30.044098 67000 solver.cpp:285]     Train net output #0: loss = 0.0660308 (* 1 = 0.0660308 loss)
I0122 18:05:30.044104 67000 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 18:05:36.295404 67000 solver.cpp:266] Iteration 15500 (15.9973 iter/s, 6.25106s/100 iter), loss = 0.0791785
I0122 18:05:36.295485 67000 solver.cpp:285]     Train net output #0: loss = 0.0791785 (* 1 = 0.0791785 loss)
I0122 18:05:36.295491 67000 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 18:05:42.545199 67000 solver.cpp:266] Iteration 15600 (16.0014 iter/s, 6.24947s/100 iter), loss = 0.109526
I0122 18:05:42.545228 67000 solver.cpp:285]     Train net output #0: loss = 0.109526 (* 1 = 0.109526 loss)
I0122 18:05:42.545233 67000 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 18:05:48.793350 67000 solver.cpp:266] Iteration 15700 (16.0054 iter/s, 6.24788s/100 iter), loss = 0.0411637
I0122 18:05:48.793380 67000 solver.cpp:285]     Train net output #0: loss = 0.0411637 (* 1 = 0.0411637 loss)
I0122 18:05:48.793385 67000 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 18:05:55.064857 67000 solver.cpp:266] Iteration 15800 (15.9458 iter/s, 6.27123s/100 iter), loss = 0.067731
I0122 18:05:55.064888 67000 solver.cpp:285]     Train net output #0: loss = 0.067731 (* 1 = 0.067731 loss)
I0122 18:05:55.064893 67000 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 18:06:01.323595 67000 solver.cpp:266] Iteration 15900 (15.9784 iter/s, 6.25846s/100 iter), loss = 0.11858
I0122 18:06:01.323623 67000 solver.cpp:285]     Train net output #0: loss = 0.11858 (* 1 = 0.11858 loss)
I0122 18:06:01.323629 67000 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 18:06:07.507364 67000 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 18:06:08.975200 67000 solver.cpp:517]     Test net output #0: accuracy = 0.741556
I0122 18:06:08.975225 67000 solver.cpp:517]     Test net output #1: loss = 0.802037 (* 1 = 0.802037 loss)
I0122 18:06:08.975229 67000 solver.cpp:517]     Test net output #2: top-1 = 0.741556
I0122 18:06:08.975234 67000 solver.cpp:517]     Test net output #3: top-5 = 0.959889
I0122 18:06:09.038126 67000 solver.cpp:266] Iteration 16000 (12.9631 iter/s, 7.7142s/100 iter), loss = 0.072644
I0122 18:06:09.038147 67000 solver.cpp:285]     Train net output #0: loss = 0.0726441 (* 1 = 0.0726441 loss)
I0122 18:06:09.038153 67000 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 18:06:15.299572 67000 solver.cpp:266] Iteration 16100 (15.9714 iter/s, 6.26118s/100 iter), loss = 0.122073
I0122 18:06:15.299600 67000 solver.cpp:285]     Train net output #0: loss = 0.122073 (* 1 = 0.122073 loss)
I0122 18:06:15.299607 67000 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 18:06:21.535171 67000 solver.cpp:266] Iteration 16200 (16.0377 iter/s, 6.23533s/100 iter), loss = 0.0878068
I0122 18:06:21.535202 67000 solver.cpp:285]     Train net output #0: loss = 0.0878068 (* 1 = 0.0878068 loss)
I0122 18:06:21.535207 67000 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 18:06:27.790081 67000 solver.cpp:266] Iteration 16300 (15.9881 iter/s, 6.25464s/100 iter), loss = 0.0925886
I0122 18:06:27.790109 67000 solver.cpp:285]     Train net output #0: loss = 0.0925886 (* 1 = 0.0925886 loss)
I0122 18:06:27.790115 67000 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 18:06:34.035524 67000 solver.cpp:266] Iteration 16400 (16.0124 iter/s, 6.24517s/100 iter), loss = 0.0727454
I0122 18:06:34.035554 67000 solver.cpp:285]     Train net output #0: loss = 0.0727455 (* 1 = 0.0727455 loss)
I0122 18:06:34.035560 67000 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 18:06:40.298487 67000 solver.cpp:266] Iteration 16500 (15.9676 iter/s, 6.26269s/100 iter), loss = 0.0972007
I0122 18:06:40.298602 67000 solver.cpp:285]     Train net output #0: loss = 0.0972007 (* 1 = 0.0972007 loss)
I0122 18:06:40.298609 67000 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 18:06:46.532177 67000 solver.cpp:266] Iteration 16600 (16.0428 iter/s, 6.23333s/100 iter), loss = 0.0826323
I0122 18:06:46.532205 67000 solver.cpp:285]     Train net output #0: loss = 0.0826323 (* 1 = 0.0826323 loss)
I0122 18:06:46.532210 67000 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 18:06:52.791409 67000 solver.cpp:266] Iteration 16700 (15.9771 iter/s, 6.25896s/100 iter), loss = 0.0634113
I0122 18:06:52.791438 67000 solver.cpp:285]     Train net output #0: loss = 0.0634113 (* 1 = 0.0634113 loss)
I0122 18:06:52.791445 67000 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 18:06:59.064481 67000 solver.cpp:266] Iteration 16800 (15.9419 iter/s, 6.2728s/100 iter), loss = 0.145399
I0122 18:06:59.064510 67000 solver.cpp:285]     Train net output #0: loss = 0.145399 (* 1 = 0.145399 loss)
I0122 18:06:59.064517 67000 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 18:07:05.329507 67000 solver.cpp:266] Iteration 16900 (15.9623 iter/s, 6.26475s/100 iter), loss = 0.136379
I0122 18:07:05.329535 67000 solver.cpp:285]     Train net output #0: loss = 0.136379 (* 1 = 0.136379 loss)
I0122 18:07:05.329541 67000 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 18:07:11.512025 67000 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 18:07:12.973769 67000 solver.cpp:517]     Test net output #0: accuracy = 0.804445
I0122 18:07:12.973794 67000 solver.cpp:517]     Test net output #1: loss = 0.618251 (* 1 = 0.618251 loss)
I0122 18:07:12.973799 67000 solver.cpp:517]     Test net output #2: top-1 = 0.804445
I0122 18:07:12.973803 67000 solver.cpp:517]     Test net output #3: top-5 = 0.986667
I0122 18:07:13.035379 67000 solver.cpp:266] Iteration 17000 (12.9777 iter/s, 7.70555s/100 iter), loss = 0.0646264
I0122 18:07:13.035400 67000 solver.cpp:285]     Train net output #0: loss = 0.0646264 (* 1 = 0.0646264 loss)
I0122 18:07:13.035408 67000 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 18:07:19.272579 67000 solver.cpp:266] Iteration 17100 (16.0335 iter/s, 6.23694s/100 iter), loss = 0.0610424
I0122 18:07:19.272606 67000 solver.cpp:285]     Train net output #0: loss = 0.0610424 (* 1 = 0.0610424 loss)
I0122 18:07:19.272613 67000 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 18:07:25.516574 67000 solver.cpp:266] Iteration 17200 (16.0161 iter/s, 6.24372s/100 iter), loss = 0.08811
I0122 18:07:25.516602 67000 solver.cpp:285]     Train net output #0: loss = 0.0881101 (* 1 = 0.0881101 loss)
I0122 18:07:25.516608 67000 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 18:07:31.750634 67000 solver.cpp:266] Iteration 17300 (16.0416 iter/s, 6.23379s/100 iter), loss = 0.0862597
I0122 18:07:31.750663 67000 solver.cpp:285]     Train net output #0: loss = 0.0862597 (* 1 = 0.0862597 loss)
I0122 18:07:31.750669 67000 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 18:07:38.013936 67000 solver.cpp:266] Iteration 17400 (15.9667 iter/s, 6.26303s/100 iter), loss = 0.0602661
I0122 18:07:38.013963 67000 solver.cpp:285]     Train net output #0: loss = 0.0602662 (* 1 = 0.0602662 loss)
I0122 18:07:38.013969 67000 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 18:07:44.272541 67000 solver.cpp:266] Iteration 17500 (15.9787 iter/s, 6.25833s/100 iter), loss = 0.0673864
I0122 18:07:44.272642 67000 solver.cpp:285]     Train net output #0: loss = 0.0673864 (* 1 = 0.0673864 loss)
I0122 18:07:44.272648 67000 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 18:07:50.547523 67000 solver.cpp:266] Iteration 17600 (15.9372 iter/s, 6.27464s/100 iter), loss = 0.0631862
I0122 18:07:50.547549 67000 solver.cpp:285]     Train net output #0: loss = 0.0631862 (* 1 = 0.0631862 loss)
I0122 18:07:50.547555 67000 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 18:07:56.825258 67000 solver.cpp:266] Iteration 17700 (15.93 iter/s, 6.27746s/100 iter), loss = 0.0960244
I0122 18:07:56.825286 67000 solver.cpp:285]     Train net output #0: loss = 0.0960244 (* 1 = 0.0960244 loss)
I0122 18:07:56.825291 67000 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 18:08:03.177845 67000 solver.cpp:266] Iteration 17800 (15.7423 iter/s, 6.35231s/100 iter), loss = 0.0484544
I0122 18:08:03.177873 67000 solver.cpp:285]     Train net output #0: loss = 0.0484544 (* 1 = 0.0484544 loss)
I0122 18:08:03.177880 67000 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 18:08:09.493314 67000 solver.cpp:266] Iteration 17900 (15.8348 iter/s, 6.31519s/100 iter), loss = 0.11282
I0122 18:08:09.493353 67000 solver.cpp:285]     Train net output #0: loss = 0.11282 (* 1 = 0.11282 loss)
I0122 18:08:09.493360 67000 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 18:08:15.722898 67000 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 18:08:17.179718 67000 solver.cpp:517]     Test net output #0: accuracy = 0.837444
I0122 18:08:17.179744 67000 solver.cpp:517]     Test net output #1: loss = 0.503591 (* 1 = 0.503591 loss)
I0122 18:08:17.179749 67000 solver.cpp:517]     Test net output #2: top-1 = 0.837444
I0122 18:08:17.179752 67000 solver.cpp:517]     Test net output #3: top-5 = 0.989222
I0122 18:08:17.242476 67000 solver.cpp:266] Iteration 18000 (12.9052 iter/s, 7.74883s/100 iter), loss = 0.115797
I0122 18:08:17.242496 67000 solver.cpp:285]     Train net output #0: loss = 0.115797 (* 1 = 0.115797 loss)
I0122 18:08:17.242501 67000 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 18:08:23.483814 67000 solver.cpp:266] Iteration 18100 (16.0229 iter/s, 6.24107s/100 iter), loss = 0.118548
I0122 18:08:23.483841 67000 solver.cpp:285]     Train net output #0: loss = 0.118548 (* 1 = 0.118548 loss)
I0122 18:08:23.483846 67000 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 18:08:29.748386 67000 solver.cpp:266] Iteration 18200 (15.9635 iter/s, 6.2643s/100 iter), loss = 0.0617489
I0122 18:08:29.748414 67000 solver.cpp:285]     Train net output #0: loss = 0.061749 (* 1 = 0.061749 loss)
I0122 18:08:29.748420 67000 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 18:08:35.976370 67000 solver.cpp:266] Iteration 18300 (16.0573 iter/s, 6.22771s/100 iter), loss = 0.106215
I0122 18:08:35.976397 67000 solver.cpp:285]     Train net output #0: loss = 0.106215 (* 1 = 0.106215 loss)
I0122 18:08:35.976404 67000 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 18:08:42.223261 67000 solver.cpp:266] Iteration 18400 (16.0087 iter/s, 6.24662s/100 iter), loss = 0.0681284
I0122 18:08:42.223289 67000 solver.cpp:285]     Train net output #0: loss = 0.0681285 (* 1 = 0.0681285 loss)
I0122 18:08:42.223294 67000 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 18:08:48.506197 67000 solver.cpp:266] Iteration 18500 (15.9168 iter/s, 6.28266s/100 iter), loss = 0.0856404
I0122 18:08:48.506300 67000 solver.cpp:285]     Train net output #0: loss = 0.0856404 (* 1 = 0.0856404 loss)
I0122 18:08:48.506307 67000 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 18:08:54.756373 67000 solver.cpp:266] Iteration 18600 (16.0004 iter/s, 6.24983s/100 iter), loss = 0.111635
I0122 18:08:54.756402 67000 solver.cpp:285]     Train net output #0: loss = 0.111635 (* 1 = 0.111635 loss)
I0122 18:08:54.756407 67000 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 18:09:01.007242 67000 solver.cpp:266] Iteration 18700 (15.9985 iter/s, 6.2506s/100 iter), loss = 0.0730627
I0122 18:09:01.007269 67000 solver.cpp:285]     Train net output #0: loss = 0.0730627 (* 1 = 0.0730627 loss)
I0122 18:09:01.007275 67000 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 18:09:07.257400 67000 solver.cpp:266] Iteration 18800 (16.0003 iter/s, 6.24989s/100 iter), loss = 0.101798
I0122 18:09:07.257427 67000 solver.cpp:285]     Train net output #0: loss = 0.101798 (* 1 = 0.101798 loss)
I0122 18:09:07.257433 67000 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 18:09:13.498987 67000 solver.cpp:266] Iteration 18900 (16.0223 iter/s, 6.24131s/100 iter), loss = 0.075621
I0122 18:09:13.499016 67000 solver.cpp:285]     Train net output #0: loss = 0.075621 (* 1 = 0.075621 loss)
I0122 18:09:13.499022 67000 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 18:09:19.683161 67000 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 18:09:21.147905 67000 solver.cpp:517]     Test net output #0: accuracy = 0.755556
I0122 18:09:21.147929 67000 solver.cpp:517]     Test net output #1: loss = 0.880201 (* 1 = 0.880201 loss)
I0122 18:09:21.147934 67000 solver.cpp:517]     Test net output #2: top-1 = 0.755556
I0122 18:09:21.147938 67000 solver.cpp:517]     Test net output #3: top-5 = 0.989223
I0122 18:09:21.212178 67000 solver.cpp:266] Iteration 19000 (12.9654 iter/s, 7.71287s/100 iter), loss = 0.118446
I0122 18:09:21.212208 67000 solver.cpp:285]     Train net output #0: loss = 0.118446 (* 1 = 0.118446 loss)
I0122 18:09:21.212215 67000 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 18:09:27.457367 67000 solver.cpp:266] Iteration 19100 (16.013 iter/s, 6.24492s/100 iter), loss = 0.0955368
I0122 18:09:27.457394 67000 solver.cpp:285]     Train net output #0: loss = 0.0955368 (* 1 = 0.0955368 loss)
I0122 18:09:27.457399 67000 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 18:09:33.683606 67000 solver.cpp:266] Iteration 19200 (16.0618 iter/s, 6.22597s/100 iter), loss = 0.0369266
I0122 18:09:33.683634 67000 solver.cpp:285]     Train net output #0: loss = 0.0369266 (* 1 = 0.0369266 loss)
I0122 18:09:33.683640 67000 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 18:09:39.943779 67000 solver.cpp:266] Iteration 19300 (15.9747 iter/s, 6.2599s/100 iter), loss = 0.07781
I0122 18:09:39.943817 67000 solver.cpp:285]     Train net output #0: loss = 0.07781 (* 1 = 0.07781 loss)
I0122 18:09:39.943823 67000 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 18:09:46.174072 67000 solver.cpp:266] Iteration 19400 (16.0513 iter/s, 6.23001s/100 iter), loss = 0.0696366
I0122 18:09:46.174111 67000 solver.cpp:285]     Train net output #0: loss = 0.0696366 (* 1 = 0.0696366 loss)
I0122 18:09:46.174118 67000 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 18:09:52.436239 67000 solver.cpp:266] Iteration 19500 (15.9696 iter/s, 6.26188s/100 iter), loss = 0.0396916
I0122 18:09:52.436313 67000 solver.cpp:285]     Train net output #0: loss = 0.0396916 (* 1 = 0.0396916 loss)
I0122 18:09:52.436319 67000 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 18:09:58.677731 67000 solver.cpp:266] Iteration 19600 (16.0226 iter/s, 6.24118s/100 iter), loss = 0.106965
I0122 18:09:58.677759 67000 solver.cpp:285]     Train net output #0: loss = 0.106965 (* 1 = 0.106965 loss)
I0122 18:09:58.677765 67000 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 18:10:04.937921 67000 solver.cpp:266] Iteration 19700 (15.9747 iter/s, 6.25992s/100 iter), loss = 0.0768816
I0122 18:10:04.937947 67000 solver.cpp:285]     Train net output #0: loss = 0.0768816 (* 1 = 0.0768816 loss)
I0122 18:10:04.937952 67000 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 18:10:11.182363 67000 solver.cpp:266] Iteration 19800 (16.0149 iter/s, 6.24417s/100 iter), loss = 0.059137
I0122 18:10:11.182390 67000 solver.cpp:285]     Train net output #0: loss = 0.0591371 (* 1 = 0.0591371 loss)
I0122 18:10:11.182396 67000 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 18:10:17.420240 67000 solver.cpp:266] Iteration 19900 (16.0318 iter/s, 6.23761s/100 iter), loss = 0.0853211
I0122 18:10:17.420269 67000 solver.cpp:285]     Train net output #0: loss = 0.0853211 (* 1 = 0.0853211 loss)
I0122 18:10:17.420275 67000 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 18:10:23.604300 67000 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/snapshots/_iter_20000.caffemodel
I0122 18:10:23.656388 67000 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/snapshots/_iter_20000.solverstate
I0122 18:10:23.664419 67000 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 18:10:25.118299 67000 solver.cpp:517]     Test net output #0: accuracy = 0.82
I0122 18:10:25.118324 67000 solver.cpp:517]     Test net output #1: loss = 0.651334 (* 1 = 0.651334 loss)
I0122 18:10:25.118329 67000 solver.cpp:517]     Test net output #2: top-1 = 0.82
I0122 18:10:25.118332 67000 solver.cpp:517]     Test net output #3: top-5 = 0.991111
I0122 18:10:25.184689 67000 solver.cpp:266] Iteration 20000 (12.8798 iter/s, 7.76412s/100 iter), loss = 0.114465
I0122 18:10:25.184720 67000 solver.cpp:285]     Train net output #0: loss = 0.114465 (* 1 = 0.114465 loss)
I0122 18:10:25.184726 67000 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 18:10:31.434763 67000 solver.cpp:266] Iteration 20100 (16.0005 iter/s, 6.2498s/100 iter), loss = 0.048766
I0122 18:10:31.434792 67000 solver.cpp:285]     Train net output #0: loss = 0.0487661 (* 1 = 0.0487661 loss)
I0122 18:10:31.434798 67000 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 18:10:37.674521 67000 solver.cpp:266] Iteration 20200 (16.027 iter/s, 6.23948s/100 iter), loss = 0.044665
I0122 18:10:37.674562 67000 solver.cpp:285]     Train net output #0: loss = 0.0446651 (* 1 = 0.0446651 loss)
I0122 18:10:37.674568 67000 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 18:10:43.909171 67000 solver.cpp:266] Iteration 20300 (16.0401 iter/s, 6.23436s/100 iter), loss = 0.0334261
I0122 18:10:43.909200 67000 solver.cpp:285]     Train net output #0: loss = 0.0334261 (* 1 = 0.0334261 loss)
I0122 18:10:43.909206 67000 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 18:10:50.151077 67000 solver.cpp:266] Iteration 20400 (16.0215 iter/s, 6.24163s/100 iter), loss = 0.0670167
I0122 18:10:50.151105 67000 solver.cpp:285]     Train net output #0: loss = 0.0670167 (* 1 = 0.0670167 loss)
I0122 18:10:50.151111 67000 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 18:10:56.388574 67000 solver.cpp:266] Iteration 20500 (16.0328 iter/s, 6.23723s/100 iter), loss = 0.053632
I0122 18:10:56.388705 67000 solver.cpp:285]     Train net output #0: loss = 0.0536321 (* 1 = 0.0536321 loss)
I0122 18:10:56.388713 67000 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 18:11:02.645505 67000 solver.cpp:266] Iteration 20600 (15.9832 iter/s, 6.25656s/100 iter), loss = 0.0243631
I0122 18:11:02.645534 67000 solver.cpp:285]     Train net output #0: loss = 0.0243632 (* 1 = 0.0243632 loss)
I0122 18:11:02.645539 67000 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 18:11:08.897322 67000 solver.cpp:266] Iteration 20700 (15.996 iter/s, 6.25155s/100 iter), loss = 0.0186053
I0122 18:11:08.897348 67000 solver.cpp:285]     Train net output #0: loss = 0.0186053 (* 1 = 0.0186053 loss)
I0122 18:11:08.897354 67000 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 18:11:15.146348 67000 solver.cpp:266] Iteration 20800 (16.0032 iter/s, 6.24876s/100 iter), loss = 0.0345129
I0122 18:11:15.146378 67000 solver.cpp:285]     Train net output #0: loss = 0.034513 (* 1 = 0.034513 loss)
I0122 18:11:15.146384 67000 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 18:11:21.379101 67000 solver.cpp:266] Iteration 20900 (16.045 iter/s, 6.23248s/100 iter), loss = 0.0210005
I0122 18:11:21.379129 67000 solver.cpp:285]     Train net output #0: loss = 0.0210006 (* 1 = 0.0210006 loss)
I0122 18:11:21.379135 67000 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 18:11:27.559610 67000 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 18:11:29.016175 67000 solver.cpp:517]     Test net output #0: accuracy = 0.891333
I0122 18:11:29.016201 67000 solver.cpp:517]     Test net output #1: loss = 0.367038 (* 1 = 0.367038 loss)
I0122 18:11:29.016206 67000 solver.cpp:517]     Test net output #2: top-1 = 0.891333
I0122 18:11:29.016209 67000 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 18:11:29.080564 67000 solver.cpp:266] Iteration 21000 (12.9851 iter/s, 7.70114s/100 iter), loss = 0.0241402
I0122 18:11:29.080595 67000 solver.cpp:285]     Train net output #0: loss = 0.0241402 (* 1 = 0.0241402 loss)
I0122 18:11:29.080601 67000 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 18:11:35.327642 67000 solver.cpp:266] Iteration 21100 (16.0082 iter/s, 6.2468s/100 iter), loss = 0.0192355
I0122 18:11:35.327674 67000 solver.cpp:285]     Train net output #0: loss = 0.0192355 (* 1 = 0.0192355 loss)
I0122 18:11:35.327680 67000 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 18:11:41.586386 67000 solver.cpp:266] Iteration 21200 (15.9783 iter/s, 6.25847s/100 iter), loss = 0.0343209
I0122 18:11:41.586426 67000 solver.cpp:285]     Train net output #0: loss = 0.034321 (* 1 = 0.034321 loss)
I0122 18:11:41.586433 67000 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 18:11:47.832923 67000 solver.cpp:266] Iteration 21300 (16.0096 iter/s, 6.24625s/100 iter), loss = 0.0293398
I0122 18:11:47.832952 67000 solver.cpp:285]     Train net output #0: loss = 0.0293399 (* 1 = 0.0293399 loss)
I0122 18:11:47.832957 67000 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 18:11:54.072664 67000 solver.cpp:266] Iteration 21400 (16.027 iter/s, 6.23947s/100 iter), loss = 0.0181117
I0122 18:11:54.072691 67000 solver.cpp:285]     Train net output #0: loss = 0.0181118 (* 1 = 0.0181118 loss)
I0122 18:11:54.072696 67000 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 18:12:00.324754 67000 solver.cpp:266] Iteration 21500 (15.9953 iter/s, 6.25182s/100 iter), loss = 0.0141793
I0122 18:12:00.324834 67000 solver.cpp:285]     Train net output #0: loss = 0.0141793 (* 1 = 0.0141793 loss)
I0122 18:12:00.324841 67000 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 18:12:06.568058 67000 solver.cpp:266] Iteration 21600 (16.018 iter/s, 6.24298s/100 iter), loss = 0.0108005
I0122 18:12:06.568099 67000 solver.cpp:285]     Train net output #0: loss = 0.0108006 (* 1 = 0.0108006 loss)
I0122 18:12:06.568106 67000 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 18:12:12.828778 67000 solver.cpp:266] Iteration 21700 (15.9733 iter/s, 6.26044s/100 iter), loss = 0.0277508
I0122 18:12:12.828806 67000 solver.cpp:285]     Train net output #0: loss = 0.0277509 (* 1 = 0.0277509 loss)
I0122 18:12:12.828812 67000 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 18:12:19.060425 67000 solver.cpp:266] Iteration 21800 (16.0478 iter/s, 6.23137s/100 iter), loss = 0.0183198
I0122 18:12:19.060453 67000 solver.cpp:285]     Train net output #0: loss = 0.0183198 (* 1 = 0.0183198 loss)
I0122 18:12:19.060459 67000 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 18:12:25.306546 67000 solver.cpp:266] Iteration 21900 (16.0106 iter/s, 6.24585s/100 iter), loss = 0.0220844
I0122 18:12:25.306574 67000 solver.cpp:285]     Train net output #0: loss = 0.0220844 (* 1 = 0.0220844 loss)
I0122 18:12:25.306581 67000 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 18:12:31.499255 67000 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 18:12:32.972692 67000 solver.cpp:517]     Test net output #0: accuracy = 0.892222
I0122 18:12:32.972718 67000 solver.cpp:517]     Test net output #1: loss = 0.353159 (* 1 = 0.353159 loss)
I0122 18:12:32.972721 67000 solver.cpp:517]     Test net output #2: top-1 = 0.892222
I0122 18:12:32.972724 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:12:33.036000 67000 solver.cpp:266] Iteration 22000 (12.9381 iter/s, 7.72913s/100 iter), loss = 0.0312743
I0122 18:12:33.036032 67000 solver.cpp:285]     Train net output #0: loss = 0.0312743 (* 1 = 0.0312743 loss)
I0122 18:12:33.036039 67000 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 18:12:39.273921 67000 solver.cpp:266] Iteration 22100 (16.0317 iter/s, 6.23765s/100 iter), loss = 0.018485
I0122 18:12:39.273949 67000 solver.cpp:285]     Train net output #0: loss = 0.018485 (* 1 = 0.018485 loss)
I0122 18:12:39.273955 67000 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 18:12:45.517184 67000 solver.cpp:266] Iteration 22200 (16.018 iter/s, 6.24299s/100 iter), loss = 0.0166552
I0122 18:12:45.517212 67000 solver.cpp:285]     Train net output #0: loss = 0.0166552 (* 1 = 0.0166552 loss)
I0122 18:12:45.517218 67000 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 18:12:51.753023 67000 solver.cpp:266] Iteration 22300 (16.037 iter/s, 6.23557s/100 iter), loss = 0.0099084
I0122 18:12:51.753052 67000 solver.cpp:285]     Train net output #0: loss = 0.00990845 (* 1 = 0.00990845 loss)
I0122 18:12:51.753057 67000 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 18:12:58.011039 67000 solver.cpp:266] Iteration 22400 (15.9802 iter/s, 6.25774s/100 iter), loss = 0.0382362
I0122 18:12:58.011070 67000 solver.cpp:285]     Train net output #0: loss = 0.0382362 (* 1 = 0.0382362 loss)
I0122 18:12:58.011075 67000 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 18:13:04.251804 67000 solver.cpp:266] Iteration 22500 (16.0244 iter/s, 6.24049s/100 iter), loss = 0.0123364
I0122 18:13:04.251894 67000 solver.cpp:285]     Train net output #0: loss = 0.0123365 (* 1 = 0.0123365 loss)
I0122 18:13:04.251902 67000 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 18:13:10.491551 67000 solver.cpp:266] Iteration 22600 (16.0271 iter/s, 6.23942s/100 iter), loss = 0.0153047
I0122 18:13:10.491580 67000 solver.cpp:285]     Train net output #0: loss = 0.0153047 (* 1 = 0.0153047 loss)
I0122 18:13:10.491585 67000 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 18:13:16.873603 67000 solver.cpp:266] Iteration 22700 (15.6696 iter/s, 6.38177s/100 iter), loss = 0.00827338
I0122 18:13:16.873632 67000 solver.cpp:285]     Train net output #0: loss = 0.00827342 (* 1 = 0.00827342 loss)
I0122 18:13:16.873637 67000 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 18:13:23.381830 67000 solver.cpp:266] Iteration 22800 (15.3658 iter/s, 6.50794s/100 iter), loss = 0.00661339
I0122 18:13:23.381860 67000 solver.cpp:285]     Train net output #0: loss = 0.00661343 (* 1 = 0.00661343 loss)
I0122 18:13:23.381865 67000 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 18:13:29.712749 67000 solver.cpp:266] Iteration 22900 (15.7962 iter/s, 6.33064s/100 iter), loss = 0.0108101
I0122 18:13:29.712779 67000 solver.cpp:285]     Train net output #0: loss = 0.0108102 (* 1 = 0.0108102 loss)
I0122 18:13:29.712785 67000 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 18:13:35.892415 67000 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 18:13:37.360623 67000 solver.cpp:517]     Test net output #0: accuracy = 0.891778
I0122 18:13:37.360651 67000 solver.cpp:517]     Test net output #1: loss = 0.359769 (* 1 = 0.359769 loss)
I0122 18:13:37.360656 67000 solver.cpp:517]     Test net output #2: top-1 = 0.891778
I0122 18:13:37.360658 67000 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 18:13:37.422371 67000 solver.cpp:266] Iteration 23000 (12.9714 iter/s, 7.7093s/100 iter), loss = 0.0153099
I0122 18:13:37.422401 67000 solver.cpp:285]     Train net output #0: loss = 0.01531 (* 1 = 0.01531 loss)
I0122 18:13:37.422410 67000 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 18:13:43.662381 67000 solver.cpp:266] Iteration 23100 (16.0263 iter/s, 6.23975s/100 iter), loss = 0.0141555
I0122 18:13:43.662410 67000 solver.cpp:285]     Train net output #0: loss = 0.0141556 (* 1 = 0.0141556 loss)
I0122 18:13:43.662415 67000 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 18:13:49.918576 67000 solver.cpp:266] Iteration 23200 (15.9849 iter/s, 6.25592s/100 iter), loss = 0.0134289
I0122 18:13:49.918604 67000 solver.cpp:285]     Train net output #0: loss = 0.0134289 (* 1 = 0.0134289 loss)
I0122 18:13:49.918610 67000 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 18:13:56.189327 67000 solver.cpp:266] Iteration 23300 (15.9478 iter/s, 6.27048s/100 iter), loss = 0.0125879
I0122 18:13:56.189357 67000 solver.cpp:285]     Train net output #0: loss = 0.0125879 (* 1 = 0.0125879 loss)
I0122 18:13:56.189363 67000 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 18:14:02.446460 67000 solver.cpp:266] Iteration 23400 (15.9825 iter/s, 6.25686s/100 iter), loss = 0.00740425
I0122 18:14:02.446488 67000 solver.cpp:285]     Train net output #0: loss = 0.0074043 (* 1 = 0.0074043 loss)
I0122 18:14:02.446494 67000 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 18:14:08.675547 67000 solver.cpp:266] Iteration 23500 (16.0544 iter/s, 6.22882s/100 iter), loss = 0.00852598
I0122 18:14:08.675607 67000 solver.cpp:285]     Train net output #0: loss = 0.00852602 (* 1 = 0.00852602 loss)
I0122 18:14:08.675614 67000 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 18:14:14.941254 67000 solver.cpp:266] Iteration 23600 (15.9607 iter/s, 6.2654s/100 iter), loss = 0.0110365
I0122 18:14:14.941283 67000 solver.cpp:285]     Train net output #0: loss = 0.0110366 (* 1 = 0.0110366 loss)
I0122 18:14:14.941289 67000 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 18:14:21.181179 67000 solver.cpp:266] Iteration 23700 (16.0265 iter/s, 6.23965s/100 iter), loss = 0.0134733
I0122 18:14:21.181210 67000 solver.cpp:285]     Train net output #0: loss = 0.0134734 (* 1 = 0.0134734 loss)
I0122 18:14:21.181231 67000 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 18:14:27.426275 67000 solver.cpp:266] Iteration 23800 (16.0133 iter/s, 6.24482s/100 iter), loss = 0.0065782
I0122 18:14:27.426304 67000 solver.cpp:285]     Train net output #0: loss = 0.00657825 (* 1 = 0.00657825 loss)
I0122 18:14:27.426311 67000 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 18:14:33.692775 67000 solver.cpp:266] Iteration 23900 (15.9586 iter/s, 6.26623s/100 iter), loss = 0.00601507
I0122 18:14:33.692804 67000 solver.cpp:285]     Train net output #0: loss = 0.00601512 (* 1 = 0.00601512 loss)
I0122 18:14:33.692809 67000 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 18:14:39.889883 67000 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 18:14:41.349208 67000 solver.cpp:517]     Test net output #0: accuracy = 0.895
I0122 18:14:41.349234 67000 solver.cpp:517]     Test net output #1: loss = 0.354861 (* 1 = 0.354861 loss)
I0122 18:14:41.349239 67000 solver.cpp:517]     Test net output #2: top-1 = 0.895
I0122 18:14:41.349259 67000 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 18:14:41.411934 67000 solver.cpp:266] Iteration 24000 (12.9553 iter/s, 7.71883s/100 iter), loss = 0.010534
I0122 18:14:41.411954 67000 solver.cpp:285]     Train net output #0: loss = 0.0105341 (* 1 = 0.0105341 loss)
I0122 18:14:41.411960 67000 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 18:14:47.673491 67000 solver.cpp:266] Iteration 24100 (15.9711 iter/s, 6.26129s/100 iter), loss = 0.008872
I0122 18:14:47.673529 67000 solver.cpp:285]     Train net output #0: loss = 0.00887205 (* 1 = 0.00887205 loss)
I0122 18:14:47.673552 67000 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 18:14:53.930367 67000 solver.cpp:266] Iteration 24200 (15.9831 iter/s, 6.25659s/100 iter), loss = 0.00546248
I0122 18:14:53.930397 67000 solver.cpp:285]     Train net output #0: loss = 0.00546253 (* 1 = 0.00546253 loss)
I0122 18:14:53.930403 67000 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 18:15:00.196274 67000 solver.cpp:266] Iteration 24300 (15.9601 iter/s, 6.26563s/100 iter), loss = 0.0103731
I0122 18:15:00.196302 67000 solver.cpp:285]     Train net output #0: loss = 0.0103732 (* 1 = 0.0103732 loss)
I0122 18:15:00.196308 67000 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 18:15:06.442307 67000 solver.cpp:266] Iteration 24400 (16.0109 iter/s, 6.24576s/100 iter), loss = 0.0144515
I0122 18:15:06.442348 67000 solver.cpp:285]     Train net output #0: loss = 0.0144515 (* 1 = 0.0144515 loss)
I0122 18:15:06.442354 67000 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 18:15:12.709609 67000 solver.cpp:266] Iteration 24500 (15.9566 iter/s, 6.26702s/100 iter), loss = 0.00891201
I0122 18:15:12.709674 67000 solver.cpp:285]     Train net output #0: loss = 0.00891206 (* 1 = 0.00891206 loss)
I0122 18:15:12.709681 67000 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 18:15:18.978413 67000 solver.cpp:266] Iteration 24600 (15.9528 iter/s, 6.2685s/100 iter), loss = 0.00966748
I0122 18:15:18.978443 67000 solver.cpp:285]     Train net output #0: loss = 0.00966753 (* 1 = 0.00966753 loss)
I0122 18:15:18.978449 67000 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 18:15:25.231420 67000 solver.cpp:266] Iteration 24700 (15.993 iter/s, 6.25273s/100 iter), loss = 0.00703308
I0122 18:15:25.231461 67000 solver.cpp:285]     Train net output #0: loss = 0.00703313 (* 1 = 0.00703313 loss)
I0122 18:15:25.231467 67000 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 18:15:31.481770 67000 solver.cpp:266] Iteration 24800 (15.9998 iter/s, 6.25006s/100 iter), loss = 0.00763937
I0122 18:15:31.481797 67000 solver.cpp:285]     Train net output #0: loss = 0.00763942 (* 1 = 0.00763942 loss)
I0122 18:15:31.481819 67000 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 18:15:37.742688 67000 solver.cpp:266] Iteration 24900 (15.9728 iter/s, 6.26065s/100 iter), loss = 0.00685758
I0122 18:15:37.742718 67000 solver.cpp:285]     Train net output #0: loss = 0.00685763 (* 1 = 0.00685763 loss)
I0122 18:15:37.742724 67000 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 18:15:43.932377 67000 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 18:15:45.384724 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894889
I0122 18:15:45.384749 67000 solver.cpp:517]     Test net output #1: loss = 0.356658 (* 1 = 0.356658 loss)
I0122 18:15:45.384754 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894889
I0122 18:15:45.384757 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 18:15:45.446069 67000 solver.cpp:266] Iteration 25000 (12.9819 iter/s, 7.70306s/100 iter), loss = 0.00448469
I0122 18:15:45.446089 67000 solver.cpp:285]     Train net output #0: loss = 0.00448473 (* 1 = 0.00448473 loss)
I0122 18:15:45.446095 67000 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 18:15:51.681686 67000 solver.cpp:266] Iteration 25100 (16.0376 iter/s, 6.23535s/100 iter), loss = 0.0111237
I0122 18:15:51.681715 67000 solver.cpp:285]     Train net output #0: loss = 0.0111238 (* 1 = 0.0111238 loss)
I0122 18:15:51.681807 67000 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 18:15:57.934175 67000 solver.cpp:266] Iteration 25200 (15.9946 iter/s, 6.25212s/100 iter), loss = 0.00675584
I0122 18:15:57.934202 67000 solver.cpp:285]     Train net output #0: loss = 0.00675589 (* 1 = 0.00675589 loss)
I0122 18:15:57.934208 67000 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 18:16:04.185079 67000 solver.cpp:266] Iteration 25300 (15.9984 iter/s, 6.25063s/100 iter), loss = 0.00772063
I0122 18:16:04.185108 67000 solver.cpp:285]     Train net output #0: loss = 0.00772068 (* 1 = 0.00772068 loss)
I0122 18:16:04.185114 67000 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 18:16:10.429788 67000 solver.cpp:266] Iteration 25400 (16.0143 iter/s, 6.24444s/100 iter), loss = 0.00250168
I0122 18:16:10.429817 67000 solver.cpp:285]     Train net output #0: loss = 0.00250173 (* 1 = 0.00250173 loss)
I0122 18:16:10.429822 67000 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 18:16:16.681766 67000 solver.cpp:266] Iteration 25500 (15.9956 iter/s, 6.2517s/100 iter), loss = 0.0107743
I0122 18:16:16.681834 67000 solver.cpp:285]     Train net output #0: loss = 0.0107743 (* 1 = 0.0107743 loss)
I0122 18:16:16.681841 67000 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 18:16:22.927686 67000 solver.cpp:266] Iteration 25600 (16.0112 iter/s, 6.24561s/100 iter), loss = 0.00804377
I0122 18:16:22.927726 67000 solver.cpp:285]     Train net output #0: loss = 0.00804382 (* 1 = 0.00804382 loss)
I0122 18:16:22.927733 67000 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 18:16:29.187886 67000 solver.cpp:266] Iteration 25700 (15.9747 iter/s, 6.25992s/100 iter), loss = 0.0119815
I0122 18:16:29.187916 67000 solver.cpp:285]     Train net output #0: loss = 0.0119815 (* 1 = 0.0119815 loss)
I0122 18:16:29.187921 67000 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 18:16:35.427614 67000 solver.cpp:266] Iteration 25800 (16.027 iter/s, 6.23946s/100 iter), loss = 0.00484792
I0122 18:16:35.427642 67000 solver.cpp:285]     Train net output #0: loss = 0.00484796 (* 1 = 0.00484796 loss)
I0122 18:16:35.427649 67000 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 18:16:41.683387 67000 solver.cpp:266] Iteration 25900 (15.9859 iter/s, 6.2555s/100 iter), loss = 0.0137837
I0122 18:16:41.683415 67000 solver.cpp:285]     Train net output #0: loss = 0.0137837 (* 1 = 0.0137837 loss)
I0122 18:16:41.683420 67000 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 18:16:47.864439 67000 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 18:16:49.331831 67000 solver.cpp:517]     Test net output #0: accuracy = 0.895
I0122 18:16:49.331857 67000 solver.cpp:517]     Test net output #1: loss = 0.363183 (* 1 = 0.363183 loss)
I0122 18:16:49.331862 67000 solver.cpp:517]     Test net output #2: top-1 = 0.895
I0122 18:16:49.331866 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:16:49.395678 67000 solver.cpp:266] Iteration 26000 (12.9669 iter/s, 7.71197s/100 iter), loss = 0.00854271
I0122 18:16:49.395709 67000 solver.cpp:285]     Train net output #0: loss = 0.00854275 (* 1 = 0.00854275 loss)
I0122 18:16:49.395716 67000 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 18:16:55.645786 67000 solver.cpp:266] Iteration 26100 (16.0004 iter/s, 6.24984s/100 iter), loss = 0.00660303
I0122 18:16:55.645815 67000 solver.cpp:285]     Train net output #0: loss = 0.00660308 (* 1 = 0.00660308 loss)
I0122 18:16:55.645822 67000 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 18:17:01.898190 67000 solver.cpp:266] Iteration 26200 (15.9945 iter/s, 6.25213s/100 iter), loss = 0.00855395
I0122 18:17:01.898219 67000 solver.cpp:285]     Train net output #0: loss = 0.008554 (* 1 = 0.008554 loss)
I0122 18:17:01.898224 67000 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 18:17:08.149564 67000 solver.cpp:266] Iteration 26300 (15.9972 iter/s, 6.2511s/100 iter), loss = 0.0132206
I0122 18:17:08.149595 67000 solver.cpp:285]     Train net output #0: loss = 0.0132207 (* 1 = 0.0132207 loss)
I0122 18:17:08.149600 67000 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 18:17:14.386430 67000 solver.cpp:266] Iteration 26400 (16.0344 iter/s, 6.23659s/100 iter), loss = 0.0083111
I0122 18:17:14.386472 67000 solver.cpp:285]     Train net output #0: loss = 0.00831115 (* 1 = 0.00831115 loss)
I0122 18:17:14.386478 67000 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 18:17:20.633028 67000 solver.cpp:266] Iteration 26500 (16.0094 iter/s, 6.24631s/100 iter), loss = 0.00426807
I0122 18:17:20.633157 67000 solver.cpp:285]     Train net output #0: loss = 0.00426811 (* 1 = 0.00426811 loss)
I0122 18:17:20.633164 67000 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 18:17:26.864871 67000 solver.cpp:266] Iteration 26600 (16.0476 iter/s, 6.23147s/100 iter), loss = 0.0189043
I0122 18:17:26.864899 67000 solver.cpp:285]     Train net output #0: loss = 0.0189043 (* 1 = 0.0189043 loss)
I0122 18:17:26.864904 67000 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 18:17:33.120630 67000 solver.cpp:266] Iteration 26700 (15.986 iter/s, 6.25549s/100 iter), loss = 0.0055924
I0122 18:17:33.120659 67000 solver.cpp:285]     Train net output #0: loss = 0.00559244 (* 1 = 0.00559244 loss)
I0122 18:17:33.120664 67000 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 18:17:39.370888 67000 solver.cpp:266] Iteration 26800 (16 iter/s, 6.24998s/100 iter), loss = 0.00680002
I0122 18:17:39.370918 67000 solver.cpp:285]     Train net output #0: loss = 0.00680007 (* 1 = 0.00680007 loss)
I0122 18:17:39.370923 67000 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 18:17:45.639933 67000 solver.cpp:266] Iteration 26900 (15.9521 iter/s, 6.26877s/100 iter), loss = 0.00590381
I0122 18:17:45.639962 67000 solver.cpp:285]     Train net output #0: loss = 0.00590386 (* 1 = 0.00590386 loss)
I0122 18:17:45.639968 67000 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 18:17:51.824082 67000 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 18:17:53.284487 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894889
I0122 18:17:53.284512 67000 solver.cpp:517]     Test net output #1: loss = 0.364265 (* 1 = 0.364265 loss)
I0122 18:17:53.284518 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894889
I0122 18:17:53.284521 67000 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 18:17:53.346724 67000 solver.cpp:266] Iteration 27000 (12.9761 iter/s, 7.70647s/100 iter), loss = 0.00610544
I0122 18:17:53.346745 67000 solver.cpp:285]     Train net output #0: loss = 0.00610548 (* 1 = 0.00610548 loss)
I0122 18:17:53.346750 67000 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 18:17:59.598912 67000 solver.cpp:266] Iteration 27100 (15.9951 iter/s, 6.25192s/100 iter), loss = 0.00435034
I0122 18:17:59.598942 67000 solver.cpp:285]     Train net output #0: loss = 0.00435039 (* 1 = 0.00435039 loss)
I0122 18:17:59.598963 67000 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 18:18:05.834429 67000 solver.cpp:266] Iteration 27200 (16.0379 iter/s, 6.23524s/100 iter), loss = 0.00608976
I0122 18:18:05.834458 67000 solver.cpp:285]     Train net output #0: loss = 0.0060898 (* 1 = 0.0060898 loss)
I0122 18:18:05.834465 67000 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 18:18:12.081110 67000 solver.cpp:266] Iteration 27300 (16.0092 iter/s, 6.24641s/100 iter), loss = 0.00509804
I0122 18:18:12.081140 67000 solver.cpp:285]     Train net output #0: loss = 0.00509809 (* 1 = 0.00509809 loss)
I0122 18:18:12.081145 67000 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 18:18:18.321521 67000 solver.cpp:266] Iteration 27400 (16.0253 iter/s, 6.24014s/100 iter), loss = 0.00683526
I0122 18:18:18.321561 67000 solver.cpp:285]     Train net output #0: loss = 0.0068353 (* 1 = 0.0068353 loss)
I0122 18:18:18.321568 67000 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 18:18:24.565132 67000 solver.cpp:266] Iteration 27500 (16.0171 iter/s, 6.24333s/100 iter), loss = 0.0048545
I0122 18:18:24.565253 67000 solver.cpp:285]     Train net output #0: loss = 0.00485454 (* 1 = 0.00485454 loss)
I0122 18:18:24.565269 67000 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 18:18:30.828658 67000 solver.cpp:266] Iteration 27600 (15.9664 iter/s, 6.26316s/100 iter), loss = 0.00731589
I0122 18:18:30.828688 67000 solver.cpp:285]     Train net output #0: loss = 0.00731593 (* 1 = 0.00731593 loss)
I0122 18:18:30.828693 67000 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 18:18:37.075887 67000 solver.cpp:266] Iteration 27700 (16.0078 iter/s, 6.24695s/100 iter), loss = 0.00657785
I0122 18:18:37.075920 67000 solver.cpp:285]     Train net output #0: loss = 0.00657789 (* 1 = 0.00657789 loss)
I0122 18:18:37.075927 67000 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 18:18:43.341888 67000 solver.cpp:266] Iteration 27800 (15.9598 iter/s, 6.26572s/100 iter), loss = 0.00889094
I0122 18:18:43.341919 67000 solver.cpp:285]     Train net output #0: loss = 0.00889098 (* 1 = 0.00889098 loss)
I0122 18:18:43.341925 67000 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 18:18:49.574118 67000 solver.cpp:266] Iteration 27900 (16.0463 iter/s, 6.23196s/100 iter), loss = 0.00997877
I0122 18:18:49.574147 67000 solver.cpp:285]     Train net output #0: loss = 0.00997881 (* 1 = 0.00997881 loss)
I0122 18:18:49.574153 67000 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 18:18:55.765851 67000 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 18:18:57.225641 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894889
I0122 18:18:57.225666 67000 solver.cpp:517]     Test net output #1: loss = 0.365802 (* 1 = 0.365802 loss)
I0122 18:18:57.225672 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894889
I0122 18:18:57.225675 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 18:18:57.288800 67000 solver.cpp:266] Iteration 28000 (12.9628 iter/s, 7.71435s/100 iter), loss = 0.00439312
I0122 18:18:57.288818 67000 solver.cpp:285]     Train net output #0: loss = 0.00439316 (* 1 = 0.00439316 loss)
I0122 18:18:57.288825 67000 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 18:19:03.535045 67000 solver.cpp:266] Iteration 28100 (16.0103 iter/s, 6.24598s/100 iter), loss = 0.00394365
I0122 18:19:03.535074 67000 solver.cpp:285]     Train net output #0: loss = 0.00394369 (* 1 = 0.00394369 loss)
I0122 18:19:03.535079 67000 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 18:19:09.784458 67000 solver.cpp:266] Iteration 28200 (16.0022 iter/s, 6.24914s/100 iter), loss = 0.00599768
I0122 18:19:09.784487 67000 solver.cpp:285]     Train net output #0: loss = 0.00599772 (* 1 = 0.00599772 loss)
I0122 18:19:09.784492 67000 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 18:19:16.046373 67000 solver.cpp:266] Iteration 28300 (15.9703 iter/s, 6.26164s/100 iter), loss = 0.00829902
I0122 18:19:16.046403 67000 solver.cpp:285]     Train net output #0: loss = 0.00829906 (* 1 = 0.00829906 loss)
I0122 18:19:16.046409 67000 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 18:19:22.296830 67000 solver.cpp:266] Iteration 28400 (15.9995 iter/s, 6.25018s/100 iter), loss = 0.00613066
I0122 18:19:22.296857 67000 solver.cpp:285]     Train net output #0: loss = 0.00613071 (* 1 = 0.00613071 loss)
I0122 18:19:22.296864 67000 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 18:19:28.534282 67000 solver.cpp:266] Iteration 28500 (16.0329 iter/s, 6.23718s/100 iter), loss = 0.0077996
I0122 18:19:28.534366 67000 solver.cpp:285]     Train net output #0: loss = 0.00779964 (* 1 = 0.00779964 loss)
I0122 18:19:28.534373 67000 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 18:19:34.789804 67000 solver.cpp:266] Iteration 28600 (15.9867 iter/s, 6.2552s/100 iter), loss = 0.00575207
I0122 18:19:34.789834 67000 solver.cpp:285]     Train net output #0: loss = 0.00575212 (* 1 = 0.00575212 loss)
I0122 18:19:34.789839 67000 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 18:19:41.056699 67000 solver.cpp:266] Iteration 28700 (15.9576 iter/s, 6.26662s/100 iter), loss = 0.00454776
I0122 18:19:41.056728 67000 solver.cpp:285]     Train net output #0: loss = 0.0045478 (* 1 = 0.0045478 loss)
I0122 18:19:41.056735 67000 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 18:19:47.314314 67000 solver.cpp:266] Iteration 28800 (15.9812 iter/s, 6.25734s/100 iter), loss = 0.0044022
I0122 18:19:47.314342 67000 solver.cpp:285]     Train net output #0: loss = 0.00440224 (* 1 = 0.00440224 loss)
I0122 18:19:47.314347 67000 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 18:19:53.523391 67000 solver.cpp:266] Iteration 28900 (16.1062 iter/s, 6.20881s/100 iter), loss = 0.00509117
I0122 18:19:53.523418 67000 solver.cpp:285]     Train net output #0: loss = 0.00509121 (* 1 = 0.00509121 loss)
I0122 18:19:53.523424 67000 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 18:19:59.736279 67000 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 18:20:01.201428 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894
I0122 18:20:01.201453 67000 solver.cpp:517]     Test net output #1: loss = 0.370167 (* 1 = 0.370167 loss)
I0122 18:20:01.201457 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894
I0122 18:20:01.201462 67000 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 18:20:01.262730 67000 solver.cpp:266] Iteration 29000 (12.9215 iter/s, 7.73901s/100 iter), loss = 0.00427909
I0122 18:20:01.262751 67000 solver.cpp:285]     Train net output #0: loss = 0.00427913 (* 1 = 0.00427913 loss)
I0122 18:20:01.262756 67000 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 18:20:07.489202 67000 solver.cpp:266] Iteration 29100 (16.0611 iter/s, 6.22621s/100 iter), loss = 0.00553058
I0122 18:20:07.489231 67000 solver.cpp:285]     Train net output #0: loss = 0.00553063 (* 1 = 0.00553063 loss)
I0122 18:20:07.489236 67000 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 18:20:13.743007 67000 solver.cpp:266] Iteration 29200 (15.991 iter/s, 6.25353s/100 iter), loss = 0.00273366
I0122 18:20:13.743036 67000 solver.cpp:285]     Train net output #0: loss = 0.0027337 (* 1 = 0.0027337 loss)
I0122 18:20:13.743042 67000 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 18:20:19.984333 67000 solver.cpp:266] Iteration 29300 (16.0229 iter/s, 6.24105s/100 iter), loss = 0.00239873
I0122 18:20:19.984362 67000 solver.cpp:285]     Train net output #0: loss = 0.00239877 (* 1 = 0.00239877 loss)
I0122 18:20:19.984367 67000 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 18:20:26.221256 67000 solver.cpp:266] Iteration 29400 (16.0342 iter/s, 6.23665s/100 iter), loss = 0.0093934
I0122 18:20:26.221284 67000 solver.cpp:285]     Train net output #0: loss = 0.00939343 (* 1 = 0.00939343 loss)
I0122 18:20:26.221290 67000 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 18:20:32.474164 67000 solver.cpp:266] Iteration 29500 (15.9933 iter/s, 6.25264s/100 iter), loss = 0.0068825
I0122 18:20:32.474275 67000 solver.cpp:285]     Train net output #0: loss = 0.00688254 (* 1 = 0.00688254 loss)
I0122 18:20:32.474292 67000 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 18:20:38.731426 67000 solver.cpp:266] Iteration 29600 (15.9823 iter/s, 6.25691s/100 iter), loss = 0.00659549
I0122 18:20:38.731453 67000 solver.cpp:285]     Train net output #0: loss = 0.00659553 (* 1 = 0.00659553 loss)
I0122 18:20:38.731459 67000 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 18:20:44.969943 67000 solver.cpp:266] Iteration 29700 (16.0301 iter/s, 6.23825s/100 iter), loss = 0.0101539
I0122 18:20:44.969971 67000 solver.cpp:285]     Train net output #0: loss = 0.0101539 (* 1 = 0.0101539 loss)
I0122 18:20:44.969977 67000 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 18:20:51.211015 67000 solver.cpp:266] Iteration 29800 (16.0236 iter/s, 6.2408s/100 iter), loss = 0.00529708
I0122 18:20:51.211043 67000 solver.cpp:285]     Train net output #0: loss = 0.00529712 (* 1 = 0.00529712 loss)
I0122 18:20:51.211050 67000 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 18:20:57.493324 67000 solver.cpp:266] Iteration 29900 (15.9184 iter/s, 6.28203s/100 iter), loss = 0.00568042
I0122 18:20:57.493352 67000 solver.cpp:285]     Train net output #0: loss = 0.00568046 (* 1 = 0.00568046 loss)
I0122 18:20:57.493357 67000 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 18:21:03.681898 67000 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 18:21:05.138700 67000 solver.cpp:517]     Test net output #0: accuracy = 0.893667
I0122 18:21:05.138726 67000 solver.cpp:517]     Test net output #1: loss = 0.371353 (* 1 = 0.371353 loss)
I0122 18:21:05.138731 67000 solver.cpp:517]     Test net output #2: top-1 = 0.893667
I0122 18:21:05.138734 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 18:21:05.201449 67000 solver.cpp:266] Iteration 30000 (12.9739 iter/s, 7.7078s/100 iter), loss = 0.00550336
I0122 18:21:05.201470 67000 solver.cpp:285]     Train net output #0: loss = 0.00550339 (* 1 = 0.00550339 loss)
I0122 18:21:05.201478 67000 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 18:21:11.448338 67000 solver.cpp:266] Iteration 30100 (16.0086 iter/s, 6.24662s/100 iter), loss = 0.00645009
I0122 18:21:11.448367 67000 solver.cpp:285]     Train net output #0: loss = 0.00645013 (* 1 = 0.00645013 loss)
I0122 18:21:11.448374 67000 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 18:21:17.692904 67000 solver.cpp:266] Iteration 30200 (16.0146 iter/s, 6.24429s/100 iter), loss = 0.00641487
I0122 18:21:17.692942 67000 solver.cpp:285]     Train net output #0: loss = 0.00641491 (* 1 = 0.00641491 loss)
I0122 18:21:17.692950 67000 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 18:21:23.957309 67000 solver.cpp:266] Iteration 30300 (15.9639 iter/s, 6.26412s/100 iter), loss = 0.00322628
I0122 18:21:23.957336 67000 solver.cpp:285]     Train net output #0: loss = 0.00322632 (* 1 = 0.00322632 loss)
I0122 18:21:23.957358 67000 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 18:21:30.199818 67000 solver.cpp:266] Iteration 30400 (16.0199 iter/s, 6.24224s/100 iter), loss = 0.00936722
I0122 18:21:30.199847 67000 solver.cpp:285]     Train net output #0: loss = 0.00936726 (* 1 = 0.00936726 loss)
I0122 18:21:30.199853 67000 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 18:21:36.448861 67000 solver.cpp:266] Iteration 30500 (16.0032 iter/s, 6.24877s/100 iter), loss = 0.00596209
I0122 18:21:36.448967 67000 solver.cpp:285]     Train net output #0: loss = 0.00596213 (* 1 = 0.00596213 loss)
I0122 18:21:36.448976 67000 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 18:21:42.710803 67000 solver.cpp:266] Iteration 30600 (15.9704 iter/s, 6.26159s/100 iter), loss = 0.00895001
I0122 18:21:42.710834 67000 solver.cpp:285]     Train net output #0: loss = 0.00895005 (* 1 = 0.00895005 loss)
I0122 18:21:42.710839 67000 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 18:21:48.960191 67000 solver.cpp:266] Iteration 30700 (16.0023 iter/s, 6.24911s/100 iter), loss = 0.00559702
I0122 18:21:48.960219 67000 solver.cpp:285]     Train net output #0: loss = 0.00559706 (* 1 = 0.00559706 loss)
I0122 18:21:48.960225 67000 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 18:21:55.223330 67000 solver.cpp:266] Iteration 30800 (15.9671 iter/s, 6.26287s/100 iter), loss = 0.00998735
I0122 18:21:55.223359 67000 solver.cpp:285]     Train net output #0: loss = 0.00998739 (* 1 = 0.00998739 loss)
I0122 18:21:55.223364 67000 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 18:22:01.465127 67000 solver.cpp:266] Iteration 30900 (16.0217 iter/s, 6.24152s/100 iter), loss = 0.00455353
I0122 18:22:01.465157 67000 solver.cpp:285]     Train net output #0: loss = 0.00455357 (* 1 = 0.00455357 loss)
I0122 18:22:01.465164 67000 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 18:22:07.655526 67000 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 18:22:09.114205 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894778
I0122 18:22:09.114230 67000 solver.cpp:517]     Test net output #1: loss = 0.374513 (* 1 = 0.374513 loss)
I0122 18:22:09.114235 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894778
I0122 18:22:09.114239 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 18:22:09.176214 67000 solver.cpp:266] Iteration 31000 (12.9689 iter/s, 7.71076s/100 iter), loss = 0.00694967
I0122 18:22:09.176234 67000 solver.cpp:285]     Train net output #0: loss = 0.00694971 (* 1 = 0.00694971 loss)
I0122 18:22:09.176241 67000 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 18:22:15.437163 67000 solver.cpp:266] Iteration 31100 (15.9727 iter/s, 6.26069s/100 iter), loss = 0.00523214
I0122 18:22:15.437191 67000 solver.cpp:285]     Train net output #0: loss = 0.00523218 (* 1 = 0.00523218 loss)
I0122 18:22:15.437197 67000 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 18:22:21.684623 67000 solver.cpp:266] Iteration 31200 (16.0072 iter/s, 6.24719s/100 iter), loss = 0.00409714
I0122 18:22:21.684651 67000 solver.cpp:285]     Train net output #0: loss = 0.00409718 (* 1 = 0.00409718 loss)
I0122 18:22:21.684657 67000 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 18:22:27.930025 67000 solver.cpp:266] Iteration 31300 (16.0125 iter/s, 6.24513s/100 iter), loss = 0.00405977
I0122 18:22:27.930053 67000 solver.cpp:285]     Train net output #0: loss = 0.00405981 (* 1 = 0.00405981 loss)
I0122 18:22:27.930059 67000 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 18:22:34.201274 67000 solver.cpp:266] Iteration 31400 (15.9465 iter/s, 6.27098s/100 iter), loss = 0.00692235
I0122 18:22:34.201301 67000 solver.cpp:285]     Train net output #0: loss = 0.00692239 (* 1 = 0.00692239 loss)
I0122 18:22:34.201308 67000 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 18:22:40.454430 67000 solver.cpp:266] Iteration 31500 (15.9926 iter/s, 6.25289s/100 iter), loss = 0.00602608
I0122 18:22:40.454540 67000 solver.cpp:285]     Train net output #0: loss = 0.00602612 (* 1 = 0.00602612 loss)
I0122 18:22:40.454547 67000 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 18:22:46.711601 67000 solver.cpp:266] Iteration 31600 (15.9826 iter/s, 6.25682s/100 iter), loss = 0.005811
I0122 18:22:46.711630 67000 solver.cpp:285]     Train net output #0: loss = 0.00581104 (* 1 = 0.00581104 loss)
I0122 18:22:46.711637 67000 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 18:22:52.959962 67000 solver.cpp:266] Iteration 31700 (16.0049 iter/s, 6.24809s/100 iter), loss = 0.00285989
I0122 18:22:52.959991 67000 solver.cpp:285]     Train net output #0: loss = 0.00285993 (* 1 = 0.00285993 loss)
I0122 18:22:52.959996 67000 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 18:22:59.208551 67000 solver.cpp:266] Iteration 31800 (16.0043 iter/s, 6.24832s/100 iter), loss = 0.0037169
I0122 18:22:59.208592 67000 solver.cpp:285]     Train net output #0: loss = 0.00371694 (* 1 = 0.00371694 loss)
I0122 18:22:59.208616 67000 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 18:23:05.456526 67000 solver.cpp:266] Iteration 31900 (16.0059 iter/s, 6.24769s/100 iter), loss = 0.00808809
I0122 18:23:05.456568 67000 solver.cpp:285]     Train net output #0: loss = 0.00808813 (* 1 = 0.00808813 loss)
I0122 18:23:05.456575 67000 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 18:23:11.643218 67000 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 18:23:13.093811 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894667
I0122 18:23:13.093837 67000 solver.cpp:517]     Test net output #1: loss = 0.376945 (* 1 = 0.376945 loss)
I0122 18:23:13.093842 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894667
I0122 18:23:13.093845 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 18:23:13.155508 67000 solver.cpp:266] Iteration 32000 (12.9893 iter/s, 7.69864s/100 iter), loss = 0.00366997
I0122 18:23:13.155526 67000 solver.cpp:285]     Train net output #0: loss = 0.00367001 (* 1 = 0.00367001 loss)
I0122 18:23:13.155532 67000 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 18:23:19.391485 67000 solver.cpp:266] Iteration 32100 (16.0367 iter/s, 6.23571s/100 iter), loss = 0.00840457
I0122 18:23:19.391515 67000 solver.cpp:285]     Train net output #0: loss = 0.00840461 (* 1 = 0.00840461 loss)
I0122 18:23:19.391521 67000 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 18:23:25.672646 67000 solver.cpp:266] Iteration 32200 (15.9213 iter/s, 6.28088s/100 iter), loss = 0.00301446
I0122 18:23:25.672673 67000 solver.cpp:285]     Train net output #0: loss = 0.0030145 (* 1 = 0.0030145 loss)
I0122 18:23:25.672679 67000 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 18:23:31.914119 67000 solver.cpp:266] Iteration 32300 (16.0226 iter/s, 6.2412s/100 iter), loss = 0.0139183
I0122 18:23:31.914147 67000 solver.cpp:285]     Train net output #0: loss = 0.0139183 (* 1 = 0.0139183 loss)
I0122 18:23:31.914155 67000 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 18:23:38.149770 67000 solver.cpp:266] Iteration 32400 (16.0375 iter/s, 6.23538s/100 iter), loss = 0.00483528
I0122 18:23:38.149798 67000 solver.cpp:285]     Train net output #0: loss = 0.00483532 (* 1 = 0.00483532 loss)
I0122 18:23:38.149803 67000 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 18:23:44.390638 67000 solver.cpp:266] Iteration 32500 (16.0241 iter/s, 6.2406s/100 iter), loss = 0.0195638
I0122 18:23:44.390763 67000 solver.cpp:285]     Train net output #0: loss = 0.0195638 (* 1 = 0.0195638 loss)
I0122 18:23:44.390770 67000 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 18:23:50.655251 67000 solver.cpp:266] Iteration 32600 (15.9636 iter/s, 6.26425s/100 iter), loss = 0.00555816
I0122 18:23:50.655282 67000 solver.cpp:285]     Train net output #0: loss = 0.00555819 (* 1 = 0.00555819 loss)
I0122 18:23:50.655287 67000 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 18:23:56.924369 67000 solver.cpp:266] Iteration 32700 (15.9519 iter/s, 6.26884s/100 iter), loss = 0.0108606
I0122 18:23:56.924408 67000 solver.cpp:285]     Train net output #0: loss = 0.0108606 (* 1 = 0.0108606 loss)
I0122 18:23:56.924415 67000 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 18:24:03.176730 67000 solver.cpp:266] Iteration 32800 (15.9947 iter/s, 6.25208s/100 iter), loss = 0.00286552
I0122 18:24:03.176759 67000 solver.cpp:285]     Train net output #0: loss = 0.00286556 (* 1 = 0.00286556 loss)
I0122 18:24:03.176765 67000 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 18:24:09.422870 67000 solver.cpp:266] Iteration 32900 (16.0106 iter/s, 6.24587s/100 iter), loss = 0.00602566
I0122 18:24:09.422899 67000 solver.cpp:285]     Train net output #0: loss = 0.0060257 (* 1 = 0.0060257 loss)
I0122 18:24:09.422920 67000 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 18:24:15.605180 67000 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 18:24:17.073035 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894889
I0122 18:24:17.073060 67000 solver.cpp:517]     Test net output #1: loss = 0.378185 (* 1 = 0.378185 loss)
I0122 18:24:17.073065 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894889
I0122 18:24:17.073068 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 18:24:17.134500 67000 solver.cpp:266] Iteration 33000 (12.968 iter/s, 7.71131s/100 iter), loss = 0.00634811
I0122 18:24:17.134518 67000 solver.cpp:285]     Train net output #0: loss = 0.00634814 (* 1 = 0.00634814 loss)
I0122 18:24:17.134526 67000 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 18:24:23.367635 67000 solver.cpp:266] Iteration 33100 (16.044 iter/s, 6.23287s/100 iter), loss = 0.00340661
I0122 18:24:23.367664 67000 solver.cpp:285]     Train net output #0: loss = 0.00340665 (* 1 = 0.00340665 loss)
I0122 18:24:23.367671 67000 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 18:24:29.614306 67000 solver.cpp:266] Iteration 33200 (16.0092 iter/s, 6.2464s/100 iter), loss = 0.00312082
I0122 18:24:29.614336 67000 solver.cpp:285]     Train net output #0: loss = 0.00312086 (* 1 = 0.00312086 loss)
I0122 18:24:29.614342 67000 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 18:24:35.852056 67000 solver.cpp:266] Iteration 33300 (16.0321 iter/s, 6.23748s/100 iter), loss = 0.00610693
I0122 18:24:35.852084 67000 solver.cpp:285]     Train net output #0: loss = 0.00610696 (* 1 = 0.00610696 loss)
I0122 18:24:35.852090 67000 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 18:24:42.113862 67000 solver.cpp:266] Iteration 33400 (15.9705 iter/s, 6.26153s/100 iter), loss = 0.00303921
I0122 18:24:42.113888 67000 solver.cpp:285]     Train net output #0: loss = 0.00303925 (* 1 = 0.00303925 loss)
I0122 18:24:42.113893 67000 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 18:24:48.382930 67000 solver.cpp:266] Iteration 33500 (15.952 iter/s, 6.2688s/100 iter), loss = 0.00551535
I0122 18:24:48.383013 67000 solver.cpp:285]     Train net output #0: loss = 0.00551539 (* 1 = 0.00551539 loss)
I0122 18:24:48.383019 67000 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 18:24:54.642112 67000 solver.cpp:266] Iteration 33600 (15.9774 iter/s, 6.25886s/100 iter), loss = 0.00467155
I0122 18:24:54.642141 67000 solver.cpp:285]     Train net output #0: loss = 0.00467159 (* 1 = 0.00467159 loss)
I0122 18:24:54.642148 67000 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 18:25:00.909132 67000 solver.cpp:266] Iteration 33700 (15.9572 iter/s, 6.26674s/100 iter), loss = 0.0050693
I0122 18:25:00.909159 67000 solver.cpp:285]     Train net output #0: loss = 0.00506934 (* 1 = 0.00506934 loss)
I0122 18:25:00.909165 67000 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 18:25:07.162175 67000 solver.cpp:266] Iteration 33800 (15.9929 iter/s, 6.25277s/100 iter), loss = 0.00710532
I0122 18:25:07.162204 67000 solver.cpp:285]     Train net output #0: loss = 0.00710536 (* 1 = 0.00710536 loss)
I0122 18:25:07.162210 67000 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 18:25:13.402966 67000 solver.cpp:266] Iteration 33900 (16.0243 iter/s, 6.24052s/100 iter), loss = 0.00364602
I0122 18:25:13.402994 67000 solver.cpp:285]     Train net output #0: loss = 0.00364606 (* 1 = 0.00364606 loss)
I0122 18:25:13.403000 67000 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 18:25:19.589032 67000 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 18:25:21.054600 67000 solver.cpp:517]     Test net output #0: accuracy = 0.895
I0122 18:25:21.054625 67000 solver.cpp:517]     Test net output #1: loss = 0.37855 (* 1 = 0.37855 loss)
I0122 18:25:21.054630 67000 solver.cpp:517]     Test net output #2: top-1 = 0.895
I0122 18:25:21.054633 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 18:25:21.116899 67000 solver.cpp:266] Iteration 34000 (12.9641 iter/s, 7.71361s/100 iter), loss = 0.00281936
I0122 18:25:21.116919 67000 solver.cpp:285]     Train net output #0: loss = 0.0028194 (* 1 = 0.0028194 loss)
I0122 18:25:21.116925 67000 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 18:25:27.359030 67000 solver.cpp:266] Iteration 34100 (16.0208 iter/s, 6.24187s/100 iter), loss = 0.00328375
I0122 18:25:27.359060 67000 solver.cpp:285]     Train net output #0: loss = 0.00328378 (* 1 = 0.00328378 loss)
I0122 18:25:27.359066 67000 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 18:25:33.618357 67000 solver.cpp:266] Iteration 34200 (15.9769 iter/s, 6.25905s/100 iter), loss = 0.0037958
I0122 18:25:33.618386 67000 solver.cpp:285]     Train net output #0: loss = 0.00379584 (* 1 = 0.00379584 loss)
I0122 18:25:33.618391 67000 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 18:25:39.879745 67000 solver.cpp:266] Iteration 34300 (15.9716 iter/s, 6.26112s/100 iter), loss = 0.00636351
I0122 18:25:39.879775 67000 solver.cpp:285]     Train net output #0: loss = 0.00636355 (* 1 = 0.00636355 loss)
I0122 18:25:39.879781 67000 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 18:25:46.130259 67000 solver.cpp:266] Iteration 34400 (15.9994 iter/s, 6.25024s/100 iter), loss = 0.0165463
I0122 18:25:46.130287 67000 solver.cpp:285]     Train net output #0: loss = 0.0165463 (* 1 = 0.0165463 loss)
I0122 18:25:46.130293 67000 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 18:25:52.411782 67000 solver.cpp:266] Iteration 34500 (15.9204 iter/s, 6.28125s/100 iter), loss = 0.004024
I0122 18:25:52.411861 67000 solver.cpp:285]     Train net output #0: loss = 0.00402404 (* 1 = 0.00402404 loss)
I0122 18:25:52.411870 67000 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 18:25:58.658524 67000 solver.cpp:266] Iteration 34600 (16.0091 iter/s, 6.24646s/100 iter), loss = 0.00461464
I0122 18:25:58.658553 67000 solver.cpp:285]     Train net output #0: loss = 0.00461468 (* 1 = 0.00461468 loss)
I0122 18:25:58.658560 67000 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 18:26:04.924491 67000 solver.cpp:266] Iteration 34700 (15.9598 iter/s, 6.26573s/100 iter), loss = 0.00478753
I0122 18:26:04.924521 67000 solver.cpp:285]     Train net output #0: loss = 0.00478757 (* 1 = 0.00478757 loss)
I0122 18:26:04.924527 67000 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 18:26:11.188181 67000 solver.cpp:266] Iteration 34800 (15.9656 iter/s, 6.26345s/100 iter), loss = 0.003716
I0122 18:26:11.188211 67000 solver.cpp:285]     Train net output #0: loss = 0.00371604 (* 1 = 0.00371604 loss)
I0122 18:26:11.188217 67000 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 18:26:17.449517 67000 solver.cpp:266] Iteration 34900 (15.9716 iter/s, 6.2611s/100 iter), loss = 0.0063761
I0122 18:26:17.449544 67000 solver.cpp:285]     Train net output #0: loss = 0.00637614 (* 1 = 0.00637614 loss)
I0122 18:26:17.449550 67000 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 18:26:23.659831 67000 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 18:26:25.114390 67000 solver.cpp:517]     Test net output #0: accuracy = 0.895222
I0122 18:26:25.114416 67000 solver.cpp:517]     Test net output #1: loss = 0.378434 (* 1 = 0.378434 loss)
I0122 18:26:25.114421 67000 solver.cpp:517]     Test net output #2: top-1 = 0.895222
I0122 18:26:25.114424 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 18:26:25.175694 67000 solver.cpp:266] Iteration 35000 (12.9435 iter/s, 7.7259s/100 iter), loss = 0.00465245
I0122 18:26:25.175725 67000 solver.cpp:285]     Train net output #0: loss = 0.0046525 (* 1 = 0.0046525 loss)
I0122 18:26:25.175734 67000 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 18:26:31.430953 67000 solver.cpp:266] Iteration 35100 (15.9871 iter/s, 6.25503s/100 iter), loss = 0.00282304
I0122 18:26:31.430980 67000 solver.cpp:285]     Train net output #0: loss = 0.00282308 (* 1 = 0.00282308 loss)
I0122 18:26:31.430986 67000 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 18:26:37.704210 67000 solver.cpp:266] Iteration 35200 (15.9413 iter/s, 6.27302s/100 iter), loss = 0.00913407
I0122 18:26:37.704238 67000 solver.cpp:285]     Train net output #0: loss = 0.00913411 (* 1 = 0.00913411 loss)
I0122 18:26:37.704244 67000 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 18:26:43.941587 67000 solver.cpp:266] Iteration 35300 (16.033 iter/s, 6.23714s/100 iter), loss = 0.00349191
I0122 18:26:43.941617 67000 solver.cpp:285]     Train net output #0: loss = 0.00349195 (* 1 = 0.00349195 loss)
I0122 18:26:43.941622 67000 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 18:26:50.203797 67000 solver.cpp:266] Iteration 35400 (15.9694 iter/s, 6.26197s/100 iter), loss = 0.00766782
I0122 18:26:50.203825 67000 solver.cpp:285]     Train net output #0: loss = 0.00766786 (* 1 = 0.00766786 loss)
I0122 18:26:50.203832 67000 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 18:26:56.451082 67000 solver.cpp:266] Iteration 35500 (16.0076 iter/s, 6.24705s/100 iter), loss = 0.00880776
I0122 18:26:56.451153 67000 solver.cpp:285]     Train net output #0: loss = 0.0088078 (* 1 = 0.0088078 loss)
I0122 18:26:56.451161 67000 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 18:27:02.707442 67000 solver.cpp:266] Iteration 35600 (15.9845 iter/s, 6.25608s/100 iter), loss = 0.002356
I0122 18:27:02.707481 67000 solver.cpp:285]     Train net output #0: loss = 0.00235604 (* 1 = 0.00235604 loss)
I0122 18:27:02.707487 67000 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 18:27:08.964042 67000 solver.cpp:266] Iteration 35700 (15.9838 iter/s, 6.25635s/100 iter), loss = 0.00682706
I0122 18:27:08.964084 67000 solver.cpp:285]     Train net output #0: loss = 0.0068271 (* 1 = 0.0068271 loss)
I0122 18:27:08.964090 67000 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 18:27:15.243646 67000 solver.cpp:266] Iteration 35800 (15.9252 iter/s, 6.27935s/100 iter), loss = 0.00362037
I0122 18:27:15.243675 67000 solver.cpp:285]     Train net output #0: loss = 0.00362041 (* 1 = 0.00362041 loss)
I0122 18:27:15.243681 67000 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 18:27:21.488452 67000 solver.cpp:266] Iteration 35900 (16.0139 iter/s, 6.24457s/100 iter), loss = 0.0040697
I0122 18:27:21.488481 67000 solver.cpp:285]     Train net output #0: loss = 0.00406974 (* 1 = 0.00406974 loss)
I0122 18:27:21.488487 67000 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 18:27:27.676550 67000 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 18:27:29.133090 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894667
I0122 18:27:29.133116 67000 solver.cpp:517]     Test net output #1: loss = 0.378431 (* 1 = 0.378431 loss)
I0122 18:27:29.133119 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894667
I0122 18:27:29.133124 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:27:29.194530 67000 solver.cpp:266] Iteration 36000 (12.9773 iter/s, 7.70579s/100 iter), loss = 0.00528045
I0122 18:27:29.194550 67000 solver.cpp:285]     Train net output #0: loss = 0.00528049 (* 1 = 0.00528049 loss)
I0122 18:27:29.194557 67000 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 18:27:35.450369 67000 solver.cpp:266] Iteration 36100 (15.9857 iter/s, 6.25561s/100 iter), loss = 0.003542
I0122 18:27:35.450398 67000 solver.cpp:285]     Train net output #0: loss = 0.00354204 (* 1 = 0.00354204 loss)
I0122 18:27:35.450404 67000 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 18:27:41.705844 67000 solver.cpp:266] Iteration 36200 (15.9866 iter/s, 6.25523s/100 iter), loss = 0.0133718
I0122 18:27:41.705885 67000 solver.cpp:285]     Train net output #0: loss = 0.0133718 (* 1 = 0.0133718 loss)
I0122 18:27:41.705891 67000 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 18:27:47.969739 67000 solver.cpp:266] Iteration 36300 (15.9652 iter/s, 6.26364s/100 iter), loss = 0.0107063
I0122 18:27:47.969768 67000 solver.cpp:285]     Train net output #0: loss = 0.0107064 (* 1 = 0.0107064 loss)
I0122 18:27:47.969774 67000 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 18:27:54.232101 67000 solver.cpp:266] Iteration 36400 (15.969 iter/s, 6.26212s/100 iter), loss = 0.00528946
I0122 18:27:54.232129 67000 solver.cpp:285]     Train net output #0: loss = 0.0052895 (* 1 = 0.0052895 loss)
I0122 18:27:54.232136 67000 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 18:28:00.499593 67000 solver.cpp:266] Iteration 36500 (15.956 iter/s, 6.26725s/100 iter), loss = 0.00530135
I0122 18:28:00.499657 67000 solver.cpp:285]     Train net output #0: loss = 0.00530139 (* 1 = 0.00530139 loss)
I0122 18:28:00.499663 67000 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 18:28:06.755461 67000 solver.cpp:266] Iteration 36600 (15.9857 iter/s, 6.25559s/100 iter), loss = 0.00550337
I0122 18:28:06.755492 67000 solver.cpp:285]     Train net output #0: loss = 0.00550341 (* 1 = 0.00550341 loss)
I0122 18:28:06.755497 67000 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 18:28:12.997931 67000 solver.cpp:266] Iteration 36700 (16.0199 iter/s, 6.24223s/100 iter), loss = 0.00732186
I0122 18:28:12.997959 67000 solver.cpp:285]     Train net output #0: loss = 0.00732189 (* 1 = 0.00732189 loss)
I0122 18:28:12.997967 67000 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 18:28:19.256371 67000 solver.cpp:266] Iteration 36800 (15.979 iter/s, 6.2582s/100 iter), loss = 0.00781282
I0122 18:28:19.256412 67000 solver.cpp:285]     Train net output #0: loss = 0.00781286 (* 1 = 0.00781286 loss)
I0122 18:28:19.256418 67000 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 18:28:25.507580 67000 solver.cpp:266] Iteration 36900 (15.9976 iter/s, 6.25095s/100 iter), loss = 0.00488373
I0122 18:28:25.507608 67000 solver.cpp:285]     Train net output #0: loss = 0.00488377 (* 1 = 0.00488377 loss)
I0122 18:28:25.507614 67000 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 18:28:31.722558 67000 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 18:28:33.177850 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894111
I0122 18:28:33.177872 67000 solver.cpp:517]     Test net output #1: loss = 0.378398 (* 1 = 0.378398 loss)
I0122 18:28:33.177877 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894111
I0122 18:28:33.177896 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:28:33.239045 67000 solver.cpp:266] Iteration 37000 (12.9346 iter/s, 7.73117s/100 iter), loss = 0.00535438
I0122 18:28:33.239066 67000 solver.cpp:285]     Train net output #0: loss = 0.00535442 (* 1 = 0.00535442 loss)
I0122 18:28:33.239073 67000 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 18:28:39.494099 67000 solver.cpp:266] Iteration 37100 (15.9877 iter/s, 6.25482s/100 iter), loss = 0.0049856
I0122 18:28:39.494128 67000 solver.cpp:285]     Train net output #0: loss = 0.00498563 (* 1 = 0.00498563 loss)
I0122 18:28:39.494134 67000 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 18:28:45.744541 67000 solver.cpp:266] Iteration 37200 (15.9995 iter/s, 6.2502s/100 iter), loss = 0.00389067
I0122 18:28:45.744568 67000 solver.cpp:285]     Train net output #0: loss = 0.0038907 (* 1 = 0.0038907 loss)
I0122 18:28:45.744575 67000 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 18:28:51.998812 67000 solver.cpp:266] Iteration 37300 (15.9897 iter/s, 6.25403s/100 iter), loss = 0.00485948
I0122 18:28:51.998841 67000 solver.cpp:285]     Train net output #0: loss = 0.00485951 (* 1 = 0.00485951 loss)
I0122 18:28:51.998847 67000 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 18:28:58.242435 67000 solver.cpp:266] Iteration 37400 (16.017 iter/s, 6.24338s/100 iter), loss = 0.00367746
I0122 18:28:58.242465 67000 solver.cpp:285]     Train net output #0: loss = 0.0036775 (* 1 = 0.0036775 loss)
I0122 18:28:58.242470 67000 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 18:29:04.508466 67000 solver.cpp:266] Iteration 37500 (15.9597 iter/s, 6.26579s/100 iter), loss = 0.00619158
I0122 18:29:04.508594 67000 solver.cpp:285]     Train net output #0: loss = 0.00619161 (* 1 = 0.00619161 loss)
I0122 18:29:04.508601 67000 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 18:29:10.748090 67000 solver.cpp:266] Iteration 37600 (16.0275 iter/s, 6.23928s/100 iter), loss = 0.00354101
I0122 18:29:10.748118 67000 solver.cpp:285]     Train net output #0: loss = 0.00354105 (* 1 = 0.00354105 loss)
I0122 18:29:10.748126 67000 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 18:29:17.024003 67000 solver.cpp:266] Iteration 37700 (15.9346 iter/s, 6.27567s/100 iter), loss = 0.00714295
I0122 18:29:17.024029 67000 solver.cpp:285]     Train net output #0: loss = 0.00714298 (* 1 = 0.00714298 loss)
I0122 18:29:17.024034 67000 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 18:29:23.263926 67000 solver.cpp:266] Iteration 37800 (16.0265 iter/s, 6.23968s/100 iter), loss = 0.00424224
I0122 18:29:23.263953 67000 solver.cpp:285]     Train net output #0: loss = 0.00424228 (* 1 = 0.00424228 loss)
I0122 18:29:23.263959 67000 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 18:29:29.516649 67000 solver.cpp:266] Iteration 37900 (15.9937 iter/s, 6.25248s/100 iter), loss = 0.00428484
I0122 18:29:29.516676 67000 solver.cpp:285]     Train net output #0: loss = 0.00428488 (* 1 = 0.00428488 loss)
I0122 18:29:29.516682 67000 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 18:29:35.712311 67000 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 18:29:37.174679 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894667
I0122 18:29:37.174705 67000 solver.cpp:517]     Test net output #1: loss = 0.378309 (* 1 = 0.378309 loss)
I0122 18:29:37.174710 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894667
I0122 18:29:37.174729 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:29:37.236147 67000 solver.cpp:266] Iteration 38000 (12.9547 iter/s, 7.71921s/100 iter), loss = 0.00563078
I0122 18:29:37.236176 67000 solver.cpp:285]     Train net output #0: loss = 0.00563082 (* 1 = 0.00563082 loss)
I0122 18:29:37.236199 67000 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 18:29:43.479441 67000 solver.cpp:266] Iteration 38100 (16.0178 iter/s, 6.24306s/100 iter), loss = 0.00733198
I0122 18:29:43.479470 67000 solver.cpp:285]     Train net output #0: loss = 0.00733201 (* 1 = 0.00733201 loss)
I0122 18:29:43.479476 67000 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 18:29:49.742908 67000 solver.cpp:266] Iteration 38200 (15.9662 iter/s, 6.26322s/100 iter), loss = 0.0054843
I0122 18:29:49.742936 67000 solver.cpp:285]     Train net output #0: loss = 0.00548434 (* 1 = 0.00548434 loss)
I0122 18:29:49.742941 67000 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 18:29:56.020717 67000 solver.cpp:266] Iteration 38300 (15.9298 iter/s, 6.27756s/100 iter), loss = 0.00638585
I0122 18:29:56.020747 67000 solver.cpp:285]     Train net output #0: loss = 0.00638589 (* 1 = 0.00638589 loss)
I0122 18:29:56.020753 67000 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 18:30:02.275761 67000 solver.cpp:266] Iteration 38400 (15.9877 iter/s, 6.2548s/100 iter), loss = 0.0108502
I0122 18:30:02.275790 67000 solver.cpp:285]     Train net output #0: loss = 0.0108502 (* 1 = 0.0108502 loss)
I0122 18:30:02.275812 67000 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 18:30:08.535961 67000 solver.cpp:266] Iteration 38500 (15.9746 iter/s, 6.25995s/100 iter), loss = 0.00600033
I0122 18:30:08.536067 67000 solver.cpp:285]     Train net output #0: loss = 0.00600036 (* 1 = 0.00600036 loss)
I0122 18:30:08.536073 67000 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 18:30:14.802906 67000 solver.cpp:266] Iteration 38600 (15.9576 iter/s, 6.26662s/100 iter), loss = 0.00838415
I0122 18:30:14.802934 67000 solver.cpp:285]     Train net output #0: loss = 0.00838419 (* 1 = 0.00838419 loss)
I0122 18:30:14.802940 67000 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 18:30:21.069121 67000 solver.cpp:266] Iteration 38700 (15.9592 iter/s, 6.26597s/100 iter), loss = 0.00514968
I0122 18:30:21.069149 67000 solver.cpp:285]     Train net output #0: loss = 0.00514972 (* 1 = 0.00514972 loss)
I0122 18:30:21.069154 67000 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 18:30:27.316071 67000 solver.cpp:266] Iteration 38800 (16.0085 iter/s, 6.2467s/100 iter), loss = 0.0110617
I0122 18:30:27.316100 67000 solver.cpp:285]     Train net output #0: loss = 0.0110617 (* 1 = 0.0110617 loss)
I0122 18:30:27.316107 67000 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 18:30:33.573786 67000 solver.cpp:266] Iteration 38900 (15.9809 iter/s, 6.25746s/100 iter), loss = 0.00451806
I0122 18:30:33.573817 67000 solver.cpp:285]     Train net output #0: loss = 0.00451809 (* 1 = 0.00451809 loss)
I0122 18:30:33.573823 67000 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 18:30:39.761173 67000 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 18:30:41.218538 67000 solver.cpp:517]     Test net output #0: accuracy = 0.894667
I0122 18:30:41.218561 67000 solver.cpp:517]     Test net output #1: loss = 0.378437 (* 1 = 0.378437 loss)
I0122 18:30:41.218565 67000 solver.cpp:517]     Test net output #2: top-1 = 0.894667
I0122 18:30:41.218569 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:30:41.281229 67000 solver.cpp:266] Iteration 39000 (12.975 iter/s, 7.70715s/100 iter), loss = 0.00348811
I0122 18:30:41.281249 67000 solver.cpp:285]     Train net output #0: loss = 0.00348815 (* 1 = 0.00348815 loss)
I0122 18:30:41.281256 67000 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 18:30:47.529371 67000 solver.cpp:266] Iteration 39100 (16.0054 iter/s, 6.2479s/100 iter), loss = 0.00471273
I0122 18:30:47.529397 67000 solver.cpp:285]     Train net output #0: loss = 0.00471277 (* 1 = 0.00471277 loss)
I0122 18:30:47.529403 67000 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 18:30:53.785001 67000 solver.cpp:266] Iteration 39200 (15.9862 iter/s, 6.25538s/100 iter), loss = 0.00585994
I0122 18:30:53.785029 67000 solver.cpp:285]     Train net output #0: loss = 0.00585997 (* 1 = 0.00585997 loss)
I0122 18:30:53.785037 67000 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 18:31:00.039317 67000 solver.cpp:266] Iteration 39300 (15.9896 iter/s, 6.25407s/100 iter), loss = 0.00408127
I0122 18:31:00.039345 67000 solver.cpp:285]     Train net output #0: loss = 0.00408131 (* 1 = 0.00408131 loss)
I0122 18:31:00.039351 67000 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 18:31:06.304453 67000 solver.cpp:266] Iteration 39400 (15.962 iter/s, 6.26489s/100 iter), loss = 0.00380395
I0122 18:31:06.304486 67000 solver.cpp:285]     Train net output #0: loss = 0.00380398 (* 1 = 0.00380398 loss)
I0122 18:31:06.304492 67000 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 18:31:12.574748 67000 solver.cpp:266] Iteration 39500 (15.9489 iter/s, 6.27004s/100 iter), loss = 0.00349731
I0122 18:31:12.574883 67000 solver.cpp:285]     Train net output #0: loss = 0.00349734 (* 1 = 0.00349734 loss)
I0122 18:31:12.574892 67000 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 18:31:18.831045 67000 solver.cpp:266] Iteration 39600 (15.9848 iter/s, 6.25594s/100 iter), loss = 0.00753639
I0122 18:31:18.831073 67000 solver.cpp:285]     Train net output #0: loss = 0.00753642 (* 1 = 0.00753642 loss)
I0122 18:31:18.831079 67000 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 18:31:25.075928 67000 solver.cpp:266] Iteration 39700 (16.0138 iter/s, 6.24463s/100 iter), loss = 0.00423478
I0122 18:31:25.075968 67000 solver.cpp:285]     Train net output #0: loss = 0.00423482 (* 1 = 0.00423482 loss)
I0122 18:31:25.075973 67000 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 18:31:31.336172 67000 solver.cpp:266] Iteration 39800 (15.9745 iter/s, 6.25998s/100 iter), loss = 0.00517149
I0122 18:31:31.336200 67000 solver.cpp:285]     Train net output #0: loss = 0.00517152 (* 1 = 0.00517152 loss)
I0122 18:31:31.336206 67000 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 18:31:37.595245 67000 solver.cpp:266] Iteration 39900 (15.9774 iter/s, 6.25882s/100 iter), loss = 0.00284946
I0122 18:31:37.595273 67000 solver.cpp:285]     Train net output #0: loss = 0.0028495 (* 1 = 0.0028495 loss)
I0122 18:31:37.595279 67000 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 18:31:43.773738 67000 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/snapshots/_iter_40000.caffemodel
I0122 18:31:43.819445 67000 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.1/snapshots/_iter_40000.solverstate
I0122 18:31:43.849530 67000 solver.cpp:378] Iteration 40000, loss = 0.00180623
I0122 18:31:43.849552 67000 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 18:31:45.302419 67000 solver.cpp:517]     Test net output #0: accuracy = 0.895222
I0122 18:31:45.302443 67000 solver.cpp:517]     Test net output #1: loss = 0.378925 (* 1 = 0.378925 loss)
I0122 18:31:45.302448 67000 solver.cpp:517]     Test net output #2: top-1 = 0.895222
I0122 18:31:45.302451 67000 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:31:45.302455 67000 solver.cpp:386] Optimization Done (15.6617 iter/s).
I0122 18:31:45.302459 67000 caffe_interface.cpp:530] Optimization Done.

# compression: second run
$PRUNE_ROOT/deephi_compress compress -config ${WORK_DIR}/config2.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_compress2_miniGoogleNet.txt
I0122 18:31:45.907310 68174 pruning_runner.cpp:190] Sens info found, use it.
I0122 18:31:45.942817 68174 pruning_runner.cpp:217] Start compressing, please wait...
I0122 18:31:47.368538 68174 pruning_runner.cpp:264] Compression complete 0.0250011%
I0122 18:31:48.017177 68174 pruning_runner.cpp:264] Compression complete 0.0499896%
I0122 18:31:48.675257 68174 pruning_runner.cpp:264] Compression complete 50.025%
I0122 18:31:49.323060 68174 pruning_runner.cpp:264] Compression complete 66.6889%
I0122 18:31:49.950793 68174 pruning_runner.cpp:264] Compression complete 95.8361%
I0122 18:31:50.584632 68174 pruning_runner.cpp:264] Compression complete 99.4598%
I0122 18:31:51.222929 68174 pruning_runner.cpp:264] Compression complete 99.865%
I0122 18:31:51.864497 68174 pruning_runner.cpp:264] Compression complete 99.9324%
I0122 18:31:52.507607 68174 pruning_runner.cpp:264] Compression complete 99.9662%
I0122 18:31:53.150473 68174 caffe_interface.cpp:66] Use GPU with device ID 0
I0122 18:31:53.150768 68174 caffe_interface.cpp:70] GPU device name: Quadro P6000
I0122 18:31:53.151670 68174 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 18:31:53.152261 68174 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 18:31:53.152590 68174 layer_factory.hpp:77] Creating layer data
I0122 18:31:53.152629 68174 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 18:31:53.152998 68174 net.cpp:94] Creating Layer data
I0122 18:31:53.153005 68174 net.cpp:409] data -> data
I0122 18:31:53.153013 68174 net.cpp:409] data -> label
I0122 18:31:53.154294 69114 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 18:31:53.154327 69114 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 18:31:53.154389 68174 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 18:31:53.154481 68174 data_layer.cpp:83] output data size: 50,3,32,32
I0122 18:31:53.157133 68174 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 18:31:53.157171 68174 net.cpp:144] Setting up data
I0122 18:31:53.157176 68174 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 18:31:53.157189 68174 net.cpp:151] Top shape: 50 (50)
I0122 18:31:53.157192 68174 net.cpp:159] Memory required for data: 614600
I0122 18:31:53.157196 68174 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 18:31:53.157202 68174 net.cpp:94] Creating Layer label_data_1_split
I0122 18:31:53.157205 68174 net.cpp:435] label_data_1_split <- label
I0122 18:31:53.157210 68174 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 18:31:53.157217 68174 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 18:31:53.157223 68174 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 18:31:53.157233 68174 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 18:31:53.157311 68174 net.cpp:144] Setting up label_data_1_split
I0122 18:31:53.157316 68174 net.cpp:151] Top shape: 50 (50)
I0122 18:31:53.157320 68174 net.cpp:151] Top shape: 50 (50)
I0122 18:31:53.157323 68174 net.cpp:151] Top shape: 50 (50)
I0122 18:31:53.157327 68174 net.cpp:151] Top shape: 50 (50)
I0122 18:31:53.157330 68174 net.cpp:159] Memory required for data: 615400
I0122 18:31:53.157332 68174 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 18:31:53.157339 68174 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 18:31:53.157346 68174 net.cpp:435] conv1/3x3_s1 <- data
I0122 18:31:53.157351 68174 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 18:31:53.158826 68174 net.cpp:144] Setting up conv1/3x3_s1
I0122 18:31:53.158838 68174 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:53.158840 68174 net.cpp:159] Memory required for data: 20276200
I0122 18:31:53.158850 68174 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 18:31:53.158856 68174 net.cpp:94] Creating Layer conv1/bn1
I0122 18:31:53.158859 68174 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 18:31:53.158865 68174 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 18:31:53.159538 68174 net.cpp:144] Setting up conv1/bn1
I0122 18:31:53.159545 68174 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:53.159549 68174 net.cpp:159] Memory required for data: 39937000
I0122 18:31:53.159560 68174 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 18:31:53.159569 68174 net.cpp:94] Creating Layer conv1/relu1
I0122 18:31:53.159571 68174 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 18:31:53.159575 68174 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 18:31:53.159582 68174 net.cpp:144] Setting up conv1/relu1
I0122 18:31:53.159586 68174 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:53.159590 68174 net.cpp:159] Memory required for data: 59597800
I0122 18:31:53.159591 68174 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:53.159596 68174 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:53.159600 68174 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 18:31:53.159603 68174 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 18:31:53.159610 68174 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 18:31:53.159672 68174 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:53.159678 68174 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:53.159682 68174 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:53.159684 68174 net.cpp:159] Memory required for data: 98919400
I0122 18:31:53.159687 68174 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 18:31:53.159694 68174 net.cpp:94] Creating Layer inception_2a/1x1
I0122 18:31:53.159698 68174 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 18:31:53.159703 68174 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 18:31:53.160009 68174 net.cpp:144] Setting up inception_2a/1x1
I0122 18:31:53.160017 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.160018 68174 net.cpp:159] Memory required for data: 105473000
I0122 18:31:53.160025 68174 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 18:31:53.160032 68174 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 18:31:53.160046 68174 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 18:31:53.160053 68174 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 18:31:53.160810 68174 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 18:31:53.160817 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.160820 68174 net.cpp:159] Memory required for data: 112026600
I0122 18:31:53.160827 68174 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 18:31:53.160831 68174 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 18:31:53.160835 68174 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 18:31:53.160840 68174 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 18:31:53.160845 68174 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 18:31:53.160848 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.160868 68174 net.cpp:159] Memory required for data: 118580200
I0122 18:31:53.160871 68174 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 18:31:53.160878 68174 net.cpp:94] Creating Layer inception_2a/3x3
I0122 18:31:53.160881 68174 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 18:31:53.160887 68174 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 18:31:53.161911 68174 net.cpp:144] Setting up inception_2a/3x3
I0122 18:31:53.161921 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.161924 68174 net.cpp:159] Memory required for data: 125133800
I0122 18:31:53.161931 68174 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 18:31:53.161938 68174 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 18:31:53.161943 68174 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 18:31:53.161949 68174 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 18:31:53.162585 68174 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 18:31:53.162591 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.162595 68174 net.cpp:159] Memory required for data: 131687400
I0122 18:31:53.162606 68174 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 18:31:53.162611 68174 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 18:31:53.162614 68174 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 18:31:53.162619 68174 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 18:31:53.162626 68174 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 18:31:53.162632 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.162636 68174 net.cpp:159] Memory required for data: 138241000
I0122 18:31:53.162637 68174 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 18:31:53.162642 68174 net.cpp:94] Creating Layer inception_2a/output
I0122 18:31:53.162645 68174 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 18:31:53.162648 68174 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 18:31:53.162654 68174 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 18:31:53.162674 68174 net.cpp:144] Setting up inception_2a/output
I0122 18:31:53.162680 68174 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 18:31:53.162683 68174 net.cpp:159] Memory required for data: 151348200
I0122 18:31:53.162685 68174 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 18:31:53.162689 68174 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 18:31:53.162693 68174 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 18:31:53.162698 68174 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 18:31:53.162703 68174 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 18:31:53.162770 68174 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 18:31:53.162775 68174 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 18:31:53.162789 68174 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 18:31:53.162791 68174 net.cpp:159] Memory required for data: 177562600
I0122 18:31:53.162794 68174 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 18:31:53.162802 68174 net.cpp:94] Creating Layer inception_3a/1x1
I0122 18:31:53.162807 68174 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 18:31:53.162813 68174 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 18:31:53.163028 68174 net.cpp:144] Setting up inception_3a/1x1
I0122 18:31:53.163034 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.163038 68174 net.cpp:159] Memory required for data: 184116200
I0122 18:31:53.163043 68174 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 18:31:53.163048 68174 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 18:31:53.163064 68174 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 18:31:53.163069 68174 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 18:31:53.163718 68174 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 18:31:53.163724 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.163728 68174 net.cpp:159] Memory required for data: 190669800
I0122 18:31:53.163735 68174 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 18:31:53.163741 68174 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 18:31:53.163744 68174 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 18:31:53.163749 68174 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 18:31:53.163756 68174 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 18:31:53.163760 68174 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:53.163763 68174 net.cpp:159] Memory required for data: 197223400
I0122 18:31:53.163765 68174 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 18:31:53.163774 68174 net.cpp:94] Creating Layer inception_3a/3x3
I0122 18:31:53.163777 68174 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 18:31:53.163784 68174 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 18:31:53.164160 68174 net.cpp:144] Setting up inception_3a/3x3
I0122 18:31:53.164167 68174 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 18:31:53.164170 68174 net.cpp:159] Memory required for data: 207053800
I0122 18:31:53.164175 68174 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 18:31:53.164182 68174 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 18:31:53.164186 68174 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 18:31:53.164191 68174 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 18:31:53.164824 68174 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 18:31:53.164830 68174 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 18:31:53.164834 68174 net.cpp:159] Memory required for data: 216884200
I0122 18:31:53.164844 68174 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 18:31:53.164850 68174 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 18:31:53.164855 68174 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 18:31:53.164858 68174 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 18:31:53.164865 68174 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 18:31:53.164867 68174 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 18:31:53.164871 68174 net.cpp:159] Memory required for data: 226714600
I0122 18:31:53.164873 68174 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 18:31:53.164877 68174 net.cpp:94] Creating Layer inception_3a/output
I0122 18:31:53.164880 68174 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 18:31:53.164885 68174 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 18:31:53.164891 68174 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 18:31:53.164911 68174 net.cpp:144] Setting up inception_3a/output
I0122 18:31:53.164916 68174 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 18:31:53.164928 68174 net.cpp:159] Memory required for data: 243098600
I0122 18:31:53.164930 68174 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 18:31:53.164935 68174 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 18:31:53.164938 68174 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 18:31:53.164943 68174 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 18:31:53.164950 68174 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 18:31:53.165009 68174 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 18:31:53.165014 68174 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 18:31:53.165017 68174 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 18:31:53.165020 68174 net.cpp:159] Memory required for data: 275866600
I0122 18:31:53.165024 68174 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 18:31:53.165031 68174 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 18:31:53.165037 68174 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 18:31:53.165043 68174 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 18:31:53.165565 68174 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 18:31:53.165572 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.165576 68174 net.cpp:159] Memory required for data: 279962600
I0122 18:31:53.165581 68174 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 18:31:53.165588 68174 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 18:31:53.165591 68174 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 18:31:53.165596 68174 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 18:31:53.166326 68174 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 18:31:53.166333 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.166335 68174 net.cpp:159] Memory required for data: 284058600
I0122 18:31:53.166344 68174 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 18:31:53.166349 68174 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 18:31:53.166352 68174 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 18:31:53.166357 68174 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 18:31:53.166364 68174 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 18:31:53.166368 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.166371 68174 net.cpp:159] Memory required for data: 288154600
I0122 18:31:53.166374 68174 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 18:31:53.166380 68174 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 18:31:53.166384 68174 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 18:31:53.166390 68174 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 18:31:53.166424 68174 net.cpp:144] Setting up downsample_4/pool_s2
I0122 18:31:53.166429 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.166432 68174 net.cpp:159] Memory required for data: 292250600
I0122 18:31:53.166435 68174 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 18:31:53.166438 68174 net.cpp:94] Creating Layer downsample_4/output
I0122 18:31:53.166442 68174 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 18:31:53.166445 68174 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 18:31:53.166450 68174 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 18:31:53.166505 68174 net.cpp:144] Setting up downsample_4/output
I0122 18:31:53.166512 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.166513 68174 net.cpp:159] Memory required for data: 300442600
I0122 18:31:53.166517 68174 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 18:31:53.166534 68174 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 18:31:53.166538 68174 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 18:31:53.166543 68174 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 18:31:53.166548 68174 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 18:31:53.166574 68174 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 18:31:53.166580 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.166584 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.166587 68174 net.cpp:159] Memory required for data: 316826600
I0122 18:31:53.166590 68174 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 18:31:53.166597 68174 net.cpp:94] Creating Layer inception_5a/1x1
I0122 18:31:53.166607 68174 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 18:31:53.166612 68174 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 18:31:53.166924 68174 net.cpp:144] Setting up inception_5a/1x1
I0122 18:31:53.166932 68174 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 18:31:53.166935 68174 net.cpp:159] Memory required for data: 322561000
I0122 18:31:53.166941 68174 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 18:31:53.166947 68174 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 18:31:53.166951 68174 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 18:31:53.166956 68174 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 18:31:53.167645 68174 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 18:31:53.167651 68174 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 18:31:53.167655 68174 net.cpp:159] Memory required for data: 328295400
I0122 18:31:53.167662 68174 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 18:31:53.167667 68174 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 18:31:53.167670 68174 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 18:31:53.167675 68174 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 18:31:53.167681 68174 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 18:31:53.167685 68174 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 18:31:53.167688 68174 net.cpp:159] Memory required for data: 334029800
I0122 18:31:53.167691 68174 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 18:31:53.167698 68174 net.cpp:94] Creating Layer inception_5a/3x3
I0122 18:31:53.167701 68174 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 18:31:53.167707 68174 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 18:31:53.168323 68174 net.cpp:144] Setting up inception_5a/3x3
I0122 18:31:53.168330 68174 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:53.168334 68174 net.cpp:159] Memory required for data: 336487400
I0122 18:31:53.168339 68174 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 18:31:53.168346 68174 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 18:31:53.168350 68174 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 18:31:53.168355 68174 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 18:31:53.169034 68174 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 18:31:53.169040 68174 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:53.169044 68174 net.cpp:159] Memory required for data: 338945000
I0122 18:31:53.169051 68174 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 18:31:53.169055 68174 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 18:31:53.169059 68174 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 18:31:53.169064 68174 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 18:31:53.169070 68174 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 18:31:53.169083 68174 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:53.169087 68174 net.cpp:159] Memory required for data: 341402600
I0122 18:31:53.169090 68174 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 18:31:53.169095 68174 net.cpp:94] Creating Layer inception_5a/output
I0122 18:31:53.169097 68174 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 18:31:53.169102 68174 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 18:31:53.169107 68174 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 18:31:53.169127 68174 net.cpp:144] Setting up inception_5a/output
I0122 18:31:53.169133 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.169137 68174 net.cpp:159] Memory required for data: 349594600
I0122 18:31:53.169139 68174 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 18:31:53.169143 68174 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 18:31:53.169149 68174 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 18:31:53.169154 68174 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 18:31:53.169160 68174 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 18:31:53.169211 68174 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 18:31:53.169217 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.169221 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.169224 68174 net.cpp:159] Memory required for data: 365978600
I0122 18:31:53.169227 68174 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 18:31:53.169234 68174 net.cpp:94] Creating Layer inception_6a/1x1
I0122 18:31:53.169239 68174 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 18:31:53.169245 68174 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 18:31:53.170208 68174 net.cpp:144] Setting up inception_6a/1x1
I0122 18:31:53.170219 68174 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:53.170222 68174 net.cpp:159] Memory required for data: 370893800
I0122 18:31:53.170228 68174 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 18:31:53.170235 68174 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 18:31:53.170238 68174 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 18:31:53.170245 68174 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 18:31:53.170857 68174 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 18:31:53.170864 68174 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:53.170866 68174 net.cpp:159] Memory required for data: 375809000
I0122 18:31:53.170876 68174 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 18:31:53.170882 68174 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 18:31:53.170886 68174 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 18:31:53.170889 68174 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 18:31:53.170897 68174 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 18:31:53.170899 68174 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:53.170902 68174 net.cpp:159] Memory required for data: 380724200
I0122 18:31:53.170904 68174 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 18:31:53.170913 68174 net.cpp:94] Creating Layer inception_6a/3x3
I0122 18:31:53.170917 68174 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 18:31:53.170934 68174 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 18:31:53.172222 68174 net.cpp:144] Setting up inception_6a/3x3
I0122 18:31:53.172233 68174 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 18:31:53.172236 68174 net.cpp:159] Memory required for data: 384001000
I0122 18:31:53.172246 68174 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 18:31:53.172255 68174 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 18:31:53.172269 68174 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 18:31:53.172276 68174 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 18:31:53.172906 68174 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 18:31:53.172914 68174 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 18:31:53.172916 68174 net.cpp:159] Memory required for data: 387277800
I0122 18:31:53.172924 68174 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 18:31:53.172930 68174 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 18:31:53.172932 68174 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 18:31:53.172937 68174 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 18:31:53.172943 68174 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 18:31:53.172947 68174 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 18:31:53.172950 68174 net.cpp:159] Memory required for data: 390554600
I0122 18:31:53.172953 68174 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 18:31:53.172957 68174 net.cpp:94] Creating Layer inception_6a/output
I0122 18:31:53.172960 68174 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 18:31:53.172964 68174 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 18:31:53.172969 68174 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 18:31:53.172986 68174 net.cpp:144] Setting up inception_6a/output
I0122 18:31:53.172991 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.172994 68174 net.cpp:159] Memory required for data: 398746600
I0122 18:31:53.172997 68174 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 18:31:53.173002 68174 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 18:31:53.173005 68174 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 18:31:53.173009 68174 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 18:31:53.173017 68174 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 18:31:53.173045 68174 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 18:31:53.173050 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.173054 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.173058 68174 net.cpp:159] Memory required for data: 415130600
I0122 18:31:53.173060 68174 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 18:31:53.173068 68174 net.cpp:94] Creating Layer inception_7a/1x1
I0122 18:31:53.173074 68174 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 18:31:53.173079 68174 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 18:31:53.173360 68174 net.cpp:144] Setting up inception_7a/1x1
I0122 18:31:53.173367 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.173369 68174 net.cpp:159] Memory required for data: 419226600
I0122 18:31:53.173374 68174 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 18:31:53.173380 68174 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 18:31:53.173383 68174 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 18:31:53.173388 68174 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 18:31:53.174031 68174 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 18:31:53.174039 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.174041 68174 net.cpp:159] Memory required for data: 423322600
I0122 18:31:53.174049 68174 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 18:31:53.174055 68174 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 18:31:53.174058 68174 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 18:31:53.174062 68174 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 18:31:53.174069 68174 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 18:31:53.174083 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.174087 68174 net.cpp:159] Memory required for data: 427418600
I0122 18:31:53.174088 68174 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 18:31:53.174096 68174 net.cpp:94] Creating Layer inception_7a/3x3
I0122 18:31:53.174100 68174 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 18:31:53.174105 68174 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 18:31:53.174948 68174 net.cpp:144] Setting up inception_7a/3x3
I0122 18:31:53.174957 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.174959 68174 net.cpp:159] Memory required for data: 431514600
I0122 18:31:53.174964 68174 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 18:31:53.174970 68174 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 18:31:53.174973 68174 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 18:31:53.174979 68174 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 18:31:53.175590 68174 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 18:31:53.175595 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.175598 68174 net.cpp:159] Memory required for data: 435610600
I0122 18:31:53.175606 68174 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 18:31:53.175611 68174 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 18:31:53.175614 68174 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 18:31:53.175618 68174 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 18:31:53.175624 68174 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 18:31:53.175628 68174 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:53.175631 68174 net.cpp:159] Memory required for data: 439706600
I0122 18:31:53.175633 68174 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 18:31:53.175638 68174 net.cpp:94] Creating Layer inception_7a/output
I0122 18:31:53.175642 68174 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 18:31:53.175644 68174 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 18:31:53.175648 68174 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 18:31:53.175667 68174 net.cpp:144] Setting up inception_7a/output
I0122 18:31:53.175671 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.175674 68174 net.cpp:159] Memory required for data: 447898600
I0122 18:31:53.175676 68174 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 18:31:53.175681 68174 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 18:31:53.175684 68174 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 18:31:53.175688 68174 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 18:31:53.175695 68174 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 18:31:53.175720 68174 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 18:31:53.175726 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.175729 68174 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:53.175732 68174 net.cpp:159] Memory required for data: 464282600
I0122 18:31:53.175735 68174 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 18:31:53.175741 68174 net.cpp:94] Creating Layer inception_8a/1x1
I0122 18:31:53.175745 68174 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 18:31:53.175750 68174 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 18:31:53.175999 68174 net.cpp:144] Setting up inception_8a/1x1
I0122 18:31:53.176005 68174 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:53.176008 68174 net.cpp:159] Memory required for data: 466740200
I0122 18:31:53.176014 68174 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 18:31:53.176020 68174 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 18:31:53.176033 68174 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 18:31:53.176039 68174 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 18:31:53.176656 68174 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 18:31:53.176662 68174 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:53.176666 68174 net.cpp:159] Memory required for data: 469197800
I0122 18:31:53.176673 68174 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 18:31:53.176677 68174 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 18:31:53.176681 68174 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 18:31:53.176686 68174 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 18:31:53.176690 68174 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 18:31:53.176694 68174 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:53.176697 68174 net.cpp:159] Memory required for data: 471655400
I0122 18:31:53.176699 68174 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 18:31:53.176707 68174 net.cpp:94] Creating Layer inception_8a/3x3
I0122 18:31:53.176709 68174 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 18:31:53.176715 68174 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 18:31:53.178295 68174 net.cpp:144] Setting up inception_8a/3x3
I0122 18:31:53.178306 68174 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:53.178309 68174 net.cpp:159] Memory required for data: 476570600
I0122 18:31:53.178315 68174 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 18:31:53.178323 68174 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 18:31:53.178325 68174 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 18:31:53.178330 68174 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 18:31:53.178972 68174 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 18:31:53.178978 68174 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:53.178982 68174 net.cpp:159] Memory required for data: 481485800
I0122 18:31:53.178990 68174 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 18:31:53.178995 68174 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 18:31:53.178998 68174 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 18:31:53.179003 68174 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 18:31:53.179009 68174 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 18:31:53.179013 68174 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:53.179016 68174 net.cpp:159] Memory required for data: 486401000
I0122 18:31:53.179018 68174 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 18:31:53.179023 68174 net.cpp:94] Creating Layer inception_8a/output
I0122 18:31:53.179026 68174 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 18:31:53.179029 68174 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 18:31:53.179034 68174 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 18:31:53.179051 68174 net.cpp:144] Setting up inception_8a/output
I0122 18:31:53.179057 68174 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 18:31:53.179060 68174 net.cpp:159] Memory required for data: 493773800
I0122 18:31:53.179062 68174 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 18:31:53.179066 68174 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 18:31:53.179070 68174 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 18:31:53.179075 68174 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 18:31:53.179081 68174 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 18:31:53.179106 68174 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 18:31:53.179112 68174 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 18:31:53.179126 68174 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 18:31:53.179128 68174 net.cpp:159] Memory required for data: 508519400
I0122 18:31:53.179131 68174 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 18:31:53.179141 68174 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 18:31:53.179145 68174 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 18:31:53.179152 68174 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 18:31:53.180657 68174 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 18:31:53.180668 68174 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 18:31:53.180671 68174 net.cpp:159] Memory required for data: 509748200
I0122 18:31:53.180677 68174 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 18:31:53.180685 68174 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 18:31:53.180688 68174 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 18:31:53.180693 68174 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 18:31:53.181347 68174 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 18:31:53.181354 68174 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 18:31:53.181358 68174 net.cpp:159] Memory required for data: 510977000
I0122 18:31:53.181366 68174 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 18:31:53.181371 68174 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 18:31:53.181375 68174 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 18:31:53.181380 68174 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 18:31:53.181385 68174 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 18:31:53.181390 68174 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 18:31:53.181391 68174 net.cpp:159] Memory required for data: 512205800
I0122 18:31:53.181396 68174 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 18:31:53.181401 68174 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 18:31:53.181403 68174 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 18:31:53.181408 68174 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 18:31:53.181437 68174 net.cpp:144] Setting up downsample_9/pool_s2
I0122 18:31:53.181442 68174 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 18:31:53.181447 68174 net.cpp:159] Memory required for data: 514049000
I0122 18:31:53.181448 68174 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 18:31:53.181455 68174 net.cpp:94] Creating Layer downsample_9/output
I0122 18:31:53.181461 68174 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 18:31:53.181465 68174 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 18:31:53.181469 68174 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 18:31:53.181488 68174 net.cpp:144] Setting up downsample_9/output
I0122 18:31:53.181493 68174 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 18:31:53.181495 68174 net.cpp:159] Memory required for data: 517121000
I0122 18:31:53.181499 68174 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 18:31:53.181504 68174 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 18:31:53.181506 68174 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 18:31:53.181511 68174 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 18:31:53.181516 68174 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 18:31:53.181543 68174 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 18:31:53.181548 68174 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 18:31:53.181552 68174 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 18:31:53.181555 68174 net.cpp:159] Memory required for data: 523265000
I0122 18:31:53.181568 68174 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 18:31:53.181576 68174 net.cpp:94] Creating Layer inception_10a/1x1
I0122 18:31:53.181578 68174 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 18:31:53.181583 68174 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 18:31:53.182044 68174 net.cpp:144] Setting up inception_10a/1x1
I0122 18:31:53.182051 68174 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:53.182054 68174 net.cpp:159] Memory required for data: 525517800
I0122 18:31:53.182060 68174 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 18:31:53.182066 68174 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 18:31:53.182073 68174 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 18:31:53.182078 68174 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 18:31:53.182698 68174 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 18:31:53.182704 68174 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:53.182708 68174 net.cpp:159] Memory required for data: 527770600
I0122 18:31:53.182715 68174 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 18:31:53.182720 68174 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 18:31:53.182724 68174 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 18:31:53.182729 68174 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 18:31:53.182734 68174 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 18:31:53.182739 68174 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:53.182741 68174 net.cpp:159] Memory required for data: 530023400
I0122 18:31:53.182744 68174 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 18:31:53.182750 68174 net.cpp:94] Creating Layer inception_10a/3x3
I0122 18:31:53.182755 68174 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 18:31:53.182761 68174 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 18:31:53.185259 68174 net.cpp:144] Setting up inception_10a/3x3
I0122 18:31:53.185271 68174 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:53.185273 68174 net.cpp:159] Memory required for data: 532071400
I0122 18:31:53.185281 68174 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 18:31:53.185286 68174 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 18:31:53.185290 68174 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 18:31:53.185295 68174 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 18:31:53.185922 68174 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 18:31:53.185930 68174 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:53.185933 68174 net.cpp:159] Memory required for data: 534119400
I0122 18:31:53.185940 68174 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 18:31:53.185947 68174 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 18:31:53.185950 68174 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 18:31:53.185955 68174 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 18:31:53.185961 68174 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 18:31:53.185966 68174 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:53.185967 68174 net.cpp:159] Memory required for data: 536167400
I0122 18:31:53.185971 68174 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 18:31:53.185974 68174 net.cpp:94] Creating Layer inception_10a/output
I0122 18:31:53.185977 68174 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 18:31:53.185981 68174 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 18:31:53.185986 68174 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 18:31:53.186002 68174 net.cpp:144] Setting up inception_10a/output
I0122 18:31:53.186008 68174 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:53.186010 68174 net.cpp:159] Memory required for data: 540468200
I0122 18:31:53.186013 68174 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 18:31:53.186026 68174 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 18:31:53.186030 68174 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 18:31:53.186035 68174 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 18:31:53.186040 68174 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 18:31:53.186065 68174 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 18:31:53.186071 68174 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:53.186075 68174 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:53.186077 68174 net.cpp:159] Memory required for data: 549069800
I0122 18:31:53.186080 68174 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 18:31:53.186087 68174 net.cpp:94] Creating Layer inception_11a/1x1
I0122 18:31:53.186092 68174 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 18:31:53.186097 68174 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 18:31:53.186632 68174 net.cpp:144] Setting up inception_11a/1x1
I0122 18:31:53.186640 68174 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:53.186643 68174 net.cpp:159] Memory required for data: 551322600
I0122 18:31:53.186648 68174 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 18:31:53.186655 68174 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 18:31:53.186658 68174 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 18:31:53.186663 68174 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 18:31:53.187273 68174 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 18:31:53.187279 68174 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:53.187283 68174 net.cpp:159] Memory required for data: 553575400
I0122 18:31:53.187290 68174 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 18:31:53.187295 68174 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 18:31:53.187299 68174 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 18:31:53.187304 68174 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 18:31:53.187309 68174 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 18:31:53.187312 68174 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:53.187314 68174 net.cpp:159] Memory required for data: 555828200
I0122 18:31:53.187319 68174 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 18:31:53.187325 68174 net.cpp:94] Creating Layer inception_11a/3x3
I0122 18:31:53.187330 68174 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 18:31:53.187335 68174 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 18:31:53.190702 68174 net.cpp:144] Setting up inception_11a/3x3
I0122 18:31:53.190713 68174 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:53.190716 68174 net.cpp:159] Memory required for data: 557876200
I0122 18:31:53.190721 68174 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 18:31:53.190726 68174 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 18:31:53.190729 68174 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 18:31:53.190733 68174 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 18:31:53.191373 68174 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 18:31:53.191380 68174 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:53.191385 68174 net.cpp:159] Memory required for data: 559924200
I0122 18:31:53.191397 68174 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 18:31:53.191404 68174 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 18:31:53.191407 68174 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 18:31:53.191412 68174 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 18:31:53.191428 68174 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 18:31:53.191432 68174 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:53.191435 68174 net.cpp:159] Memory required for data: 561972200
I0122 18:31:53.191437 68174 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 18:31:53.191442 68174 net.cpp:94] Creating Layer inception_11a/output
I0122 18:31:53.191445 68174 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 18:31:53.191449 68174 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 18:31:53.191453 68174 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 18:31:53.191471 68174 net.cpp:144] Setting up inception_11a/output
I0122 18:31:53.191476 68174 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:53.191480 68174 net.cpp:159] Memory required for data: 566273000
I0122 18:31:53.191483 68174 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 18:31:53.191488 68174 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 18:31:53.191491 68174 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 18:31:53.191496 68174 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 18:31:53.191514 68174 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 18:31:53.191519 68174 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 18:31:53.191521 68174 net.cpp:159] Memory required for data: 566340200
I0122 18:31:53.191524 68174 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 18:31:53.191529 68174 net.cpp:94] Creating Layer drop_8x8_s1
I0122 18:31:53.191531 68174 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 18:31:53.191536 68174 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 18:31:53.191553 68174 net.cpp:144] Setting up drop_8x8_s1
I0122 18:31:53.191558 68174 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 18:31:53.191560 68174 net.cpp:159] Memory required for data: 566407400
I0122 18:31:53.191562 68174 layer_factory.hpp:77] Creating layer loss/classifier
I0122 18:31:53.191570 68174 net.cpp:94] Creating Layer loss/classifier
I0122 18:31:53.191572 68174 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 18:31:53.191576 68174 net.cpp:409] loss/classifier -> loss/classifier
I0122 18:31:53.191704 68174 net.cpp:144] Setting up loss/classifier
I0122 18:31:53.191710 68174 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:53.191714 68174 net.cpp:159] Memory required for data: 566409400
I0122 18:31:53.191717 68174 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 18:31:53.191722 68174 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 18:31:53.191726 68174 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 18:31:53.191730 68174 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 18:31:53.191736 68174 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 18:31:53.191741 68174 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 18:31:53.191749 68174 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 18:31:53.191794 68174 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 18:31:53.191799 68174 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:53.191802 68174 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:53.191805 68174 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:53.191808 68174 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:53.191810 68174 net.cpp:159] Memory required for data: 566417400
I0122 18:31:53.191813 68174 layer_factory.hpp:77] Creating layer loss
I0122 18:31:53.191818 68174 net.cpp:94] Creating Layer loss
I0122 18:31:53.191821 68174 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 18:31:53.191825 68174 net.cpp:435] loss <- label_data_1_split_0
I0122 18:31:53.191830 68174 net.cpp:409] loss -> loss
I0122 18:31:53.191838 68174 layer_factory.hpp:77] Creating layer loss
I0122 18:31:53.191915 68174 net.cpp:144] Setting up loss
I0122 18:31:53.191920 68174 net.cpp:151] Top shape: (1)
I0122 18:31:53.191921 68174 net.cpp:154]     with loss weight 1
I0122 18:31:53.191932 68174 net.cpp:159] Memory required for data: 566417404
I0122 18:31:53.191936 68174 layer_factory.hpp:77] Creating layer accuracy
I0122 18:31:53.191941 68174 net.cpp:94] Creating Layer accuracy
I0122 18:31:53.191944 68174 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 18:31:53.191948 68174 net.cpp:435] accuracy <- label_data_1_split_1
I0122 18:31:53.191952 68174 net.cpp:409] accuracy -> accuracy
I0122 18:31:53.191962 68174 net.cpp:144] Setting up accuracy
I0122 18:31:53.191967 68174 net.cpp:151] Top shape: (1)
I0122 18:31:53.191970 68174 net.cpp:159] Memory required for data: 566417408
I0122 18:31:53.191972 68174 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 18:31:53.191977 68174 net.cpp:94] Creating Layer accuracy-top1
I0122 18:31:53.191979 68174 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 18:31:53.191983 68174 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 18:31:53.191988 68174 net.cpp:409] accuracy-top1 -> top-1
I0122 18:31:53.191993 68174 net.cpp:144] Setting up accuracy-top1
I0122 18:31:53.191996 68174 net.cpp:151] Top shape: (1)
I0122 18:31:53.192000 68174 net.cpp:159] Memory required for data: 566417412
I0122 18:31:53.192003 68174 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 18:31:53.192006 68174 net.cpp:94] Creating Layer accuracy-top5
I0122 18:31:53.192009 68174 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 18:31:53.192013 68174 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 18:31:53.192018 68174 net.cpp:409] accuracy-top5 -> top-5
I0122 18:31:53.192023 68174 net.cpp:144] Setting up accuracy-top5
I0122 18:31:53.192025 68174 net.cpp:151] Top shape: (1)
I0122 18:31:53.192028 68174 net.cpp:159] Memory required for data: 566417416
I0122 18:31:53.192031 68174 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 18:31:53.192034 68174 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 18:31:53.192037 68174 net.cpp:222] accuracy does not need backward computation.
I0122 18:31:53.192041 68174 net.cpp:220] loss needs backward computation.
I0122 18:31:53.192045 68174 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 18:31:53.192049 68174 net.cpp:220] loss/classifier needs backward computation.
I0122 18:31:53.192051 68174 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 18:31:53.192054 68174 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 18:31:53.192057 68174 net.cpp:220] inception_11a/output needs backward computation.
I0122 18:31:53.192061 68174 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 18:31:53.192065 68174 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 18:31:53.192067 68174 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 18:31:53.192070 68174 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 18:31:53.192073 68174 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 18:31:53.192075 68174 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 18:31:53.192080 68174 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 18:31:53.192083 68174 net.cpp:220] inception_10a/output needs backward computation.
I0122 18:31:53.192086 68174 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 18:31:53.192090 68174 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 18:31:53.192092 68174 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 18:31:53.192096 68174 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 18:31:53.192100 68174 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 18:31:53.192101 68174 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 18:31:53.192106 68174 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 18:31:53.192113 68174 net.cpp:220] downsample_9/output needs backward computation.
I0122 18:31:53.192116 68174 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 18:31:53.192119 68174 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 18:31:53.192123 68174 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 18:31:53.192126 68174 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 18:31:53.192129 68174 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 18:31:53.192132 68174 net.cpp:220] inception_8a/output needs backward computation.
I0122 18:31:53.192137 68174 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 18:31:53.192139 68174 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 18:31:53.192142 68174 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 18:31:53.192145 68174 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 18:31:53.192148 68174 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 18:31:53.192152 68174 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 18:31:53.192155 68174 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 18:31:53.192158 68174 net.cpp:220] inception_7a/output needs backward computation.
I0122 18:31:53.192163 68174 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 18:31:53.192167 68174 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 18:31:53.192168 68174 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 18:31:53.192173 68174 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 18:31:53.192175 68174 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 18:31:53.192178 68174 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 18:31:53.192181 68174 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 18:31:53.192184 68174 net.cpp:220] inception_6a/output needs backward computation.
I0122 18:31:53.192188 68174 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 18:31:53.192191 68174 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 18:31:53.192194 68174 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 18:31:53.192198 68174 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 18:31:53.192200 68174 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 18:31:53.192203 68174 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 18:31:53.192205 68174 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 18:31:53.192209 68174 net.cpp:220] inception_5a/output needs backward computation.
I0122 18:31:53.192212 68174 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 18:31:53.192215 68174 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 18:31:53.192217 68174 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 18:31:53.192220 68174 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 18:31:53.192224 68174 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 18:31:53.192226 68174 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 18:31:53.192229 68174 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 18:31:53.192232 68174 net.cpp:220] downsample_4/output needs backward computation.
I0122 18:31:53.192236 68174 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 18:31:53.192240 68174 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 18:31:53.192242 68174 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 18:31:53.192246 68174 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 18:31:53.192255 68174 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 18:31:53.192257 68174 net.cpp:220] inception_3a/output needs backward computation.
I0122 18:31:53.192260 68174 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 18:31:53.192263 68174 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 18:31:53.192266 68174 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 18:31:53.192270 68174 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 18:31:53.192272 68174 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 18:31:53.192275 68174 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 18:31:53.192278 68174 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 18:31:53.192281 68174 net.cpp:220] inception_2a/output needs backward computation.
I0122 18:31:53.192284 68174 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 18:31:53.192287 68174 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 18:31:53.192291 68174 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 18:31:53.192296 68174 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 18:31:53.192297 68174 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 18:31:53.192301 68174 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 18:31:53.192304 68174 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 18:31:53.192306 68174 net.cpp:220] conv1/relu1 needs backward computation.
I0122 18:31:53.192309 68174 net.cpp:220] conv1/bn1 needs backward computation.
I0122 18:31:53.192312 68174 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 18:31:53.192317 68174 net.cpp:222] label_data_1_split does not need backward computation.
I0122 18:31:53.192322 68174 net.cpp:222] data does not need backward computation.
I0122 18:31:53.192323 68174 net.cpp:264] This network produces output accuracy
I0122 18:31:53.192327 68174 net.cpp:264] This network produces output loss
I0122 18:31:53.192330 68174 net.cpp:264] This network produces output top-1
I0122 18:31:53.192333 68174 net.cpp:264] This network produces output top-5
I0122 18:31:53.192397 68174 net.cpp:284] Network initialization done.
I0122 18:31:53.194986 68174 caffe_interface.cpp:363] Running for 180 iterations.
I0122 18:31:53.218435 68174 caffe_interface.cpp:125] Batch 0, accuracy = 0.92
I0122 18:31:53.218451 68174 caffe_interface.cpp:125] Batch 0, loss = 0.231189
I0122 18:31:53.218454 68174 caffe_interface.cpp:125] Batch 0, top-1 = 0.92
I0122 18:31:53.218457 68174 caffe_interface.cpp:125] Batch 0, top-5 = 1
I0122 18:31:53.228451 68174 caffe_interface.cpp:125] Batch 1, accuracy = 0.9
I0122 18:31:53.228463 68174 caffe_interface.cpp:125] Batch 1, loss = 0.49243
I0122 18:31:53.228468 68174 caffe_interface.cpp:125] Batch 1, top-1 = 0.9
I0122 18:31:53.228471 68174 caffe_interface.cpp:125] Batch 1, top-5 = 1
I0122 18:31:53.236932 68174 caffe_interface.cpp:125] Batch 2, accuracy = 0.9
I0122 18:31:53.236941 68174 caffe_interface.cpp:125] Batch 2, loss = 0.247435
I0122 18:31:53.236945 68174 caffe_interface.cpp:125] Batch 2, top-1 = 0.9
I0122 18:31:53.236948 68174 caffe_interface.cpp:125] Batch 2, top-5 = 1
I0122 18:31:53.245422 68174 caffe_interface.cpp:125] Batch 3, accuracy = 0.88
I0122 18:31:53.245431 68174 caffe_interface.cpp:125] Batch 3, loss = 0.919515
I0122 18:31:53.245434 68174 caffe_interface.cpp:125] Batch 3, top-1 = 0.88
I0122 18:31:53.245437 68174 caffe_interface.cpp:125] Batch 3, top-5 = 1
I0122 18:31:53.253877 68174 caffe_interface.cpp:125] Batch 4, accuracy = 0.94
I0122 18:31:53.253886 68174 caffe_interface.cpp:125] Batch 4, loss = 0.309195
I0122 18:31:53.253890 68174 caffe_interface.cpp:125] Batch 4, top-1 = 0.94
I0122 18:31:53.253891 68174 caffe_interface.cpp:125] Batch 4, top-5 = 1
I0122 18:31:53.263485 68174 caffe_interface.cpp:125] Batch 5, accuracy = 0.9
I0122 18:31:53.263495 68174 caffe_interface.cpp:125] Batch 5, loss = 0.287776
I0122 18:31:53.263510 68174 caffe_interface.cpp:125] Batch 5, top-1 = 0.9
I0122 18:31:53.263514 68174 caffe_interface.cpp:125] Batch 5, top-5 = 1
I0122 18:31:53.271972 68174 caffe_interface.cpp:125] Batch 6, accuracy = 0.88
I0122 18:31:53.271982 68174 caffe_interface.cpp:125] Batch 6, loss = 0.307659
I0122 18:31:53.271986 68174 caffe_interface.cpp:125] Batch 6, top-1 = 0.88
I0122 18:31:53.271988 68174 caffe_interface.cpp:125] Batch 6, top-5 = 1
I0122 18:31:53.280441 68174 caffe_interface.cpp:125] Batch 7, accuracy = 1
I0122 18:31:53.280449 68174 caffe_interface.cpp:125] Batch 7, loss = 0.0656272
I0122 18:31:53.280453 68174 caffe_interface.cpp:125] Batch 7, top-1 = 1
I0122 18:31:53.280457 68174 caffe_interface.cpp:125] Batch 7, top-5 = 1
I0122 18:31:53.288913 68174 caffe_interface.cpp:125] Batch 8, accuracy = 0.9
I0122 18:31:53.288921 68174 caffe_interface.cpp:125] Batch 8, loss = 0.503626
I0122 18:31:53.288925 68174 caffe_interface.cpp:125] Batch 8, top-1 = 0.9
I0122 18:31:53.288928 68174 caffe_interface.cpp:125] Batch 8, top-5 = 1
I0122 18:31:53.298140 68174 caffe_interface.cpp:125] Batch 9, accuracy = 0.9
I0122 18:31:53.298149 68174 caffe_interface.cpp:125] Batch 9, loss = 0.425276
I0122 18:31:53.298153 68174 caffe_interface.cpp:125] Batch 9, top-1 = 0.9
I0122 18:31:53.298156 68174 caffe_interface.cpp:125] Batch 9, top-5 = 0.98
I0122 18:31:53.306602 68174 caffe_interface.cpp:125] Batch 10, accuracy = 0.9
I0122 18:31:53.306612 68174 caffe_interface.cpp:125] Batch 10, loss = 0.594146
I0122 18:31:53.306614 68174 caffe_interface.cpp:125] Batch 10, top-1 = 0.9
I0122 18:31:53.306617 68174 caffe_interface.cpp:125] Batch 10, top-5 = 0.98
I0122 18:31:53.315054 68174 caffe_interface.cpp:125] Batch 11, accuracy = 0.94
I0122 18:31:53.315063 68174 caffe_interface.cpp:125] Batch 11, loss = 0.217211
I0122 18:31:53.315068 68174 caffe_interface.cpp:125] Batch 11, top-1 = 0.94
I0122 18:31:53.315070 68174 caffe_interface.cpp:125] Batch 11, top-5 = 0.98
I0122 18:31:53.324594 68174 caffe_interface.cpp:125] Batch 12, accuracy = 0.86
I0122 18:31:53.324602 68174 caffe_interface.cpp:125] Batch 12, loss = 0.274538
I0122 18:31:53.324605 68174 caffe_interface.cpp:125] Batch 12, top-1 = 0.86
I0122 18:31:53.324607 68174 caffe_interface.cpp:125] Batch 12, top-5 = 1
I0122 18:31:53.333043 68174 caffe_interface.cpp:125] Batch 13, accuracy = 0.92
I0122 18:31:53.333052 68174 caffe_interface.cpp:125] Batch 13, loss = 0.452039
I0122 18:31:53.333055 68174 caffe_interface.cpp:125] Batch 13, top-1 = 0.92
I0122 18:31:53.333058 68174 caffe_interface.cpp:125] Batch 13, top-5 = 1
I0122 18:31:53.341482 68174 caffe_interface.cpp:125] Batch 14, accuracy = 0.96
I0122 18:31:53.341491 68174 caffe_interface.cpp:125] Batch 14, loss = 0.119435
I0122 18:31:53.341495 68174 caffe_interface.cpp:125] Batch 14, top-1 = 0.96
I0122 18:31:53.341497 68174 caffe_interface.cpp:125] Batch 14, top-5 = 1
I0122 18:31:53.349944 68174 caffe_interface.cpp:125] Batch 15, accuracy = 0.94
I0122 18:31:53.349953 68174 caffe_interface.cpp:125] Batch 15, loss = 0.246331
I0122 18:31:53.349957 68174 caffe_interface.cpp:125] Batch 15, top-1 = 0.94
I0122 18:31:53.349959 68174 caffe_interface.cpp:125] Batch 15, top-5 = 1
I0122 18:31:53.359371 68174 caffe_interface.cpp:125] Batch 16, accuracy = 0.92
I0122 18:31:53.359380 68174 caffe_interface.cpp:125] Batch 16, loss = 0.351636
I0122 18:31:53.359381 68174 caffe_interface.cpp:125] Batch 16, top-1 = 0.92
I0122 18:31:53.359383 68174 caffe_interface.cpp:125] Batch 16, top-5 = 1
I0122 18:31:53.367771 68174 caffe_interface.cpp:125] Batch 17, accuracy = 0.94
I0122 18:31:53.367779 68174 caffe_interface.cpp:125] Batch 17, loss = 0.186164
I0122 18:31:53.367782 68174 caffe_interface.cpp:125] Batch 17, top-1 = 0.94
I0122 18:31:53.367784 68174 caffe_interface.cpp:125] Batch 17, top-5 = 1
I0122 18:31:53.376194 68174 caffe_interface.cpp:125] Batch 18, accuracy = 0.84
I0122 18:31:53.376202 68174 caffe_interface.cpp:125] Batch 18, loss = 0.435713
I0122 18:31:53.376206 68174 caffe_interface.cpp:125] Batch 18, top-1 = 0.84
I0122 18:31:53.376209 68174 caffe_interface.cpp:125] Batch 18, top-5 = 1
I0122 18:31:53.384650 68174 caffe_interface.cpp:125] Batch 19, accuracy = 0.9
I0122 18:31:53.384660 68174 caffe_interface.cpp:125] Batch 19, loss = 0.33671
I0122 18:31:53.384665 68174 caffe_interface.cpp:125] Batch 19, top-1 = 0.9
I0122 18:31:53.384667 68174 caffe_interface.cpp:125] Batch 19, top-5 = 1
I0122 18:31:53.394186 68174 caffe_interface.cpp:125] Batch 20, accuracy = 0.9
I0122 18:31:53.394196 68174 caffe_interface.cpp:125] Batch 20, loss = 0.394573
I0122 18:31:53.394198 68174 caffe_interface.cpp:125] Batch 20, top-1 = 0.9
I0122 18:31:53.394201 68174 caffe_interface.cpp:125] Batch 20, top-5 = 1
I0122 18:31:53.402640 68174 caffe_interface.cpp:125] Batch 21, accuracy = 0.84
I0122 18:31:53.402649 68174 caffe_interface.cpp:125] Batch 21, loss = 0.811609
I0122 18:31:53.402653 68174 caffe_interface.cpp:125] Batch 21, top-1 = 0.84
I0122 18:31:53.402655 68174 caffe_interface.cpp:125] Batch 21, top-5 = 1
I0122 18:31:53.411008 68174 caffe_interface.cpp:125] Batch 22, accuracy = 0.9
I0122 18:31:53.411018 68174 caffe_interface.cpp:125] Batch 22, loss = 0.248601
I0122 18:31:53.411021 68174 caffe_interface.cpp:125] Batch 22, top-1 = 0.9
I0122 18:31:53.411025 68174 caffe_interface.cpp:125] Batch 22, top-5 = 1
I0122 18:31:53.418984 68174 caffe_interface.cpp:125] Batch 23, accuracy = 0.92
I0122 18:31:53.418993 68174 caffe_interface.cpp:125] Batch 23, loss = 0.236756
I0122 18:31:53.418996 68174 caffe_interface.cpp:125] Batch 23, top-1 = 0.92
I0122 18:31:53.418999 68174 caffe_interface.cpp:125] Batch 23, top-5 = 1
I0122 18:31:53.428102 68174 caffe_interface.cpp:125] Batch 24, accuracy = 0.88
I0122 18:31:53.428110 68174 caffe_interface.cpp:125] Batch 24, loss = 0.375515
I0122 18:31:53.428114 68174 caffe_interface.cpp:125] Batch 24, top-1 = 0.88
I0122 18:31:53.428117 68174 caffe_interface.cpp:125] Batch 24, top-5 = 1
I0122 18:31:53.436079 68174 caffe_interface.cpp:125] Batch 25, accuracy = 0.92
I0122 18:31:53.436087 68174 caffe_interface.cpp:125] Batch 25, loss = 0.366291
I0122 18:31:53.436090 68174 caffe_interface.cpp:125] Batch 25, top-1 = 0.92
I0122 18:31:53.436092 68174 caffe_interface.cpp:125] Batch 25, top-5 = 1
I0122 18:31:53.444067 68174 caffe_interface.cpp:125] Batch 26, accuracy = 0.88
I0122 18:31:53.444077 68174 caffe_interface.cpp:125] Batch 26, loss = 0.460876
I0122 18:31:53.444079 68174 caffe_interface.cpp:125] Batch 26, top-1 = 0.88
I0122 18:31:53.444082 68174 caffe_interface.cpp:125] Batch 26, top-5 = 1
I0122 18:31:53.452046 68174 caffe_interface.cpp:125] Batch 27, accuracy = 0.94
I0122 18:31:53.452055 68174 caffe_interface.cpp:125] Batch 27, loss = 0.0760321
I0122 18:31:53.452059 68174 caffe_interface.cpp:125] Batch 27, top-1 = 0.94
I0122 18:31:53.452062 68174 caffe_interface.cpp:125] Batch 27, top-5 = 1
I0122 18:31:53.461113 68174 caffe_interface.cpp:125] Batch 28, accuracy = 0.88
I0122 18:31:53.461122 68174 caffe_interface.cpp:125] Batch 28, loss = 0.23646
I0122 18:31:53.461123 68174 caffe_interface.cpp:125] Batch 28, top-1 = 0.88
I0122 18:31:53.461127 68174 caffe_interface.cpp:125] Batch 28, top-5 = 1
I0122 18:31:53.469049 68174 caffe_interface.cpp:125] Batch 29, accuracy = 0.92
I0122 18:31:53.469058 68174 caffe_interface.cpp:125] Batch 29, loss = 0.496632
I0122 18:31:53.469060 68174 caffe_interface.cpp:125] Batch 29, top-1 = 0.92
I0122 18:31:53.469063 68174 caffe_interface.cpp:125] Batch 29, top-5 = 1
I0122 18:31:53.477890 68174 caffe_interface.cpp:125] Batch 30, accuracy = 0.94
I0122 18:31:53.477900 68174 caffe_interface.cpp:125] Batch 30, loss = 0.142466
I0122 18:31:53.477906 68174 caffe_interface.cpp:125] Batch 30, top-1 = 0.94
I0122 18:31:53.477911 68174 caffe_interface.cpp:125] Batch 30, top-5 = 1
I0122 18:31:53.486088 68174 caffe_interface.cpp:125] Batch 31, accuracy = 0.9
I0122 18:31:53.486096 68174 caffe_interface.cpp:125] Batch 31, loss = 0.319998
I0122 18:31:53.486099 68174 caffe_interface.cpp:125] Batch 31, top-1 = 0.9
I0122 18:31:53.486101 68174 caffe_interface.cpp:125] Batch 31, top-5 = 1
I0122 18:31:53.495174 68174 caffe_interface.cpp:125] Batch 32, accuracy = 0.9
I0122 18:31:53.495193 68174 caffe_interface.cpp:125] Batch 32, loss = 0.420904
I0122 18:31:53.495196 68174 caffe_interface.cpp:125] Batch 32, top-1 = 0.9
I0122 18:31:53.495199 68174 caffe_interface.cpp:125] Batch 32, top-5 = 1
I0122 18:31:53.503180 68174 caffe_interface.cpp:125] Batch 33, accuracy = 0.8
I0122 18:31:53.503190 68174 caffe_interface.cpp:125] Batch 33, loss = 0.88246
I0122 18:31:53.503191 68174 caffe_interface.cpp:125] Batch 33, top-1 = 0.8
I0122 18:31:53.503195 68174 caffe_interface.cpp:125] Batch 33, top-5 = 0.98
I0122 18:31:53.511183 68174 caffe_interface.cpp:125] Batch 34, accuracy = 0.9
I0122 18:31:53.511191 68174 caffe_interface.cpp:125] Batch 34, loss = 0.286029
I0122 18:31:53.511194 68174 caffe_interface.cpp:125] Batch 34, top-1 = 0.9
I0122 18:31:53.511198 68174 caffe_interface.cpp:125] Batch 34, top-5 = 1
I0122 18:31:53.519155 68174 caffe_interface.cpp:125] Batch 35, accuracy = 0.84
I0122 18:31:53.519165 68174 caffe_interface.cpp:125] Batch 35, loss = 0.459684
I0122 18:31:53.519167 68174 caffe_interface.cpp:125] Batch 35, top-1 = 0.84
I0122 18:31:53.519170 68174 caffe_interface.cpp:125] Batch 35, top-5 = 1
I0122 18:31:53.528183 68174 caffe_interface.cpp:125] Batch 36, accuracy = 0.94
I0122 18:31:53.528192 68174 caffe_interface.cpp:125] Batch 36, loss = 0.136879
I0122 18:31:53.528194 68174 caffe_interface.cpp:125] Batch 36, top-1 = 0.94
I0122 18:31:53.528196 68174 caffe_interface.cpp:125] Batch 36, top-5 = 1
I0122 18:31:53.536166 68174 caffe_interface.cpp:125] Batch 37, accuracy = 0.92
I0122 18:31:53.536176 68174 caffe_interface.cpp:125] Batch 37, loss = 0.401388
I0122 18:31:53.536180 68174 caffe_interface.cpp:125] Batch 37, top-1 = 0.92
I0122 18:31:53.536182 68174 caffe_interface.cpp:125] Batch 37, top-5 = 1
I0122 18:31:53.544134 68174 caffe_interface.cpp:125] Batch 38, accuracy = 0.82
I0122 18:31:53.544143 68174 caffe_interface.cpp:125] Batch 38, loss = 0.438917
I0122 18:31:53.544147 68174 caffe_interface.cpp:125] Batch 38, top-1 = 0.82
I0122 18:31:53.544149 68174 caffe_interface.cpp:125] Batch 38, top-5 = 1
I0122 18:31:53.552104 68174 caffe_interface.cpp:125] Batch 39, accuracy = 0.92
I0122 18:31:53.552114 68174 caffe_interface.cpp:125] Batch 39, loss = 0.225023
I0122 18:31:53.552116 68174 caffe_interface.cpp:125] Batch 39, top-1 = 0.92
I0122 18:31:53.552119 68174 caffe_interface.cpp:125] Batch 39, top-5 = 1
I0122 18:31:53.561152 68174 caffe_interface.cpp:125] Batch 40, accuracy = 0.94
I0122 18:31:53.561161 68174 caffe_interface.cpp:125] Batch 40, loss = 0.189357
I0122 18:31:53.561163 68174 caffe_interface.cpp:125] Batch 40, top-1 = 0.94
I0122 18:31:53.561166 68174 caffe_interface.cpp:125] Batch 40, top-5 = 1
I0122 18:31:53.569102 68174 caffe_interface.cpp:125] Batch 41, accuracy = 0.8
I0122 18:31:53.569111 68174 caffe_interface.cpp:125] Batch 41, loss = 0.723452
I0122 18:31:53.569114 68174 caffe_interface.cpp:125] Batch 41, top-1 = 0.8
I0122 18:31:53.569118 68174 caffe_interface.cpp:125] Batch 41, top-5 = 1
I0122 18:31:53.577076 68174 caffe_interface.cpp:125] Batch 42, accuracy = 0.84
I0122 18:31:53.577085 68174 caffe_interface.cpp:125] Batch 42, loss = 0.385548
I0122 18:31:53.577090 68174 caffe_interface.cpp:125] Batch 42, top-1 = 0.84
I0122 18:31:53.577091 68174 caffe_interface.cpp:125] Batch 42, top-5 = 0.98
I0122 18:31:53.585059 68174 caffe_interface.cpp:125] Batch 43, accuracy = 0.92
I0122 18:31:53.585068 68174 caffe_interface.cpp:125] Batch 43, loss = 0.380804
I0122 18:31:53.585072 68174 caffe_interface.cpp:125] Batch 43, top-1 = 0.92
I0122 18:31:53.585074 68174 caffe_interface.cpp:125] Batch 43, top-5 = 1
I0122 18:31:53.593029 68174 caffe_interface.cpp:125] Batch 44, accuracy = 0.9
I0122 18:31:53.593037 68174 caffe_interface.cpp:125] Batch 44, loss = 0.393728
I0122 18:31:53.593041 68174 caffe_interface.cpp:125] Batch 44, top-1 = 0.9
I0122 18:31:53.593044 68174 caffe_interface.cpp:125] Batch 44, top-5 = 1
I0122 18:31:53.601897 68174 caffe_interface.cpp:125] Batch 45, accuracy = 0.94
I0122 18:31:53.601909 68174 caffe_interface.cpp:125] Batch 45, loss = 0.397123
I0122 18:31:53.601922 68174 caffe_interface.cpp:125] Batch 45, top-1 = 0.94
I0122 18:31:53.601924 68174 caffe_interface.cpp:125] Batch 45, top-5 = 1
I0122 18:31:53.609877 68174 caffe_interface.cpp:125] Batch 46, accuracy = 0.9
I0122 18:31:53.609886 68174 caffe_interface.cpp:125] Batch 46, loss = 0.283408
I0122 18:31:53.609889 68174 caffe_interface.cpp:125] Batch 46, top-1 = 0.9
I0122 18:31:53.609892 68174 caffe_interface.cpp:125] Batch 46, top-5 = 1
I0122 18:31:53.617844 68174 caffe_interface.cpp:125] Batch 47, accuracy = 0.9
I0122 18:31:53.617853 68174 caffe_interface.cpp:125] Batch 47, loss = 0.473608
I0122 18:31:53.617857 68174 caffe_interface.cpp:125] Batch 47, top-1 = 0.9
I0122 18:31:53.617861 68174 caffe_interface.cpp:125] Batch 47, top-5 = 0.98
I0122 18:31:53.625803 68174 caffe_interface.cpp:125] Batch 48, accuracy = 0.9
I0122 18:31:53.625813 68174 caffe_interface.cpp:125] Batch 48, loss = 0.234541
I0122 18:31:53.625815 68174 caffe_interface.cpp:125] Batch 48, top-1 = 0.9
I0122 18:31:53.625818 68174 caffe_interface.cpp:125] Batch 48, top-5 = 1
I0122 18:31:53.634620 68174 caffe_interface.cpp:125] Batch 49, accuracy = 0.88
I0122 18:31:53.634629 68174 caffe_interface.cpp:125] Batch 49, loss = 0.366409
I0122 18:31:53.634632 68174 caffe_interface.cpp:125] Batch 49, top-1 = 0.88
I0122 18:31:53.634634 68174 caffe_interface.cpp:125] Batch 49, top-5 = 1
I0122 18:31:53.642597 68174 caffe_interface.cpp:125] Batch 50, accuracy = 0.9
I0122 18:31:53.642606 68174 caffe_interface.cpp:125] Batch 50, loss = 0.394422
I0122 18:31:53.642609 68174 caffe_interface.cpp:125] Batch 50, top-1 = 0.9
I0122 18:31:53.642612 68174 caffe_interface.cpp:125] Batch 50, top-5 = 1
I0122 18:31:53.650552 68174 caffe_interface.cpp:125] Batch 51, accuracy = 0.96
I0122 18:31:53.650562 68174 caffe_interface.cpp:125] Batch 51, loss = 0.095024
I0122 18:31:53.650565 68174 caffe_interface.cpp:125] Batch 51, top-1 = 0.96
I0122 18:31:53.650568 68174 caffe_interface.cpp:125] Batch 51, top-5 = 1
I0122 18:31:53.658550 68174 caffe_interface.cpp:125] Batch 52, accuracy = 0.88
I0122 18:31:53.658558 68174 caffe_interface.cpp:125] Batch 52, loss = 0.515182
I0122 18:31:53.658561 68174 caffe_interface.cpp:125] Batch 52, top-1 = 0.88
I0122 18:31:53.658565 68174 caffe_interface.cpp:125] Batch 52, top-5 = 1
I0122 18:31:53.667548 68174 caffe_interface.cpp:125] Batch 53, accuracy = 0.86
I0122 18:31:53.667557 68174 caffe_interface.cpp:125] Batch 53, loss = 0.495143
I0122 18:31:53.667560 68174 caffe_interface.cpp:125] Batch 53, top-1 = 0.86
I0122 18:31:53.667563 68174 caffe_interface.cpp:125] Batch 53, top-5 = 1
I0122 18:31:53.675534 68174 caffe_interface.cpp:125] Batch 54, accuracy = 0.92
I0122 18:31:53.675544 68174 caffe_interface.cpp:125] Batch 54, loss = 0.402533
I0122 18:31:53.675546 68174 caffe_interface.cpp:125] Batch 54, top-1 = 0.92
I0122 18:31:53.675549 68174 caffe_interface.cpp:125] Batch 54, top-5 = 1
I0122 18:31:53.683501 68174 caffe_interface.cpp:125] Batch 55, accuracy = 0.88
I0122 18:31:53.683511 68174 caffe_interface.cpp:125] Batch 55, loss = 0.393275
I0122 18:31:53.683514 68174 caffe_interface.cpp:125] Batch 55, top-1 = 0.88
I0122 18:31:53.683516 68174 caffe_interface.cpp:125] Batch 55, top-5 = 1
I0122 18:31:53.691437 68174 caffe_interface.cpp:125] Batch 56, accuracy = 0.88
I0122 18:31:53.691445 68174 caffe_interface.cpp:125] Batch 56, loss = 0.485032
I0122 18:31:53.691449 68174 caffe_interface.cpp:125] Batch 56, top-1 = 0.88
I0122 18:31:53.691452 68174 caffe_interface.cpp:125] Batch 56, top-5 = 0.98
I0122 18:31:53.700482 68174 caffe_interface.cpp:125] Batch 57, accuracy = 0.9
I0122 18:31:53.700490 68174 caffe_interface.cpp:125] Batch 57, loss = 0.275216
I0122 18:31:53.700495 68174 caffe_interface.cpp:125] Batch 57, top-1 = 0.9
I0122 18:31:53.700497 68174 caffe_interface.cpp:125] Batch 57, top-5 = 1
I0122 18:31:53.708436 68174 caffe_interface.cpp:125] Batch 58, accuracy = 0.9
I0122 18:31:53.708446 68174 caffe_interface.cpp:125] Batch 58, loss = 0.308424
I0122 18:31:53.708449 68174 caffe_interface.cpp:125] Batch 58, top-1 = 0.9
I0122 18:31:53.708452 68174 caffe_interface.cpp:125] Batch 58, top-5 = 1
I0122 18:31:53.716420 68174 caffe_interface.cpp:125] Batch 59, accuracy = 0.92
I0122 18:31:53.716430 68174 caffe_interface.cpp:125] Batch 59, loss = 0.192517
I0122 18:31:53.716434 68174 caffe_interface.cpp:125] Batch 59, top-1 = 0.92
I0122 18:31:53.716436 68174 caffe_interface.cpp:125] Batch 59, top-5 = 1
I0122 18:31:53.724356 68174 caffe_interface.cpp:125] Batch 60, accuracy = 0.88
I0122 18:31:53.724365 68174 caffe_interface.cpp:125] Batch 60, loss = 0.266444
I0122 18:31:53.724369 68174 caffe_interface.cpp:125] Batch 60, top-1 = 0.88
I0122 18:31:53.724371 68174 caffe_interface.cpp:125] Batch 60, top-5 = 1
I0122 18:31:53.733435 68174 caffe_interface.cpp:125] Batch 61, accuracy = 0.86
I0122 18:31:53.733444 68174 caffe_interface.cpp:125] Batch 61, loss = 0.569067
I0122 18:31:53.733448 68174 caffe_interface.cpp:125] Batch 61, top-1 = 0.86
I0122 18:31:53.733451 68174 caffe_interface.cpp:125] Batch 61, top-5 = 1
I0122 18:31:53.741385 68174 caffe_interface.cpp:125] Batch 62, accuracy = 0.82
I0122 18:31:53.741394 68174 caffe_interface.cpp:125] Batch 62, loss = 0.642491
I0122 18:31:53.741397 68174 caffe_interface.cpp:125] Batch 62, top-1 = 0.82
I0122 18:31:53.741400 68174 caffe_interface.cpp:125] Batch 62, top-5 = 1
I0122 18:31:53.749313 68174 caffe_interface.cpp:125] Batch 63, accuracy = 0.92
I0122 18:31:53.749322 68174 caffe_interface.cpp:125] Batch 63, loss = 0.22783
I0122 18:31:53.749326 68174 caffe_interface.cpp:125] Batch 63, top-1 = 0.92
I0122 18:31:53.749330 68174 caffe_interface.cpp:125] Batch 63, top-5 = 1
I0122 18:31:53.757252 68174 caffe_interface.cpp:125] Batch 64, accuracy = 0.88
I0122 18:31:53.757261 68174 caffe_interface.cpp:125] Batch 64, loss = 0.446845
I0122 18:31:53.757266 68174 caffe_interface.cpp:125] Batch 64, top-1 = 0.88
I0122 18:31:53.757268 68174 caffe_interface.cpp:125] Batch 64, top-5 = 1
I0122 18:31:53.766281 68174 caffe_interface.cpp:125] Batch 65, accuracy = 0.9
I0122 18:31:53.766289 68174 caffe_interface.cpp:125] Batch 65, loss = 0.154286
I0122 18:31:53.766293 68174 caffe_interface.cpp:125] Batch 65, top-1 = 0.9
I0122 18:31:53.766294 68174 caffe_interface.cpp:125] Batch 65, top-5 = 1
I0122 18:31:53.774264 68174 caffe_interface.cpp:125] Batch 66, accuracy = 0.9
I0122 18:31:53.774273 68174 caffe_interface.cpp:125] Batch 66, loss = 0.345984
I0122 18:31:53.774276 68174 caffe_interface.cpp:125] Batch 66, top-1 = 0.9
I0122 18:31:53.774279 68174 caffe_interface.cpp:125] Batch 66, top-5 = 1
I0122 18:31:53.782223 68174 caffe_interface.cpp:125] Batch 67, accuracy = 0.9
I0122 18:31:53.782233 68174 caffe_interface.cpp:125] Batch 67, loss = 0.546761
I0122 18:31:53.782238 68174 caffe_interface.cpp:125] Batch 67, top-1 = 0.9
I0122 18:31:53.782239 68174 caffe_interface.cpp:125] Batch 67, top-5 = 0.98
I0122 18:31:53.790158 68174 caffe_interface.cpp:125] Batch 68, accuracy = 0.92
I0122 18:31:53.790166 68174 caffe_interface.cpp:125] Batch 68, loss = 0.229299
I0122 18:31:53.790169 68174 caffe_interface.cpp:125] Batch 68, top-1 = 0.92
I0122 18:31:53.790172 68174 caffe_interface.cpp:125] Batch 68, top-5 = 1
I0122 18:31:53.799172 68174 caffe_interface.cpp:125] Batch 69, accuracy = 0.94
I0122 18:31:53.799180 68174 caffe_interface.cpp:125] Batch 69, loss = 0.241759
I0122 18:31:53.799182 68174 caffe_interface.cpp:125] Batch 69, top-1 = 0.94
I0122 18:31:53.799185 68174 caffe_interface.cpp:125] Batch 69, top-5 = 1
I0122 18:31:53.807075 68174 caffe_interface.cpp:125] Batch 70, accuracy = 0.92
I0122 18:31:53.807082 68174 caffe_interface.cpp:125] Batch 70, loss = 0.296835
I0122 18:31:53.807085 68174 caffe_interface.cpp:125] Batch 70, top-1 = 0.92
I0122 18:31:53.807087 68174 caffe_interface.cpp:125] Batch 70, top-5 = 1
I0122 18:31:53.814993 68174 caffe_interface.cpp:125] Batch 71, accuracy = 0.86
I0122 18:31:53.815002 68174 caffe_interface.cpp:125] Batch 71, loss = 0.47187
I0122 18:31:53.815004 68174 caffe_interface.cpp:125] Batch 71, top-1 = 0.86
I0122 18:31:53.815007 68174 caffe_interface.cpp:125] Batch 71, top-5 = 1
I0122 18:31:53.822964 68174 caffe_interface.cpp:125] Batch 72, accuracy = 0.84
I0122 18:31:53.822984 68174 caffe_interface.cpp:125] Batch 72, loss = 0.648658
I0122 18:31:53.822988 68174 caffe_interface.cpp:125] Batch 72, top-1 = 0.84
I0122 18:31:53.822990 68174 caffe_interface.cpp:125] Batch 72, top-5 = 0.98
I0122 18:31:53.832016 68174 caffe_interface.cpp:125] Batch 73, accuracy = 0.92
I0122 18:31:53.832026 68174 caffe_interface.cpp:125] Batch 73, loss = 0.541203
I0122 18:31:53.832029 68174 caffe_interface.cpp:125] Batch 73, top-1 = 0.92
I0122 18:31:53.832031 68174 caffe_interface.cpp:125] Batch 73, top-5 = 1
I0122 18:31:53.839957 68174 caffe_interface.cpp:125] Batch 74, accuracy = 0.84
I0122 18:31:53.839967 68174 caffe_interface.cpp:125] Batch 74, loss = 0.588569
I0122 18:31:53.839969 68174 caffe_interface.cpp:125] Batch 74, top-1 = 0.84
I0122 18:31:53.839972 68174 caffe_interface.cpp:125] Batch 74, top-5 = 1
I0122 18:31:53.847899 68174 caffe_interface.cpp:125] Batch 75, accuracy = 0.9
I0122 18:31:53.847909 68174 caffe_interface.cpp:125] Batch 75, loss = 0.413374
I0122 18:31:53.847913 68174 caffe_interface.cpp:125] Batch 75, top-1 = 0.9
I0122 18:31:53.847914 68174 caffe_interface.cpp:125] Batch 75, top-5 = 1
I0122 18:31:53.855859 68174 caffe_interface.cpp:125] Batch 76, accuracy = 0.88
I0122 18:31:53.855867 68174 caffe_interface.cpp:125] Batch 76, loss = 0.484759
I0122 18:31:53.855870 68174 caffe_interface.cpp:125] Batch 76, top-1 = 0.88
I0122 18:31:53.855873 68174 caffe_interface.cpp:125] Batch 76, top-5 = 0.98
I0122 18:31:53.864848 68174 caffe_interface.cpp:125] Batch 77, accuracy = 0.88
I0122 18:31:53.864856 68174 caffe_interface.cpp:125] Batch 77, loss = 0.349547
I0122 18:31:53.864858 68174 caffe_interface.cpp:125] Batch 77, top-1 = 0.88
I0122 18:31:53.864861 68174 caffe_interface.cpp:125] Batch 77, top-5 = 0.98
I0122 18:31:53.873023 68174 caffe_interface.cpp:125] Batch 78, accuracy = 0.96
I0122 18:31:53.873030 68174 caffe_interface.cpp:125] Batch 78, loss = 0.176085
I0122 18:31:53.873033 68174 caffe_interface.cpp:125] Batch 78, top-1 = 0.96
I0122 18:31:53.873035 68174 caffe_interface.cpp:125] Batch 78, top-5 = 1
I0122 18:31:53.881314 68174 caffe_interface.cpp:125] Batch 79, accuracy = 0.9
I0122 18:31:53.881322 68174 caffe_interface.cpp:125] Batch 79, loss = 0.282982
I0122 18:31:53.881325 68174 caffe_interface.cpp:125] Batch 79, top-1 = 0.9
I0122 18:31:53.881327 68174 caffe_interface.cpp:125] Batch 79, top-5 = 1
I0122 18:31:53.889269 68174 caffe_interface.cpp:125] Batch 80, accuracy = 0.96
I0122 18:31:53.889277 68174 caffe_interface.cpp:125] Batch 80, loss = 0.0960914
I0122 18:31:53.889281 68174 caffe_interface.cpp:125] Batch 80, top-1 = 0.96
I0122 18:31:53.889282 68174 caffe_interface.cpp:125] Batch 80, top-5 = 1
I0122 18:31:53.898331 68174 caffe_interface.cpp:125] Batch 81, accuracy = 0.9
I0122 18:31:53.898341 68174 caffe_interface.cpp:125] Batch 81, loss = 0.49778
I0122 18:31:53.898344 68174 caffe_interface.cpp:125] Batch 81, top-1 = 0.9
I0122 18:31:53.898346 68174 caffe_interface.cpp:125] Batch 81, top-5 = 1
I0122 18:31:53.906282 68174 caffe_interface.cpp:125] Batch 82, accuracy = 0.88
I0122 18:31:53.906291 68174 caffe_interface.cpp:125] Batch 82, loss = 0.380441
I0122 18:31:53.906293 68174 caffe_interface.cpp:125] Batch 82, top-1 = 0.88
I0122 18:31:53.906296 68174 caffe_interface.cpp:125] Batch 82, top-5 = 0.98
I0122 18:31:53.914228 68174 caffe_interface.cpp:125] Batch 83, accuracy = 0.86
I0122 18:31:53.914237 68174 caffe_interface.cpp:125] Batch 83, loss = 0.326336
I0122 18:31:53.914240 68174 caffe_interface.cpp:125] Batch 83, top-1 = 0.86
I0122 18:31:53.914243 68174 caffe_interface.cpp:125] Batch 83, top-5 = 1
I0122 18:31:53.922173 68174 caffe_interface.cpp:125] Batch 84, accuracy = 0.86
I0122 18:31:53.922181 68174 caffe_interface.cpp:125] Batch 84, loss = 0.418865
I0122 18:31:53.922184 68174 caffe_interface.cpp:125] Batch 84, top-1 = 0.86
I0122 18:31:53.922188 68174 caffe_interface.cpp:125] Batch 84, top-5 = 0.98
I0122 18:31:53.931169 68174 caffe_interface.cpp:125] Batch 85, accuracy = 0.94
I0122 18:31:53.931177 68174 caffe_interface.cpp:125] Batch 85, loss = 0.299732
I0122 18:31:53.931180 68174 caffe_interface.cpp:125] Batch 85, top-1 = 0.94
I0122 18:31:53.931192 68174 caffe_interface.cpp:125] Batch 85, top-5 = 1
I0122 18:31:53.939118 68174 caffe_interface.cpp:125] Batch 86, accuracy = 0.88
I0122 18:31:53.939127 68174 caffe_interface.cpp:125] Batch 86, loss = 0.30015
I0122 18:31:53.939131 68174 caffe_interface.cpp:125] Batch 86, top-1 = 0.88
I0122 18:31:53.939133 68174 caffe_interface.cpp:125] Batch 86, top-5 = 1
I0122 18:31:53.947062 68174 caffe_interface.cpp:125] Batch 87, accuracy = 0.92
I0122 18:31:53.947072 68174 caffe_interface.cpp:125] Batch 87, loss = 0.189298
I0122 18:31:53.947075 68174 caffe_interface.cpp:125] Batch 87, top-1 = 0.92
I0122 18:31:53.947078 68174 caffe_interface.cpp:125] Batch 87, top-5 = 1
I0122 18:31:53.955003 68174 caffe_interface.cpp:125] Batch 88, accuracy = 0.9
I0122 18:31:53.955011 68174 caffe_interface.cpp:125] Batch 88, loss = 0.325817
I0122 18:31:53.955014 68174 caffe_interface.cpp:125] Batch 88, top-1 = 0.9
I0122 18:31:53.955018 68174 caffe_interface.cpp:125] Batch 88, top-5 = 1
I0122 18:31:53.964041 68174 caffe_interface.cpp:125] Batch 89, accuracy = 0.92
I0122 18:31:53.964051 68174 caffe_interface.cpp:125] Batch 89, loss = 0.313704
I0122 18:31:53.964052 68174 caffe_interface.cpp:125] Batch 89, top-1 = 0.92
I0122 18:31:53.964054 68174 caffe_interface.cpp:125] Batch 89, top-5 = 1
I0122 18:31:53.971948 68174 caffe_interface.cpp:125] Batch 90, accuracy = 0.86
I0122 18:31:53.971956 68174 caffe_interface.cpp:125] Batch 90, loss = 0.477957
I0122 18:31:53.971959 68174 caffe_interface.cpp:125] Batch 90, top-1 = 0.86
I0122 18:31:53.971961 68174 caffe_interface.cpp:125] Batch 90, top-5 = 0.98
I0122 18:31:53.979874 68174 caffe_interface.cpp:125] Batch 91, accuracy = 0.84
I0122 18:31:53.979883 68174 caffe_interface.cpp:125] Batch 91, loss = 0.335734
I0122 18:31:53.979887 68174 caffe_interface.cpp:125] Batch 91, top-1 = 0.84
I0122 18:31:53.979888 68174 caffe_interface.cpp:125] Batch 91, top-5 = 1
I0122 18:31:53.987824 68174 caffe_interface.cpp:125] Batch 92, accuracy = 0.86
I0122 18:31:53.987833 68174 caffe_interface.cpp:125] Batch 92, loss = 0.505752
I0122 18:31:53.987836 68174 caffe_interface.cpp:125] Batch 92, top-1 = 0.86
I0122 18:31:53.987839 68174 caffe_interface.cpp:125] Batch 92, top-5 = 0.96
I0122 18:31:53.995790 68174 caffe_interface.cpp:125] Batch 93, accuracy = 0.9
I0122 18:31:53.995800 68174 caffe_interface.cpp:125] Batch 93, loss = 0.366325
I0122 18:31:53.995803 68174 caffe_interface.cpp:125] Batch 93, top-1 = 0.9
I0122 18:31:53.995806 68174 caffe_interface.cpp:125] Batch 93, top-5 = 0.98
I0122 18:31:54.004613 68174 caffe_interface.cpp:125] Batch 94, accuracy = 0.78
I0122 18:31:54.004621 68174 caffe_interface.cpp:125] Batch 94, loss = 0.587008
I0122 18:31:54.004624 68174 caffe_interface.cpp:125] Batch 94, top-1 = 0.78
I0122 18:31:54.004626 68174 caffe_interface.cpp:125] Batch 94, top-5 = 1
I0122 18:31:54.012536 68174 caffe_interface.cpp:125] Batch 95, accuracy = 0.96
I0122 18:31:54.012543 68174 caffe_interface.cpp:125] Batch 95, loss = 0.161573
I0122 18:31:54.012547 68174 caffe_interface.cpp:125] Batch 95, top-1 = 0.96
I0122 18:31:54.012548 68174 caffe_interface.cpp:125] Batch 95, top-5 = 1
I0122 18:31:54.020450 68174 caffe_interface.cpp:125] Batch 96, accuracy = 0.8
I0122 18:31:54.020458 68174 caffe_interface.cpp:125] Batch 96, loss = 0.795473
I0122 18:31:54.020462 68174 caffe_interface.cpp:125] Batch 96, top-1 = 0.8
I0122 18:31:54.020464 68174 caffe_interface.cpp:125] Batch 96, top-5 = 0.96
I0122 18:31:54.028352 68174 caffe_interface.cpp:125] Batch 97, accuracy = 0.86
I0122 18:31:54.028360 68174 caffe_interface.cpp:125] Batch 97, loss = 0.458979
I0122 18:31:54.028363 68174 caffe_interface.cpp:125] Batch 97, top-1 = 0.86
I0122 18:31:54.028365 68174 caffe_interface.cpp:125] Batch 97, top-5 = 1
I0122 18:31:54.037400 68174 caffe_interface.cpp:125] Batch 98, accuracy = 0.94
I0122 18:31:54.037408 68174 caffe_interface.cpp:125] Batch 98, loss = 0.23502
I0122 18:31:54.037410 68174 caffe_interface.cpp:125] Batch 98, top-1 = 0.94
I0122 18:31:54.037413 68174 caffe_interface.cpp:125] Batch 98, top-5 = 1
I0122 18:31:54.045339 68174 caffe_interface.cpp:125] Batch 99, accuracy = 0.86
I0122 18:31:54.045349 68174 caffe_interface.cpp:125] Batch 99, loss = 0.401867
I0122 18:31:54.045352 68174 caffe_interface.cpp:125] Batch 99, top-1 = 0.86
I0122 18:31:54.045356 68174 caffe_interface.cpp:125] Batch 99, top-5 = 1
I0122 18:31:54.053293 68174 caffe_interface.cpp:125] Batch 100, accuracy = 0.94
I0122 18:31:54.053303 68174 caffe_interface.cpp:125] Batch 100, loss = 0.224726
I0122 18:31:54.053306 68174 caffe_interface.cpp:125] Batch 100, top-1 = 0.94
I0122 18:31:54.053309 68174 caffe_interface.cpp:125] Batch 100, top-5 = 1
I0122 18:31:54.061254 68174 caffe_interface.cpp:125] Batch 101, accuracy = 0.88
I0122 18:31:54.061264 68174 caffe_interface.cpp:125] Batch 101, loss = 0.51782
I0122 18:31:54.061269 68174 caffe_interface.cpp:125] Batch 101, top-1 = 0.88
I0122 18:31:54.061270 68174 caffe_interface.cpp:125] Batch 101, top-5 = 0.98
I0122 18:31:54.070308 68174 caffe_interface.cpp:125] Batch 102, accuracy = 0.82
I0122 18:31:54.070317 68174 caffe_interface.cpp:125] Batch 102, loss = 0.530001
I0122 18:31:54.070322 68174 caffe_interface.cpp:125] Batch 102, top-1 = 0.82
I0122 18:31:54.070323 68174 caffe_interface.cpp:125] Batch 102, top-5 = 0.98
I0122 18:31:54.078269 68174 caffe_interface.cpp:125] Batch 103, accuracy = 0.9
I0122 18:31:54.078279 68174 caffe_interface.cpp:125] Batch 103, loss = 0.190654
I0122 18:31:54.078282 68174 caffe_interface.cpp:125] Batch 103, top-1 = 0.9
I0122 18:31:54.078284 68174 caffe_interface.cpp:125] Batch 103, top-5 = 1
I0122 18:31:54.086242 68174 caffe_interface.cpp:125] Batch 104, accuracy = 0.9
I0122 18:31:54.086251 68174 caffe_interface.cpp:125] Batch 104, loss = 0.276656
I0122 18:31:54.086256 68174 caffe_interface.cpp:125] Batch 104, top-1 = 0.9
I0122 18:31:54.086258 68174 caffe_interface.cpp:125] Batch 104, top-5 = 1
I0122 18:31:54.094213 68174 caffe_interface.cpp:125] Batch 105, accuracy = 0.9
I0122 18:31:54.094221 68174 caffe_interface.cpp:125] Batch 105, loss = 0.2572
I0122 18:31:54.094225 68174 caffe_interface.cpp:125] Batch 105, top-1 = 0.9
I0122 18:31:54.094228 68174 caffe_interface.cpp:125] Batch 105, top-5 = 1
I0122 18:31:54.103235 68174 caffe_interface.cpp:125] Batch 106, accuracy = 0.92
I0122 18:31:54.103243 68174 caffe_interface.cpp:125] Batch 106, loss = 0.222101
I0122 18:31:54.103245 68174 caffe_interface.cpp:125] Batch 106, top-1 = 0.92
I0122 18:31:54.103247 68174 caffe_interface.cpp:125] Batch 106, top-5 = 1
I0122 18:31:54.111202 68174 caffe_interface.cpp:125] Batch 107, accuracy = 0.82
I0122 18:31:54.111212 68174 caffe_interface.cpp:125] Batch 107, loss = 0.762711
I0122 18:31:54.111215 68174 caffe_interface.cpp:125] Batch 107, top-1 = 0.82
I0122 18:31:54.111218 68174 caffe_interface.cpp:125] Batch 107, top-5 = 1
I0122 18:31:54.119181 68174 caffe_interface.cpp:125] Batch 108, accuracy = 0.82
I0122 18:31:54.119190 68174 caffe_interface.cpp:125] Batch 108, loss = 0.793216
I0122 18:31:54.119194 68174 caffe_interface.cpp:125] Batch 108, top-1 = 0.82
I0122 18:31:54.119196 68174 caffe_interface.cpp:125] Batch 108, top-5 = 1
I0122 18:31:54.127135 68174 caffe_interface.cpp:125] Batch 109, accuracy = 0.86
I0122 18:31:54.127146 68174 caffe_interface.cpp:125] Batch 109, loss = 0.495695
I0122 18:31:54.127148 68174 caffe_interface.cpp:125] Batch 109, top-1 = 0.86
I0122 18:31:54.127151 68174 caffe_interface.cpp:125] Batch 109, top-5 = 1
I0122 18:31:54.136173 68174 caffe_interface.cpp:125] Batch 110, accuracy = 0.86
I0122 18:31:54.136181 68174 caffe_interface.cpp:125] Batch 110, loss = 0.613243
I0122 18:31:54.136184 68174 caffe_interface.cpp:125] Batch 110, top-1 = 0.86
I0122 18:31:54.136188 68174 caffe_interface.cpp:125] Batch 110, top-5 = 1
I0122 18:31:54.144147 68174 caffe_interface.cpp:125] Batch 111, accuracy = 0.86
I0122 18:31:54.144156 68174 caffe_interface.cpp:125] Batch 111, loss = 0.668127
I0122 18:31:54.144160 68174 caffe_interface.cpp:125] Batch 111, top-1 = 0.86
I0122 18:31:54.144163 68174 caffe_interface.cpp:125] Batch 111, top-5 = 0.98
I0122 18:31:54.152091 68174 caffe_interface.cpp:125] Batch 112, accuracy = 0.96
I0122 18:31:54.152112 68174 caffe_interface.cpp:125] Batch 112, loss = 0.15578
I0122 18:31:54.152115 68174 caffe_interface.cpp:125] Batch 112, top-1 = 0.96
I0122 18:31:54.152118 68174 caffe_interface.cpp:125] Batch 112, top-5 = 1
I0122 18:31:54.160051 68174 caffe_interface.cpp:125] Batch 113, accuracy = 0.88
I0122 18:31:54.160061 68174 caffe_interface.cpp:125] Batch 113, loss = 0.534951
I0122 18:31:54.160064 68174 caffe_interface.cpp:125] Batch 113, top-1 = 0.88
I0122 18:31:54.160068 68174 caffe_interface.cpp:125] Batch 113, top-5 = 1
I0122 18:31:54.169100 68174 caffe_interface.cpp:125] Batch 114, accuracy = 0.78
I0122 18:31:54.169108 68174 caffe_interface.cpp:125] Batch 114, loss = 1.00814
I0122 18:31:54.169111 68174 caffe_interface.cpp:125] Batch 114, top-1 = 0.78
I0122 18:31:54.169114 68174 caffe_interface.cpp:125] Batch 114, top-5 = 1
I0122 18:31:54.177055 68174 caffe_interface.cpp:125] Batch 115, accuracy = 0.94
I0122 18:31:54.177064 68174 caffe_interface.cpp:125] Batch 115, loss = 0.316088
I0122 18:31:54.177068 68174 caffe_interface.cpp:125] Batch 115, top-1 = 0.94
I0122 18:31:54.177072 68174 caffe_interface.cpp:125] Batch 115, top-5 = 1
I0122 18:31:54.185005 68174 caffe_interface.cpp:125] Batch 116, accuracy = 0.84
I0122 18:31:54.185014 68174 caffe_interface.cpp:125] Batch 116, loss = 0.486055
I0122 18:31:54.185019 68174 caffe_interface.cpp:125] Batch 116, top-1 = 0.84
I0122 18:31:54.185021 68174 caffe_interface.cpp:125] Batch 116, top-5 = 1
I0122 18:31:54.192950 68174 caffe_interface.cpp:125] Batch 117, accuracy = 0.9
I0122 18:31:54.192958 68174 caffe_interface.cpp:125] Batch 117, loss = 0.470628
I0122 18:31:54.192962 68174 caffe_interface.cpp:125] Batch 117, top-1 = 0.9
I0122 18:31:54.192965 68174 caffe_interface.cpp:125] Batch 117, top-5 = 1
I0122 18:31:54.201982 68174 caffe_interface.cpp:125] Batch 118, accuracy = 0.92
I0122 18:31:54.201990 68174 caffe_interface.cpp:125] Batch 118, loss = 0.369625
I0122 18:31:54.201993 68174 caffe_interface.cpp:125] Batch 118, top-1 = 0.92
I0122 18:31:54.201997 68174 caffe_interface.cpp:125] Batch 118, top-5 = 0.98
I0122 18:31:54.209931 68174 caffe_interface.cpp:125] Batch 119, accuracy = 0.82
I0122 18:31:54.209940 68174 caffe_interface.cpp:125] Batch 119, loss = 0.55112
I0122 18:31:54.209944 68174 caffe_interface.cpp:125] Batch 119, top-1 = 0.82
I0122 18:31:54.209946 68174 caffe_interface.cpp:125] Batch 119, top-5 = 1
I0122 18:31:54.217882 68174 caffe_interface.cpp:125] Batch 120, accuracy = 0.9
I0122 18:31:54.217891 68174 caffe_interface.cpp:125] Batch 120, loss = 0.318814
I0122 18:31:54.217895 68174 caffe_interface.cpp:125] Batch 120, top-1 = 0.9
I0122 18:31:54.217897 68174 caffe_interface.cpp:125] Batch 120, top-5 = 1
I0122 18:31:54.225841 68174 caffe_interface.cpp:125] Batch 121, accuracy = 0.8
I0122 18:31:54.225852 68174 caffe_interface.cpp:125] Batch 121, loss = 0.830765
I0122 18:31:54.225854 68174 caffe_interface.cpp:125] Batch 121, top-1 = 0.8
I0122 18:31:54.225857 68174 caffe_interface.cpp:125] Batch 121, top-5 = 0.98
I0122 18:31:54.234872 68174 caffe_interface.cpp:125] Batch 122, accuracy = 0.96
I0122 18:31:54.234881 68174 caffe_interface.cpp:125] Batch 122, loss = 0.090492
I0122 18:31:54.234885 68174 caffe_interface.cpp:125] Batch 122, top-1 = 0.96
I0122 18:31:54.234887 68174 caffe_interface.cpp:125] Batch 122, top-5 = 1
I0122 18:31:54.242851 68174 caffe_interface.cpp:125] Batch 123, accuracy = 0.92
I0122 18:31:54.242861 68174 caffe_interface.cpp:125] Batch 123, loss = 0.443426
I0122 18:31:54.242863 68174 caffe_interface.cpp:125] Batch 123, top-1 = 0.92
I0122 18:31:54.242866 68174 caffe_interface.cpp:125] Batch 123, top-5 = 0.96
I0122 18:31:54.250804 68174 caffe_interface.cpp:125] Batch 124, accuracy = 0.92
I0122 18:31:54.250813 68174 caffe_interface.cpp:125] Batch 124, loss = 0.143889
I0122 18:31:54.250818 68174 caffe_interface.cpp:125] Batch 124, top-1 = 0.92
I0122 18:31:54.250820 68174 caffe_interface.cpp:125] Batch 124, top-5 = 1
I0122 18:31:54.258729 68174 caffe_interface.cpp:125] Batch 125, accuracy = 0.9
I0122 18:31:54.258746 68174 caffe_interface.cpp:125] Batch 125, loss = 0.458767
I0122 18:31:54.258749 68174 caffe_interface.cpp:125] Batch 125, top-1 = 0.9
I0122 18:31:54.258751 68174 caffe_interface.cpp:125] Batch 125, top-5 = 1
I0122 18:31:54.267760 68174 caffe_interface.cpp:125] Batch 126, accuracy = 0.86
I0122 18:31:54.267768 68174 caffe_interface.cpp:125] Batch 126, loss = 0.472491
I0122 18:31:54.267771 68174 caffe_interface.cpp:125] Batch 126, top-1 = 0.86
I0122 18:31:54.267774 68174 caffe_interface.cpp:125] Batch 126, top-5 = 1
I0122 18:31:54.275741 68174 caffe_interface.cpp:125] Batch 127, accuracy = 0.94
I0122 18:31:54.275751 68174 caffe_interface.cpp:125] Batch 127, loss = 0.128541
I0122 18:31:54.275755 68174 caffe_interface.cpp:125] Batch 127, top-1 = 0.94
I0122 18:31:54.275758 68174 caffe_interface.cpp:125] Batch 127, top-5 = 1
I0122 18:31:54.283720 68174 caffe_interface.cpp:125] Batch 128, accuracy = 0.88
I0122 18:31:54.283730 68174 caffe_interface.cpp:125] Batch 128, loss = 0.375513
I0122 18:31:54.283732 68174 caffe_interface.cpp:125] Batch 128, top-1 = 0.88
I0122 18:31:54.283735 68174 caffe_interface.cpp:125] Batch 128, top-5 = 1
I0122 18:31:54.291656 68174 caffe_interface.cpp:125] Batch 129, accuracy = 0.82
I0122 18:31:54.291666 68174 caffe_interface.cpp:125] Batch 129, loss = 0.641645
I0122 18:31:54.291668 68174 caffe_interface.cpp:125] Batch 129, top-1 = 0.82
I0122 18:31:54.291671 68174 caffe_interface.cpp:125] Batch 129, top-5 = 1
I0122 18:31:54.300689 68174 caffe_interface.cpp:125] Batch 130, accuracy = 0.86
I0122 18:31:54.300698 68174 caffe_interface.cpp:125] Batch 130, loss = 0.494916
I0122 18:31:54.300701 68174 caffe_interface.cpp:125] Batch 130, top-1 = 0.86
I0122 18:31:54.300704 68174 caffe_interface.cpp:125] Batch 130, top-5 = 1
I0122 18:31:54.308647 68174 caffe_interface.cpp:125] Batch 131, accuracy = 0.84
I0122 18:31:54.308656 68174 caffe_interface.cpp:125] Batch 131, loss = 0.591055
I0122 18:31:54.308660 68174 caffe_interface.cpp:125] Batch 131, top-1 = 0.84
I0122 18:31:54.308662 68174 caffe_interface.cpp:125] Batch 131, top-5 = 0.98
I0122 18:31:54.316606 68174 caffe_interface.cpp:125] Batch 132, accuracy = 0.82
I0122 18:31:54.316615 68174 caffe_interface.cpp:125] Batch 132, loss = 0.768594
I0122 18:31:54.316618 68174 caffe_interface.cpp:125] Batch 132, top-1 = 0.82
I0122 18:31:54.316622 68174 caffe_interface.cpp:125] Batch 132, top-5 = 0.98
I0122 18:31:54.324563 68174 caffe_interface.cpp:125] Batch 133, accuracy = 0.9
I0122 18:31:54.324573 68174 caffe_interface.cpp:125] Batch 133, loss = 0.324904
I0122 18:31:54.324575 68174 caffe_interface.cpp:125] Batch 133, top-1 = 0.9
I0122 18:31:54.324579 68174 caffe_interface.cpp:125] Batch 133, top-5 = 1
I0122 18:31:54.333612 68174 caffe_interface.cpp:125] Batch 134, accuracy = 0.88
I0122 18:31:54.333622 68174 caffe_interface.cpp:125] Batch 134, loss = 0.64519
I0122 18:31:54.333626 68174 caffe_interface.cpp:125] Batch 134, top-1 = 0.88
I0122 18:31:54.333628 68174 caffe_interface.cpp:125] Batch 134, top-5 = 1
I0122 18:31:54.341555 68174 caffe_interface.cpp:125] Batch 135, accuracy = 0.84
I0122 18:31:54.341564 68174 caffe_interface.cpp:125] Batch 135, loss = 0.871109
I0122 18:31:54.341568 68174 caffe_interface.cpp:125] Batch 135, top-1 = 0.84
I0122 18:31:54.341572 68174 caffe_interface.cpp:125] Batch 135, top-5 = 1
I0122 18:31:54.349500 68174 caffe_interface.cpp:125] Batch 136, accuracy = 0.94
I0122 18:31:54.349509 68174 caffe_interface.cpp:125] Batch 136, loss = 0.122773
I0122 18:31:54.349514 68174 caffe_interface.cpp:125] Batch 136, top-1 = 0.94
I0122 18:31:54.349516 68174 caffe_interface.cpp:125] Batch 136, top-5 = 1
I0122 18:31:54.357435 68174 caffe_interface.cpp:125] Batch 137, accuracy = 0.94
I0122 18:31:54.357445 68174 caffe_interface.cpp:125] Batch 137, loss = 0.2558
I0122 18:31:54.357447 68174 caffe_interface.cpp:125] Batch 137, top-1 = 0.94
I0122 18:31:54.357450 68174 caffe_interface.cpp:125] Batch 137, top-5 = 1
I0122 18:31:54.366441 68174 caffe_interface.cpp:125] Batch 138, accuracy = 0.88
I0122 18:31:54.366449 68174 caffe_interface.cpp:125] Batch 138, loss = 0.659286
I0122 18:31:54.366461 68174 caffe_interface.cpp:125] Batch 138, top-1 = 0.88
I0122 18:31:54.366463 68174 caffe_interface.cpp:125] Batch 138, top-5 = 0.98
I0122 18:31:54.374411 68174 caffe_interface.cpp:125] Batch 139, accuracy = 0.8
I0122 18:31:54.374420 68174 caffe_interface.cpp:125] Batch 139, loss = 0.548724
I0122 18:31:54.374423 68174 caffe_interface.cpp:125] Batch 139, top-1 = 0.8
I0122 18:31:54.374426 68174 caffe_interface.cpp:125] Batch 139, top-5 = 0.98
I0122 18:31:54.382370 68174 caffe_interface.cpp:125] Batch 140, accuracy = 0.88
I0122 18:31:54.382380 68174 caffe_interface.cpp:125] Batch 140, loss = 0.745965
I0122 18:31:54.382385 68174 caffe_interface.cpp:125] Batch 140, top-1 = 0.88
I0122 18:31:54.382387 68174 caffe_interface.cpp:125] Batch 140, top-5 = 1
I0122 18:31:54.390334 68174 caffe_interface.cpp:125] Batch 141, accuracy = 0.9
I0122 18:31:54.390344 68174 caffe_interface.cpp:125] Batch 141, loss = 0.338585
I0122 18:31:54.390347 68174 caffe_interface.cpp:125] Batch 141, top-1 = 0.9
I0122 18:31:54.390350 68174 caffe_interface.cpp:125] Batch 141, top-5 = 1
I0122 18:31:54.399376 68174 caffe_interface.cpp:125] Batch 142, accuracy = 0.94
I0122 18:31:54.399385 68174 caffe_interface.cpp:125] Batch 142, loss = 0.181745
I0122 18:31:54.399389 68174 caffe_interface.cpp:125] Batch 142, top-1 = 0.94
I0122 18:31:54.399391 68174 caffe_interface.cpp:125] Batch 142, top-5 = 1
I0122 18:31:54.407335 68174 caffe_interface.cpp:125] Batch 143, accuracy = 0.84
I0122 18:31:54.407346 68174 caffe_interface.cpp:125] Batch 143, loss = 0.479449
I0122 18:31:54.407349 68174 caffe_interface.cpp:125] Batch 143, top-1 = 0.84
I0122 18:31:54.407351 68174 caffe_interface.cpp:125] Batch 143, top-5 = 1
I0122 18:31:54.415302 68174 caffe_interface.cpp:125] Batch 144, accuracy = 0.94
I0122 18:31:54.415310 68174 caffe_interface.cpp:125] Batch 144, loss = 0.177662
I0122 18:31:54.415314 68174 caffe_interface.cpp:125] Batch 144, top-1 = 0.94
I0122 18:31:54.415318 68174 caffe_interface.cpp:125] Batch 144, top-5 = 0.98
I0122 18:31:54.423259 68174 caffe_interface.cpp:125] Batch 145, accuracy = 0.88
I0122 18:31:54.423269 68174 caffe_interface.cpp:125] Batch 145, loss = 0.451713
I0122 18:31:54.423271 68174 caffe_interface.cpp:125] Batch 145, top-1 = 0.88
I0122 18:31:54.423274 68174 caffe_interface.cpp:125] Batch 145, top-5 = 1
I0122 18:31:54.432276 68174 caffe_interface.cpp:125] Batch 146, accuracy = 0.82
I0122 18:31:54.432283 68174 caffe_interface.cpp:125] Batch 146, loss = 0.835052
I0122 18:31:54.432286 68174 caffe_interface.cpp:125] Batch 146, top-1 = 0.82
I0122 18:31:54.432288 68174 caffe_interface.cpp:125] Batch 146, top-5 = 1
I0122 18:31:54.440234 68174 caffe_interface.cpp:125] Batch 147, accuracy = 0.94
I0122 18:31:54.440243 68174 caffe_interface.cpp:125] Batch 147, loss = 0.203328
I0122 18:31:54.440248 68174 caffe_interface.cpp:125] Batch 147, top-1 = 0.94
I0122 18:31:54.440249 68174 caffe_interface.cpp:125] Batch 147, top-5 = 1
I0122 18:31:54.448163 68174 caffe_interface.cpp:125] Batch 148, accuracy = 0.96
I0122 18:31:54.448173 68174 caffe_interface.cpp:125] Batch 148, loss = 0.110309
I0122 18:31:54.448175 68174 caffe_interface.cpp:125] Batch 148, top-1 = 0.96
I0122 18:31:54.448179 68174 caffe_interface.cpp:125] Batch 148, top-5 = 1
I0122 18:31:54.456141 68174 caffe_interface.cpp:125] Batch 149, accuracy = 0.94
I0122 18:31:54.456151 68174 caffe_interface.cpp:125] Batch 149, loss = 0.253972
I0122 18:31:54.456153 68174 caffe_interface.cpp:125] Batch 149, top-1 = 0.94
I0122 18:31:54.456156 68174 caffe_interface.cpp:125] Batch 149, top-5 = 1
I0122 18:31:54.465159 68174 caffe_interface.cpp:125] Batch 150, accuracy = 0.92
I0122 18:31:54.465167 68174 caffe_interface.cpp:125] Batch 150, loss = 0.18184
I0122 18:31:54.465170 68174 caffe_interface.cpp:125] Batch 150, top-1 = 0.92
I0122 18:31:54.465173 68174 caffe_interface.cpp:125] Batch 150, top-5 = 1
I0122 18:31:54.473147 68174 caffe_interface.cpp:125] Batch 151, accuracy = 0.82
I0122 18:31:54.473156 68174 caffe_interface.cpp:125] Batch 151, loss = 0.594809
I0122 18:31:54.473160 68174 caffe_interface.cpp:125] Batch 151, top-1 = 0.82
I0122 18:31:54.473173 68174 caffe_interface.cpp:125] Batch 151, top-5 = 0.98
I0122 18:31:54.481107 68174 caffe_interface.cpp:125] Batch 152, accuracy = 0.86
I0122 18:31:54.481117 68174 caffe_interface.cpp:125] Batch 152, loss = 0.468156
I0122 18:31:54.481120 68174 caffe_interface.cpp:125] Batch 152, top-1 = 0.86
I0122 18:31:54.481122 68174 caffe_interface.cpp:125] Batch 152, top-5 = 1
I0122 18:31:54.489061 68174 caffe_interface.cpp:125] Batch 153, accuracy = 0.94
I0122 18:31:54.489070 68174 caffe_interface.cpp:125] Batch 153, loss = 0.291781
I0122 18:31:54.489073 68174 caffe_interface.cpp:125] Batch 153, top-1 = 0.94
I0122 18:31:54.489076 68174 caffe_interface.cpp:125] Batch 153, top-5 = 1
I0122 18:31:54.498096 68174 caffe_interface.cpp:125] Batch 154, accuracy = 0.88
I0122 18:31:54.498105 68174 caffe_interface.cpp:125] Batch 154, loss = 0.215255
I0122 18:31:54.498106 68174 caffe_interface.cpp:125] Batch 154, top-1 = 0.88
I0122 18:31:54.498108 68174 caffe_interface.cpp:125] Batch 154, top-5 = 1
I0122 18:31:54.506006 68174 caffe_interface.cpp:125] Batch 155, accuracy = 0.96
I0122 18:31:54.506013 68174 caffe_interface.cpp:125] Batch 155, loss = 0.101457
I0122 18:31:54.506016 68174 caffe_interface.cpp:125] Batch 155, top-1 = 0.96
I0122 18:31:54.506018 68174 caffe_interface.cpp:125] Batch 155, top-5 = 1
I0122 18:31:54.513936 68174 caffe_interface.cpp:125] Batch 156, accuracy = 0.92
I0122 18:31:54.513943 68174 caffe_interface.cpp:125] Batch 156, loss = 0.205528
I0122 18:31:54.513947 68174 caffe_interface.cpp:125] Batch 156, top-1 = 0.92
I0122 18:31:54.513949 68174 caffe_interface.cpp:125] Batch 156, top-5 = 1
I0122 18:31:54.521838 68174 caffe_interface.cpp:125] Batch 157, accuracy = 0.9
I0122 18:31:54.521847 68174 caffe_interface.cpp:125] Batch 157, loss = 0.328688
I0122 18:31:54.521849 68174 caffe_interface.cpp:125] Batch 157, top-1 = 0.9
I0122 18:31:54.521852 68174 caffe_interface.cpp:125] Batch 157, top-5 = 1
I0122 18:31:54.529737 68174 caffe_interface.cpp:125] Batch 158, accuracy = 0.86
I0122 18:31:54.529747 68174 caffe_interface.cpp:125] Batch 158, loss = 0.520865
I0122 18:31:54.529748 68174 caffe_interface.cpp:125] Batch 158, top-1 = 0.86
I0122 18:31:54.529752 68174 caffe_interface.cpp:125] Batch 158, top-5 = 1
I0122 18:31:54.538581 68174 caffe_interface.cpp:125] Batch 159, accuracy = 0.88
I0122 18:31:54.538589 68174 caffe_interface.cpp:125] Batch 159, loss = 0.365203
I0122 18:31:54.538592 68174 caffe_interface.cpp:125] Batch 159, top-1 = 0.88
I0122 18:31:54.538594 68174 caffe_interface.cpp:125] Batch 159, top-5 = 0.98
I0122 18:31:54.546491 68174 caffe_interface.cpp:125] Batch 160, accuracy = 0.88
I0122 18:31:54.546499 68174 caffe_interface.cpp:125] Batch 160, loss = 0.371962
I0122 18:31:54.546502 68174 caffe_interface.cpp:125] Batch 160, top-1 = 0.88
I0122 18:31:54.546504 68174 caffe_interface.cpp:125] Batch 160, top-5 = 1
I0122 18:31:54.554466 68174 caffe_interface.cpp:125] Batch 161, accuracy = 0.88
I0122 18:31:54.554474 68174 caffe_interface.cpp:125] Batch 161, loss = 0.470224
I0122 18:31:54.554478 68174 caffe_interface.cpp:125] Batch 161, top-1 = 0.88
I0122 18:31:54.554481 68174 caffe_interface.cpp:125] Batch 161, top-5 = 1
I0122 18:31:54.562405 68174 caffe_interface.cpp:125] Batch 162, accuracy = 0.86
I0122 18:31:54.562414 68174 caffe_interface.cpp:125] Batch 162, loss = 0.444447
I0122 18:31:54.562418 68174 caffe_interface.cpp:125] Batch 162, top-1 = 0.86
I0122 18:31:54.562420 68174 caffe_interface.cpp:125] Batch 162, top-5 = 1
I0122 18:31:54.571410 68174 caffe_interface.cpp:125] Batch 163, accuracy = 0.94
I0122 18:31:54.571419 68174 caffe_interface.cpp:125] Batch 163, loss = 0.18359
I0122 18:31:54.571421 68174 caffe_interface.cpp:125] Batch 163, top-1 = 0.94
I0122 18:31:54.571424 68174 caffe_interface.cpp:125] Batch 163, top-5 = 1
I0122 18:31:54.579335 68174 caffe_interface.cpp:125] Batch 164, accuracy = 0.8
I0122 18:31:54.579344 68174 caffe_interface.cpp:125] Batch 164, loss = 0.788862
I0122 18:31:54.579346 68174 caffe_interface.cpp:125] Batch 164, top-1 = 0.8
I0122 18:31:54.579357 68174 caffe_interface.cpp:125] Batch 164, top-5 = 0.98
I0122 18:31:54.587256 68174 caffe_interface.cpp:125] Batch 165, accuracy = 0.88
I0122 18:31:54.587265 68174 caffe_interface.cpp:125] Batch 165, loss = 0.438226
I0122 18:31:54.587268 68174 caffe_interface.cpp:125] Batch 165, top-1 = 0.88
I0122 18:31:54.587270 68174 caffe_interface.cpp:125] Batch 165, top-5 = 1
I0122 18:31:54.595155 68174 caffe_interface.cpp:125] Batch 166, accuracy = 0.9
I0122 18:31:54.595163 68174 caffe_interface.cpp:125] Batch 166, loss = 0.197079
I0122 18:31:54.595165 68174 caffe_interface.cpp:125] Batch 166, top-1 = 0.9
I0122 18:31:54.595168 68174 caffe_interface.cpp:125] Batch 166, top-5 = 1
I0122 18:31:54.604169 68174 caffe_interface.cpp:125] Batch 167, accuracy = 0.84
I0122 18:31:54.604177 68174 caffe_interface.cpp:125] Batch 167, loss = 0.595484
I0122 18:31:54.604180 68174 caffe_interface.cpp:125] Batch 167, top-1 = 0.84
I0122 18:31:54.604182 68174 caffe_interface.cpp:125] Batch 167, top-5 = 1
I0122 18:31:54.612078 68174 caffe_interface.cpp:125] Batch 168, accuracy = 0.96
I0122 18:31:54.612087 68174 caffe_interface.cpp:125] Batch 168, loss = 0.126922
I0122 18:31:54.612089 68174 caffe_interface.cpp:125] Batch 168, top-1 = 0.96
I0122 18:31:54.612092 68174 caffe_interface.cpp:125] Batch 168, top-5 = 1
I0122 18:31:54.619987 68174 caffe_interface.cpp:125] Batch 169, accuracy = 0.88
I0122 18:31:54.619994 68174 caffe_interface.cpp:125] Batch 169, loss = 0.432382
I0122 18:31:54.619997 68174 caffe_interface.cpp:125] Batch 169, top-1 = 0.88
I0122 18:31:54.619999 68174 caffe_interface.cpp:125] Batch 169, top-5 = 0.98
I0122 18:31:54.627928 68174 caffe_interface.cpp:125] Batch 170, accuracy = 0.9
I0122 18:31:54.627936 68174 caffe_interface.cpp:125] Batch 170, loss = 0.223371
I0122 18:31:54.627939 68174 caffe_interface.cpp:125] Batch 170, top-1 = 0.9
I0122 18:31:54.627943 68174 caffe_interface.cpp:125] Batch 170, top-5 = 1
I0122 18:31:54.636945 68174 caffe_interface.cpp:125] Batch 171, accuracy = 0.88
I0122 18:31:54.636952 68174 caffe_interface.cpp:125] Batch 171, loss = 0.386629
I0122 18:31:54.636955 68174 caffe_interface.cpp:125] Batch 171, top-1 = 0.88
I0122 18:31:54.636957 68174 caffe_interface.cpp:125] Batch 171, top-5 = 1
I0122 18:31:54.644881 68174 caffe_interface.cpp:125] Batch 172, accuracy = 0.88
I0122 18:31:54.644891 68174 caffe_interface.cpp:125] Batch 172, loss = 0.42387
I0122 18:31:54.644894 68174 caffe_interface.cpp:125] Batch 172, top-1 = 0.88
I0122 18:31:54.644897 68174 caffe_interface.cpp:125] Batch 172, top-5 = 0.98
I0122 18:31:54.652806 68174 caffe_interface.cpp:125] Batch 173, accuracy = 0.94
I0122 18:31:54.652814 68174 caffe_interface.cpp:125] Batch 173, loss = 0.092656
I0122 18:31:54.652818 68174 caffe_interface.cpp:125] Batch 173, top-1 = 0.94
I0122 18:31:54.652822 68174 caffe_interface.cpp:125] Batch 173, top-5 = 1
I0122 18:31:54.660758 68174 caffe_interface.cpp:125] Batch 174, accuracy = 0.9
I0122 18:31:54.660768 68174 caffe_interface.cpp:125] Batch 174, loss = 0.310774
I0122 18:31:54.660770 68174 caffe_interface.cpp:125] Batch 174, top-1 = 0.9
I0122 18:31:54.660773 68174 caffe_interface.cpp:125] Batch 174, top-5 = 1
I0122 18:31:54.669770 68174 caffe_interface.cpp:125] Batch 175, accuracy = 0.9
I0122 18:31:54.669780 68174 caffe_interface.cpp:125] Batch 175, loss = 0.273294
I0122 18:31:54.669782 68174 caffe_interface.cpp:125] Batch 175, top-1 = 0.9
I0122 18:31:54.669785 68174 caffe_interface.cpp:125] Batch 175, top-5 = 1
I0122 18:31:54.678386 68174 caffe_interface.cpp:125] Batch 176, accuracy = 0.84
I0122 18:31:54.678395 68174 caffe_interface.cpp:125] Batch 176, loss = 0.797771
I0122 18:31:54.678397 68174 caffe_interface.cpp:125] Batch 176, top-1 = 0.84
I0122 18:31:54.678400 68174 caffe_interface.cpp:125] Batch 176, top-5 = 0.94
I0122 18:31:54.686540 68174 caffe_interface.cpp:125] Batch 177, accuracy = 0.86
I0122 18:31:54.686548 68174 caffe_interface.cpp:125] Batch 177, loss = 0.602641
I0122 18:31:54.686550 68174 caffe_interface.cpp:125] Batch 177, top-1 = 0.86
I0122 18:31:54.686553 68174 caffe_interface.cpp:125] Batch 177, top-5 = 0.98
I0122 18:31:54.694452 68174 caffe_interface.cpp:125] Batch 178, accuracy = 0.92
I0122 18:31:54.694460 68174 caffe_interface.cpp:125] Batch 178, loss = 0.174315
I0122 18:31:54.694463 68174 caffe_interface.cpp:125] Batch 178, top-1 = 0.92
I0122 18:31:54.694464 68174 caffe_interface.cpp:125] Batch 178, top-5 = 1
I0122 18:31:54.703481 68174 caffe_interface.cpp:125] Batch 179, accuracy = 0.92
I0122 18:31:54.703490 68174 caffe_interface.cpp:125] Batch 179, loss = 0.478473
I0122 18:31:54.703493 68174 caffe_interface.cpp:125] Batch 179, top-1 = 0.92
I0122 18:31:54.703496 68174 caffe_interface.cpp:125] Batch 179, top-5 = 1
I0122 18:31:54.703500 68174 caffe_interface.cpp:130] Loss: 0.392776
I0122 18:31:54.703503 68174 caffe_interface.cpp:142] accuracy = 0.891
I0122 18:31:54.703510 68174 caffe_interface.cpp:142] loss = 0.392776 (* 1 = 0.392776 loss)
I0122 18:31:54.703516 68174 caffe_interface.cpp:142] top-1 = 0.891
I0122 18:31:54.703519 68174 caffe_interface.cpp:142] top-5 = 0.995556
I0122 18:31:54.871489 68174 pruning_runner.cpp:306] pruning done, output model: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/sparse.caffemodel
I0122 18:31:54.871506 68174 pruning_runner.cpp:320] summary of REGULAR compression with rate 0.2:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.897777736    | 0.891000211    | -0.00677752495 |
+-------------------------------------------------------------------+
| Weights        | 1652899        | 1280841        | -22.5094204%   |
+-------------------------------------------------------------------+
| Operations     | 533938176      | 425767552      | -20.259016%    |
+-------------------------------------------------------------------+
To fine-tune the compressed model, please run:
deephi_compress finetune -config cifar10/deephi/miniGoogleNet/pruning/config2.prototxt
## fine-tuning: second run
$PRUNE_ROOT/deephi_compress finetune -config ${WORK_DIR}/config2.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_finetune2_miniGoogleNet.txt
I0122 18:31:55.115264 69145 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/net_finetune.prototxt
I0122 18:31:55.293560 69145 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 18:31:55.294070 69145 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24754061312, dev_info[0]: total=25620447232 free=24754061312
I0122 18:31:55.294082 69145 caffe_interface.cpp:493] Using GPUs 0
I0122 18:31:55.294333 69145 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 18:31:55.883486 69145 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/net_finetune.prototxt"
type: "SGD"
I0122 18:31:55.883594 69145 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/net_finetune.prototxt
I0122 18:31:55.884205 69145 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 18:31:55.884248 69145 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 18:31:55.884253 69145 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 18:31:55.884254 69145 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 18:31:55.884779 69145 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 18:31:55.885087 69145 layer_factory.hpp:77] Creating layer data
I0122 18:31:55.885183 69145 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 18:31:55.886036 69145 net.cpp:94] Creating Layer data
I0122 18:31:55.886047 69145 net.cpp:409] data -> data
I0122 18:31:55.886057 69145 net.cpp:409] data -> label
I0122 18:31:55.887524 69184 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 18:31:55.887571 69184 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 18:31:55.887667 69145 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 18:31:55.887874 69145 data_layer.cpp:83] output data size: 128,3,32,32
I0122 18:31:55.895584 69145 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 18:31:55.895624 69145 net.cpp:144] Setting up data
I0122 18:31:55.895632 69145 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 18:31:55.895635 69145 net.cpp:151] Top shape: 128 (128)
I0122 18:31:55.895637 69145 net.cpp:159] Memory required for data: 1573376
I0122 18:31:55.895642 69145 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 18:31:55.895654 69145 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 18:31:55.895658 69145 net.cpp:435] conv1/3x3_s1 <- data
I0122 18:31:55.895671 69145 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 18:31:55.897261 69145 net.cpp:144] Setting up conv1/3x3_s1
I0122 18:31:55.897272 69145 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 18:31:55.897275 69145 net.cpp:159] Memory required for data: 51905024
I0122 18:31:55.897289 69145 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 18:31:55.897298 69145 net.cpp:94] Creating Layer conv1/bn1
I0122 18:31:55.897301 69145 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 18:31:55.897307 69145 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 18:31:55.897943 69145 net.cpp:144] Setting up conv1/bn1
I0122 18:31:55.897950 69145 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 18:31:55.897953 69145 net.cpp:159] Memory required for data: 102236672
I0122 18:31:55.897965 69145 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 18:31:55.897971 69145 net.cpp:94] Creating Layer conv1/relu1
I0122 18:31:55.897984 69145 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 18:31:55.897994 69145 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 18:31:55.898007 69145 net.cpp:144] Setting up conv1/relu1
I0122 18:31:55.898026 69145 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 18:31:55.898028 69145 net.cpp:159] Memory required for data: 152568320
I0122 18:31:55.898031 69145 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:55.898038 69145 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:55.898043 69145 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 18:31:55.898051 69145 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 18:31:55.898062 69145 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 18:31:55.898102 69145 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:55.898108 69145 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 18:31:55.898110 69145 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 18:31:55.898113 69145 net.cpp:159] Memory required for data: 253231616
I0122 18:31:55.898118 69145 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 18:31:55.898128 69145 net.cpp:94] Creating Layer inception_2a/1x1
I0122 18:31:55.898134 69145 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 18:31:55.898144 69145 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 18:31:55.898972 69145 net.cpp:144] Setting up inception_2a/1x1
I0122 18:31:55.898979 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.898982 69145 net.cpp:159] Memory required for data: 270008832
I0122 18:31:55.898988 69145 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 18:31:55.898999 69145 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 18:31:55.899005 69145 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 18:31:55.899015 69145 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 18:31:55.899776 69145 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 18:31:55.899785 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.899788 69145 net.cpp:159] Memory required for data: 286786048
I0122 18:31:55.899796 69145 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 18:31:55.899806 69145 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 18:31:55.899811 69145 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 18:31:55.899817 69145 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 18:31:55.899827 69145 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 18:31:55.899832 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.899840 69145 net.cpp:159] Memory required for data: 303563264
I0122 18:31:55.899844 69145 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 18:31:55.899858 69145 net.cpp:94] Creating Layer inception_2a/3x3
I0122 18:31:55.899864 69145 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 18:31:55.899873 69145 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 18:31:55.901126 69145 net.cpp:144] Setting up inception_2a/3x3
I0122 18:31:55.901137 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.901140 69145 net.cpp:159] Memory required for data: 320340480
I0122 18:31:55.901149 69145 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 18:31:55.901165 69145 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 18:31:55.901172 69145 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 18:31:55.901183 69145 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 18:31:55.901924 69145 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 18:31:55.901932 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.901935 69145 net.cpp:159] Memory required for data: 337117696
I0122 18:31:55.901950 69145 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 18:31:55.901962 69145 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 18:31:55.901965 69145 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 18:31:55.901973 69145 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 18:31:55.901993 69145 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 18:31:55.901998 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.902002 69145 net.cpp:159] Memory required for data: 353894912
I0122 18:31:55.902005 69145 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 18:31:55.902012 69145 net.cpp:94] Creating Layer inception_2a/output
I0122 18:31:55.902019 69145 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 18:31:55.902031 69145 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 18:31:55.902040 69145 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 18:31:55.902067 69145 net.cpp:144] Setting up inception_2a/output
I0122 18:31:55.902074 69145 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 18:31:55.902076 69145 net.cpp:159] Memory required for data: 387449344
I0122 18:31:55.902079 69145 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 18:31:55.902084 69145 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 18:31:55.902091 69145 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 18:31:55.902099 69145 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 18:31:55.902110 69145 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 18:31:55.902148 69145 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 18:31:55.902155 69145 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 18:31:55.902159 69145 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 18:31:55.902163 69145 net.cpp:159] Memory required for data: 454558208
I0122 18:31:55.902166 69145 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 18:31:55.902180 69145 net.cpp:94] Creating Layer inception_3a/1x1
I0122 18:31:55.902186 69145 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 18:31:55.902195 69145 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 18:31:55.902437 69145 net.cpp:144] Setting up inception_3a/1x1
I0122 18:31:55.902444 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.902447 69145 net.cpp:159] Memory required for data: 471335424
I0122 18:31:55.902452 69145 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 18:31:55.902462 69145 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 18:31:55.902467 69145 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 18:31:55.902477 69145 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 18:31:55.903133 69145 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 18:31:55.903141 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.903144 69145 net.cpp:159] Memory required for data: 488112640
I0122 18:31:55.903151 69145 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 18:31:55.903156 69145 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 18:31:55.903159 69145 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 18:31:55.903170 69145 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 18:31:55.903179 69145 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 18:31:55.903187 69145 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 18:31:55.903190 69145 net.cpp:159] Memory required for data: 504889856
I0122 18:31:55.903195 69145 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 18:31:55.903210 69145 net.cpp:94] Creating Layer inception_3a/3x3
I0122 18:31:55.903218 69145 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 18:31:55.903225 69145 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 18:31:55.903643 69145 net.cpp:144] Setting up inception_3a/3x3
I0122 18:31:55.903650 69145 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 18:31:55.903653 69145 net.cpp:159] Memory required for data: 530055680
I0122 18:31:55.903666 69145 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 18:31:55.903678 69145 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 18:31:55.903686 69145 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 18:31:55.903694 69145 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 18:31:55.904356 69145 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 18:31:55.904363 69145 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 18:31:55.904367 69145 net.cpp:159] Memory required for data: 555221504
I0122 18:31:55.904381 69145 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 18:31:55.904393 69145 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 18:31:55.904399 69145 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 18:31:55.904407 69145 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 18:31:55.904415 69145 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 18:31:55.904423 69145 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 18:31:55.904428 69145 net.cpp:159] Memory required for data: 580387328
I0122 18:31:55.904433 69145 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 18:31:55.904438 69145 net.cpp:94] Creating Layer inception_3a/output
I0122 18:31:55.904445 69145 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 18:31:55.904451 69145 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 18:31:55.904460 69145 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 18:31:55.904490 69145 net.cpp:144] Setting up inception_3a/output
I0122 18:31:55.904496 69145 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 18:31:55.904500 69145 net.cpp:159] Memory required for data: 622330368
I0122 18:31:55.904502 69145 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 18:31:55.904507 69145 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 18:31:55.904510 69145 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 18:31:55.904518 69145 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 18:31:55.904527 69145 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 18:31:55.904563 69145 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 18:31:55.904569 69145 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 18:31:55.904573 69145 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 18:31:55.904577 69145 net.cpp:159] Memory required for data: 706216448
I0122 18:31:55.904578 69145 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 18:31:55.904590 69145 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 18:31:55.904598 69145 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 18:31:55.904606 69145 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 18:31:55.905169 69145 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 18:31:55.905177 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.905181 69145 net.cpp:159] Memory required for data: 716702208
I0122 18:31:55.905186 69145 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 18:31:55.905200 69145 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 18:31:55.905205 69145 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 18:31:55.905215 69145 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 18:31:55.906008 69145 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 18:31:55.906018 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.906021 69145 net.cpp:159] Memory required for data: 727187968
I0122 18:31:55.906030 69145 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 18:31:55.906039 69145 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 18:31:55.906044 69145 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 18:31:55.906064 69145 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 18:31:55.906072 69145 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 18:31:55.906080 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.906083 69145 net.cpp:159] Memory required for data: 737673728
I0122 18:31:55.906087 69145 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 18:31:55.906102 69145 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 18:31:55.906110 69145 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 18:31:55.906117 69145 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 18:31:55.906174 69145 net.cpp:144] Setting up downsample_4/pool_s2
I0122 18:31:55.906183 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.906185 69145 net.cpp:159] Memory required for data: 748159488
I0122 18:31:55.906190 69145 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 18:31:55.906198 69145 net.cpp:94] Creating Layer downsample_4/output
I0122 18:31:55.906204 69145 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 18:31:55.906209 69145 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 18:31:55.906217 69145 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 18:31:55.906241 69145 net.cpp:144] Setting up downsample_4/output
I0122 18:31:55.906249 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.906251 69145 net.cpp:159] Memory required for data: 769131008
I0122 18:31:55.906253 69145 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 18:31:55.906260 69145 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 18:31:55.906265 69145 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 18:31:55.906272 69145 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 18:31:55.906283 69145 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 18:31:55.906319 69145 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 18:31:55.906325 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.906329 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.906332 69145 net.cpp:159] Memory required for data: 811074048
I0122 18:31:55.906334 69145 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 18:31:55.906349 69145 net.cpp:94] Creating Layer inception_5a/1x1
I0122 18:31:55.906355 69145 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 18:31:55.906364 69145 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 18:31:55.906728 69145 net.cpp:144] Setting up inception_5a/1x1
I0122 18:31:55.906735 69145 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 18:31:55.906738 69145 net.cpp:159] Memory required for data: 825754112
I0122 18:31:55.906744 69145 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 18:31:55.906754 69145 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 18:31:55.906760 69145 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 18:31:55.906769 69145 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 18:31:55.907428 69145 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 18:31:55.907436 69145 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 18:31:55.907441 69145 net.cpp:159] Memory required for data: 840434176
I0122 18:31:55.907449 69145 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 18:31:55.907455 69145 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 18:31:55.907459 69145 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 18:31:55.907469 69145 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 18:31:55.907480 69145 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 18:31:55.907485 69145 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 18:31:55.907500 69145 net.cpp:159] Memory required for data: 855114240
I0122 18:31:55.907505 69145 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 18:31:55.907516 69145 net.cpp:94] Creating Layer inception_5a/3x3
I0122 18:31:55.907522 69145 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 18:31:55.907533 69145 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 18:31:55.908308 69145 net.cpp:144] Setting up inception_5a/3x3
I0122 18:31:55.908318 69145 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 18:31:55.908320 69145 net.cpp:159] Memory required for data: 861405696
I0122 18:31:55.908325 69145 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 18:31:55.908337 69145 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 18:31:55.908344 69145 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 18:31:55.908356 69145 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 18:31:55.909018 69145 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 18:31:55.909026 69145 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 18:31:55.909029 69145 net.cpp:159] Memory required for data: 867697152
I0122 18:31:55.909039 69145 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 18:31:55.909051 69145 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 18:31:55.909059 69145 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 18:31:55.909065 69145 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 18:31:55.909073 69145 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 18:31:55.909078 69145 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 18:31:55.909083 69145 net.cpp:159] Memory required for data: 873988608
I0122 18:31:55.909087 69145 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 18:31:55.909095 69145 net.cpp:94] Creating Layer inception_5a/output
I0122 18:31:55.909099 69145 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 18:31:55.909104 69145 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 18:31:55.909112 69145 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 18:31:55.909137 69145 net.cpp:144] Setting up inception_5a/output
I0122 18:31:55.909144 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.909149 69145 net.cpp:159] Memory required for data: 894960128
I0122 18:31:55.909152 69145 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 18:31:55.909157 69145 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 18:31:55.909160 69145 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 18:31:55.909169 69145 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 18:31:55.909178 69145 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 18:31:55.909216 69145 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 18:31:55.909224 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.909229 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.909230 69145 net.cpp:159] Memory required for data: 936903168
I0122 18:31:55.909234 69145 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 18:31:55.909245 69145 net.cpp:94] Creating Layer inception_6a/1x1
I0122 18:31:55.909252 69145 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 18:31:55.909262 69145 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 18:31:55.910300 69145 net.cpp:144] Setting up inception_6a/1x1
I0122 18:31:55.910311 69145 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 18:31:55.910315 69145 net.cpp:159] Memory required for data: 949486080
I0122 18:31:55.910321 69145 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 18:31:55.910337 69145 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 18:31:55.910356 69145 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 18:31:55.910367 69145 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 18:31:55.911139 69145 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 18:31:55.911147 69145 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 18:31:55.911151 69145 net.cpp:159] Memory required for data: 962068992
I0122 18:31:55.911159 69145 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 18:31:55.911168 69145 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 18:31:55.911175 69145 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 18:31:55.911181 69145 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 18:31:55.911192 69145 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 18:31:55.911198 69145 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 18:31:55.911202 69145 net.cpp:159] Memory required for data: 974651904
I0122 18:31:55.911206 69145 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 18:31:55.911222 69145 net.cpp:94] Creating Layer inception_6a/3x3
I0122 18:31:55.911229 69145 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 18:31:55.911237 69145 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 18:31:55.912016 69145 net.cpp:144] Setting up inception_6a/3x3
I0122 18:31:55.912027 69145 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 18:31:55.912030 69145 net.cpp:159] Memory required for data: 983040512
I0122 18:31:55.912045 69145 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 18:31:55.912060 69145 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 18:31:55.912067 69145 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 18:31:55.912075 69145 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 18:31:55.912842 69145 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 18:31:55.912848 69145 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 18:31:55.912853 69145 net.cpp:159] Memory required for data: 991429120
I0122 18:31:55.912860 69145 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 18:31:55.912868 69145 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 18:31:55.912879 69145 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 18:31:55.912889 69145 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 18:31:55.912899 69145 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 18:31:55.912911 69145 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 18:31:55.912917 69145 net.cpp:159] Memory required for data: 999817728
I0122 18:31:55.912921 69145 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 18:31:55.912928 69145 net.cpp:94] Creating Layer inception_6a/output
I0122 18:31:55.912932 69145 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 18:31:55.912937 69145 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 18:31:55.912947 69145 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 18:31:55.912978 69145 net.cpp:144] Setting up inception_6a/output
I0122 18:31:55.912986 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.912989 69145 net.cpp:159] Memory required for data: 1020789248
I0122 18:31:55.912992 69145 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 18:31:55.912997 69145 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 18:31:55.913000 69145 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 18:31:55.913009 69145 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 18:31:55.913020 69145 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 18:31:55.913182 69145 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 18:31:55.913187 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.913198 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.913203 69145 net.cpp:159] Memory required for data: 1062732288
I0122 18:31:55.913206 69145 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 18:31:55.913219 69145 net.cpp:94] Creating Layer inception_7a/1x1
I0122 18:31:55.913225 69145 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 18:31:55.913235 69145 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 18:31:55.913553 69145 net.cpp:144] Setting up inception_7a/1x1
I0122 18:31:55.913561 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.913564 69145 net.cpp:159] Memory required for data: 1073218048
I0122 18:31:55.913570 69145 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 18:31:55.913579 69145 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 18:31:55.913585 69145 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 18:31:55.913592 69145 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 18:31:55.914283 69145 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 18:31:55.914290 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.914294 69145 net.cpp:159] Memory required for data: 1083703808
I0122 18:31:55.914300 69145 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 18:31:55.914312 69145 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 18:31:55.914319 69145 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 18:31:55.914325 69145 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 18:31:55.914335 69145 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 18:31:55.914342 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.914346 69145 net.cpp:159] Memory required for data: 1094189568
I0122 18:31:55.914350 69145 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 18:31:55.914373 69145 net.cpp:94] Creating Layer inception_7a/3x3
I0122 18:31:55.914381 69145 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 18:31:55.914387 69145 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 18:31:55.915412 69145 net.cpp:144] Setting up inception_7a/3x3
I0122 18:31:55.915422 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.915426 69145 net.cpp:159] Memory required for data: 1104675328
I0122 18:31:55.915432 69145 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 18:31:55.915443 69145 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 18:31:55.915452 69145 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 18:31:55.915462 69145 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 18:31:55.916131 69145 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 18:31:55.916139 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.916142 69145 net.cpp:159] Memory required for data: 1115161088
I0122 18:31:55.916152 69145 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 18:31:55.916157 69145 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 18:31:55.916160 69145 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 18:31:55.916168 69145 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 18:31:55.916179 69145 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 18:31:55.916185 69145 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 18:31:55.916193 69145 net.cpp:159] Memory required for data: 1125646848
I0122 18:31:55.916196 69145 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 18:31:55.916205 69145 net.cpp:94] Creating Layer inception_7a/output
I0122 18:31:55.916211 69145 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 18:31:55.916218 69145 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 18:31:55.916224 69145 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 18:31:55.916255 69145 net.cpp:144] Setting up inception_7a/output
I0122 18:31:55.916262 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.916272 69145 net.cpp:159] Memory required for data: 1146618368
I0122 18:31:55.916276 69145 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 18:31:55.916283 69145 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 18:31:55.916287 69145 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 18:31:55.916296 69145 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 18:31:55.916308 69145 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 18:31:55.916347 69145 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 18:31:55.916353 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.916357 69145 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 18:31:55.916359 69145 net.cpp:159] Memory required for data: 1188561408
I0122 18:31:55.916363 69145 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 18:31:55.916373 69145 net.cpp:94] Creating Layer inception_8a/1x1
I0122 18:31:55.916380 69145 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 18:31:55.916389 69145 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 18:31:55.916677 69145 net.cpp:144] Setting up inception_8a/1x1
I0122 18:31:55.916687 69145 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 18:31:55.916688 69145 net.cpp:159] Memory required for data: 1194852864
I0122 18:31:55.916693 69145 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 18:31:55.916707 69145 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 18:31:55.916713 69145 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 18:31:55.916723 69145 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 18:31:55.917486 69145 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 18:31:55.917493 69145 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 18:31:55.917496 69145 net.cpp:159] Memory required for data: 1201144320
I0122 18:31:55.917505 69145 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 18:31:55.917510 69145 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 18:31:55.917520 69145 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 18:31:55.917526 69145 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 18:31:55.917536 69145 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 18:31:55.917542 69145 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 18:31:55.917556 69145 net.cpp:159] Memory required for data: 1207435776
I0122 18:31:55.917559 69145 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 18:31:55.917577 69145 net.cpp:94] Creating Layer inception_8a/3x3
I0122 18:31:55.917584 69145 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 18:31:55.917593 69145 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 18:31:55.919294 69145 net.cpp:144] Setting up inception_8a/3x3
I0122 18:31:55.919306 69145 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 18:31:55.919309 69145 net.cpp:159] Memory required for data: 1220018688
I0122 18:31:55.919315 69145 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 18:31:55.919324 69145 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 18:31:55.919328 69145 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 18:31:55.919338 69145 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 18:31:55.920042 69145 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 18:31:55.920048 69145 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 18:31:55.920051 69145 net.cpp:159] Memory required for data: 1232601600
I0122 18:31:55.920060 69145 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 18:31:55.920071 69145 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 18:31:55.920076 69145 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 18:31:55.920099 69145 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 18:31:55.920107 69145 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 18:31:55.920112 69145 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 18:31:55.920116 69145 net.cpp:159] Memory required for data: 1245184512
I0122 18:31:55.920120 69145 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 18:31:55.920126 69145 net.cpp:94] Creating Layer inception_8a/output
I0122 18:31:55.920131 69145 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 18:31:55.920137 69145 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 18:31:55.920150 69145 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 18:31:55.920176 69145 net.cpp:144] Setting up inception_8a/output
I0122 18:31:55.920186 69145 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 18:31:55.920187 69145 net.cpp:159] Memory required for data: 1264058880
I0122 18:31:55.920190 69145 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 18:31:55.920197 69145 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 18:31:55.920202 69145 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 18:31:55.920212 69145 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 18:31:55.920219 69145 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 18:31:55.920261 69145 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 18:31:55.920267 69145 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 18:31:55.920271 69145 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 18:31:55.920274 69145 net.cpp:159] Memory required for data: 1301807616
I0122 18:31:55.920276 69145 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 18:31:55.920290 69145 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 18:31:55.920297 69145 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 18:31:55.920308 69145 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 18:31:55.921255 69145 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 18:31:55.921265 69145 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 18:31:55.921268 69145 net.cpp:159] Memory required for data: 1304953344
I0122 18:31:55.921273 69145 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 18:31:55.921286 69145 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 18:31:55.921294 69145 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 18:31:55.921304 69145 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 18:31:55.922000 69145 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 18:31:55.922008 69145 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 18:31:55.922013 69145 net.cpp:159] Memory required for data: 1308099072
I0122 18:31:55.922020 69145 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 18:31:55.922032 69145 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 18:31:55.922036 69145 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 18:31:55.922046 69145 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 18:31:55.922058 69145 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 18:31:55.922065 69145 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 18:31:55.922066 69145 net.cpp:159] Memory required for data: 1311244800
I0122 18:31:55.922071 69145 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 18:31:55.922078 69145 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 18:31:55.922082 69145 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 18:31:55.922089 69145 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 18:31:55.922130 69145 net.cpp:144] Setting up downsample_9/pool_s2
I0122 18:31:55.922142 69145 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 18:31:55.922145 69145 net.cpp:159] Memory required for data: 1315963392
I0122 18:31:55.922147 69145 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 18:31:55.922154 69145 net.cpp:94] Creating Layer downsample_9/output
I0122 18:31:55.922158 69145 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 18:31:55.922163 69145 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 18:31:55.922170 69145 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 18:31:55.922196 69145 net.cpp:144] Setting up downsample_9/output
I0122 18:31:55.922204 69145 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 18:31:55.922206 69145 net.cpp:159] Memory required for data: 1323827712
I0122 18:31:55.922209 69145 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 18:31:55.922221 69145 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 18:31:55.922227 69145 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 18:31:55.922235 69145 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 18:31:55.922243 69145 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 18:31:55.922284 69145 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 18:31:55.922291 69145 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 18:31:55.922294 69145 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 18:31:55.922297 69145 net.cpp:159] Memory required for data: 1339556352
I0122 18:31:55.922300 69145 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 18:31:55.922312 69145 net.cpp:94] Creating Layer inception_10a/1x1
I0122 18:31:55.922318 69145 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 18:31:55.922327 69145 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 18:31:55.922811 69145 net.cpp:144] Setting up inception_10a/1x1
I0122 18:31:55.922819 69145 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 18:31:55.922822 69145 net.cpp:159] Memory required for data: 1345323520
I0122 18:31:55.922827 69145 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 18:31:55.922842 69145 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 18:31:55.922848 69145 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 18:31:55.922855 69145 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 18:31:55.923550 69145 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 18:31:55.923558 69145 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 18:31:55.923561 69145 net.cpp:159] Memory required for data: 1351090688
I0122 18:31:55.923569 69145 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 18:31:55.923578 69145 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 18:31:55.923583 69145 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 18:31:55.923593 69145 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 18:31:55.923602 69145 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 18:31:55.923609 69145 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 18:31:55.923614 69145 net.cpp:159] Memory required for data: 1356857856
I0122 18:31:55.923619 69145 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 18:31:55.923631 69145 net.cpp:94] Creating Layer inception_10a/3x3
I0122 18:31:55.923637 69145 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 18:31:55.923647 69145 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 18:31:55.926868 69145 net.cpp:144] Setting up inception_10a/3x3
I0122 18:31:55.926882 69145 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 18:31:55.926884 69145 net.cpp:159] Memory required for data: 1362100736
I0122 18:31:55.926892 69145 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 18:31:55.926914 69145 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 18:31:55.926920 69145 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 18:31:55.926930 69145 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 18:31:55.927588 69145 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 18:31:55.927597 69145 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 18:31:55.927599 69145 net.cpp:159] Memory required for data: 1367343616
I0122 18:31:55.927608 69145 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 18:31:55.927618 69145 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 18:31:55.927623 69145 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 18:31:55.927631 69145 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 18:31:55.927642 69145 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 18:31:55.927651 69145 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 18:31:55.927654 69145 net.cpp:159] Memory required for data: 1372586496
I0122 18:31:55.927659 69145 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 18:31:55.927665 69145 net.cpp:94] Creating Layer inception_10a/output
I0122 18:31:55.927672 69145 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 18:31:55.927677 69145 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 18:31:55.927686 69145 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 18:31:55.927716 69145 net.cpp:144] Setting up inception_10a/output
I0122 18:31:55.927722 69145 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 18:31:55.927726 69145 net.cpp:159] Memory required for data: 1383596544
I0122 18:31:55.927728 69145 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 18:31:55.927733 69145 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 18:31:55.927738 69145 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 18:31:55.927747 69145 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 18:31:55.927757 69145 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 18:31:55.927795 69145 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 18:31:55.927801 69145 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 18:31:55.927805 69145 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 18:31:55.927808 69145 net.cpp:159] Memory required for data: 1405616640
I0122 18:31:55.927810 69145 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 18:31:55.927824 69145 net.cpp:94] Creating Layer inception_11a/1x1
I0122 18:31:55.927829 69145 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 18:31:55.927839 69145 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 18:31:55.928422 69145 net.cpp:144] Setting up inception_11a/1x1
I0122 18:31:55.928432 69145 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 18:31:55.928436 69145 net.cpp:159] Memory required for data: 1411383808
I0122 18:31:55.928442 69145 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 18:31:55.928454 69145 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 18:31:55.928462 69145 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 18:31:55.928468 69145 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 18:31:55.929158 69145 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 18:31:55.929167 69145 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 18:31:55.929170 69145 net.cpp:159] Memory required for data: 1417150976
I0122 18:31:55.929180 69145 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 18:31:55.929189 69145 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 18:31:55.929193 69145 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 18:31:55.929214 69145 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 18:31:55.929222 69145 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 18:31:55.929229 69145 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 18:31:55.929234 69145 net.cpp:159] Memory required for data: 1422918144
I0122 18:31:55.929239 69145 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 18:31:55.929250 69145 net.cpp:94] Creating Layer inception_11a/3x3
I0122 18:31:55.929256 69145 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 18:31:55.929266 69145 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 18:31:55.933145 69145 net.cpp:144] Setting up inception_11a/3x3
I0122 18:31:55.933157 69145 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 18:31:55.933161 69145 net.cpp:159] Memory required for data: 1428161024
I0122 18:31:55.933166 69145 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 18:31:55.933177 69145 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 18:31:55.933184 69145 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 18:31:55.933192 69145 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 18:31:55.933856 69145 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 18:31:55.933866 69145 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 18:31:55.933868 69145 net.cpp:159] Memory required for data: 1433403904
I0122 18:31:55.933894 69145 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 18:31:55.933903 69145 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 18:31:55.933912 69145 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 18:31:55.933917 69145 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 18:31:55.933926 69145 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 18:31:55.933933 69145 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 18:31:55.933938 69145 net.cpp:159] Memory required for data: 1438646784
I0122 18:31:55.933943 69145 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 18:31:55.933949 69145 net.cpp:94] Creating Layer inception_11a/output
I0122 18:31:55.933954 69145 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 18:31:55.933959 69145 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 18:31:55.933969 69145 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 18:31:55.933997 69145 net.cpp:144] Setting up inception_11a/output
I0122 18:31:55.934003 69145 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 18:31:55.934007 69145 net.cpp:159] Memory required for data: 1449656832
I0122 18:31:55.934010 69145 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 18:31:55.934017 69145 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 18:31:55.934024 69145 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 18:31:55.934032 69145 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 18:31:55.934064 69145 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 18:31:55.934070 69145 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 18:31:55.934073 69145 net.cpp:159] Memory required for data: 1449828864
I0122 18:31:55.934077 69145 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 18:31:55.934083 69145 net.cpp:94] Creating Layer drop_8x8_s1
I0122 18:31:55.934088 69145 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 18:31:55.934094 69145 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 18:31:55.934121 69145 net.cpp:144] Setting up drop_8x8_s1
I0122 18:31:55.934128 69145 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 18:31:55.934130 69145 net.cpp:159] Memory required for data: 1450000896
I0122 18:31:55.934132 69145 layer_factory.hpp:77] Creating layer loss/classifier
I0122 18:31:55.934142 69145 net.cpp:94] Creating Layer loss/classifier
I0122 18:31:55.934149 69145 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 18:31:55.934154 69145 net.cpp:409] loss/classifier -> loss/classifier
I0122 18:31:55.934303 69145 net.cpp:144] Setting up loss/classifier
I0122 18:31:55.934319 69145 net.cpp:151] Top shape: 128 10 (1280)
I0122 18:31:55.934320 69145 net.cpp:159] Memory required for data: 1450006016
I0122 18:31:55.934325 69145 layer_factory.hpp:77] Creating layer loss
I0122 18:31:55.934331 69145 net.cpp:94] Creating Layer loss
I0122 18:31:55.934339 69145 net.cpp:435] loss <- loss/classifier
I0122 18:31:55.934343 69145 net.cpp:435] loss <- label
I0122 18:31:55.934351 69145 net.cpp:409] loss -> loss
I0122 18:31:55.934363 69145 layer_factory.hpp:77] Creating layer loss
I0122 18:31:55.934450 69145 net.cpp:144] Setting up loss
I0122 18:31:55.934456 69145 net.cpp:151] Top shape: (1)
I0122 18:31:55.934459 69145 net.cpp:154]     with loss weight 1
I0122 18:31:55.934469 69145 net.cpp:159] Memory required for data: 1450006020
I0122 18:31:55.934474 69145 net.cpp:220] loss needs backward computation.
I0122 18:31:55.934487 69145 net.cpp:220] loss/classifier needs backward computation.
I0122 18:31:55.934491 69145 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 18:31:55.934496 69145 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 18:31:55.934500 69145 net.cpp:220] inception_11a/output needs backward computation.
I0122 18:31:55.934505 69145 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 18:31:55.934509 69145 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 18:31:55.934512 69145 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 18:31:55.934517 69145 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 18:31:55.934522 69145 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 18:31:55.934525 69145 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 18:31:55.934530 69145 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 18:31:55.934535 69145 net.cpp:220] inception_10a/output needs backward computation.
I0122 18:31:55.934540 69145 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 18:31:55.934545 69145 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 18:31:55.934548 69145 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 18:31:55.934553 69145 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 18:31:55.934557 69145 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 18:31:55.934561 69145 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 18:31:55.934566 69145 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 18:31:55.934571 69145 net.cpp:220] downsample_9/output needs backward computation.
I0122 18:31:55.934576 69145 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 18:31:55.934584 69145 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 18:31:55.934587 69145 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 18:31:55.934593 69145 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 18:31:55.934598 69145 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 18:31:55.934603 69145 net.cpp:220] inception_8a/output needs backward computation.
I0122 18:31:55.934608 69145 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 18:31:55.934613 69145 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 18:31:55.934617 69145 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 18:31:55.934623 69145 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 18:31:55.934628 69145 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 18:31:55.934633 69145 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 18:31:55.934638 69145 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 18:31:55.934641 69145 net.cpp:220] inception_7a/output needs backward computation.
I0122 18:31:55.934648 69145 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 18:31:55.934660 69145 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 18:31:55.934664 69145 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 18:31:55.934667 69145 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 18:31:55.934670 69145 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 18:31:55.934675 69145 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 18:31:55.934680 69145 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 18:31:55.934684 69145 net.cpp:220] inception_6a/output needs backward computation.
I0122 18:31:55.934689 69145 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 18:31:55.934695 69145 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 18:31:55.934698 69145 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 18:31:55.934703 69145 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 18:31:55.934707 69145 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 18:31:55.934711 69145 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 18:31:55.934716 69145 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 18:31:55.934720 69145 net.cpp:220] inception_5a/output needs backward computation.
I0122 18:31:55.934728 69145 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 18:31:55.934733 69145 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 18:31:55.934737 69145 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 18:31:55.934741 69145 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 18:31:55.934746 69145 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 18:31:55.934751 69145 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 18:31:55.934756 69145 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 18:31:55.934759 69145 net.cpp:220] downsample_4/output needs backward computation.
I0122 18:31:55.934765 69145 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 18:31:55.934770 69145 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 18:31:55.934774 69145 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 18:31:55.934778 69145 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 18:31:55.934782 69145 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 18:31:55.934788 69145 net.cpp:220] inception_3a/output needs backward computation.
I0122 18:31:55.934793 69145 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 18:31:55.934798 69145 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 18:31:55.934801 69145 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 18:31:55.934806 69145 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 18:31:55.934810 69145 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 18:31:55.934814 69145 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 18:31:55.934820 69145 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 18:31:55.934825 69145 net.cpp:220] inception_2a/output needs backward computation.
I0122 18:31:55.934832 69145 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 18:31:55.934836 69145 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 18:31:55.934840 69145 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 18:31:55.934845 69145 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 18:31:55.934849 69145 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 18:31:55.934854 69145 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 18:31:55.934859 69145 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 18:31:55.934868 69145 net.cpp:220] conv1/relu1 needs backward computation.
I0122 18:31:55.934873 69145 net.cpp:220] conv1/bn1 needs backward computation.
I0122 18:31:55.934877 69145 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 18:31:55.934882 69145 net.cpp:222] data does not need backward computation.
I0122 18:31:55.934887 69145 net.cpp:264] This network produces output loss
I0122 18:31:55.934957 69145 net.cpp:284] Network initialization done.
I0122 18:31:55.935876 69145 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/net_finetune.prototxt
I0122 18:31:55.935969 69145 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 18:31:55.936625 69145 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 18:31:55.937058 69145 layer_factory.hpp:77] Creating layer data
I0122 18:31:55.937114 69145 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 18:31:55.938056 69145 net.cpp:94] Creating Layer data
I0122 18:31:55.938069 69145 net.cpp:409] data -> data
I0122 18:31:55.938081 69145 net.cpp:409] data -> label
I0122 18:31:55.939019 69214 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 18:31:55.939051 69214 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 18:31:55.939132 69145 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 18:31:55.939241 69145 data_layer.cpp:83] output data size: 50,3,32,32
I0122 18:31:55.942153 69145 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 18:31:55.942195 69145 net.cpp:144] Setting up data
I0122 18:31:55.942207 69145 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 18:31:55.942212 69145 net.cpp:151] Top shape: 50 (50)
I0122 18:31:55.942215 69145 net.cpp:159] Memory required for data: 614600
I0122 18:31:55.942219 69145 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 18:31:55.942230 69145 net.cpp:94] Creating Layer label_data_1_split
I0122 18:31:55.942236 69145 net.cpp:435] label_data_1_split <- label
I0122 18:31:55.942245 69145 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 18:31:55.942253 69145 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 18:31:55.942265 69145 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 18:31:55.942273 69145 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 18:31:55.942409 69145 net.cpp:144] Setting up label_data_1_split
I0122 18:31:55.942416 69145 net.cpp:151] Top shape: 50 (50)
I0122 18:31:55.942420 69145 net.cpp:151] Top shape: 50 (50)
I0122 18:31:55.942425 69145 net.cpp:151] Top shape: 50 (50)
I0122 18:31:55.942427 69145 net.cpp:151] Top shape: 50 (50)
I0122 18:31:55.942431 69145 net.cpp:159] Memory required for data: 615400
I0122 18:31:55.942436 69145 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 18:31:55.942451 69145 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 18:31:55.942457 69145 net.cpp:435] conv1/3x3_s1 <- data
I0122 18:31:55.942466 69145 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 18:31:55.942764 69145 net.cpp:144] Setting up conv1/3x3_s1
I0122 18:31:55.942771 69145 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:55.942775 69145 net.cpp:159] Memory required for data: 20276200
I0122 18:31:55.942785 69145 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 18:31:55.942798 69145 net.cpp:94] Creating Layer conv1/bn1
I0122 18:31:55.942802 69145 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 18:31:55.942823 69145 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 18:31:55.943560 69145 net.cpp:144] Setting up conv1/bn1
I0122 18:31:55.943568 69145 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:55.943572 69145 net.cpp:159] Memory required for data: 39937000
I0122 18:31:55.943583 69145 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 18:31:55.943595 69145 net.cpp:94] Creating Layer conv1/relu1
I0122 18:31:55.943600 69145 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 18:31:55.943606 69145 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 18:31:55.943617 69145 net.cpp:144] Setting up conv1/relu1
I0122 18:31:55.943624 69145 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:55.943629 69145 net.cpp:159] Memory required for data: 59597800
I0122 18:31:55.943632 69145 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:55.943639 69145 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:55.943644 69145 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 18:31:55.943653 69145 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 18:31:55.943665 69145 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 18:31:55.943835 69145 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 18:31:55.943842 69145 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:55.943846 69145 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 18:31:55.943850 69145 net.cpp:159] Memory required for data: 98919400
I0122 18:31:55.943852 69145 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 18:31:55.943863 69145 net.cpp:94] Creating Layer inception_2a/1x1
I0122 18:31:55.943871 69145 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 18:31:55.943879 69145 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 18:31:55.944293 69145 net.cpp:144] Setting up inception_2a/1x1
I0122 18:31:55.944300 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.944303 69145 net.cpp:159] Memory required for data: 105473000
I0122 18:31:55.944310 69145 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 18:31:55.944322 69145 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 18:31:55.944326 69145 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 18:31:55.944337 69145 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 18:31:55.945152 69145 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 18:31:55.945159 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.945161 69145 net.cpp:159] Memory required for data: 112026600
I0122 18:31:55.945170 69145 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 18:31:55.945181 69145 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 18:31:55.945185 69145 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 18:31:55.945194 69145 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 18:31:55.945205 69145 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 18:31:55.945211 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.945214 69145 net.cpp:159] Memory required for data: 118580200
I0122 18:31:55.945219 69145 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 18:31:55.945231 69145 net.cpp:94] Creating Layer inception_2a/3x3
I0122 18:31:55.945237 69145 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 18:31:55.945246 69145 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 18:31:55.945694 69145 net.cpp:144] Setting up inception_2a/3x3
I0122 18:31:55.945703 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.945705 69145 net.cpp:159] Memory required for data: 125133800
I0122 18:31:55.945710 69145 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 18:31:55.945719 69145 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 18:31:55.945722 69145 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 18:31:55.945741 69145 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 18:31:55.946478 69145 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 18:31:55.946486 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.946491 69145 net.cpp:159] Memory required for data: 131687400
I0122 18:31:55.946503 69145 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 18:31:55.946514 69145 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 18:31:55.946518 69145 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 18:31:55.946527 69145 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 18:31:55.946538 69145 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 18:31:55.946544 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.946548 69145 net.cpp:159] Memory required for data: 138241000
I0122 18:31:55.946554 69145 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 18:31:55.946561 69145 net.cpp:94] Creating Layer inception_2a/output
I0122 18:31:55.946565 69145 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 18:31:55.946570 69145 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 18:31:55.946578 69145 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 18:31:55.946660 69145 net.cpp:144] Setting up inception_2a/output
I0122 18:31:55.946668 69145 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 18:31:55.946671 69145 net.cpp:159] Memory required for data: 151348200
I0122 18:31:55.946674 69145 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 18:31:55.946679 69145 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 18:31:55.946684 69145 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 18:31:55.946691 69145 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 18:31:55.946702 69145 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 18:31:55.946743 69145 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 18:31:55.946748 69145 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 18:31:55.946751 69145 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 18:31:55.946758 69145 net.cpp:159] Memory required for data: 177562600
I0122 18:31:55.946760 69145 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 18:31:55.946771 69145 net.cpp:94] Creating Layer inception_3a/1x1
I0122 18:31:55.946776 69145 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 18:31:55.946785 69145 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 18:31:55.947054 69145 net.cpp:144] Setting up inception_3a/1x1
I0122 18:31:55.947062 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.947063 69145 net.cpp:159] Memory required for data: 184116200
I0122 18:31:55.947069 69145 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 18:31:55.947078 69145 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 18:31:55.947083 69145 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 18:31:55.947093 69145 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 18:31:55.947877 69145 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 18:31:55.947885 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.947887 69145 net.cpp:159] Memory required for data: 190669800
I0122 18:31:55.947894 69145 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 18:31:55.947916 69145 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 18:31:55.947922 69145 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 18:31:55.947928 69145 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 18:31:55.947934 69145 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 18:31:55.947944 69145 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 18:31:55.947949 69145 net.cpp:159] Memory required for data: 197223400
I0122 18:31:55.947964 69145 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 18:31:55.947976 69145 net.cpp:94] Creating Layer inception_3a/3x3
I0122 18:31:55.947983 69145 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 18:31:55.947993 69145 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 18:31:55.949110 69145 net.cpp:144] Setting up inception_3a/3x3
I0122 18:31:55.949120 69145 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 18:31:55.949129 69145 net.cpp:159] Memory required for data: 207053800
I0122 18:31:55.949136 69145 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 18:31:55.949144 69145 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 18:31:55.949148 69145 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 18:31:55.949167 69145 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 18:31:55.949966 69145 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 18:31:55.949975 69145 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 18:31:55.949977 69145 net.cpp:159] Memory required for data: 216884200
I0122 18:31:55.949990 69145 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 18:31:55.950002 69145 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 18:31:55.950008 69145 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 18:31:55.950016 69145 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 18:31:55.950028 69145 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 18:31:55.950034 69145 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 18:31:55.950037 69145 net.cpp:159] Memory required for data: 226714600
I0122 18:31:55.950042 69145 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 18:31:55.950048 69145 net.cpp:94] Creating Layer inception_3a/output
I0122 18:31:55.950055 69145 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 18:31:55.950060 69145 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 18:31:55.950068 69145 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 18:31:55.950129 69145 net.cpp:144] Setting up inception_3a/output
I0122 18:31:55.950134 69145 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 18:31:55.950137 69145 net.cpp:159] Memory required for data: 243098600
I0122 18:31:55.950139 69145 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 18:31:55.950147 69145 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 18:31:55.950153 69145 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 18:31:55.950160 69145 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 18:31:55.950178 69145 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 18:31:55.950222 69145 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 18:31:55.950227 69145 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 18:31:55.950232 69145 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 18:31:55.950234 69145 net.cpp:159] Memory required for data: 275866600
I0122 18:31:55.950237 69145 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 18:31:55.950251 69145 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 18:31:55.950258 69145 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 18:31:55.950266 69145 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 18:31:55.950847 69145 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 18:31:55.950855 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.950857 69145 net.cpp:159] Memory required for data: 279962600
I0122 18:31:55.950863 69145 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 18:31:55.950873 69145 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 18:31:55.950878 69145 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 18:31:55.950902 69145 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 18:31:55.951757 69145 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 18:31:55.951766 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.951768 69145 net.cpp:159] Memory required for data: 284058600
I0122 18:31:55.951777 69145 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 18:31:55.951788 69145 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 18:31:55.951797 69145 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 18:31:55.951807 69145 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 18:31:55.951815 69145 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 18:31:55.951823 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.951828 69145 net.cpp:159] Memory required for data: 288154600
I0122 18:31:55.951831 69145 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 18:31:55.951839 69145 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 18:31:55.951844 69145 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 18:31:55.951861 69145 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 18:31:55.951913 69145 net.cpp:144] Setting up downsample_4/pool_s2
I0122 18:31:55.951920 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.951921 69145 net.cpp:159] Memory required for data: 292250600
I0122 18:31:55.951925 69145 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 18:31:55.951930 69145 net.cpp:94] Creating Layer downsample_4/output
I0122 18:31:55.951932 69145 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 18:31:55.951937 69145 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 18:31:55.951946 69145 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 18:31:55.951973 69145 net.cpp:144] Setting up downsample_4/output
I0122 18:31:55.951979 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.951982 69145 net.cpp:159] Memory required for data: 300442600
I0122 18:31:55.951985 69145 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 18:31:55.951992 69145 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 18:31:55.952008 69145 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 18:31:55.952015 69145 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 18:31:55.952025 69145 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 18:31:55.952064 69145 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 18:31:55.952070 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.952073 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.952077 69145 net.cpp:159] Memory required for data: 316826600
I0122 18:31:55.952080 69145 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 18:31:55.952088 69145 net.cpp:94] Creating Layer inception_5a/1x1
I0122 18:31:55.952091 69145 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 18:31:55.952101 69145 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 18:31:55.952462 69145 net.cpp:144] Setting up inception_5a/1x1
I0122 18:31:55.952469 69145 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 18:31:55.952473 69145 net.cpp:159] Memory required for data: 322561000
I0122 18:31:55.952478 69145 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 18:31:55.952489 69145 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 18:31:55.952497 69145 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 18:31:55.952507 69145 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 18:31:55.953352 69145 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 18:31:55.953372 69145 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 18:31:55.953375 69145 net.cpp:159] Memory required for data: 328295400
I0122 18:31:55.953383 69145 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 18:31:55.953393 69145 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 18:31:55.953397 69145 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 18:31:55.953404 69145 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 18:31:55.953414 69145 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 18:31:55.953423 69145 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 18:31:55.953428 69145 net.cpp:159] Memory required for data: 334029800
I0122 18:31:55.953431 69145 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 18:31:55.953455 69145 net.cpp:94] Creating Layer inception_5a/3x3
I0122 18:31:55.953462 69145 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 18:31:55.953469 69145 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 18:31:55.954151 69145 net.cpp:144] Setting up inception_5a/3x3
I0122 18:31:55.954160 69145 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:55.954164 69145 net.cpp:159] Memory required for data: 336487400
I0122 18:31:55.954169 69145 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 18:31:55.954182 69145 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 18:31:55.954190 69145 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 18:31:55.954200 69145 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 18:31:55.955044 69145 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 18:31:55.955050 69145 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:55.955054 69145 net.cpp:159] Memory required for data: 338945000
I0122 18:31:55.955063 69145 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 18:31:55.955075 69145 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 18:31:55.955080 69145 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 18:31:55.955086 69145 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 18:31:55.955099 69145 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 18:31:55.955107 69145 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:55.955111 69145 net.cpp:159] Memory required for data: 341402600
I0122 18:31:55.955116 69145 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 18:31:55.955122 69145 net.cpp:94] Creating Layer inception_5a/output
I0122 18:31:55.955128 69145 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 18:31:55.955134 69145 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 18:31:55.955142 69145 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 18:31:55.955183 69145 net.cpp:144] Setting up inception_5a/output
I0122 18:31:55.955188 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.955191 69145 net.cpp:159] Memory required for data: 349594600
I0122 18:31:55.955193 69145 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 18:31:55.955200 69145 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 18:31:55.955204 69145 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 18:31:55.955210 69145 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 18:31:55.955224 69145 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 18:31:55.955265 69145 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 18:31:55.955271 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.955274 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.955277 69145 net.cpp:159] Memory required for data: 365978600
I0122 18:31:55.955281 69145 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 18:31:55.955307 69145 net.cpp:94] Creating Layer inception_6a/1x1
I0122 18:31:55.955314 69145 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 18:31:55.955328 69145 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 18:31:55.955693 69145 net.cpp:144] Setting up inception_6a/1x1
I0122 18:31:55.955699 69145 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:55.955703 69145 net.cpp:159] Memory required for data: 370893800
I0122 18:31:55.955708 69145 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 18:31:55.955718 69145 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 18:31:55.955724 69145 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 18:31:55.955734 69145 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 18:31:55.956573 69145 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 18:31:55.956581 69145 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:55.956583 69145 net.cpp:159] Memory required for data: 375809000
I0122 18:31:55.956593 69145 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 18:31:55.956604 69145 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 18:31:55.956609 69145 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 18:31:55.956616 69145 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 18:31:55.956629 69145 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 18:31:55.956634 69145 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:55.956638 69145 net.cpp:159] Memory required for data: 380724200
I0122 18:31:55.956642 69145 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 18:31:55.956655 69145 net.cpp:94] Creating Layer inception_6a/3x3
I0122 18:31:55.956661 69145 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 18:31:55.956670 69145 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 18:31:55.958150 69145 net.cpp:144] Setting up inception_6a/3x3
I0122 18:31:55.958168 69145 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 18:31:55.958171 69145 net.cpp:159] Memory required for data: 384001000
I0122 18:31:55.958189 69145 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 18:31:55.958202 69145 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 18:31:55.958210 69145 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 18:31:55.958220 69145 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 18:31:55.958938 69145 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 18:31:55.958946 69145 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 18:31:55.958948 69145 net.cpp:159] Memory required for data: 387277800
I0122 18:31:55.958957 69145 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 18:31:55.958971 69145 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 18:31:55.958974 69145 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 18:31:55.958984 69145 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 18:31:55.958994 69145 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 18:31:55.959004 69145 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 18:31:55.959007 69145 net.cpp:159] Memory required for data: 390554600
I0122 18:31:55.959012 69145 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 18:31:55.959020 69145 net.cpp:94] Creating Layer inception_6a/output
I0122 18:31:55.959026 69145 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 18:31:55.959031 69145 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 18:31:55.959039 69145 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 18:31:55.959066 69145 net.cpp:144] Setting up inception_6a/output
I0122 18:31:55.959074 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.959075 69145 net.cpp:159] Memory required for data: 398746600
I0122 18:31:55.959079 69145 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 18:31:55.959086 69145 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 18:31:55.959101 69145 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 18:31:55.959108 69145 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 18:31:55.959120 69145 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 18:31:55.959161 69145 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 18:31:55.959167 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.959170 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.959173 69145 net.cpp:159] Memory required for data: 415130600
I0122 18:31:55.959175 69145 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 18:31:55.959187 69145 net.cpp:94] Creating Layer inception_7a/1x1
I0122 18:31:55.959193 69145 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 18:31:55.959201 69145 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 18:31:55.959525 69145 net.cpp:144] Setting up inception_7a/1x1
I0122 18:31:55.959533 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.959535 69145 net.cpp:159] Memory required for data: 419226600
I0122 18:31:55.959540 69145 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 18:31:55.959553 69145 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 18:31:55.959560 69145 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 18:31:55.959568 69145 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 18:31:55.960279 69145 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 18:31:55.960288 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.960290 69145 net.cpp:159] Memory required for data: 423322600
I0122 18:31:55.960300 69145 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 18:31:55.960309 69145 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 18:31:55.960314 69145 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 18:31:55.960322 69145 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 18:31:55.960332 69145 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 18:31:55.960338 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.960345 69145 net.cpp:159] Memory required for data: 427418600
I0122 18:31:55.960350 69145 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 18:31:55.960361 69145 net.cpp:94] Creating Layer inception_7a/3x3
I0122 18:31:55.960367 69145 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 18:31:55.960376 69145 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 18:31:55.961267 69145 net.cpp:144] Setting up inception_7a/3x3
I0122 18:31:55.961277 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.961279 69145 net.cpp:159] Memory required for data: 431514600
I0122 18:31:55.961284 69145 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 18:31:55.961297 69145 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 18:31:55.961302 69145 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 18:31:55.961311 69145 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 18:31:55.962031 69145 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 18:31:55.962039 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.962043 69145 net.cpp:159] Memory required for data: 435610600
I0122 18:31:55.962050 69145 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 18:31:55.962061 69145 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 18:31:55.962069 69145 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 18:31:55.962075 69145 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 18:31:55.962083 69145 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 18:31:55.962090 69145 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 18:31:55.962095 69145 net.cpp:159] Memory required for data: 439706600
I0122 18:31:55.962110 69145 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 18:31:55.962116 69145 net.cpp:94] Creating Layer inception_7a/output
I0122 18:31:55.962119 69145 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 18:31:55.962126 69145 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 18:31:55.962136 69145 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 18:31:55.962167 69145 net.cpp:144] Setting up inception_7a/output
I0122 18:31:55.962172 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.962175 69145 net.cpp:159] Memory required for data: 447898600
I0122 18:31:55.962178 69145 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 18:31:55.962184 69145 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 18:31:55.962188 69145 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 18:31:55.962198 69145 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 18:31:55.962209 69145 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 18:31:55.962247 69145 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 18:31:55.962254 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.962257 69145 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 18:31:55.962260 69145 net.cpp:159] Memory required for data: 464282600
I0122 18:31:55.962262 69145 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 18:31:55.962275 69145 net.cpp:94] Creating Layer inception_8a/1x1
I0122 18:31:55.962281 69145 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 18:31:55.962291 69145 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 18:31:55.962591 69145 net.cpp:144] Setting up inception_8a/1x1
I0122 18:31:55.962597 69145 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:55.962601 69145 net.cpp:159] Memory required for data: 466740200
I0122 18:31:55.962606 69145 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 18:31:55.962617 69145 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 18:31:55.962623 69145 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 18:31:55.962631 69145 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 18:31:55.963335 69145 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 18:31:55.963342 69145 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:55.963346 69145 net.cpp:159] Memory required for data: 469197800
I0122 18:31:55.963356 69145 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 18:31:55.963366 69145 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 18:31:55.963371 69145 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 18:31:55.963376 69145 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 18:31:55.963388 69145 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 18:31:55.963398 69145 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 18:31:55.963402 69145 net.cpp:159] Memory required for data: 471655400
I0122 18:31:55.963407 69145 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 18:31:55.963419 69145 net.cpp:94] Creating Layer inception_8a/3x3
I0122 18:31:55.963425 69145 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 18:31:55.963434 69145 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 18:31:55.965090 69145 net.cpp:144] Setting up inception_8a/3x3
I0122 18:31:55.965103 69145 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:55.965106 69145 net.cpp:159] Memory required for data: 476570600
I0122 18:31:55.965112 69145 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 18:31:55.965132 69145 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 18:31:55.965140 69145 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 18:31:55.965160 69145 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 18:31:55.965873 69145 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 18:31:55.965881 69145 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:55.965885 69145 net.cpp:159] Memory required for data: 481485800
I0122 18:31:55.965894 69145 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 18:31:55.965903 69145 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 18:31:55.965911 69145 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 18:31:55.965922 69145 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 18:31:55.965934 69145 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 18:31:55.965942 69145 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 18:31:55.965946 69145 net.cpp:159] Memory required for data: 486401000
I0122 18:31:55.965950 69145 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 18:31:55.965960 69145 net.cpp:94] Creating Layer inception_8a/output
I0122 18:31:55.965963 69145 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 18:31:55.965968 69145 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 18:31:55.965977 69145 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 18:31:55.966006 69145 net.cpp:144] Setting up inception_8a/output
I0122 18:31:55.966012 69145 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 18:31:55.966015 69145 net.cpp:159] Memory required for data: 493773800
I0122 18:31:55.966018 69145 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 18:31:55.966023 69145 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 18:31:55.966027 69145 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 18:31:55.966037 69145 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 18:31:55.966048 69145 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 18:31:55.966086 69145 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 18:31:55.966092 69145 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 18:31:55.966096 69145 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 18:31:55.966099 69145 net.cpp:159] Memory required for data: 508519400
I0122 18:31:55.966101 69145 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 18:31:55.966115 69145 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 18:31:55.966121 69145 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 18:31:55.966130 69145 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 18:31:55.967698 69145 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 18:31:55.967710 69145 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 18:31:55.967713 69145 net.cpp:159] Memory required for data: 509748200
I0122 18:31:55.967721 69145 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 18:31:55.967734 69145 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 18:31:55.967741 69145 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 18:31:55.967751 69145 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 18:31:55.968479 69145 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 18:31:55.968487 69145 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 18:31:55.968489 69145 net.cpp:159] Memory required for data: 510977000
I0122 18:31:55.968498 69145 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 18:31:55.968508 69145 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 18:31:55.968513 69145 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 18:31:55.968519 69145 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 18:31:55.968528 69145 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 18:31:55.968545 69145 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 18:31:55.968549 69145 net.cpp:159] Memory required for data: 512205800
I0122 18:31:55.968551 69145 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 18:31:55.968560 69145 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 18:31:55.968567 69145 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 18:31:55.968576 69145 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 18:31:55.968616 69145 net.cpp:144] Setting up downsample_9/pool_s2
I0122 18:31:55.968622 69145 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 18:31:55.968626 69145 net.cpp:159] Memory required for data: 514049000
I0122 18:31:55.968628 69145 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 18:31:55.968641 69145 net.cpp:94] Creating Layer downsample_9/output
I0122 18:31:55.968647 69145 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 18:31:55.968653 69145 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 18:31:55.968659 69145 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 18:31:55.968683 69145 net.cpp:144] Setting up downsample_9/output
I0122 18:31:55.968689 69145 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 18:31:55.968693 69145 net.cpp:159] Memory required for data: 517121000
I0122 18:31:55.968695 69145 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 18:31:55.968700 69145 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 18:31:55.968704 69145 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 18:31:55.968713 69145 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 18:31:55.968724 69145 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 18:31:55.968765 69145 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 18:31:55.968770 69145 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 18:31:55.968775 69145 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 18:31:55.968777 69145 net.cpp:159] Memory required for data: 523265000
I0122 18:31:55.968780 69145 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 18:31:55.968791 69145 net.cpp:94] Creating Layer inception_10a/1x1
I0122 18:31:55.968798 69145 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 18:31:55.968808 69145 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 18:31:55.969295 69145 net.cpp:144] Setting up inception_10a/1x1
I0122 18:31:55.969305 69145 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:55.969308 69145 net.cpp:159] Memory required for data: 525517800
I0122 18:31:55.969316 69145 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 18:31:55.969326 69145 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 18:31:55.969332 69145 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 18:31:55.969339 69145 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 18:31:55.970062 69145 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 18:31:55.970070 69145 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:55.970073 69145 net.cpp:159] Memory required for data: 527770600
I0122 18:31:55.970083 69145 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 18:31:55.970091 69145 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 18:31:55.970096 69145 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 18:31:55.970105 69145 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 18:31:55.970118 69145 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 18:31:55.970121 69145 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:55.970125 69145 net.cpp:159] Memory required for data: 530023400
I0122 18:31:55.970129 69145 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 18:31:55.970151 69145 net.cpp:94] Creating Layer inception_10a/3x3
I0122 18:31:55.970157 69145 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 18:31:55.970166 69145 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 18:31:55.972693 69145 net.cpp:144] Setting up inception_10a/3x3
I0122 18:31:55.972704 69145 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:55.972707 69145 net.cpp:159] Memory required for data: 532071400
I0122 18:31:55.972712 69145 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 18:31:55.972723 69145 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 18:31:55.972728 69145 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 18:31:55.972736 69145 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 18:31:55.973426 69145 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 18:31:55.973433 69145 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:55.973438 69145 net.cpp:159] Memory required for data: 534119400
I0122 18:31:55.973445 69145 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 18:31:55.973455 69145 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 18:31:55.973460 69145 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 18:31:55.973469 69145 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 18:31:55.973479 69145 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 18:31:55.973484 69145 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:55.973486 69145 net.cpp:159] Memory required for data: 536167400
I0122 18:31:55.973491 69145 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 18:31:55.973498 69145 net.cpp:94] Creating Layer inception_10a/output
I0122 18:31:55.973505 69145 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 18:31:55.973510 69145 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 18:31:55.973517 69145 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 18:31:55.973546 69145 net.cpp:144] Setting up inception_10a/output
I0122 18:31:55.973551 69145 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:55.973553 69145 net.cpp:159] Memory required for data: 540468200
I0122 18:31:55.973556 69145 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 18:31:55.973563 69145 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 18:31:55.973567 69145 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 18:31:55.973574 69145 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 18:31:55.973585 69145 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 18:31:55.973623 69145 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 18:31:55.973628 69145 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:55.973632 69145 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:55.973635 69145 net.cpp:159] Memory required for data: 549069800
I0122 18:31:55.973637 69145 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 18:31:55.973649 69145 net.cpp:94] Creating Layer inception_11a/1x1
I0122 18:31:55.973655 69145 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 18:31:55.973664 69145 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 18:31:55.974241 69145 net.cpp:144] Setting up inception_11a/1x1
I0122 18:31:55.974249 69145 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:55.974252 69145 net.cpp:159] Memory required for data: 551322600
I0122 18:31:55.974258 69145 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 18:31:55.974268 69145 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 18:31:55.974274 69145 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 18:31:55.974283 69145 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 18:31:55.974989 69145 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 18:31:55.974997 69145 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:55.974999 69145 net.cpp:159] Memory required for data: 553575400
I0122 18:31:55.975008 69145 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 18:31:55.975031 69145 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 18:31:55.975037 69145 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 18:31:55.975044 69145 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 18:31:55.975049 69145 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 18:31:55.975057 69145 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 18:31:55.975061 69145 net.cpp:159] Memory required for data: 555828200
I0122 18:31:55.975065 69145 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 18:31:55.975077 69145 net.cpp:94] Creating Layer inception_11a/3x3
I0122 18:31:55.975085 69145 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 18:31:55.975092 69145 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 18:31:55.978812 69145 net.cpp:144] Setting up inception_11a/3x3
I0122 18:31:55.978824 69145 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:55.978827 69145 net.cpp:159] Memory required for data: 557876200
I0122 18:31:55.978833 69145 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 18:31:55.978843 69145 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 18:31:55.978859 69145 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 18:31:55.978869 69145 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 18:31:55.979578 69145 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 18:31:55.979588 69145 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:55.979589 69145 net.cpp:159] Memory required for data: 559924200
I0122 18:31:55.979615 69145 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 18:31:55.979624 69145 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 18:31:55.979627 69145 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 18:31:55.979632 69145 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 18:31:55.979645 69145 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 18:31:55.979650 69145 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 18:31:55.979653 69145 net.cpp:159] Memory required for data: 561972200
I0122 18:31:55.979657 69145 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 18:31:55.979665 69145 net.cpp:94] Creating Layer inception_11a/output
I0122 18:31:55.979671 69145 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 18:31:55.979676 69145 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 18:31:55.979683 69145 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 18:31:55.979713 69145 net.cpp:144] Setting up inception_11a/output
I0122 18:31:55.979720 69145 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 18:31:55.979722 69145 net.cpp:159] Memory required for data: 566273000
I0122 18:31:55.979725 69145 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 18:31:55.979732 69145 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 18:31:55.979735 69145 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 18:31:55.979743 69145 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 18:31:55.979774 69145 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 18:31:55.979780 69145 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 18:31:55.979784 69145 net.cpp:159] Memory required for data: 566340200
I0122 18:31:55.979785 69145 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 18:31:55.979791 69145 net.cpp:94] Creating Layer drop_8x8_s1
I0122 18:31:55.979797 69145 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 18:31:55.979805 69145 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 18:31:55.979830 69145 net.cpp:144] Setting up drop_8x8_s1
I0122 18:31:55.979836 69145 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 18:31:55.979848 69145 net.cpp:159] Memory required for data: 566407400
I0122 18:31:55.979851 69145 layer_factory.hpp:77] Creating layer loss/classifier
I0122 18:31:55.979861 69145 net.cpp:94] Creating Layer loss/classifier
I0122 18:31:55.979866 69145 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 18:31:55.979876 69145 net.cpp:409] loss/classifier -> loss/classifier
I0122 18:31:55.980028 69145 net.cpp:144] Setting up loss/classifier
I0122 18:31:55.980034 69145 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:55.980036 69145 net.cpp:159] Memory required for data: 566409400
I0122 18:31:55.980042 69145 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 18:31:55.980049 69145 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 18:31:55.980054 69145 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 18:31:55.980062 69145 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 18:31:55.980072 69145 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 18:31:55.980083 69145 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 18:31:55.980093 69145 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 18:31:55.980151 69145 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 18:31:55.980157 69145 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:55.980160 69145 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:55.980163 69145 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:55.980167 69145 net.cpp:151] Top shape: 50 10 (500)
I0122 18:31:55.980172 69145 net.cpp:159] Memory required for data: 566417400
I0122 18:31:55.980176 69145 layer_factory.hpp:77] Creating layer loss
I0122 18:31:55.980183 69145 net.cpp:94] Creating Layer loss
I0122 18:31:55.980190 69145 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 18:31:55.980196 69145 net.cpp:435] loss <- label_data_1_split_0
I0122 18:31:55.980201 69145 net.cpp:409] loss -> loss
I0122 18:31:55.980211 69145 layer_factory.hpp:77] Creating layer loss
I0122 18:31:55.980299 69145 net.cpp:144] Setting up loss
I0122 18:31:55.980305 69145 net.cpp:151] Top shape: (1)
I0122 18:31:55.980307 69145 net.cpp:154]     with loss weight 1
I0122 18:31:55.980317 69145 net.cpp:159] Memory required for data: 566417404
I0122 18:31:55.980320 69145 layer_factory.hpp:77] Creating layer accuracy
I0122 18:31:55.980329 69145 net.cpp:94] Creating Layer accuracy
I0122 18:31:55.980335 69145 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 18:31:55.980340 69145 net.cpp:435] accuracy <- label_data_1_split_1
I0122 18:31:55.980346 69145 net.cpp:409] accuracy -> accuracy
I0122 18:31:55.980362 69145 net.cpp:144] Setting up accuracy
I0122 18:31:55.980370 69145 net.cpp:151] Top shape: (1)
I0122 18:31:55.980372 69145 net.cpp:159] Memory required for data: 566417408
I0122 18:31:55.980374 69145 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 18:31:55.980381 69145 net.cpp:94] Creating Layer accuracy-top1
I0122 18:31:55.980384 69145 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 18:31:55.980389 69145 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 18:31:55.980396 69145 net.cpp:409] accuracy-top1 -> top-1
I0122 18:31:55.980406 69145 net.cpp:144] Setting up accuracy-top1
I0122 18:31:55.980412 69145 net.cpp:151] Top shape: (1)
I0122 18:31:55.980414 69145 net.cpp:159] Memory required for data: 566417412
I0122 18:31:55.980418 69145 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 18:31:55.980424 69145 net.cpp:94] Creating Layer accuracy-top5
I0122 18:31:55.980428 69145 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 18:31:55.980433 69145 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 18:31:55.980439 69145 net.cpp:409] accuracy-top5 -> top-5
I0122 18:31:55.980456 69145 net.cpp:144] Setting up accuracy-top5
I0122 18:31:55.980460 69145 net.cpp:151] Top shape: (1)
I0122 18:31:55.980463 69145 net.cpp:159] Memory required for data: 566417416
I0122 18:31:55.980468 69145 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 18:31:55.980473 69145 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 18:31:55.980478 69145 net.cpp:222] accuracy does not need backward computation.
I0122 18:31:55.980482 69145 net.cpp:220] loss needs backward computation.
I0122 18:31:55.980489 69145 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 18:31:55.980496 69145 net.cpp:220] loss/classifier needs backward computation.
I0122 18:31:55.980500 69145 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 18:31:55.980504 69145 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 18:31:55.980509 69145 net.cpp:220] inception_11a/output needs backward computation.
I0122 18:31:55.980515 69145 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 18:31:55.980518 69145 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 18:31:55.980521 69145 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 18:31:55.980525 69145 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 18:31:55.980530 69145 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 18:31:55.980535 69145 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 18:31:55.980538 69145 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 18:31:55.980543 69145 net.cpp:220] inception_10a/output needs backward computation.
I0122 18:31:55.980548 69145 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 18:31:55.980552 69145 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 18:31:55.980556 69145 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 18:31:55.980561 69145 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 18:31:55.980566 69145 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 18:31:55.980569 69145 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 18:31:55.980573 69145 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 18:31:55.980578 69145 net.cpp:220] downsample_9/output needs backward computation.
I0122 18:31:55.980583 69145 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 18:31:55.980588 69145 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 18:31:55.980592 69145 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 18:31:55.980595 69145 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 18:31:55.980602 69145 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 18:31:55.980605 69145 net.cpp:220] inception_8a/output needs backward computation.
I0122 18:31:55.980612 69145 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 18:31:55.980615 69145 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 18:31:55.980619 69145 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 18:31:55.980625 69145 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 18:31:55.980629 69145 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 18:31:55.980633 69145 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 18:31:55.980638 69145 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 18:31:55.980643 69145 net.cpp:220] inception_7a/output needs backward computation.
I0122 18:31:55.980648 69145 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 18:31:55.980651 69145 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 18:31:55.980656 69145 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 18:31:55.980660 69145 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 18:31:55.980670 69145 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 18:31:55.980674 69145 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 18:31:55.980679 69145 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 18:31:55.980682 69145 net.cpp:220] inception_6a/output needs backward computation.
I0122 18:31:55.980687 69145 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 18:31:55.980691 69145 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 18:31:55.980696 69145 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 18:31:55.980700 69145 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 18:31:55.980705 69145 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 18:31:55.980708 69145 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 18:31:55.980715 69145 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 18:31:55.980720 69145 net.cpp:220] inception_5a/output needs backward computation.
I0122 18:31:55.980726 69145 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 18:31:55.980731 69145 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 18:31:55.980736 69145 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 18:31:55.980739 69145 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 18:31:55.980743 69145 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 18:31:55.980747 69145 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 18:31:55.980752 69145 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 18:31:55.980757 69145 net.cpp:220] downsample_4/output needs backward computation.
I0122 18:31:55.980762 69145 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 18:31:55.980767 69145 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 18:31:55.980772 69145 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 18:31:55.980775 69145 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 18:31:55.980779 69145 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 18:31:55.980784 69145 net.cpp:220] inception_3a/output needs backward computation.
I0122 18:31:55.980789 69145 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 18:31:55.980793 69145 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 18:31:55.980798 69145 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 18:31:55.980801 69145 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 18:31:55.980806 69145 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 18:31:55.980810 69145 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 18:31:55.980814 69145 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 18:31:55.980819 69145 net.cpp:220] inception_2a/output needs backward computation.
I0122 18:31:55.980824 69145 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 18:31:55.980829 69145 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 18:31:55.980832 69145 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 18:31:55.980837 69145 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 18:31:55.980841 69145 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 18:31:55.980845 69145 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 18:31:55.980850 69145 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 18:31:55.980854 69145 net.cpp:220] conv1/relu1 needs backward computation.
I0122 18:31:55.980859 69145 net.cpp:220] conv1/bn1 needs backward computation.
I0122 18:31:55.980864 69145 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 18:31:55.980875 69145 net.cpp:222] label_data_1_split does not need backward computation.
I0122 18:31:55.980881 69145 net.cpp:222] data does not need backward computation.
I0122 18:31:55.980890 69145 net.cpp:264] This network produces output accuracy
I0122 18:31:55.980893 69145 net.cpp:264] This network produces output loss
I0122 18:31:55.980897 69145 net.cpp:264] This network produces output top-1
I0122 18:31:55.980901 69145 net.cpp:264] This network produces output top-5
I0122 18:31:55.980981 69145 net.cpp:284] Network initialization done.
I0122 18:31:55.981307 69145 solver.cpp:63] Solver scaffolding done.
I0122 18:31:55.985815 69145 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/sparse.caffemodel
I0122 18:31:56.029609 69145 caffe_interface.cpp:527] Starting Optimization
I0122 18:31:56.029630 69145 solver.cpp:335] Solving 
I0122 18:31:56.029633 69145 solver.cpp:336] Learning Rate Policy: step
I0122 18:31:56.032357 69145 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 18:31:57.489120 69145 solver.cpp:517]     Test net output #0: accuracy = 0.891
I0122 18:31:57.489158 69145 solver.cpp:517]     Test net output #1: loss = 0.392776 (* 1 = 0.392776 loss)
I0122 18:31:57.489163 69145 solver.cpp:517]     Test net output #2: top-1 = 0.891
I0122 18:31:57.489166 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 18:31:57.568707 69145 solver.cpp:266] Iteration 0 (0 iter/s, 1.539s/100 iter), loss = 0.00864745
I0122 18:31:57.568743 69145 solver.cpp:285]     Train net output #0: loss = 0.00864745 (* 1 = 0.00864745 loss)
I0122 18:31:57.568759 69145 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 18:32:03.675849 69145 solver.cpp:266] Iteration 100 (16.375 iter/s, 6.10689s/100 iter), loss = 1.17373
I0122 18:32:03.675881 69145 solver.cpp:285]     Train net output #0: loss = 1.17373 (* 1 = 1.17373 loss)
I0122 18:32:03.675887 69145 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 18:32:09.771085 69145 solver.cpp:266] Iteration 200 (16.4069 iter/s, 6.09499s/100 iter), loss = 1.24249
I0122 18:32:09.771114 69145 solver.cpp:285]     Train net output #0: loss = 1.24249 (* 1 = 1.24249 loss)
I0122 18:32:09.771119 69145 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 18:32:15.872691 69145 solver.cpp:266] Iteration 300 (16.3898 iter/s, 6.10136s/100 iter), loss = 0.993618
I0122 18:32:15.872722 69145 solver.cpp:285]     Train net output #0: loss = 0.993618 (* 1 = 0.993618 loss)
I0122 18:32:15.872727 69145 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 18:32:21.976200 69145 solver.cpp:266] Iteration 400 (16.3847 iter/s, 6.10326s/100 iter), loss = 0.848938
I0122 18:32:21.976233 69145 solver.cpp:285]     Train net output #0: loss = 0.848938 (* 1 = 0.848938 loss)
I0122 18:32:21.976238 69145 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 18:32:28.099090 69145 solver.cpp:266] Iteration 500 (16.3328 iter/s, 6.12264s/100 iter), loss = 0.7788
I0122 18:32:28.099297 69145 solver.cpp:285]     Train net output #0: loss = 0.7788 (* 1 = 0.7788 loss)
I0122 18:32:28.099306 69145 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 18:32:34.275799 69145 solver.cpp:266] Iteration 600 (16.191 iter/s, 6.17629s/100 iter), loss = 0.690213
I0122 18:32:34.275831 69145 solver.cpp:285]     Train net output #0: loss = 0.690213 (* 1 = 0.690213 loss)
I0122 18:32:34.275836 69145 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 18:32:40.519490 69145 solver.cpp:266] Iteration 700 (16.0168 iter/s, 6.24343s/100 iter), loss = 0.810086
I0122 18:32:40.519520 69145 solver.cpp:285]     Train net output #0: loss = 0.810086 (* 1 = 0.810086 loss)
I0122 18:32:40.519526 69145 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 18:32:46.781350 69145 solver.cpp:266] Iteration 800 (15.9703 iter/s, 6.2616s/100 iter), loss = 0.700975
I0122 18:32:46.781381 69145 solver.cpp:285]     Train net output #0: loss = 0.700975 (* 1 = 0.700975 loss)
I0122 18:32:46.781388 69145 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 18:32:53.051285 69145 solver.cpp:266] Iteration 900 (15.9498 iter/s, 6.26968s/100 iter), loss = 0.512801
I0122 18:32:53.051316 69145 solver.cpp:285]     Train net output #0: loss = 0.512801 (* 1 = 0.512801 loss)
I0122 18:32:53.051321 69145 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 18:32:59.270682 69145 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 18:33:00.727684 69145 solver.cpp:517]     Test net output #0: accuracy = 0.259222
I0122 18:33:00.727711 69145 solver.cpp:517]     Test net output #1: loss = 7.71966 (* 1 = 7.71966 loss)
I0122 18:33:00.727716 69145 solver.cpp:517]     Test net output #2: top-1 = 0.259222
I0122 18:33:00.727720 69145 solver.cpp:517]     Test net output #3: top-5 = 0.682111
I0122 18:33:00.790169 69145 solver.cpp:266] Iteration 1000 (12.9223 iter/s, 7.73858s/100 iter), loss = 0.645587
I0122 18:33:00.790190 69145 solver.cpp:285]     Train net output #0: loss = 0.645587 (* 1 = 0.645587 loss)
I0122 18:33:00.790197 69145 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 18:33:07.140537 69145 solver.cpp:266] Iteration 1100 (15.7477 iter/s, 6.35012s/100 iter), loss = 0.69845
I0122 18:33:07.140578 69145 solver.cpp:285]     Train net output #0: loss = 0.69845 (* 1 = 0.69845 loss)
I0122 18:33:07.140586 69145 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 18:33:13.429595 69145 solver.cpp:266] Iteration 1200 (15.9013 iter/s, 6.28879s/100 iter), loss = 0.526266
I0122 18:33:13.429636 69145 solver.cpp:285]     Train net output #0: loss = 0.526266 (* 1 = 0.526266 loss)
I0122 18:33:13.429642 69145 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 18:33:19.732331 69145 solver.cpp:266] Iteration 1300 (15.8668 iter/s, 6.30247s/100 iter), loss = 0.533617
I0122 18:33:19.732372 69145 solver.cpp:285]     Train net output #0: loss = 0.533617 (* 1 = 0.533617 loss)
I0122 18:33:19.732379 69145 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 18:33:26.044976 69145 solver.cpp:266] Iteration 1400 (15.8419 iter/s, 6.31238s/100 iter), loss = 0.626537
I0122 18:33:26.045007 69145 solver.cpp:285]     Train net output #0: loss = 0.626537 (* 1 = 0.626537 loss)
I0122 18:33:26.045013 69145 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 18:33:32.331624 69145 solver.cpp:266] Iteration 1500 (15.9074 iter/s, 6.28639s/100 iter), loss = 0.554066
I0122 18:33:32.331768 69145 solver.cpp:285]     Train net output #0: loss = 0.554066 (* 1 = 0.554066 loss)
I0122 18:33:32.331775 69145 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 18:33:38.596282 69145 solver.cpp:266] Iteration 1600 (15.9635 iter/s, 6.26429s/100 iter), loss = 0.664887
I0122 18:33:38.596323 69145 solver.cpp:285]     Train net output #0: loss = 0.664887 (* 1 = 0.664887 loss)
I0122 18:33:38.596330 69145 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 18:33:44.892073 69145 solver.cpp:266] Iteration 1700 (15.8843 iter/s, 6.29552s/100 iter), loss = 0.605402
I0122 18:33:44.892115 69145 solver.cpp:285]     Train net output #0: loss = 0.605402 (* 1 = 0.605402 loss)
I0122 18:33:44.892122 69145 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 18:33:51.267365 69145 solver.cpp:266] Iteration 1800 (15.6862 iter/s, 6.37502s/100 iter), loss = 0.574516
I0122 18:33:51.267410 69145 solver.cpp:285]     Train net output #0: loss = 0.574516 (* 1 = 0.574516 loss)
I0122 18:33:51.267416 69145 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 18:33:57.707013 69145 solver.cpp:266] Iteration 1900 (15.5295 iter/s, 6.43937s/100 iter), loss = 0.47072
I0122 18:33:57.707044 69145 solver.cpp:285]     Train net output #0: loss = 0.47072 (* 1 = 0.47072 loss)
I0122 18:33:57.707049 69145 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 18:34:04.090618 69145 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 18:34:05.593717 69145 solver.cpp:517]     Test net output #0: accuracy = 0.489555
I0122 18:34:05.593744 69145 solver.cpp:517]     Test net output #1: loss = 1.58235 (* 1 = 1.58235 loss)
I0122 18:34:05.593749 69145 solver.cpp:517]     Test net output #2: top-1 = 0.489555
I0122 18:34:05.593753 69145 solver.cpp:517]     Test net output #3: top-5 = 0.909555
I0122 18:34:05.657296 69145 solver.cpp:266] Iteration 2000 (12.5787 iter/s, 7.94997s/100 iter), loss = 0.581657
I0122 18:34:05.657317 69145 solver.cpp:285]     Train net output #0: loss = 0.581657 (* 1 = 0.581657 loss)
I0122 18:34:05.657323 69145 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 18:34:11.966162 69145 solver.cpp:266] Iteration 2100 (15.8513 iter/s, 6.30861s/100 iter), loss = 0.664455
I0122 18:34:11.966193 69145 solver.cpp:285]     Train net output #0: loss = 0.664455 (* 1 = 0.664455 loss)
I0122 18:34:11.966198 69145 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 18:34:18.320931 69145 solver.cpp:266] Iteration 2200 (15.7369 iter/s, 6.35451s/100 iter), loss = 0.463381
I0122 18:34:18.320960 69145 solver.cpp:285]     Train net output #0: loss = 0.463381 (* 1 = 0.463381 loss)
I0122 18:34:18.320966 69145 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 18:34:24.599141 69145 solver.cpp:266] Iteration 2300 (15.9288 iter/s, 6.27795s/100 iter), loss = 0.542764
I0122 18:34:24.599172 69145 solver.cpp:285]     Train net output #0: loss = 0.542764 (* 1 = 0.542764 loss)
I0122 18:34:24.599179 69145 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 18:34:30.855528 69145 solver.cpp:266] Iteration 2400 (15.9843 iter/s, 6.25613s/100 iter), loss = 0.507805
I0122 18:34:30.855561 69145 solver.cpp:285]     Train net output #0: loss = 0.507805 (* 1 = 0.507805 loss)
I0122 18:34:30.855566 69145 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 18:34:37.147187 69145 solver.cpp:266] Iteration 2500 (15.8947 iter/s, 6.2914s/100 iter), loss = 0.421235
I0122 18:34:37.147330 69145 solver.cpp:285]     Train net output #0: loss = 0.421235 (* 1 = 0.421235 loss)
I0122 18:34:37.147337 69145 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 18:34:43.405182 69145 solver.cpp:266] Iteration 2600 (15.9805 iter/s, 6.25763s/100 iter), loss = 0.539385
I0122 18:34:43.405213 69145 solver.cpp:285]     Train net output #0: loss = 0.539385 (* 1 = 0.539385 loss)
I0122 18:34:43.405220 69145 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 18:34:49.670878 69145 solver.cpp:266] Iteration 2700 (15.9606 iter/s, 6.26544s/100 iter), loss = 0.611844
I0122 18:34:49.670908 69145 solver.cpp:285]     Train net output #0: loss = 0.611844 (* 1 = 0.611844 loss)
I0122 18:34:49.670915 69145 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 18:34:55.939623 69145 solver.cpp:266] Iteration 2800 (15.9528 iter/s, 6.26849s/100 iter), loss = 0.508086
I0122 18:34:55.939656 69145 solver.cpp:285]     Train net output #0: loss = 0.508086 (* 1 = 0.508086 loss)
I0122 18:34:55.939661 69145 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 18:35:02.207492 69145 solver.cpp:266] Iteration 2900 (15.955 iter/s, 6.26761s/100 iter), loss = 0.585026
I0122 18:35:02.207521 69145 solver.cpp:285]     Train net output #0: loss = 0.585026 (* 1 = 0.585026 loss)
I0122 18:35:02.207527 69145 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 18:35:08.412298 69145 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 18:35:09.874840 69145 solver.cpp:517]     Test net output #0: accuracy = 0.667222
I0122 18:35:09.874867 69145 solver.cpp:517]     Test net output #1: loss = 0.991142 (* 1 = 0.991142 loss)
I0122 18:35:09.874871 69145 solver.cpp:517]     Test net output #2: top-1 = 0.667222
I0122 18:35:09.874874 69145 solver.cpp:517]     Test net output #3: top-5 = 0.965667
I0122 18:35:09.938891 69145 solver.cpp:266] Iteration 3000 (12.9348 iter/s, 7.73109s/100 iter), loss = 0.397818
I0122 18:35:09.938912 69145 solver.cpp:285]     Train net output #0: loss = 0.397818 (* 1 = 0.397818 loss)
I0122 18:35:09.938920 69145 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 18:35:16.195535 69145 solver.cpp:266] Iteration 3100 (15.9837 iter/s, 6.25639s/100 iter), loss = 0.522475
I0122 18:35:16.195567 69145 solver.cpp:285]     Train net output #0: loss = 0.522475 (* 1 = 0.522475 loss)
I0122 18:35:16.195574 69145 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 18:35:22.460276 69145 solver.cpp:266] Iteration 3200 (15.963 iter/s, 6.26448s/100 iter), loss = 0.495116
I0122 18:35:22.460307 69145 solver.cpp:285]     Train net output #0: loss = 0.495116 (* 1 = 0.495116 loss)
I0122 18:35:22.460314 69145 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 18:35:28.768460 69145 solver.cpp:266] Iteration 3300 (15.8531 iter/s, 6.30792s/100 iter), loss = 0.418182
I0122 18:35:28.768491 69145 solver.cpp:285]     Train net output #0: loss = 0.418182 (* 1 = 0.418182 loss)
I0122 18:35:28.768496 69145 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 18:35:35.030424 69145 solver.cpp:266] Iteration 3400 (15.9701 iter/s, 6.2617s/100 iter), loss = 0.529875
I0122 18:35:35.030467 69145 solver.cpp:285]     Train net output #0: loss = 0.529875 (* 1 = 0.529875 loss)
I0122 18:35:35.030474 69145 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 18:35:41.289824 69145 solver.cpp:266] Iteration 3500 (15.9767 iter/s, 6.25913s/100 iter), loss = 0.449794
I0122 18:35:41.289919 69145 solver.cpp:285]     Train net output #0: loss = 0.449794 (* 1 = 0.449794 loss)
I0122 18:35:41.289927 69145 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 18:35:47.578686 69145 solver.cpp:266] Iteration 3600 (15.9019 iter/s, 6.28854s/100 iter), loss = 0.591853
I0122 18:35:47.578716 69145 solver.cpp:285]     Train net output #0: loss = 0.591853 (* 1 = 0.591853 loss)
I0122 18:35:47.578722 69145 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 18:35:53.848819 69145 solver.cpp:266] Iteration 3700 (15.9493 iter/s, 6.26987s/100 iter), loss = 0.43997
I0122 18:35:53.848861 69145 solver.cpp:285]     Train net output #0: loss = 0.43997 (* 1 = 0.43997 loss)
I0122 18:35:53.848867 69145 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 18:36:00.108616 69145 solver.cpp:266] Iteration 3800 (15.9757 iter/s, 6.25953s/100 iter), loss = 0.495337
I0122 18:36:00.108646 69145 solver.cpp:285]     Train net output #0: loss = 0.495337 (* 1 = 0.495337 loss)
I0122 18:36:00.108652 69145 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 18:36:06.400861 69145 solver.cpp:266] Iteration 3900 (15.8932 iter/s, 6.29198s/100 iter), loss = 0.510733
I0122 18:36:06.400893 69145 solver.cpp:285]     Train net output #0: loss = 0.510733 (* 1 = 0.510733 loss)
I0122 18:36:06.400899 69145 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 18:36:12.602532 69145 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 18:36:14.059314 69145 solver.cpp:517]     Test net output #0: accuracy = 0.565667
I0122 18:36:14.059340 69145 solver.cpp:517]     Test net output #1: loss = 1.29652 (* 1 = 1.29652 loss)
I0122 18:36:14.059343 69145 solver.cpp:517]     Test net output #2: top-1 = 0.565667
I0122 18:36:14.059345 69145 solver.cpp:517]     Test net output #3: top-5 = 0.930111
I0122 18:36:14.122249 69145 solver.cpp:266] Iteration 4000 (12.9516 iter/s, 7.72108s/100 iter), loss = 0.54129
I0122 18:36:14.122272 69145 solver.cpp:285]     Train net output #0: loss = 0.54129 (* 1 = 0.54129 loss)
I0122 18:36:14.122278 69145 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 18:36:20.408062 69145 solver.cpp:266] Iteration 4100 (15.9095 iter/s, 6.28556s/100 iter), loss = 0.511388
I0122 18:36:20.408092 69145 solver.cpp:285]     Train net output #0: loss = 0.511388 (* 1 = 0.511388 loss)
I0122 18:36:20.408097 69145 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 18:36:26.694217 69145 solver.cpp:266] Iteration 4200 (15.9086 iter/s, 6.2859s/100 iter), loss = 0.479553
I0122 18:36:26.694247 69145 solver.cpp:285]     Train net output #0: loss = 0.479553 (* 1 = 0.479553 loss)
I0122 18:36:26.694252 69145 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 18:36:32.962911 69145 solver.cpp:266] Iteration 4300 (15.953 iter/s, 6.26843s/100 iter), loss = 0.548989
I0122 18:36:32.962941 69145 solver.cpp:285]     Train net output #0: loss = 0.548989 (* 1 = 0.548989 loss)
I0122 18:36:32.962947 69145 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 18:36:39.220003 69145 solver.cpp:266] Iteration 4400 (15.9825 iter/s, 6.25683s/100 iter), loss = 0.533358
I0122 18:36:39.220034 69145 solver.cpp:285]     Train net output #0: loss = 0.533358 (* 1 = 0.533358 loss)
I0122 18:36:39.220041 69145 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 18:36:45.494025 69145 solver.cpp:266] Iteration 4500 (15.9394 iter/s, 6.27376s/100 iter), loss = 0.340596
I0122 18:36:45.494166 69145 solver.cpp:285]     Train net output #0: loss = 0.340596 (* 1 = 0.340596 loss)
I0122 18:36:45.494174 69145 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 18:36:51.812286 69145 solver.cpp:266] Iteration 4600 (15.8281 iter/s, 6.31789s/100 iter), loss = 0.665164
I0122 18:36:51.812315 69145 solver.cpp:285]     Train net output #0: loss = 0.665164 (* 1 = 0.665164 loss)
I0122 18:36:51.812320 69145 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 18:36:58.094080 69145 solver.cpp:266] Iteration 4700 (15.9197 iter/s, 6.28153s/100 iter), loss = 0.597811
I0122 18:36:58.094111 69145 solver.cpp:285]     Train net output #0: loss = 0.597811 (* 1 = 0.597811 loss)
I0122 18:36:58.094116 69145 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 18:37:04.373793 69145 solver.cpp:266] Iteration 4800 (15.925 iter/s, 6.27945s/100 iter), loss = 0.397829
I0122 18:37:04.373822 69145 solver.cpp:285]     Train net output #0: loss = 0.397829 (* 1 = 0.397829 loss)
I0122 18:37:04.373827 69145 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 18:37:10.748589 69145 solver.cpp:266] Iteration 4900 (15.6874 iter/s, 6.37453s/100 iter), loss = 0.51554
I0122 18:37:10.748621 69145 solver.cpp:285]     Train net output #0: loss = 0.51554 (* 1 = 0.51554 loss)
I0122 18:37:10.748627 69145 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 18:37:16.990382 69145 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 18:37:18.469627 69145 solver.cpp:517]     Test net output #0: accuracy = 0.575556
I0122 18:37:18.469655 69145 solver.cpp:517]     Test net output #1: loss = 1.26395 (* 1 = 1.26395 loss)
I0122 18:37:18.469660 69145 solver.cpp:517]     Test net output #2: top-1 = 0.575556
I0122 18:37:18.469663 69145 solver.cpp:517]     Test net output #3: top-5 = 0.947222
I0122 18:37:18.533476 69145 solver.cpp:266] Iteration 5000 (12.8459 iter/s, 7.78457s/100 iter), loss = 0.596379
I0122 18:37:18.533499 69145 solver.cpp:285]     Train net output #0: loss = 0.596379 (* 1 = 0.596379 loss)
I0122 18:37:18.533506 69145 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 18:37:24.806082 69145 solver.cpp:266] Iteration 5100 (15.943 iter/s, 6.27235s/100 iter), loss = 0.546582
I0122 18:37:24.806113 69145 solver.cpp:285]     Train net output #0: loss = 0.546582 (* 1 = 0.546582 loss)
I0122 18:37:24.806119 69145 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 18:37:31.074940 69145 solver.cpp:266] Iteration 5200 (15.9525 iter/s, 6.2686s/100 iter), loss = 0.465341
I0122 18:37:31.074970 69145 solver.cpp:285]     Train net output #0: loss = 0.465341 (* 1 = 0.465341 loss)
I0122 18:37:31.074992 69145 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 18:37:37.496196 69145 solver.cpp:266] Iteration 5300 (15.5739 iter/s, 6.42099s/100 iter), loss = 0.577654
I0122 18:37:37.496227 69145 solver.cpp:285]     Train net output #0: loss = 0.577654 (* 1 = 0.577654 loss)
I0122 18:37:37.496233 69145 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 18:37:43.785822 69145 solver.cpp:266] Iteration 5400 (15.8999 iter/s, 6.28936s/100 iter), loss = 0.583559
I0122 18:37:43.785851 69145 solver.cpp:285]     Train net output #0: loss = 0.583559 (* 1 = 0.583559 loss)
I0122 18:37:43.785858 69145 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 18:37:50.063434 69145 solver.cpp:266] Iteration 5500 (15.9303 iter/s, 6.27735s/100 iter), loss = 0.421941
I0122 18:37:50.063513 69145 solver.cpp:285]     Train net output #0: loss = 0.421941 (* 1 = 0.421941 loss)
I0122 18:37:50.063534 69145 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 18:37:56.325914 69145 solver.cpp:266] Iteration 5600 (15.9689 iter/s, 6.26217s/100 iter), loss = 0.601403
I0122 18:37:56.325944 69145 solver.cpp:285]     Train net output #0: loss = 0.601403 (* 1 = 0.601403 loss)
I0122 18:37:56.325949 69145 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 18:38:02.621575 69145 solver.cpp:266] Iteration 5700 (15.8846 iter/s, 6.2954s/100 iter), loss = 0.347218
I0122 18:38:02.621606 69145 solver.cpp:285]     Train net output #0: loss = 0.347218 (* 1 = 0.347218 loss)
I0122 18:38:02.621611 69145 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 18:38:08.896409 69145 solver.cpp:266] Iteration 5800 (15.9373 iter/s, 6.27457s/100 iter), loss = 0.517224
I0122 18:38:08.896437 69145 solver.cpp:285]     Train net output #0: loss = 0.517224 (* 1 = 0.517224 loss)
I0122 18:38:08.896443 69145 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 18:38:15.215282 69145 solver.cpp:266] Iteration 5900 (15.8263 iter/s, 6.31861s/100 iter), loss = 0.620427
I0122 18:38:15.215312 69145 solver.cpp:285]     Train net output #0: loss = 0.620427 (* 1 = 0.620427 loss)
I0122 18:38:15.215317 69145 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 18:38:21.450165 69145 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 18:38:22.910516 69145 solver.cpp:517]     Test net output #0: accuracy = 0.445444
I0122 18:38:22.910552 69145 solver.cpp:517]     Test net output #1: loss = 1.73961 (* 1 = 1.73961 loss)
I0122 18:38:22.910557 69145 solver.cpp:517]     Test net output #2: top-1 = 0.445444
I0122 18:38:22.910578 69145 solver.cpp:517]     Test net output #3: top-5 = 0.889556
I0122 18:38:22.973594 69145 solver.cpp:266] Iteration 6000 (12.8899 iter/s, 7.758s/100 iter), loss = 0.638391
I0122 18:38:22.973614 69145 solver.cpp:285]     Train net output #0: loss = 0.638391 (* 1 = 0.638391 loss)
I0122 18:38:22.973620 69145 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 18:38:29.284447 69145 solver.cpp:266] Iteration 6100 (15.8464 iter/s, 6.3106s/100 iter), loss = 0.37499
I0122 18:38:29.284476 69145 solver.cpp:285]     Train net output #0: loss = 0.37499 (* 1 = 0.37499 loss)
I0122 18:38:29.284481 69145 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 18:38:35.604943 69145 solver.cpp:266] Iteration 6200 (15.8222 iter/s, 6.32023s/100 iter), loss = 0.431036
I0122 18:38:35.604971 69145 solver.cpp:285]     Train net output #0: loss = 0.431036 (* 1 = 0.431036 loss)
I0122 18:38:35.604977 69145 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 18:38:41.866922 69145 solver.cpp:266] Iteration 6300 (15.9701 iter/s, 6.26172s/100 iter), loss = 0.379543
I0122 18:38:41.866952 69145 solver.cpp:285]     Train net output #0: loss = 0.379543 (* 1 = 0.379543 loss)
I0122 18:38:41.866958 69145 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 18:38:48.111559 69145 solver.cpp:266] Iteration 6400 (16.0144 iter/s, 6.24437s/100 iter), loss = 0.442277
I0122 18:38:48.111590 69145 solver.cpp:285]     Train net output #0: loss = 0.442277 (* 1 = 0.442277 loss)
I0122 18:38:48.111595 69145 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 18:38:54.359550 69145 solver.cpp:266] Iteration 6500 (16.0058 iter/s, 6.24773s/100 iter), loss = 0.617571
I0122 18:38:54.359673 69145 solver.cpp:285]     Train net output #0: loss = 0.617571 (* 1 = 0.617571 loss)
I0122 18:38:54.359679 69145 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 18:39:00.606945 69145 solver.cpp:266] Iteration 6600 (16.0076 iter/s, 6.24704s/100 iter), loss = 0.695587
I0122 18:39:00.606973 69145 solver.cpp:285]     Train net output #0: loss = 0.695587 (* 1 = 0.695587 loss)
I0122 18:39:00.606979 69145 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 18:39:06.864018 69145 solver.cpp:266] Iteration 6700 (15.9826 iter/s, 6.25681s/100 iter), loss = 0.461575
I0122 18:39:06.864048 69145 solver.cpp:285]     Train net output #0: loss = 0.461575 (* 1 = 0.461575 loss)
I0122 18:39:06.864053 69145 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 18:39:13.101224 69145 solver.cpp:266] Iteration 6800 (16.0335 iter/s, 6.23694s/100 iter), loss = 0.55742
I0122 18:39:13.101254 69145 solver.cpp:285]     Train net output #0: loss = 0.55742 (* 1 = 0.55742 loss)
I0122 18:39:13.101259 69145 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 18:39:19.359988 69145 solver.cpp:266] Iteration 6900 (15.9783 iter/s, 6.2585s/100 iter), loss = 0.410388
I0122 18:39:19.360018 69145 solver.cpp:285]     Train net output #0: loss = 0.410388 (* 1 = 0.410388 loss)
I0122 18:39:19.360024 69145 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 18:39:25.527942 69145 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 18:39:26.981704 69145 solver.cpp:517]     Test net output #0: accuracy = 0.578555
I0122 18:39:26.981729 69145 solver.cpp:517]     Test net output #1: loss = 1.40112 (* 1 = 1.40112 loss)
I0122 18:39:26.981732 69145 solver.cpp:517]     Test net output #2: top-1 = 0.578555
I0122 18:39:26.981735 69145 solver.cpp:517]     Test net output #3: top-5 = 0.937667
I0122 18:39:27.044782 69145 solver.cpp:266] Iteration 7000 (13.0132 iter/s, 7.68448s/100 iter), loss = 0.426228
I0122 18:39:27.044804 69145 solver.cpp:285]     Train net output #0: loss = 0.426228 (* 1 = 0.426228 loss)
I0122 18:39:27.044811 69145 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 18:39:33.303987 69145 solver.cpp:266] Iteration 7100 (15.9771 iter/s, 6.25895s/100 iter), loss = 0.611606
I0122 18:39:33.304018 69145 solver.cpp:285]     Train net output #0: loss = 0.611606 (* 1 = 0.611606 loss)
I0122 18:39:33.304023 69145 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 18:39:39.537041 69145 solver.cpp:266] Iteration 7200 (16.0442 iter/s, 6.23279s/100 iter), loss = 0.389395
I0122 18:39:39.537072 69145 solver.cpp:285]     Train net output #0: loss = 0.389395 (* 1 = 0.389395 loss)
I0122 18:39:39.537078 69145 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 18:39:45.787408 69145 solver.cpp:266] Iteration 7300 (15.9997 iter/s, 6.2501s/100 iter), loss = 0.531715
I0122 18:39:45.787436 69145 solver.cpp:285]     Train net output #0: loss = 0.531715 (* 1 = 0.531715 loss)
I0122 18:39:45.787442 69145 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 18:39:52.037603 69145 solver.cpp:266] Iteration 7400 (16.0002 iter/s, 6.24993s/100 iter), loss = 0.505067
I0122 18:39:52.037633 69145 solver.cpp:285]     Train net output #0: loss = 0.505067 (* 1 = 0.505067 loss)
I0122 18:39:52.037638 69145 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 18:39:58.286015 69145 solver.cpp:266] Iteration 7500 (16.0047 iter/s, 6.24815s/100 iter), loss = 0.467511
I0122 18:39:58.286137 69145 solver.cpp:285]     Train net output #0: loss = 0.467511 (* 1 = 0.467511 loss)
I0122 18:39:58.286144 69145 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 18:40:04.532374 69145 solver.cpp:266] Iteration 7600 (16.0102 iter/s, 6.24601s/100 iter), loss = 0.459779
I0122 18:40:04.532404 69145 solver.cpp:285]     Train net output #0: loss = 0.459779 (* 1 = 0.459779 loss)
I0122 18:40:04.532411 69145 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 18:40:10.779706 69145 solver.cpp:266] Iteration 7700 (16.0075 iter/s, 6.24707s/100 iter), loss = 0.410516
I0122 18:40:10.779736 69145 solver.cpp:285]     Train net output #0: loss = 0.410516 (* 1 = 0.410516 loss)
I0122 18:40:10.779742 69145 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 18:40:17.023689 69145 solver.cpp:266] Iteration 7800 (16.0161 iter/s, 6.24372s/100 iter), loss = 0.438959
I0122 18:40:17.023720 69145 solver.cpp:285]     Train net output #0: loss = 0.438959 (* 1 = 0.438959 loss)
I0122 18:40:17.023726 69145 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 18:40:23.281365 69145 solver.cpp:266] Iteration 7900 (15.9811 iter/s, 6.25741s/100 iter), loss = 0.501094
I0122 18:40:23.281395 69145 solver.cpp:285]     Train net output #0: loss = 0.501094 (* 1 = 0.501094 loss)
I0122 18:40:23.281400 69145 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 18:40:29.472568 69145 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 18:40:30.926129 69145 solver.cpp:517]     Test net output #0: accuracy = 0.61
I0122 18:40:30.926164 69145 solver.cpp:517]     Test net output #1: loss = 1.23325 (* 1 = 1.23325 loss)
I0122 18:40:30.926169 69145 solver.cpp:517]     Test net output #2: top-1 = 0.61
I0122 18:40:30.926172 69145 solver.cpp:517]     Test net output #3: top-5 = 0.926223
I0122 18:40:30.989758 69145 solver.cpp:266] Iteration 8000 (12.9734 iter/s, 7.70808s/100 iter), loss = 0.424757
I0122 18:40:30.989779 69145 solver.cpp:285]     Train net output #0: loss = 0.424757 (* 1 = 0.424757 loss)
I0122 18:40:30.989785 69145 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 18:40:37.246809 69145 solver.cpp:266] Iteration 8100 (15.9826 iter/s, 6.25679s/100 iter), loss = 0.61286
I0122 18:40:37.246840 69145 solver.cpp:285]     Train net output #0: loss = 0.61286 (* 1 = 0.61286 loss)
I0122 18:40:37.246845 69145 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 18:40:43.460983 69145 solver.cpp:266] Iteration 8200 (16.0929 iter/s, 6.21391s/100 iter), loss = 0.571829
I0122 18:40:43.461014 69145 solver.cpp:285]     Train net output #0: loss = 0.571829 (* 1 = 0.571829 loss)
I0122 18:40:43.461019 69145 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 18:40:49.705215 69145 solver.cpp:266] Iteration 8300 (16.0155 iter/s, 6.24397s/100 iter), loss = 0.505904
I0122 18:40:49.705245 69145 solver.cpp:285]     Train net output #0: loss = 0.505904 (* 1 = 0.505904 loss)
I0122 18:40:49.705250 69145 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 18:40:55.980270 69145 solver.cpp:266] Iteration 8400 (15.9368 iter/s, 6.27479s/100 iter), loss = 0.301846
I0122 18:40:55.980312 69145 solver.cpp:285]     Train net output #0: loss = 0.301846 (* 1 = 0.301846 loss)
I0122 18:40:55.980319 69145 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 18:41:02.214308 69145 solver.cpp:266] Iteration 8500 (16.0417 iter/s, 6.23376s/100 iter), loss = 0.635548
I0122 18:41:02.214427 69145 solver.cpp:285]     Train net output #0: loss = 0.635548 (* 1 = 0.635548 loss)
I0122 18:41:02.214435 69145 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 18:41:08.451784 69145 solver.cpp:266] Iteration 8600 (16.033 iter/s, 6.23712s/100 iter), loss = 0.346886
I0122 18:41:08.451813 69145 solver.cpp:285]     Train net output #0: loss = 0.346886 (* 1 = 0.346886 loss)
I0122 18:41:08.451819 69145 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 18:41:14.715070 69145 solver.cpp:266] Iteration 8700 (15.9667 iter/s, 6.26302s/100 iter), loss = 0.466417
I0122 18:41:14.715099 69145 solver.cpp:285]     Train net output #0: loss = 0.466417 (* 1 = 0.466417 loss)
I0122 18:41:14.715104 69145 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 18:41:20.967072 69145 solver.cpp:266] Iteration 8800 (15.9956 iter/s, 6.25174s/100 iter), loss = 0.609338
I0122 18:41:20.967103 69145 solver.cpp:285]     Train net output #0: loss = 0.609338 (* 1 = 0.609338 loss)
I0122 18:41:20.967108 69145 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 18:41:27.214318 69145 solver.cpp:266] Iteration 8900 (16.0077 iter/s, 6.24698s/100 iter), loss = 0.500085
I0122 18:41:27.214347 69145 solver.cpp:285]     Train net output #0: loss = 0.500085 (* 1 = 0.500085 loss)
I0122 18:41:27.214354 69145 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 18:41:33.404237 69145 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 18:41:34.864449 69145 solver.cpp:517]     Test net output #0: accuracy = 0.683111
I0122 18:41:34.864473 69145 solver.cpp:517]     Test net output #1: loss = 0.940032 (* 1 = 0.940032 loss)
I0122 18:41:34.864478 69145 solver.cpp:517]     Test net output #2: top-1 = 0.683111
I0122 18:41:34.864481 69145 solver.cpp:517]     Test net output #3: top-5 = 0.968222
I0122 18:41:34.927965 69145 solver.cpp:266] Iteration 9000 (12.9646 iter/s, 7.71333s/100 iter), loss = 0.406535
I0122 18:41:34.927987 69145 solver.cpp:285]     Train net output #0: loss = 0.406535 (* 1 = 0.406535 loss)
I0122 18:41:34.927994 69145 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 18:41:41.162395 69145 solver.cpp:266] Iteration 9100 (16.0406 iter/s, 6.23417s/100 iter), loss = 0.392935
I0122 18:41:41.162425 69145 solver.cpp:285]     Train net output #0: loss = 0.392935 (* 1 = 0.392935 loss)
I0122 18:41:41.162431 69145 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 18:41:47.396956 69145 solver.cpp:266] Iteration 9200 (16.0403 iter/s, 6.2343s/100 iter), loss = 0.682226
I0122 18:41:47.396987 69145 solver.cpp:285]     Train net output #0: loss = 0.682226 (* 1 = 0.682226 loss)
I0122 18:41:47.396993 69145 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 18:41:53.648948 69145 solver.cpp:266] Iteration 9300 (15.9956 iter/s, 6.25173s/100 iter), loss = 0.390463
I0122 18:41:53.648979 69145 solver.cpp:285]     Train net output #0: loss = 0.390463 (* 1 = 0.390463 loss)
I0122 18:41:53.648984 69145 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 18:41:59.893355 69145 solver.cpp:266] Iteration 9400 (16.015 iter/s, 6.24414s/100 iter), loss = 0.542663
I0122 18:41:59.893385 69145 solver.cpp:285]     Train net output #0: loss = 0.542663 (* 1 = 0.542663 loss)
I0122 18:41:59.893391 69145 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 18:42:06.135372 69145 solver.cpp:266] Iteration 9500 (16.0211 iter/s, 6.24175s/100 iter), loss = 0.429811
I0122 18:42:06.135452 69145 solver.cpp:285]     Train net output #0: loss = 0.429811 (* 1 = 0.429811 loss)
I0122 18:42:06.135458 69145 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 18:42:12.393362 69145 solver.cpp:266] Iteration 9600 (15.9804 iter/s, 6.25768s/100 iter), loss = 0.499184
I0122 18:42:12.393391 69145 solver.cpp:285]     Train net output #0: loss = 0.499184 (* 1 = 0.499184 loss)
I0122 18:42:12.393398 69145 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 18:42:18.640748 69145 solver.cpp:266] Iteration 9700 (16.0074 iter/s, 6.24712s/100 iter), loss = 0.45323
I0122 18:42:18.640779 69145 solver.cpp:285]     Train net output #0: loss = 0.45323 (* 1 = 0.45323 loss)
I0122 18:42:18.640784 69145 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 18:42:24.876488 69145 solver.cpp:266] Iteration 9800 (16.0373 iter/s, 6.23548s/100 iter), loss = 0.447508
I0122 18:42:24.876518 69145 solver.cpp:285]     Train net output #0: loss = 0.447508 (* 1 = 0.447508 loss)
I0122 18:42:24.876524 69145 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 18:42:31.144256 69145 solver.cpp:266] Iteration 9900 (15.9553 iter/s, 6.2675s/100 iter), loss = 0.512786
I0122 18:42:31.144287 69145 solver.cpp:285]     Train net output #0: loss = 0.512786 (* 1 = 0.512786 loss)
I0122 18:42:31.144294 69145 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 18:42:37.328758 69145 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 18:42:38.790437 69145 solver.cpp:517]     Test net output #0: accuracy = 0.579111
I0122 18:42:38.790462 69145 solver.cpp:517]     Test net output #1: loss = 1.50379 (* 1 = 1.50379 loss)
I0122 18:42:38.790465 69145 solver.cpp:517]     Test net output #2: top-1 = 0.579111
I0122 18:42:38.790469 69145 solver.cpp:517]     Test net output #3: top-5 = 0.964667
I0122 18:42:38.855429 69145 solver.cpp:266] Iteration 10000 (12.9687 iter/s, 7.71086s/100 iter), loss = 0.526898
I0122 18:42:38.855449 69145 solver.cpp:285]     Train net output #0: loss = 0.526898 (* 1 = 0.526898 loss)
I0122 18:42:38.855454 69145 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 18:42:45.107822 69145 solver.cpp:266] Iteration 10100 (15.9945 iter/s, 6.25214s/100 iter), loss = 0.462512
I0122 18:42:45.107851 69145 solver.cpp:285]     Train net output #0: loss = 0.462512 (* 1 = 0.462512 loss)
I0122 18:42:45.107856 69145 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 18:42:51.365708 69145 solver.cpp:266] Iteration 10200 (15.9805 iter/s, 6.25762s/100 iter), loss = 0.352411
I0122 18:42:51.365751 69145 solver.cpp:285]     Train net output #0: loss = 0.352411 (* 1 = 0.352411 loss)
I0122 18:42:51.365757 69145 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 18:42:57.605600 69145 solver.cpp:266] Iteration 10300 (16.0266 iter/s, 6.23962s/100 iter), loss = 0.17756
I0122 18:42:57.605628 69145 solver.cpp:285]     Train net output #0: loss = 0.17756 (* 1 = 0.17756 loss)
I0122 18:42:57.605634 69145 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 18:43:03.825932 69145 solver.cpp:266] Iteration 10400 (16.077 iter/s, 6.22007s/100 iter), loss = 0.366159
I0122 18:43:03.825974 69145 solver.cpp:285]     Train net output #0: loss = 0.366159 (* 1 = 0.366159 loss)
I0122 18:43:03.825980 69145 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 18:43:10.069664 69145 solver.cpp:266] Iteration 10500 (16.0168 iter/s, 6.24346s/100 iter), loss = 0.252966
I0122 18:43:10.069725 69145 solver.cpp:285]     Train net output #0: loss = 0.252966 (* 1 = 0.252966 loss)
I0122 18:43:10.069732 69145 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 18:43:16.329416 69145 solver.cpp:266] Iteration 10600 (15.9758 iter/s, 6.25946s/100 iter), loss = 0.261687
I0122 18:43:16.329447 69145 solver.cpp:285]     Train net output #0: loss = 0.261687 (* 1 = 0.261687 loss)
I0122 18:43:16.329453 69145 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 18:43:22.575454 69145 solver.cpp:266] Iteration 10700 (16.0108 iter/s, 6.24577s/100 iter), loss = 0.303818
I0122 18:43:22.575484 69145 solver.cpp:285]     Train net output #0: loss = 0.303818 (* 1 = 0.303818 loss)
I0122 18:43:22.575490 69145 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 18:43:28.820256 69145 solver.cpp:266] Iteration 10800 (16.014 iter/s, 6.24454s/100 iter), loss = 0.178226
I0122 18:43:28.820297 69145 solver.cpp:285]     Train net output #0: loss = 0.178226 (* 1 = 0.178226 loss)
I0122 18:43:28.820303 69145 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 18:43:35.130167 69145 solver.cpp:266] Iteration 10900 (15.8488 iter/s, 6.30963s/100 iter), loss = 0.242422
I0122 18:43:35.130197 69145 solver.cpp:285]     Train net output #0: loss = 0.242422 (* 1 = 0.242422 loss)
I0122 18:43:35.130201 69145 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 18:43:41.641407 69145 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 18:43:43.171540 69145 solver.cpp:517]     Test net output #0: accuracy = 0.785777
I0122 18:43:43.171566 69145 solver.cpp:517]     Test net output #1: loss = 0.71861 (* 1 = 0.71861 loss)
I0122 18:43:43.171569 69145 solver.cpp:517]     Test net output #2: top-1 = 0.785777
I0122 18:43:43.171572 69145 solver.cpp:517]     Test net output #3: top-5 = 0.974223
I0122 18:43:43.236343 69145 solver.cpp:266] Iteration 11000 (12.3368 iter/s, 8.10585s/100 iter), loss = 0.271922
I0122 18:43:43.236366 69145 solver.cpp:285]     Train net output #0: loss = 0.271922 (* 1 = 0.271922 loss)
I0122 18:43:43.236371 69145 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 18:43:49.536507 69145 solver.cpp:266] Iteration 11100 (15.8733 iter/s, 6.2999s/100 iter), loss = 0.166334
I0122 18:43:49.536538 69145 solver.cpp:285]     Train net output #0: loss = 0.166334 (* 1 = 0.166334 loss)
I0122 18:43:49.536545 69145 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 18:43:55.770032 69145 solver.cpp:266] Iteration 11200 (16.043 iter/s, 6.23326s/100 iter), loss = 0.203991
I0122 18:43:55.770062 69145 solver.cpp:285]     Train net output #0: loss = 0.203991 (* 1 = 0.203991 loss)
I0122 18:43:55.770068 69145 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 18:44:02.013414 69145 solver.cpp:266] Iteration 11300 (16.0176 iter/s, 6.24312s/100 iter), loss = 0.138946
I0122 18:44:02.013456 69145 solver.cpp:285]     Train net output #0: loss = 0.138946 (* 1 = 0.138946 loss)
I0122 18:44:02.013463 69145 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 18:44:08.277074 69145 solver.cpp:266] Iteration 11400 (15.9658 iter/s, 6.26338s/100 iter), loss = 0.208637
I0122 18:44:08.277107 69145 solver.cpp:285]     Train net output #0: loss = 0.208637 (* 1 = 0.208637 loss)
I0122 18:44:08.277112 69145 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 18:44:14.549340 69145 solver.cpp:266] Iteration 11500 (15.9439 iter/s, 6.272s/100 iter), loss = 0.13543
I0122 18:44:14.549459 69145 solver.cpp:285]     Train net output #0: loss = 0.13543 (* 1 = 0.13543 loss)
I0122 18:44:14.549466 69145 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 18:44:20.792742 69145 solver.cpp:266] Iteration 11600 (16.0178 iter/s, 6.24305s/100 iter), loss = 0.2021
I0122 18:44:20.792773 69145 solver.cpp:285]     Train net output #0: loss = 0.2021 (* 1 = 0.2021 loss)
I0122 18:44:20.792778 69145 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 18:44:27.038233 69145 solver.cpp:266] Iteration 11700 (16.0122 iter/s, 6.24523s/100 iter), loss = 0.163766
I0122 18:44:27.038264 69145 solver.cpp:285]     Train net output #0: loss = 0.163766 (* 1 = 0.163766 loss)
I0122 18:44:27.038269 69145 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 18:44:33.307317 69145 solver.cpp:266] Iteration 11800 (15.952 iter/s, 6.26882s/100 iter), loss = 0.193705
I0122 18:44:33.307346 69145 solver.cpp:285]     Train net output #0: loss = 0.193705 (* 1 = 0.193705 loss)
I0122 18:44:33.307351 69145 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 18:44:39.552109 69145 solver.cpp:266] Iteration 11900 (16.014 iter/s, 6.24453s/100 iter), loss = 0.143815
I0122 18:44:39.552140 69145 solver.cpp:285]     Train net output #0: loss = 0.143815 (* 1 = 0.143815 loss)
I0122 18:44:39.552146 69145 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 18:44:45.752058 69145 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 18:44:47.202015 69145 solver.cpp:517]     Test net output #0: accuracy = 0.663333
I0122 18:44:47.202052 69145 solver.cpp:517]     Test net output #1: loss = 1.05182 (* 1 = 1.05182 loss)
I0122 18:44:47.202057 69145 solver.cpp:517]     Test net output #2: top-1 = 0.663333
I0122 18:44:47.202060 69145 solver.cpp:517]     Test net output #3: top-5 = 0.939112
I0122 18:44:47.264729 69145 solver.cpp:266] Iteration 12000 (12.9663 iter/s, 7.7123s/100 iter), loss = 0.116841
I0122 18:44:47.264751 69145 solver.cpp:285]     Train net output #0: loss = 0.116841 (* 1 = 0.116841 loss)
I0122 18:44:47.264756 69145 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 18:44:53.511162 69145 solver.cpp:266] Iteration 12100 (16.0098 iter/s, 6.24617s/100 iter), loss = 0.109582
I0122 18:44:53.511191 69145 solver.cpp:285]     Train net output #0: loss = 0.109582 (* 1 = 0.109582 loss)
I0122 18:44:53.511198 69145 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 18:44:59.768154 69145 solver.cpp:266] Iteration 12200 (15.9828 iter/s, 6.25673s/100 iter), loss = 0.1289
I0122 18:44:59.768184 69145 solver.cpp:285]     Train net output #0: loss = 0.1289 (* 1 = 0.1289 loss)
I0122 18:44:59.768190 69145 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 18:45:06.022321 69145 solver.cpp:266] Iteration 12300 (15.99 iter/s, 6.2539s/100 iter), loss = 0.133608
I0122 18:45:06.022351 69145 solver.cpp:285]     Train net output #0: loss = 0.133608 (* 1 = 0.133608 loss)
I0122 18:45:06.022356 69145 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 18:45:12.274246 69145 solver.cpp:266] Iteration 12400 (15.9958 iter/s, 6.25166s/100 iter), loss = 0.15968
I0122 18:45:12.274277 69145 solver.cpp:285]     Train net output #0: loss = 0.15968 (* 1 = 0.15968 loss)
I0122 18:45:12.274282 69145 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 18:45:18.533253 69145 solver.cpp:266] Iteration 12500 (15.9777 iter/s, 6.25874s/100 iter), loss = 0.0938869
I0122 18:45:18.533355 69145 solver.cpp:285]     Train net output #0: loss = 0.0938869 (* 1 = 0.0938869 loss)
I0122 18:45:18.533362 69145 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 18:45:24.788987 69145 solver.cpp:266] Iteration 12600 (15.9862 iter/s, 6.2554s/100 iter), loss = 0.0941591
I0122 18:45:24.789017 69145 solver.cpp:285]     Train net output #0: loss = 0.094159 (* 1 = 0.094159 loss)
I0122 18:45:24.789022 69145 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 18:45:31.011799 69145 solver.cpp:266] Iteration 12700 (16.0706 iter/s, 6.22255s/100 iter), loss = 0.10917
I0122 18:45:31.011828 69145 solver.cpp:285]     Train net output #0: loss = 0.10917 (* 1 = 0.10917 loss)
I0122 18:45:31.011850 69145 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 18:45:37.282488 69145 solver.cpp:266] Iteration 12800 (15.9479 iter/s, 6.27042s/100 iter), loss = 0.148112
I0122 18:45:37.282521 69145 solver.cpp:285]     Train net output #0: loss = 0.148112 (* 1 = 0.148112 loss)
I0122 18:45:37.282527 69145 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 18:45:43.547474 69145 solver.cpp:266] Iteration 12900 (15.9624 iter/s, 6.26472s/100 iter), loss = 0.0850376
I0122 18:45:43.547505 69145 solver.cpp:285]     Train net output #0: loss = 0.0850376 (* 1 = 0.0850376 loss)
I0122 18:45:43.547511 69145 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 18:45:49.735966 69145 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 18:45:51.196883 69145 solver.cpp:517]     Test net output #0: accuracy = 0.653445
I0122 18:45:51.196908 69145 solver.cpp:517]     Test net output #1: loss = 1.07124 (* 1 = 1.07124 loss)
I0122 18:45:51.196913 69145 solver.cpp:517]     Test net output #2: top-1 = 0.653445
I0122 18:45:51.196916 69145 solver.cpp:517]     Test net output #3: top-5 = 0.940111
I0122 18:45:51.259737 69145 solver.cpp:266] Iteration 13000 (12.9669 iter/s, 7.71194s/100 iter), loss = 0.107137
I0122 18:45:51.259769 69145 solver.cpp:285]     Train net output #0: loss = 0.107137 (* 1 = 0.107137 loss)
I0122 18:45:51.259776 69145 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 18:45:57.520287 69145 solver.cpp:266] Iteration 13100 (15.9737 iter/s, 6.26028s/100 iter), loss = 0.107634
I0122 18:45:57.520316 69145 solver.cpp:285]     Train net output #0: loss = 0.107634 (* 1 = 0.107634 loss)
I0122 18:45:57.520323 69145 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 18:46:03.762894 69145 solver.cpp:266] Iteration 13200 (16.0196 iter/s, 6.24234s/100 iter), loss = 0.125996
I0122 18:46:03.762924 69145 solver.cpp:285]     Train net output #0: loss = 0.125996 (* 1 = 0.125996 loss)
I0122 18:46:03.762929 69145 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 18:46:10.013178 69145 solver.cpp:266] Iteration 13300 (16 iter/s, 6.25002s/100 iter), loss = 0.159197
I0122 18:46:10.013218 69145 solver.cpp:285]     Train net output #0: loss = 0.159196 (* 1 = 0.159196 loss)
I0122 18:46:10.013223 69145 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 18:46:16.277365 69145 solver.cpp:266] Iteration 13400 (15.9645 iter/s, 6.26391s/100 iter), loss = 0.125877
I0122 18:46:16.277395 69145 solver.cpp:285]     Train net output #0: loss = 0.125877 (* 1 = 0.125877 loss)
I0122 18:46:16.277400 69145 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 18:46:22.519402 69145 solver.cpp:266] Iteration 13500 (16.0211 iter/s, 6.24177s/100 iter), loss = 0.0902493
I0122 18:46:22.519521 69145 solver.cpp:285]     Train net output #0: loss = 0.0902492 (* 1 = 0.0902492 loss)
I0122 18:46:22.519528 69145 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 18:46:28.788899 69145 solver.cpp:266] Iteration 13600 (15.9511 iter/s, 6.26914s/100 iter), loss = 0.0504428
I0122 18:46:28.788938 69145 solver.cpp:285]     Train net output #0: loss = 0.0504427 (* 1 = 0.0504427 loss)
I0122 18:46:28.788942 69145 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 18:46:35.037536 69145 solver.cpp:266] Iteration 13700 (16.0042 iter/s, 6.24836s/100 iter), loss = 0.0442312
I0122 18:46:35.037567 69145 solver.cpp:285]     Train net output #0: loss = 0.0442311 (* 1 = 0.0442311 loss)
I0122 18:46:35.037572 69145 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 18:46:41.305263 69145 solver.cpp:266] Iteration 13800 (15.9554 iter/s, 6.26746s/100 iter), loss = 0.11375
I0122 18:46:41.305294 69145 solver.cpp:285]     Train net output #0: loss = 0.11375 (* 1 = 0.11375 loss)
I0122 18:46:41.305299 69145 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 18:46:47.549046 69145 solver.cpp:266] Iteration 13900 (16.0166 iter/s, 6.24352s/100 iter), loss = 0.116187
I0122 18:46:47.549077 69145 solver.cpp:285]     Train net output #0: loss = 0.116187 (* 1 = 0.116187 loss)
I0122 18:46:47.549082 69145 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 18:46:53.734099 69145 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 18:46:55.190524 69145 solver.cpp:517]     Test net output #0: accuracy = 0.708445
I0122 18:46:55.190549 69145 solver.cpp:517]     Test net output #1: loss = 0.923447 (* 1 = 0.923447 loss)
I0122 18:46:55.190553 69145 solver.cpp:517]     Test net output #2: top-1 = 0.708445
I0122 18:46:55.190557 69145 solver.cpp:517]     Test net output #3: top-5 = 0.955445
I0122 18:46:55.254060 69145 solver.cpp:266] Iteration 14000 (12.9791 iter/s, 7.70469s/100 iter), loss = 0.0569819
I0122 18:46:55.254081 69145 solver.cpp:285]     Train net output #0: loss = 0.0569819 (* 1 = 0.0569819 loss)
I0122 18:46:55.254086 69145 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 18:47:01.486119 69145 solver.cpp:266] Iteration 14100 (16.0467 iter/s, 6.2318s/100 iter), loss = 0.107781
I0122 18:47:01.486148 69145 solver.cpp:285]     Train net output #0: loss = 0.107781 (* 1 = 0.107781 loss)
I0122 18:47:01.486155 69145 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 18:47:07.753185 69145 solver.cpp:266] Iteration 14200 (15.9571 iter/s, 6.2668s/100 iter), loss = 0.0626542
I0122 18:47:07.753214 69145 solver.cpp:285]     Train net output #0: loss = 0.0626541 (* 1 = 0.0626541 loss)
I0122 18:47:07.753221 69145 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 18:47:14.009024 69145 solver.cpp:266] Iteration 14300 (15.9857 iter/s, 6.25557s/100 iter), loss = 0.0846735
I0122 18:47:14.009054 69145 solver.cpp:285]     Train net output #0: loss = 0.0846734 (* 1 = 0.0846734 loss)
I0122 18:47:14.009060 69145 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 18:47:20.243609 69145 solver.cpp:266] Iteration 14400 (16.0402 iter/s, 6.23432s/100 iter), loss = 0.0746211
I0122 18:47:20.243641 69145 solver.cpp:285]     Train net output #0: loss = 0.074621 (* 1 = 0.074621 loss)
I0122 18:47:20.243646 69145 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 18:47:26.489537 69145 solver.cpp:266] Iteration 14500 (16.0111 iter/s, 6.24566s/100 iter), loss = 0.0744771
I0122 18:47:26.489662 69145 solver.cpp:285]     Train net output #0: loss = 0.074477 (* 1 = 0.074477 loss)
I0122 18:47:26.489670 69145 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 18:47:32.753901 69145 solver.cpp:266] Iteration 14600 (15.9642 iter/s, 6.264s/100 iter), loss = 0.130839
I0122 18:47:32.753934 69145 solver.cpp:285]     Train net output #0: loss = 0.130839 (* 1 = 0.130839 loss)
I0122 18:47:32.753940 69145 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 18:47:39.011669 69145 solver.cpp:266] Iteration 14700 (15.9808 iter/s, 6.2575s/100 iter), loss = 0.08469
I0122 18:47:39.011699 69145 solver.cpp:285]     Train net output #0: loss = 0.0846899 (* 1 = 0.0846899 loss)
I0122 18:47:39.011705 69145 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 18:47:45.257617 69145 solver.cpp:266] Iteration 14800 (16.0111 iter/s, 6.24568s/100 iter), loss = 0.112961
I0122 18:47:45.257647 69145 solver.cpp:285]     Train net output #0: loss = 0.112961 (* 1 = 0.112961 loss)
I0122 18:47:45.257652 69145 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 18:47:51.504957 69145 solver.cpp:266] Iteration 14900 (16.0075 iter/s, 6.24707s/100 iter), loss = 0.0559875
I0122 18:47:51.504987 69145 solver.cpp:285]     Train net output #0: loss = 0.0559874 (* 1 = 0.0559874 loss)
I0122 18:47:51.504992 69145 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 18:47:57.708295 69145 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 18:47:59.160118 69145 solver.cpp:517]     Test net output #0: accuracy = 0.728889
I0122 18:47:59.160145 69145 solver.cpp:517]     Test net output #1: loss = 0.847611 (* 1 = 0.847611 loss)
I0122 18:47:59.160149 69145 solver.cpp:517]     Test net output #2: top-1 = 0.728889
I0122 18:47:59.160152 69145 solver.cpp:517]     Test net output #3: top-5 = 0.960223
I0122 18:47:59.221567 69145 solver.cpp:266] Iteration 15000 (12.9596 iter/s, 7.71629s/100 iter), loss = 0.100056
I0122 18:47:59.221588 69145 solver.cpp:285]     Train net output #0: loss = 0.100056 (* 1 = 0.100056 loss)
I0122 18:47:59.221596 69145 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 18:48:05.470738 69145 solver.cpp:266] Iteration 15100 (16.0028 iter/s, 6.24891s/100 iter), loss = 0.0805891
I0122 18:48:05.470768 69145 solver.cpp:285]     Train net output #0: loss = 0.080589 (* 1 = 0.080589 loss)
I0122 18:48:05.470774 69145 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 18:48:11.702877 69145 solver.cpp:266] Iteration 15200 (16.0465 iter/s, 6.23187s/100 iter), loss = 0.118709
I0122 18:48:11.702906 69145 solver.cpp:285]     Train net output #0: loss = 0.118709 (* 1 = 0.118709 loss)
I0122 18:48:11.702913 69145 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 18:48:17.954226 69145 solver.cpp:266] Iteration 15300 (15.9972 iter/s, 6.25108s/100 iter), loss = 0.0945379
I0122 18:48:17.954255 69145 solver.cpp:285]     Train net output #0: loss = 0.0945378 (* 1 = 0.0945378 loss)
I0122 18:48:17.954262 69145 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 18:48:24.227361 69145 solver.cpp:266] Iteration 15400 (15.9417 iter/s, 6.27287s/100 iter), loss = 0.0848468
I0122 18:48:24.227391 69145 solver.cpp:285]     Train net output #0: loss = 0.0848467 (* 1 = 0.0848467 loss)
I0122 18:48:24.227397 69145 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 18:48:30.477807 69145 solver.cpp:266] Iteration 15500 (15.9995 iter/s, 6.25018s/100 iter), loss = 0.0750245
I0122 18:48:30.477893 69145 solver.cpp:285]     Train net output #0: loss = 0.0750243 (* 1 = 0.0750243 loss)
I0122 18:48:30.477900 69145 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 18:48:36.732744 69145 solver.cpp:266] Iteration 15600 (15.9882 iter/s, 6.25462s/100 iter), loss = 0.054905
I0122 18:48:36.732774 69145 solver.cpp:285]     Train net output #0: loss = 0.0549049 (* 1 = 0.0549049 loss)
I0122 18:48:36.732780 69145 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 18:48:42.970057 69145 solver.cpp:266] Iteration 15700 (16.0332 iter/s, 6.23705s/100 iter), loss = 0.0716194
I0122 18:48:42.970088 69145 solver.cpp:285]     Train net output #0: loss = 0.0716193 (* 1 = 0.0716193 loss)
I0122 18:48:42.970094 69145 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 18:48:49.230032 69145 solver.cpp:266] Iteration 15800 (15.9752 iter/s, 6.25971s/100 iter), loss = 0.0461587
I0122 18:48:49.230063 69145 solver.cpp:285]     Train net output #0: loss = 0.0461586 (* 1 = 0.0461586 loss)
I0122 18:48:49.230068 69145 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 18:48:55.472664 69145 solver.cpp:266] Iteration 15900 (16.0196 iter/s, 6.24236s/100 iter), loss = 0.0613214
I0122 18:48:55.472697 69145 solver.cpp:285]     Train net output #0: loss = 0.0613212 (* 1 = 0.0613212 loss)
I0122 18:48:55.472702 69145 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 18:49:01.707160 69145 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 18:49:03.186282 69145 solver.cpp:517]     Test net output #0: accuracy = 0.783111
I0122 18:49:03.186311 69145 solver.cpp:517]     Test net output #1: loss = 0.659822 (* 1 = 0.659822 loss)
I0122 18:49:03.186316 69145 solver.cpp:517]     Test net output #2: top-1 = 0.783111
I0122 18:49:03.186321 69145 solver.cpp:517]     Test net output #3: top-5 = 0.977445
I0122 18:49:03.248694 69145 solver.cpp:266] Iteration 16000 (12.8606 iter/s, 7.77571s/100 iter), loss = 0.142925
I0122 18:49:03.248718 69145 solver.cpp:285]     Train net output #0: loss = 0.142925 (* 1 = 0.142925 loss)
I0122 18:49:03.248723 69145 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 18:49:09.560617 69145 solver.cpp:266] Iteration 16100 (15.8437 iter/s, 6.31166s/100 iter), loss = 0.158491
I0122 18:49:09.560662 69145 solver.cpp:285]     Train net output #0: loss = 0.158491 (* 1 = 0.158491 loss)
I0122 18:49:09.560672 69145 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 18:49:15.828109 69145 solver.cpp:266] Iteration 16200 (15.956 iter/s, 6.26722s/100 iter), loss = 0.0843103
I0122 18:49:15.828141 69145 solver.cpp:285]     Train net output #0: loss = 0.0843102 (* 1 = 0.0843102 loss)
I0122 18:49:15.828148 69145 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 18:49:22.131145 69145 solver.cpp:266] Iteration 16300 (15.866 iter/s, 6.30277s/100 iter), loss = 0.0809063
I0122 18:49:22.131176 69145 solver.cpp:285]     Train net output #0: loss = 0.0809061 (* 1 = 0.0809061 loss)
I0122 18:49:22.131184 69145 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 18:49:28.415341 69145 solver.cpp:266] Iteration 16400 (15.9136 iter/s, 6.28393s/100 iter), loss = 0.136861
I0122 18:49:28.415374 69145 solver.cpp:285]     Train net output #0: loss = 0.136861 (* 1 = 0.136861 loss)
I0122 18:49:28.415380 69145 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 18:49:34.680441 69145 solver.cpp:266] Iteration 16500 (15.9621 iter/s, 6.26483s/100 iter), loss = 0.0815476
I0122 18:49:34.680562 69145 solver.cpp:285]     Train net output #0: loss = 0.0815475 (* 1 = 0.0815475 loss)
I0122 18:49:34.680569 69145 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 18:49:40.930554 69145 solver.cpp:266] Iteration 16600 (16.0006 iter/s, 6.24976s/100 iter), loss = 0.0692396
I0122 18:49:40.930583 69145 solver.cpp:285]     Train net output #0: loss = 0.0692395 (* 1 = 0.0692395 loss)
I0122 18:49:40.930604 69145 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 18:49:47.165298 69145 solver.cpp:266] Iteration 16700 (16.0398 iter/s, 6.23448s/100 iter), loss = 0.0578236
I0122 18:49:47.165328 69145 solver.cpp:285]     Train net output #0: loss = 0.0578234 (* 1 = 0.0578234 loss)
I0122 18:49:47.165333 69145 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 18:49:53.389334 69145 solver.cpp:266] Iteration 16800 (16.0674 iter/s, 6.22377s/100 iter), loss = 0.0466289
I0122 18:49:53.389364 69145 solver.cpp:285]     Train net output #0: loss = 0.0466288 (* 1 = 0.0466288 loss)
I0122 18:49:53.389369 69145 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 18:49:59.614334 69145 solver.cpp:266] Iteration 16900 (16.0649 iter/s, 6.22473s/100 iter), loss = 0.1567
I0122 18:49:59.614363 69145 solver.cpp:285]     Train net output #0: loss = 0.1567 (* 1 = 0.1567 loss)
I0122 18:49:59.614369 69145 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 18:50:05.761543 69145 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 18:50:07.218571 69145 solver.cpp:517]     Test net output #0: accuracy = 0.800333
I0122 18:50:07.218597 69145 solver.cpp:517]     Test net output #1: loss = 0.652265 (* 1 = 0.652265 loss)
I0122 18:50:07.218602 69145 solver.cpp:517]     Test net output #2: top-1 = 0.800333
I0122 18:50:07.218622 69145 solver.cpp:517]     Test net output #3: top-5 = 0.989444
I0122 18:50:07.281116 69145 solver.cpp:266] Iteration 17000 (13.0438 iter/s, 7.66647s/100 iter), loss = 0.0856547
I0122 18:50:07.281136 69145 solver.cpp:285]     Train net output #0: loss = 0.0856546 (* 1 = 0.0856546 loss)
I0122 18:50:07.281142 69145 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 18:50:13.509047 69145 solver.cpp:266] Iteration 17100 (16.0574 iter/s, 6.22768s/100 iter), loss = 0.097342
I0122 18:50:13.509088 69145 solver.cpp:285]     Train net output #0: loss = 0.0973419 (* 1 = 0.0973419 loss)
I0122 18:50:13.509094 69145 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 18:50:19.735653 69145 solver.cpp:266] Iteration 17200 (16.0608 iter/s, 6.22633s/100 iter), loss = 0.100818
I0122 18:50:19.735683 69145 solver.cpp:285]     Train net output #0: loss = 0.100818 (* 1 = 0.100818 loss)
I0122 18:50:19.735688 69145 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 18:50:25.964674 69145 solver.cpp:266] Iteration 17300 (16.0546 iter/s, 6.22876s/100 iter), loss = 0.132417
I0122 18:50:25.964716 69145 solver.cpp:285]     Train net output #0: loss = 0.132417 (* 1 = 0.132417 loss)
I0122 18:50:25.964723 69145 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 18:50:32.184372 69145 solver.cpp:266] Iteration 17400 (16.0787 iter/s, 6.21942s/100 iter), loss = 0.138274
I0122 18:50:32.184413 69145 solver.cpp:285]     Train net output #0: loss = 0.138274 (* 1 = 0.138274 loss)
I0122 18:50:32.184420 69145 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 18:50:38.433687 69145 solver.cpp:266] Iteration 17500 (16.0025 iter/s, 6.24904s/100 iter), loss = 0.0956182
I0122 18:50:38.433789 69145 solver.cpp:285]     Train net output #0: loss = 0.0956181 (* 1 = 0.0956181 loss)
I0122 18:50:38.433794 69145 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 18:50:44.642709 69145 solver.cpp:266] Iteration 17600 (16.1065 iter/s, 6.20869s/100 iter), loss = 0.0714527
I0122 18:50:44.642737 69145 solver.cpp:285]     Train net output #0: loss = 0.0714526 (* 1 = 0.0714526 loss)
I0122 18:50:44.642743 69145 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 18:50:50.854143 69145 solver.cpp:266] Iteration 17700 (16.1 iter/s, 6.21117s/100 iter), loss = 0.146256
I0122 18:50:50.854172 69145 solver.cpp:285]     Train net output #0: loss = 0.146256 (* 1 = 0.146256 loss)
I0122 18:50:50.854177 69145 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 18:50:57.092509 69145 solver.cpp:266] Iteration 17800 (16.0305 iter/s, 6.2381s/100 iter), loss = 0.0529273
I0122 18:50:57.092538 69145 solver.cpp:285]     Train net output #0: loss = 0.0529272 (* 1 = 0.0529272 loss)
I0122 18:50:57.092545 69145 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 18:51:03.311121 69145 solver.cpp:266] Iteration 17900 (16.0814 iter/s, 6.21835s/100 iter), loss = 0.0362121
I0122 18:51:03.311152 69145 solver.cpp:285]     Train net output #0: loss = 0.0362119 (* 1 = 0.0362119 loss)
I0122 18:51:03.311158 69145 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 18:51:09.486061 69145 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 18:51:10.935328 69145 solver.cpp:517]     Test net output #0: accuracy = 0.835556
I0122 18:51:10.935350 69145 solver.cpp:517]     Test net output #1: loss = 0.512659 (* 1 = 0.512659 loss)
I0122 18:51:10.935355 69145 solver.cpp:517]     Test net output #2: top-1 = 0.835556
I0122 18:51:10.935359 69145 solver.cpp:517]     Test net output #3: top-5 = 0.990111
I0122 18:51:10.998298 69145 solver.cpp:266] Iteration 18000 (13.0092 iter/s, 7.68686s/100 iter), loss = 0.0461048
I0122 18:51:10.998318 69145 solver.cpp:285]     Train net output #0: loss = 0.0461046 (* 1 = 0.0461046 loss)
I0122 18:51:10.998324 69145 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 18:51:17.234174 69145 solver.cpp:266] Iteration 18100 (16.0369 iter/s, 6.23562s/100 iter), loss = 0.131286
I0122 18:51:17.234201 69145 solver.cpp:285]     Train net output #0: loss = 0.131285 (* 1 = 0.131285 loss)
I0122 18:51:17.234206 69145 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 18:51:23.480839 69145 solver.cpp:266] Iteration 18200 (16.0092 iter/s, 6.2464s/100 iter), loss = 0.0267821
I0122 18:51:23.480868 69145 solver.cpp:285]     Train net output #0: loss = 0.026782 (* 1 = 0.026782 loss)
I0122 18:51:23.480875 69145 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 18:51:29.705824 69145 solver.cpp:266] Iteration 18300 (16.065 iter/s, 6.22472s/100 iter), loss = 0.112332
I0122 18:51:29.705852 69145 solver.cpp:285]     Train net output #0: loss = 0.112332 (* 1 = 0.112332 loss)
I0122 18:51:29.705858 69145 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 18:51:35.961474 69145 solver.cpp:266] Iteration 18400 (15.9862 iter/s, 6.25538s/100 iter), loss = 0.113111
I0122 18:51:35.961503 69145 solver.cpp:285]     Train net output #0: loss = 0.113111 (* 1 = 0.113111 loss)
I0122 18:51:35.961509 69145 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 18:51:42.183213 69145 solver.cpp:266] Iteration 18500 (16.0734 iter/s, 6.22147s/100 iter), loss = 0.0750109
I0122 18:51:42.183313 69145 solver.cpp:285]     Train net output #0: loss = 0.0750107 (* 1 = 0.0750107 loss)
I0122 18:51:42.183320 69145 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 18:51:48.421914 69145 solver.cpp:266] Iteration 18600 (16.0298 iter/s, 6.23836s/100 iter), loss = 0.14679
I0122 18:51:48.421943 69145 solver.cpp:285]     Train net output #0: loss = 0.14679 (* 1 = 0.14679 loss)
I0122 18:51:48.421949 69145 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 18:51:54.664717 69145 solver.cpp:266] Iteration 18700 (16.0191 iter/s, 6.24254s/100 iter), loss = 0.0691423
I0122 18:51:54.664757 69145 solver.cpp:285]     Train net output #0: loss = 0.0691421 (* 1 = 0.0691421 loss)
I0122 18:51:54.664764 69145 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 18:52:00.915859 69145 solver.cpp:266] Iteration 18800 (15.9978 iter/s, 6.25086s/100 iter), loss = 0.12669
I0122 18:52:00.915889 69145 solver.cpp:285]     Train net output #0: loss = 0.12669 (* 1 = 0.12669 loss)
I0122 18:52:00.915894 69145 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 18:52:07.151669 69145 solver.cpp:266] Iteration 18900 (16.0371 iter/s, 6.23554s/100 iter), loss = 0.0678376
I0122 18:52:07.151696 69145 solver.cpp:285]     Train net output #0: loss = 0.0678374 (* 1 = 0.0678374 loss)
I0122 18:52:07.151702 69145 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 18:52:13.330350 69145 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 18:52:14.781016 69145 solver.cpp:517]     Test net output #0: accuracy = 0.839111
I0122 18:52:14.781040 69145 solver.cpp:517]     Test net output #1: loss = 0.551633 (* 1 = 0.551633 loss)
I0122 18:52:14.781044 69145 solver.cpp:517]     Test net output #2: top-1 = 0.839111
I0122 18:52:14.781047 69145 solver.cpp:517]     Test net output #3: top-5 = 0.988444
I0122 18:52:14.843961 69145 solver.cpp:266] Iteration 19000 (13.0006 iter/s, 7.69198s/100 iter), loss = 0.131244
I0122 18:52:14.843982 69145 solver.cpp:285]     Train net output #0: loss = 0.131244 (* 1 = 0.131244 loss)
I0122 18:52:14.843988 69145 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 18:52:21.076236 69145 solver.cpp:266] Iteration 19100 (16.0462 iter/s, 6.23202s/100 iter), loss = 0.110863
I0122 18:52:21.076265 69145 solver.cpp:285]     Train net output #0: loss = 0.110863 (* 1 = 0.110863 loss)
I0122 18:52:21.076270 69145 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 18:52:27.319895 69145 solver.cpp:266] Iteration 19200 (16.0169 iter/s, 6.24339s/100 iter), loss = 0.0627216
I0122 18:52:27.319924 69145 solver.cpp:285]     Train net output #0: loss = 0.0627214 (* 1 = 0.0627214 loss)
I0122 18:52:27.319931 69145 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 18:52:33.543658 69145 solver.cpp:266] Iteration 19300 (16.0681 iter/s, 6.2235s/100 iter), loss = 0.0871404
I0122 18:52:33.543686 69145 solver.cpp:285]     Train net output #0: loss = 0.0871402 (* 1 = 0.0871402 loss)
I0122 18:52:33.543692 69145 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 18:52:39.795153 69145 solver.cpp:266] Iteration 19400 (15.9969 iter/s, 6.25123s/100 iter), loss = 0.0445563
I0122 18:52:39.795181 69145 solver.cpp:285]     Train net output #0: loss = 0.0445561 (* 1 = 0.0445561 loss)
I0122 18:52:39.795186 69145 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 18:52:46.049053 69145 solver.cpp:266] Iteration 19500 (15.9907 iter/s, 6.25363s/100 iter), loss = 0.110723
I0122 18:52:46.049127 69145 solver.cpp:285]     Train net output #0: loss = 0.110723 (* 1 = 0.110723 loss)
I0122 18:52:46.049134 69145 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 18:52:52.275964 69145 solver.cpp:266] Iteration 19600 (16.0601 iter/s, 6.2266s/100 iter), loss = 0.150825
I0122 18:52:52.275993 69145 solver.cpp:285]     Train net output #0: loss = 0.150824 (* 1 = 0.150824 loss)
I0122 18:52:52.275998 69145 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 18:52:58.505367 69145 solver.cpp:266] Iteration 19700 (16.0536 iter/s, 6.22914s/100 iter), loss = 0.0658688
I0122 18:52:58.505398 69145 solver.cpp:285]     Train net output #0: loss = 0.0658686 (* 1 = 0.0658686 loss)
I0122 18:52:58.505403 69145 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 18:53:04.747484 69145 solver.cpp:266] Iteration 19800 (16.0209 iter/s, 6.24185s/100 iter), loss = 0.203343
I0122 18:53:04.747514 69145 solver.cpp:285]     Train net output #0: loss = 0.203342 (* 1 = 0.203342 loss)
I0122 18:53:04.747519 69145 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 18:53:10.971207 69145 solver.cpp:266] Iteration 19900 (16.0682 iter/s, 6.22346s/100 iter), loss = 0.0775592
I0122 18:53:10.971237 69145 solver.cpp:285]     Train net output #0: loss = 0.077559 (* 1 = 0.077559 loss)
I0122 18:53:10.971243 69145 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 18:53:17.166803 69145 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/snapshots/_iter_20000.caffemodel
I0122 18:53:17.218446 69145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/snapshots/_iter_20000.solverstate
I0122 18:53:17.226418 69145 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 18:53:18.681865 69145 solver.cpp:517]     Test net output #0: accuracy = 0.849555
I0122 18:53:18.681891 69145 solver.cpp:517]     Test net output #1: loss = 0.498121 (* 1 = 0.498121 loss)
I0122 18:53:18.681896 69145 solver.cpp:517]     Test net output #2: top-1 = 0.849555
I0122 18:53:18.681900 69145 solver.cpp:517]     Test net output #3: top-5 = 0.992
I0122 18:53:18.744669 69145 solver.cpp:266] Iteration 20000 (12.8648 iter/s, 7.77314s/100 iter), loss = 0.0726634
I0122 18:53:18.744690 69145 solver.cpp:285]     Train net output #0: loss = 0.0726632 (* 1 = 0.0726632 loss)
I0122 18:53:18.744698 69145 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 18:53:24.975358 69145 solver.cpp:266] Iteration 20100 (16.0503 iter/s, 6.23043s/100 iter), loss = 0.0885038
I0122 18:53:24.975387 69145 solver.cpp:285]     Train net output #0: loss = 0.0885036 (* 1 = 0.0885036 loss)
I0122 18:53:24.975394 69145 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 18:53:31.214037 69145 solver.cpp:266] Iteration 20200 (16.0297 iter/s, 6.23841s/100 iter), loss = 0.0267631
I0122 18:53:31.214066 69145 solver.cpp:285]     Train net output #0: loss = 0.0267629 (* 1 = 0.0267629 loss)
I0122 18:53:31.214072 69145 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 18:53:37.453037 69145 solver.cpp:266] Iteration 20300 (16.0289 iter/s, 6.23873s/100 iter), loss = 0.0455344
I0122 18:53:37.453065 69145 solver.cpp:285]     Train net output #0: loss = 0.0455342 (* 1 = 0.0455342 loss)
I0122 18:53:37.453071 69145 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 18:53:43.682098 69145 solver.cpp:266] Iteration 20400 (16.0545 iter/s, 6.2288s/100 iter), loss = 0.039934
I0122 18:53:43.682126 69145 solver.cpp:285]     Train net output #0: loss = 0.0399338 (* 1 = 0.0399338 loss)
I0122 18:53:43.682132 69145 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 18:53:49.937129 69145 solver.cpp:266] Iteration 20500 (15.9878 iter/s, 6.25477s/100 iter), loss = 0.0436847
I0122 18:53:49.937206 69145 solver.cpp:285]     Train net output #0: loss = 0.0436845 (* 1 = 0.0436845 loss)
I0122 18:53:49.937213 69145 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 18:53:56.171494 69145 solver.cpp:266] Iteration 20600 (16.0409 iter/s, 6.23405s/100 iter), loss = 0.04296
I0122 18:53:56.171525 69145 solver.cpp:285]     Train net output #0: loss = 0.0429598 (* 1 = 0.0429598 loss)
I0122 18:53:56.171530 69145 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 18:54:02.400962 69145 solver.cpp:266] Iteration 20700 (16.0534 iter/s, 6.2292s/100 iter), loss = 0.0245079
I0122 18:54:02.400992 69145 solver.cpp:285]     Train net output #0: loss = 0.0245077 (* 1 = 0.0245077 loss)
I0122 18:54:02.400998 69145 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 18:54:08.642858 69145 solver.cpp:266] Iteration 20800 (16.0215 iter/s, 6.24163s/100 iter), loss = 0.0318295
I0122 18:54:08.642886 69145 solver.cpp:285]     Train net output #0: loss = 0.0318293 (* 1 = 0.0318293 loss)
I0122 18:54:08.642891 69145 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 18:54:14.863399 69145 solver.cpp:266] Iteration 20900 (16.0765 iter/s, 6.22028s/100 iter), loss = 0.0237816
I0122 18:54:14.863426 69145 solver.cpp:285]     Train net output #0: loss = 0.0237814 (* 1 = 0.0237814 loss)
I0122 18:54:14.863431 69145 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 18:54:21.039482 69145 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 18:54:22.498554 69145 solver.cpp:517]     Test net output #0: accuracy = 0.892556
I0122 18:54:22.498579 69145 solver.cpp:517]     Test net output #1: loss = 0.353184 (* 1 = 0.353184 loss)
I0122 18:54:22.498584 69145 solver.cpp:517]     Test net output #2: top-1 = 0.892556
I0122 18:54:22.498587 69145 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 18:54:22.561458 69145 solver.cpp:266] Iteration 21000 (12.9908 iter/s, 7.69774s/100 iter), loss = 0.0288175
I0122 18:54:22.561480 69145 solver.cpp:285]     Train net output #0: loss = 0.0288173 (* 1 = 0.0288173 loss)
I0122 18:54:22.561486 69145 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 18:54:28.800446 69145 solver.cpp:266] Iteration 21100 (16.0289 iter/s, 6.23873s/100 iter), loss = 0.0239391
I0122 18:54:28.800474 69145 solver.cpp:285]     Train net output #0: loss = 0.0239389 (* 1 = 0.0239389 loss)
I0122 18:54:28.800480 69145 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 18:54:35.052971 69145 solver.cpp:266] Iteration 21200 (15.9942 iter/s, 6.25226s/100 iter), loss = 0.0190116
I0122 18:54:35.053000 69145 solver.cpp:285]     Train net output #0: loss = 0.0190115 (* 1 = 0.0190115 loss)
I0122 18:54:35.053006 69145 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 18:54:41.286725 69145 solver.cpp:266] Iteration 21300 (16.0424 iter/s, 6.23349s/100 iter), loss = 0.0370594
I0122 18:54:41.286753 69145 solver.cpp:285]     Train net output #0: loss = 0.0370592 (* 1 = 0.0370592 loss)
I0122 18:54:41.286758 69145 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 18:54:47.524207 69145 solver.cpp:266] Iteration 21400 (16.0328 iter/s, 6.23722s/100 iter), loss = 0.0256433
I0122 18:54:47.524237 69145 solver.cpp:285]     Train net output #0: loss = 0.0256431 (* 1 = 0.0256431 loss)
I0122 18:54:47.524243 69145 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 18:54:53.757283 69145 solver.cpp:266] Iteration 21500 (16.0441 iter/s, 6.23281s/100 iter), loss = 0.0126985
I0122 18:54:53.757406 69145 solver.cpp:285]     Train net output #0: loss = 0.0126983 (* 1 = 0.0126983 loss)
I0122 18:54:53.757413 69145 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 18:55:00.001942 69145 solver.cpp:266] Iteration 21600 (16.0146 iter/s, 6.2443s/100 iter), loss = 0.0108583
I0122 18:55:00.001971 69145 solver.cpp:285]     Train net output #0: loss = 0.0108581 (* 1 = 0.0108581 loss)
I0122 18:55:00.001977 69145 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 18:55:06.246340 69145 solver.cpp:266] Iteration 21700 (16.015 iter/s, 6.24413s/100 iter), loss = 0.0186422
I0122 18:55:06.246371 69145 solver.cpp:285]     Train net output #0: loss = 0.018642 (* 1 = 0.018642 loss)
I0122 18:55:06.246376 69145 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 18:55:12.475975 69145 solver.cpp:266] Iteration 21800 (16.053 iter/s, 6.22936s/100 iter), loss = 0.00913521
I0122 18:55:12.476004 69145 solver.cpp:285]     Train net output #0: loss = 0.00913502 (* 1 = 0.00913502 loss)
I0122 18:55:12.476011 69145 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 18:55:18.705920 69145 solver.cpp:266] Iteration 21900 (16.0522 iter/s, 6.22968s/100 iter), loss = 0.0396529
I0122 18:55:18.705951 69145 solver.cpp:285]     Train net output #0: loss = 0.0396527 (* 1 = 0.0396527 loss)
I0122 18:55:18.705956 69145 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 18:55:24.906090 69145 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 18:55:26.362601 69145 solver.cpp:517]     Test net output #0: accuracy = 0.897333
I0122 18:55:26.362627 69145 solver.cpp:517]     Test net output #1: loss = 0.349041 (* 1 = 0.349041 loss)
I0122 18:55:26.362632 69145 solver.cpp:517]     Test net output #2: top-1 = 0.897333
I0122 18:55:26.362635 69145 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 18:55:26.426304 69145 solver.cpp:266] Iteration 22000 (12.9533 iter/s, 7.72007s/100 iter), loss = 0.00776631
I0122 18:55:26.426324 69145 solver.cpp:285]     Train net output #0: loss = 0.00776611 (* 1 = 0.00776611 loss)
I0122 18:55:26.426331 69145 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 18:55:32.655565 69145 solver.cpp:266] Iteration 22100 (16.0539 iter/s, 6.229s/100 iter), loss = 0.00895582
I0122 18:55:32.655604 69145 solver.cpp:285]     Train net output #0: loss = 0.00895562 (* 1 = 0.00895562 loss)
I0122 18:55:32.655611 69145 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 18:55:38.887327 69145 solver.cpp:266] Iteration 22200 (16.0475 iter/s, 6.23149s/100 iter), loss = 0.0152461
I0122 18:55:38.887357 69145 solver.cpp:285]     Train net output #0: loss = 0.0152459 (* 1 = 0.0152459 loss)
I0122 18:55:38.887363 69145 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 18:55:45.123795 69145 solver.cpp:266] Iteration 22300 (16.0354 iter/s, 6.2362s/100 iter), loss = 0.00875536
I0122 18:55:45.123822 69145 solver.cpp:285]     Train net output #0: loss = 0.00875516 (* 1 = 0.00875516 loss)
I0122 18:55:45.123828 69145 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 18:55:51.353322 69145 solver.cpp:266] Iteration 22400 (16.0533 iter/s, 6.22926s/100 iter), loss = 0.0274585
I0122 18:55:51.353353 69145 solver.cpp:285]     Train net output #0: loss = 0.0274583 (* 1 = 0.0274583 loss)
I0122 18:55:51.353358 69145 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 18:55:57.598701 69145 solver.cpp:266] Iteration 22500 (16.0125 iter/s, 6.24511s/100 iter), loss = 0.0310827
I0122 18:55:57.598820 69145 solver.cpp:285]     Train net output #0: loss = 0.0310825 (* 1 = 0.0310825 loss)
I0122 18:55:57.598829 69145 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 18:56:04.045711 69145 solver.cpp:266] Iteration 22600 (15.5119 iter/s, 6.44665s/100 iter), loss = 0.0122913
I0122 18:56:04.045740 69145 solver.cpp:285]     Train net output #0: loss = 0.0122911 (* 1 = 0.0122911 loss)
I0122 18:56:04.045747 69145 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 18:56:10.597810 69145 solver.cpp:266] Iteration 22700 (15.2629 iter/s, 6.55182s/100 iter), loss = 0.00826379
I0122 18:56:10.597841 69145 solver.cpp:285]     Train net output #0: loss = 0.00826358 (* 1 = 0.00826358 loss)
I0122 18:56:10.597847 69145 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 18:56:16.817329 69145 solver.cpp:266] Iteration 22800 (16.0791 iter/s, 6.21925s/100 iter), loss = 0.00851265
I0122 18:56:16.817360 69145 solver.cpp:285]     Train net output #0: loss = 0.00851244 (* 1 = 0.00851244 loss)
I0122 18:56:16.817366 69145 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 18:56:23.049558 69145 solver.cpp:266] Iteration 22900 (16.0463 iter/s, 6.23196s/100 iter), loss = 0.0136649
I0122 18:56:23.049589 69145 solver.cpp:285]     Train net output #0: loss = 0.0136647 (* 1 = 0.0136647 loss)
I0122 18:56:23.049595 69145 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 18:56:29.214819 69145 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 18:56:30.664927 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900333
I0122 18:56:30.664952 69145 solver.cpp:517]     Test net output #1: loss = 0.352228 (* 1 = 0.352228 loss)
I0122 18:56:30.664957 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900333
I0122 18:56:30.664959 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 18:56:30.727088 69145 solver.cpp:266] Iteration 23000 (13.0256 iter/s, 7.67721s/100 iter), loss = 0.0128846
I0122 18:56:30.727108 69145 solver.cpp:285]     Train net output #0: loss = 0.0128844 (* 1 = 0.0128844 loss)
I0122 18:56:30.727131 69145 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 18:56:36.966569 69145 solver.cpp:266] Iteration 23100 (16.0276 iter/s, 6.23922s/100 iter), loss = 0.0147062
I0122 18:56:36.966598 69145 solver.cpp:285]     Train net output #0: loss = 0.014706 (* 1 = 0.014706 loss)
I0122 18:56:36.966603 69145 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 18:56:43.212946 69145 solver.cpp:266] Iteration 23200 (16.01 iter/s, 6.24611s/100 iter), loss = 0.0122355
I0122 18:56:43.212975 69145 solver.cpp:285]     Train net output #0: loss = 0.0122353 (* 1 = 0.0122353 loss)
I0122 18:56:43.212980 69145 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 18:56:49.439182 69145 solver.cpp:266] Iteration 23300 (16.0618 iter/s, 6.22597s/100 iter), loss = 0.0121126
I0122 18:56:49.439210 69145 solver.cpp:285]     Train net output #0: loss = 0.0121124 (* 1 = 0.0121124 loss)
I0122 18:56:49.439215 69145 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 18:56:55.668841 69145 solver.cpp:266] Iteration 23400 (16.0529 iter/s, 6.22939s/100 iter), loss = 0.00857409
I0122 18:56:55.668871 69145 solver.cpp:285]     Train net output #0: loss = 0.0085739 (* 1 = 0.0085739 loss)
I0122 18:56:55.668877 69145 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 18:57:01.896750 69145 solver.cpp:266] Iteration 23500 (16.0574 iter/s, 6.22764s/100 iter), loss = 0.0208419
I0122 18:57:01.896857 69145 solver.cpp:285]     Train net output #0: loss = 0.0208417 (* 1 = 0.0208417 loss)
I0122 18:57:01.896863 69145 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 18:57:08.134627 69145 solver.cpp:266] Iteration 23600 (16.032 iter/s, 6.23753s/100 iter), loss = 0.016386
I0122 18:57:08.134657 69145 solver.cpp:285]     Train net output #0: loss = 0.0163858 (* 1 = 0.0163858 loss)
I0122 18:57:08.134663 69145 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 18:57:14.367651 69145 solver.cpp:266] Iteration 23700 (16.0443 iter/s, 6.23276s/100 iter), loss = 0.00967692
I0122 18:57:14.367682 69145 solver.cpp:285]     Train net output #0: loss = 0.00967674 (* 1 = 0.00967674 loss)
I0122 18:57:14.367688 69145 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 18:57:20.590528 69145 solver.cpp:266] Iteration 23800 (16.0704 iter/s, 6.22261s/100 iter), loss = 0.0136982
I0122 18:57:20.590556 69145 solver.cpp:285]     Train net output #0: loss = 0.013698 (* 1 = 0.013698 loss)
I0122 18:57:20.590562 69145 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 18:57:26.811489 69145 solver.cpp:266] Iteration 23900 (16.0754 iter/s, 6.2207s/100 iter), loss = 0.00893906
I0122 18:57:26.811518 69145 solver.cpp:285]     Train net output #0: loss = 0.00893888 (* 1 = 0.00893888 loss)
I0122 18:57:26.811523 69145 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 18:57:32.993357 69145 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 18:57:34.445919 69145 solver.cpp:517]     Test net output #0: accuracy = 0.899555
I0122 18:57:34.445955 69145 solver.cpp:517]     Test net output #1: loss = 0.357964 (* 1 = 0.357964 loss)
I0122 18:57:34.445960 69145 solver.cpp:517]     Test net output #2: top-1 = 0.899555
I0122 18:57:34.445964 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 18:57:34.508741 69145 solver.cpp:266] Iteration 24000 (12.9922 iter/s, 7.69693s/100 iter), loss = 0.010662
I0122 18:57:34.508764 69145 solver.cpp:285]     Train net output #0: loss = 0.0106618 (* 1 = 0.0106618 loss)
I0122 18:57:34.508769 69145 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 18:57:40.750066 69145 solver.cpp:266] Iteration 24100 (16.0229 iter/s, 6.24106s/100 iter), loss = 0.00764152
I0122 18:57:40.750095 69145 solver.cpp:285]     Train net output #0: loss = 0.00764134 (* 1 = 0.00764134 loss)
I0122 18:57:40.750102 69145 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 18:57:46.978937 69145 solver.cpp:266] Iteration 24200 (16.055 iter/s, 6.2286s/100 iter), loss = 0.00598059
I0122 18:57:46.978968 69145 solver.cpp:285]     Train net output #0: loss = 0.00598041 (* 1 = 0.00598041 loss)
I0122 18:57:46.978974 69145 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 18:57:53.199261 69145 solver.cpp:266] Iteration 24300 (16.077 iter/s, 6.22006s/100 iter), loss = 0.015405
I0122 18:57:53.199293 69145 solver.cpp:285]     Train net output #0: loss = 0.0154048 (* 1 = 0.0154048 loss)
I0122 18:57:53.199299 69145 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 18:57:59.420718 69145 solver.cpp:266] Iteration 24400 (16.0741 iter/s, 6.22119s/100 iter), loss = 0.0059916
I0122 18:57:59.420759 69145 solver.cpp:285]     Train net output #0: loss = 0.00599142 (* 1 = 0.00599142 loss)
I0122 18:57:59.420766 69145 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 18:58:05.674892 69145 solver.cpp:266] Iteration 24500 (15.99 iter/s, 6.25389s/100 iter), loss = 0.0114721
I0122 18:58:05.674957 69145 solver.cpp:285]     Train net output #0: loss = 0.011472 (* 1 = 0.011472 loss)
I0122 18:58:05.674963 69145 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 18:58:11.912166 69145 solver.cpp:266] Iteration 24600 (16.0334 iter/s, 6.23697s/100 iter), loss = 0.00595732
I0122 18:58:11.912197 69145 solver.cpp:285]     Train net output #0: loss = 0.00595713 (* 1 = 0.00595713 loss)
I0122 18:58:11.912202 69145 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 18:58:18.140607 69145 solver.cpp:266] Iteration 24700 (16.0561 iter/s, 6.22817s/100 iter), loss = 0.00817644
I0122 18:58:18.140636 69145 solver.cpp:285]     Train net output #0: loss = 0.00817626 (* 1 = 0.00817626 loss)
I0122 18:58:18.140643 69145 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 18:58:24.386487 69145 solver.cpp:266] Iteration 24800 (16.0112 iter/s, 6.24561s/100 iter), loss = 0.0101945
I0122 18:58:24.386518 69145 solver.cpp:285]     Train net output #0: loss = 0.0101943 (* 1 = 0.0101943 loss)
I0122 18:58:24.386523 69145 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 18:58:30.632128 69145 solver.cpp:266] Iteration 24900 (16.0119 iter/s, 6.24537s/100 iter), loss = 0.00846407
I0122 18:58:30.632169 69145 solver.cpp:285]     Train net output #0: loss = 0.00846388 (* 1 = 0.00846388 loss)
I0122 18:58:30.632175 69145 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 18:58:36.816051 69145 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 18:58:38.266965 69145 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 18:58:38.266991 69145 solver.cpp:517]     Test net output #1: loss = 0.359098 (* 1 = 0.359098 loss)
I0122 18:58:38.266996 69145 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 18:58:38.266999 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 18:58:38.329080 69145 solver.cpp:266] Iteration 25000 (12.9927 iter/s, 7.69662s/100 iter), loss = 0.00747285
I0122 18:58:38.329102 69145 solver.cpp:285]     Train net output #0: loss = 0.00747266 (* 1 = 0.00747266 loss)
I0122 18:58:38.329109 69145 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 18:58:44.544746 69145 solver.cpp:266] Iteration 25100 (16.0891 iter/s, 6.21541s/100 iter), loss = 0.0132921
I0122 18:58:44.544776 69145 solver.cpp:285]     Train net output #0: loss = 0.013292 (* 1 = 0.013292 loss)
I0122 18:58:44.544782 69145 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 18:58:50.750074 69145 solver.cpp:266] Iteration 25200 (16.1159 iter/s, 6.20506s/100 iter), loss = 0.0130859
I0122 18:58:50.750104 69145 solver.cpp:285]     Train net output #0: loss = 0.0130858 (* 1 = 0.0130858 loss)
I0122 18:58:50.750111 69145 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 18:58:56.987493 69145 solver.cpp:266] Iteration 25300 (16.033 iter/s, 6.23715s/100 iter), loss = 0.00708408
I0122 18:58:56.987522 69145 solver.cpp:285]     Train net output #0: loss = 0.00708389 (* 1 = 0.00708389 loss)
I0122 18:58:56.987527 69145 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 18:59:03.208921 69145 solver.cpp:266] Iteration 25400 (16.0742 iter/s, 6.22116s/100 iter), loss = 0.00672911
I0122 18:59:03.208951 69145 solver.cpp:285]     Train net output #0: loss = 0.00672892 (* 1 = 0.00672892 loss)
I0122 18:59:03.208956 69145 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 18:59:09.454473 69145 solver.cpp:266] Iteration 25500 (16.0121 iter/s, 6.24528s/100 iter), loss = 0.00917343
I0122 18:59:09.454581 69145 solver.cpp:285]     Train net output #0: loss = 0.00917324 (* 1 = 0.00917324 loss)
I0122 18:59:09.454588 69145 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 18:59:15.681841 69145 solver.cpp:266] Iteration 25600 (16.059 iter/s, 6.22702s/100 iter), loss = 0.0104834
I0122 18:59:15.681871 69145 solver.cpp:285]     Train net output #0: loss = 0.0104832 (* 1 = 0.0104832 loss)
I0122 18:59:15.681877 69145 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 18:59:21.928248 69145 solver.cpp:266] Iteration 25700 (16.0099 iter/s, 6.24614s/100 iter), loss = 0.01843
I0122 18:59:21.928278 69145 solver.cpp:285]     Train net output #0: loss = 0.0184298 (* 1 = 0.0184298 loss)
I0122 18:59:21.928284 69145 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 18:59:28.161376 69145 solver.cpp:266] Iteration 25800 (16.044 iter/s, 6.23286s/100 iter), loss = 0.0241701
I0122 18:59:28.161406 69145 solver.cpp:285]     Train net output #0: loss = 0.0241699 (* 1 = 0.0241699 loss)
I0122 18:59:28.161411 69145 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 18:59:34.391718 69145 solver.cpp:266] Iteration 25900 (16.0512 iter/s, 6.23008s/100 iter), loss = 0.0271913
I0122 18:59:34.391747 69145 solver.cpp:285]     Train net output #0: loss = 0.0271911 (* 1 = 0.0271911 loss)
I0122 18:59:34.391753 69145 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 18:59:40.567745 69145 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 18:59:42.022783 69145 solver.cpp:517]     Test net output #0: accuracy = 0.899666
I0122 18:59:42.022807 69145 solver.cpp:517]     Test net output #1: loss = 0.362712 (* 1 = 0.362712 loss)
I0122 18:59:42.022811 69145 solver.cpp:517]     Test net output #2: top-1 = 0.899666
I0122 18:59:42.022814 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 18:59:42.085130 69145 solver.cpp:266] Iteration 26000 (12.9987 iter/s, 7.69309s/100 iter), loss = 0.00771227
I0122 18:59:42.085150 69145 solver.cpp:285]     Train net output #0: loss = 0.00771209 (* 1 = 0.00771209 loss)
I0122 18:59:42.085156 69145 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 18:59:48.304441 69145 solver.cpp:266] Iteration 26100 (16.0796 iter/s, 6.21905s/100 iter), loss = 0.0120826
I0122 18:59:48.304471 69145 solver.cpp:285]     Train net output #0: loss = 0.0120824 (* 1 = 0.0120824 loss)
I0122 18:59:48.304477 69145 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 18:59:54.527155 69145 solver.cpp:266] Iteration 26200 (16.0708 iter/s, 6.22245s/100 iter), loss = 0.0100045
I0122 18:59:54.527184 69145 solver.cpp:285]     Train net output #0: loss = 0.0100043 (* 1 = 0.0100043 loss)
I0122 18:59:54.527189 69145 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 19:00:00.762820 69145 solver.cpp:266] Iteration 26300 (16.0375 iter/s, 6.2354s/100 iter), loss = 0.00843261
I0122 19:00:00.762848 69145 solver.cpp:285]     Train net output #0: loss = 0.00843242 (* 1 = 0.00843242 loss)
I0122 19:00:00.762854 69145 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 19:00:07.001546 69145 solver.cpp:266] Iteration 26400 (16.0296 iter/s, 6.23846s/100 iter), loss = 0.00648116
I0122 19:00:07.001576 69145 solver.cpp:285]     Train net output #0: loss = 0.00648097 (* 1 = 0.00648097 loss)
I0122 19:00:07.001582 69145 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 19:00:13.215334 69145 solver.cpp:266] Iteration 26500 (16.0939 iter/s, 6.21352s/100 iter), loss = 0.00616924
I0122 19:00:13.215451 69145 solver.cpp:285]     Train net output #0: loss = 0.00616905 (* 1 = 0.00616905 loss)
I0122 19:00:13.215459 69145 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 19:00:19.464638 69145 solver.cpp:266] Iteration 26600 (16.0027 iter/s, 6.24895s/100 iter), loss = 0.00596318
I0122 19:00:19.464666 69145 solver.cpp:285]     Train net output #0: loss = 0.00596299 (* 1 = 0.00596299 loss)
I0122 19:00:19.464673 69145 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 19:00:25.683974 69145 solver.cpp:266] Iteration 26700 (16.0796 iter/s, 6.21907s/100 iter), loss = 0.0096451
I0122 19:00:25.684002 69145 solver.cpp:285]     Train net output #0: loss = 0.00964491 (* 1 = 0.00964491 loss)
I0122 19:00:25.684008 69145 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 19:00:31.906785 69145 solver.cpp:266] Iteration 26800 (16.0706 iter/s, 6.22254s/100 iter), loss = 0.00602106
I0122 19:00:31.906814 69145 solver.cpp:285]     Train net output #0: loss = 0.00602087 (* 1 = 0.00602087 loss)
I0122 19:00:31.906821 69145 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 19:00:38.138547 69145 solver.cpp:266] Iteration 26900 (16.0475 iter/s, 6.23149s/100 iter), loss = 0.0106935
I0122 19:00:38.138576 69145 solver.cpp:285]     Train net output #0: loss = 0.0106933 (* 1 = 0.0106933 loss)
I0122 19:00:38.138581 69145 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 19:00:44.296429 69145 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 19:00:45.757076 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900555
I0122 19:00:45.757100 69145 solver.cpp:517]     Test net output #1: loss = 0.361804 (* 1 = 0.361804 loss)
I0122 19:00:45.757105 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900555
I0122 19:00:45.757108 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:00:45.820412 69145 solver.cpp:266] Iteration 27000 (13.0182 iter/s, 7.68155s/100 iter), loss = 0.00700049
I0122 19:00:45.820435 69145 solver.cpp:285]     Train net output #0: loss = 0.0070003 (* 1 = 0.0070003 loss)
I0122 19:00:45.820441 69145 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 19:00:52.045919 69145 solver.cpp:266] Iteration 27100 (16.0636 iter/s, 6.22525s/100 iter), loss = 0.0205831
I0122 19:00:52.045948 69145 solver.cpp:285]     Train net output #0: loss = 0.0205829 (* 1 = 0.0205829 loss)
I0122 19:00:52.045955 69145 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 19:00:58.271440 69145 solver.cpp:266] Iteration 27200 (16.0636 iter/s, 6.22525s/100 iter), loss = 0.00306174
I0122 19:00:58.271469 69145 solver.cpp:285]     Train net output #0: loss = 0.00306155 (* 1 = 0.00306155 loss)
I0122 19:00:58.271476 69145 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 19:01:04.536512 69145 solver.cpp:266] Iteration 27300 (15.9622 iter/s, 6.2648s/100 iter), loss = 0.0143102
I0122 19:01:04.536541 69145 solver.cpp:285]     Train net output #0: loss = 0.01431 (* 1 = 0.01431 loss)
I0122 19:01:04.536547 69145 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 19:01:10.764559 69145 solver.cpp:266] Iteration 27400 (16.0571 iter/s, 6.22778s/100 iter), loss = 0.00575627
I0122 19:01:10.764587 69145 solver.cpp:285]     Train net output #0: loss = 0.00575608 (* 1 = 0.00575608 loss)
I0122 19:01:10.764593 69145 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 19:01:16.984761 69145 solver.cpp:266] Iteration 27500 (16.0773 iter/s, 6.21994s/100 iter), loss = 0.00365498
I0122 19:01:16.984881 69145 solver.cpp:285]     Train net output #0: loss = 0.00365478 (* 1 = 0.00365478 loss)
I0122 19:01:16.984889 69145 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 19:01:23.208961 69145 solver.cpp:266] Iteration 27600 (16.0672 iter/s, 6.22384s/100 iter), loss = 0.00470949
I0122 19:01:23.208987 69145 solver.cpp:285]     Train net output #0: loss = 0.00470929 (* 1 = 0.00470929 loss)
I0122 19:01:23.209009 69145 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 19:01:29.458463 69145 solver.cpp:266] Iteration 27700 (16.002 iter/s, 6.24924s/100 iter), loss = 0.00863267
I0122 19:01:29.458492 69145 solver.cpp:285]     Train net output #0: loss = 0.00863247 (* 1 = 0.00863247 loss)
I0122 19:01:29.458498 69145 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 19:01:35.684729 69145 solver.cpp:266] Iteration 27800 (16.0617 iter/s, 6.226s/100 iter), loss = 0.0122244
I0122 19:01:35.684757 69145 solver.cpp:285]     Train net output #0: loss = 0.0122242 (* 1 = 0.0122242 loss)
I0122 19:01:35.684764 69145 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 19:01:41.919049 69145 solver.cpp:266] Iteration 27900 (16.0409 iter/s, 6.23405s/100 iter), loss = 0.00922158
I0122 19:01:41.919080 69145 solver.cpp:285]     Train net output #0: loss = 0.00922138 (* 1 = 0.00922138 loss)
I0122 19:01:41.919085 69145 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 19:01:48.082378 69145 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 19:01:49.540335 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900666
I0122 19:01:49.540372 69145 solver.cpp:517]     Test net output #1: loss = 0.365978 (* 1 = 0.365978 loss)
I0122 19:01:49.540376 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900666
I0122 19:01:49.540380 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:01:49.602543 69145 solver.cpp:266] Iteration 28000 (13.0155 iter/s, 7.68318s/100 iter), loss = 0.0045591
I0122 19:01:49.602564 69145 solver.cpp:285]     Train net output #0: loss = 0.0045589 (* 1 = 0.0045589 loss)
I0122 19:01:49.602571 69145 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 19:01:55.837469 69145 solver.cpp:266] Iteration 28100 (16.0394 iter/s, 6.23467s/100 iter), loss = 0.00605272
I0122 19:01:55.837498 69145 solver.cpp:285]     Train net output #0: loss = 0.00605252 (* 1 = 0.00605252 loss)
I0122 19:01:55.837520 69145 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 19:02:02.064013 69145 solver.cpp:266] Iteration 28200 (16.061 iter/s, 6.22628s/100 iter), loss = 0.00361844
I0122 19:02:02.064043 69145 solver.cpp:285]     Train net output #0: loss = 0.00361824 (* 1 = 0.00361824 loss)
I0122 19:02:02.064047 69145 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 19:02:08.301254 69145 solver.cpp:266] Iteration 28300 (16.0334 iter/s, 6.23697s/100 iter), loss = 0.00433879
I0122 19:02:08.301283 69145 solver.cpp:285]     Train net output #0: loss = 0.00433859 (* 1 = 0.00433859 loss)
I0122 19:02:08.301290 69145 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 19:02:14.525569 69145 solver.cpp:266] Iteration 28400 (16.0667 iter/s, 6.22405s/100 iter), loss = 0.00910675
I0122 19:02:14.525599 69145 solver.cpp:285]     Train net output #0: loss = 0.00910655 (* 1 = 0.00910655 loss)
I0122 19:02:14.525604 69145 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 19:02:20.753878 69145 solver.cpp:266] Iteration 28500 (16.0564 iter/s, 6.22804s/100 iter), loss = 0.00318886
I0122 19:02:20.753998 69145 solver.cpp:285]     Train net output #0: loss = 0.00318867 (* 1 = 0.00318867 loss)
I0122 19:02:20.754005 69145 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 19:02:26.972640 69145 solver.cpp:266] Iteration 28600 (16.0813 iter/s, 6.21841s/100 iter), loss = 0.0130778
I0122 19:02:26.972671 69145 solver.cpp:285]     Train net output #0: loss = 0.0130776 (* 1 = 0.0130776 loss)
I0122 19:02:26.972676 69145 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 19:02:33.223238 69145 solver.cpp:266] Iteration 28700 (15.9992 iter/s, 6.25033s/100 iter), loss = 0.00729709
I0122 19:02:33.223268 69145 solver.cpp:285]     Train net output #0: loss = 0.00729689 (* 1 = 0.00729689 loss)
I0122 19:02:33.223273 69145 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 19:02:39.438843 69145 solver.cpp:266] Iteration 28800 (16.0892 iter/s, 6.21534s/100 iter), loss = 0.00863803
I0122 19:02:39.438872 69145 solver.cpp:285]     Train net output #0: loss = 0.00863783 (* 1 = 0.00863783 loss)
I0122 19:02:39.438879 69145 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 19:02:45.659122 69145 solver.cpp:266] Iteration 28900 (16.0771 iter/s, 6.22001s/100 iter), loss = 0.00503035
I0122 19:02:45.659152 69145 solver.cpp:285]     Train net output #0: loss = 0.00503015 (* 1 = 0.00503015 loss)
I0122 19:02:45.659158 69145 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 19:02:51.833954 69145 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 19:02:53.287813 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900111
I0122 19:02:53.287840 69145 solver.cpp:517]     Test net output #1: loss = 0.364806 (* 1 = 0.364806 loss)
I0122 19:02:53.287845 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900111
I0122 19:02:53.287849 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:02:53.350849 69145 solver.cpp:266] Iteration 29000 (13.0015 iter/s, 7.69141s/100 iter), loss = 0.00923951
I0122 19:02:53.350872 69145 solver.cpp:285]     Train net output #0: loss = 0.00923931 (* 1 = 0.00923931 loss)
I0122 19:02:53.350878 69145 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 19:02:59.594681 69145 solver.cpp:266] Iteration 29100 (16.0165 iter/s, 6.24357s/100 iter), loss = 0.00473898
I0122 19:02:59.594712 69145 solver.cpp:285]     Train net output #0: loss = 0.00473878 (* 1 = 0.00473878 loss)
I0122 19:02:59.594718 69145 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 19:03:05.824982 69145 solver.cpp:266] Iteration 29200 (16.0513 iter/s, 6.23003s/100 iter), loss = 0.00479075
I0122 19:03:05.825011 69145 solver.cpp:285]     Train net output #0: loss = 0.00479055 (* 1 = 0.00479055 loss)
I0122 19:03:05.825017 69145 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 19:03:12.062700 69145 solver.cpp:266] Iteration 29300 (16.0322 iter/s, 6.23745s/100 iter), loss = 0.00331146
I0122 19:03:12.062731 69145 solver.cpp:285]     Train net output #0: loss = 0.00331126 (* 1 = 0.00331126 loss)
I0122 19:03:12.062736 69145 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 19:03:18.293579 69145 solver.cpp:266] Iteration 29400 (16.0498 iter/s, 6.23061s/100 iter), loss = 0.00927113
I0122 19:03:18.293610 69145 solver.cpp:285]     Train net output #0: loss = 0.00927093 (* 1 = 0.00927093 loss)
I0122 19:03:18.293617 69145 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 19:03:24.518318 69145 solver.cpp:266] Iteration 29500 (16.0656 iter/s, 6.22447s/100 iter), loss = 0.00503098
I0122 19:03:24.518422 69145 solver.cpp:285]     Train net output #0: loss = 0.00503078 (* 1 = 0.00503078 loss)
I0122 19:03:24.518429 69145 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 19:03:30.762190 69145 solver.cpp:266] Iteration 29600 (16.0166 iter/s, 6.24353s/100 iter), loss = 0.0113492
I0122 19:03:30.762221 69145 solver.cpp:285]     Train net output #0: loss = 0.011349 (* 1 = 0.011349 loss)
I0122 19:03:30.762228 69145 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 19:03:36.982201 69145 solver.cpp:266] Iteration 29700 (16.0778 iter/s, 6.21974s/100 iter), loss = 0.0111879
I0122 19:03:36.982230 69145 solver.cpp:285]     Train net output #0: loss = 0.0111877 (* 1 = 0.0111877 loss)
I0122 19:03:36.982236 69145 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 19:03:43.221308 69145 solver.cpp:266] Iteration 29800 (16.0286 iter/s, 6.23884s/100 iter), loss = 0.00632494
I0122 19:03:43.221339 69145 solver.cpp:285]     Train net output #0: loss = 0.00632474 (* 1 = 0.00632474 loss)
I0122 19:03:43.221345 69145 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 19:03:49.461314 69145 solver.cpp:266] Iteration 29900 (16.0263 iter/s, 6.23974s/100 iter), loss = 0.00926089
I0122 19:03:49.461345 69145 solver.cpp:285]     Train net output #0: loss = 0.00926069 (* 1 = 0.00926069 loss)
I0122 19:03:49.461350 69145 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 19:03:55.636790 69145 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 19:03:57.098304 69145 solver.cpp:517]     Test net output #0: accuracy = 0.901666
I0122 19:03:57.098332 69145 solver.cpp:517]     Test net output #1: loss = 0.365989 (* 1 = 0.365989 loss)
I0122 19:03:57.098336 69145 solver.cpp:517]     Test net output #2: top-1 = 0.901666
I0122 19:03:57.098340 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:03:57.159883 69145 solver.cpp:266] Iteration 30000 (12.99 iter/s, 7.69825s/100 iter), loss = 0.00434339
I0122 19:03:57.159906 69145 solver.cpp:285]     Train net output #0: loss = 0.00434319 (* 1 = 0.00434319 loss)
I0122 19:03:57.159914 69145 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 19:04:03.374537 69145 solver.cpp:266] Iteration 30100 (16.0917 iter/s, 6.21439s/100 iter), loss = 0.00518698
I0122 19:04:03.374567 69145 solver.cpp:285]     Train net output #0: loss = 0.00518678 (* 1 = 0.00518678 loss)
I0122 19:04:03.374572 69145 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 19:04:09.590495 69145 solver.cpp:266] Iteration 30200 (16.0883 iter/s, 6.21569s/100 iter), loss = 0.00907847
I0122 19:04:09.590525 69145 solver.cpp:285]     Train net output #0: loss = 0.00907828 (* 1 = 0.00907828 loss)
I0122 19:04:09.590530 69145 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 19:04:15.810737 69145 solver.cpp:266] Iteration 30300 (16.0772 iter/s, 6.21997s/100 iter), loss = 0.00405713
I0122 19:04:15.810766 69145 solver.cpp:285]     Train net output #0: loss = 0.00405693 (* 1 = 0.00405693 loss)
I0122 19:04:15.810772 69145 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 19:04:22.052002 69145 solver.cpp:266] Iteration 30400 (16.0231 iter/s, 6.241s/100 iter), loss = 0.00400309
I0122 19:04:22.052033 69145 solver.cpp:285]     Train net output #0: loss = 0.00400289 (* 1 = 0.00400289 loss)
I0122 19:04:22.052039 69145 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 19:04:28.267133 69145 solver.cpp:266] Iteration 30500 (16.0905 iter/s, 6.21486s/100 iter), loss = 0.00547465
I0122 19:04:28.267194 69145 solver.cpp:285]     Train net output #0: loss = 0.00547445 (* 1 = 0.00547445 loss)
I0122 19:04:28.267201 69145 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 19:04:34.523418 69145 solver.cpp:266] Iteration 30600 (15.9847 iter/s, 6.25598s/100 iter), loss = 0.00407396
I0122 19:04:34.523448 69145 solver.cpp:285]     Train net output #0: loss = 0.00407375 (* 1 = 0.00407375 loss)
I0122 19:04:34.523454 69145 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 19:04:40.764699 69145 solver.cpp:266] Iteration 30700 (16.023 iter/s, 6.24101s/100 iter), loss = 0.00519743
I0122 19:04:40.764729 69145 solver.cpp:285]     Train net output #0: loss = 0.00519723 (* 1 = 0.00519723 loss)
I0122 19:04:40.764735 69145 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 19:04:47.003515 69145 solver.cpp:266] Iteration 30800 (16.0294 iter/s, 6.23855s/100 iter), loss = 0.00661562
I0122 19:04:47.003546 69145 solver.cpp:285]     Train net output #0: loss = 0.00661541 (* 1 = 0.00661541 loss)
I0122 19:04:47.003552 69145 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 19:04:53.233978 69145 solver.cpp:266] Iteration 30900 (16.0509 iter/s, 6.23019s/100 iter), loss = 0.00807926
I0122 19:04:53.234007 69145 solver.cpp:285]     Train net output #0: loss = 0.00807905 (* 1 = 0.00807905 loss)
I0122 19:04:53.234014 69145 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 19:04:59.407339 69145 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 19:05:00.856771 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900999
I0122 19:05:00.856797 69145 solver.cpp:517]     Test net output #1: loss = 0.369335 (* 1 = 0.369335 loss)
I0122 19:05:00.856803 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900999
I0122 19:05:00.856806 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 19:05:00.918720 69145 solver.cpp:266] Iteration 31000 (13.0133 iter/s, 7.68442s/100 iter), loss = 0.00771861
I0122 19:05:00.918752 69145 solver.cpp:285]     Train net output #0: loss = 0.0077184 (* 1 = 0.0077184 loss)
I0122 19:05:00.918759 69145 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 19:05:07.151194 69145 solver.cpp:266] Iteration 31100 (16.0457 iter/s, 6.2322s/100 iter), loss = 0.00457189
I0122 19:05:07.151222 69145 solver.cpp:285]     Train net output #0: loss = 0.00457168 (* 1 = 0.00457168 loss)
I0122 19:05:07.151228 69145 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 19:05:13.368932 69145 solver.cpp:266] Iteration 31200 (16.0837 iter/s, 6.21747s/100 iter), loss = 0.00420975
I0122 19:05:13.368960 69145 solver.cpp:285]     Train net output #0: loss = 0.00420954 (* 1 = 0.00420954 loss)
I0122 19:05:13.368965 69145 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 19:05:19.608383 69145 solver.cpp:266] Iteration 31300 (16.0277 iter/s, 6.23918s/100 iter), loss = 0.0025777
I0122 19:05:19.608413 69145 solver.cpp:285]     Train net output #0: loss = 0.0025775 (* 1 = 0.0025775 loss)
I0122 19:05:19.608419 69145 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 19:05:25.849053 69145 solver.cpp:266] Iteration 31400 (16.0246 iter/s, 6.2404s/100 iter), loss = 0.00429707
I0122 19:05:25.849083 69145 solver.cpp:285]     Train net output #0: loss = 0.00429686 (* 1 = 0.00429686 loss)
I0122 19:05:25.849090 69145 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 19:05:32.076190 69145 solver.cpp:266] Iteration 31500 (16.0594 iter/s, 6.22687s/100 iter), loss = 0.00494031
I0122 19:05:32.076290 69145 solver.cpp:285]     Train net output #0: loss = 0.0049401 (* 1 = 0.0049401 loss)
I0122 19:05:32.076297 69145 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 19:05:38.300915 69145 solver.cpp:266] Iteration 31600 (16.0658 iter/s, 6.22439s/100 iter), loss = 0.00562523
I0122 19:05:38.300945 69145 solver.cpp:285]     Train net output #0: loss = 0.00562502 (* 1 = 0.00562502 loss)
I0122 19:05:38.300951 69145 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 19:05:44.533754 69145 solver.cpp:266] Iteration 31700 (16.0447 iter/s, 6.23257s/100 iter), loss = 0.00271036
I0122 19:05:44.533783 69145 solver.cpp:285]     Train net output #0: loss = 0.00271015 (* 1 = 0.00271015 loss)
I0122 19:05:44.533789 69145 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 19:05:50.770506 69145 solver.cpp:266] Iteration 31800 (16.0347 iter/s, 6.23648s/100 iter), loss = 0.00604747
I0122 19:05:50.770537 69145 solver.cpp:285]     Train net output #0: loss = 0.00604727 (* 1 = 0.00604727 loss)
I0122 19:05:50.770543 69145 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 19:05:56.994104 69145 solver.cpp:266] Iteration 31900 (16.0686 iter/s, 6.22333s/100 iter), loss = 0.0066794
I0122 19:05:56.994132 69145 solver.cpp:285]     Train net output #0: loss = 0.00667919 (* 1 = 0.00667919 loss)
I0122 19:05:56.994138 69145 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 19:06:03.168488 69145 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 19:06:04.621459 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900777
I0122 19:06:04.621486 69145 solver.cpp:517]     Test net output #1: loss = 0.37158 (* 1 = 0.37158 loss)
I0122 19:06:04.621490 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900777
I0122 19:06:04.621511 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:06:04.683568 69145 solver.cpp:266] Iteration 32000 (13.0053 iter/s, 7.68915s/100 iter), loss = 0.00255036
I0122 19:06:04.683589 69145 solver.cpp:285]     Train net output #0: loss = 0.00255015 (* 1 = 0.00255015 loss)
I0122 19:06:04.683596 69145 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 19:06:10.924935 69145 solver.cpp:266] Iteration 32100 (16.0228 iter/s, 6.24111s/100 iter), loss = 0.00631146
I0122 19:06:10.924964 69145 solver.cpp:285]     Train net output #0: loss = 0.00631126 (* 1 = 0.00631126 loss)
I0122 19:06:10.924970 69145 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 19:06:17.153102 69145 solver.cpp:266] Iteration 32200 (16.0568 iter/s, 6.2279s/100 iter), loss = 0.00576307
I0122 19:06:17.153133 69145 solver.cpp:285]     Train net output #0: loss = 0.00576287 (* 1 = 0.00576287 loss)
I0122 19:06:17.153139 69145 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 19:06:23.363471 69145 solver.cpp:266] Iteration 32300 (16.1028 iter/s, 6.2101s/100 iter), loss = 0.00712509
I0122 19:06:23.363500 69145 solver.cpp:285]     Train net output #0: loss = 0.00712488 (* 1 = 0.00712488 loss)
I0122 19:06:23.363507 69145 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 19:06:29.602398 69145 solver.cpp:266] Iteration 32400 (16.0291 iter/s, 6.23866s/100 iter), loss = 0.00850853
I0122 19:06:29.602442 69145 solver.cpp:285]     Train net output #0: loss = 0.00850832 (* 1 = 0.00850832 loss)
I0122 19:06:29.602447 69145 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 19:06:35.837530 69145 solver.cpp:266] Iteration 32500 (16.0389 iter/s, 6.23485s/100 iter), loss = 0.00610084
I0122 19:06:35.837648 69145 solver.cpp:285]     Train net output #0: loss = 0.00610063 (* 1 = 0.00610063 loss)
I0122 19:06:35.837656 69145 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 19:06:42.065824 69145 solver.cpp:266] Iteration 32600 (16.0567 iter/s, 6.22794s/100 iter), loss = 0.00870981
I0122 19:06:42.065855 69145 solver.cpp:285]     Train net output #0: loss = 0.0087096 (* 1 = 0.0087096 loss)
I0122 19:06:42.065861 69145 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 19:06:48.294469 69145 solver.cpp:266] Iteration 32700 (16.0555 iter/s, 6.22838s/100 iter), loss = 0.00462209
I0122 19:06:48.294500 69145 solver.cpp:285]     Train net output #0: loss = 0.00462188 (* 1 = 0.00462188 loss)
I0122 19:06:48.294507 69145 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 19:06:54.535944 69145 solver.cpp:266] Iteration 32800 (16.0225 iter/s, 6.24121s/100 iter), loss = 0.010088
I0122 19:06:54.535975 69145 solver.cpp:285]     Train net output #0: loss = 0.0100878 (* 1 = 0.0100878 loss)
I0122 19:06:54.535981 69145 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 19:07:00.773617 69145 solver.cpp:266] Iteration 32900 (16.0323 iter/s, 6.2374s/100 iter), loss = 0.0170992
I0122 19:07:00.773646 69145 solver.cpp:285]     Train net output #0: loss = 0.017099 (* 1 = 0.017099 loss)
I0122 19:07:00.773651 69145 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 19:07:06.947414 69145 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 19:07:08.402998 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900555
I0122 19:07:08.403024 69145 solver.cpp:517]     Test net output #1: loss = 0.372229 (* 1 = 0.372229 loss)
I0122 19:07:08.403028 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900555
I0122 19:07:08.403033 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995555
I0122 19:07:08.465651 69145 solver.cpp:266] Iteration 33000 (13.001 iter/s, 7.69171s/100 iter), loss = 0.00384205
I0122 19:07:08.465672 69145 solver.cpp:285]     Train net output #0: loss = 0.00384184 (* 1 = 0.00384184 loss)
I0122 19:07:08.465678 69145 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 19:07:14.696802 69145 solver.cpp:266] Iteration 33100 (16.0491 iter/s, 6.23089s/100 iter), loss = 0.00527523
I0122 19:07:14.696833 69145 solver.cpp:285]     Train net output #0: loss = 0.00527503 (* 1 = 0.00527503 loss)
I0122 19:07:14.696840 69145 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 19:07:20.920735 69145 solver.cpp:266] Iteration 33200 (16.0677 iter/s, 6.22367s/100 iter), loss = 0.00483877
I0122 19:07:20.920764 69145 solver.cpp:285]     Train net output #0: loss = 0.00483856 (* 1 = 0.00483856 loss)
I0122 19:07:20.920770 69145 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 19:07:27.161706 69145 solver.cpp:266] Iteration 33300 (16.0238 iter/s, 6.2407s/100 iter), loss = 0.00476813
I0122 19:07:27.161736 69145 solver.cpp:285]     Train net output #0: loss = 0.00476793 (* 1 = 0.00476793 loss)
I0122 19:07:27.161741 69145 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 19:07:33.391995 69145 solver.cpp:266] Iteration 33400 (16.0513 iter/s, 6.23002s/100 iter), loss = 0.00255219
I0122 19:07:33.392026 69145 solver.cpp:285]     Train net output #0: loss = 0.00255199 (* 1 = 0.00255199 loss)
I0122 19:07:33.392032 69145 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 19:07:39.618129 69145 solver.cpp:266] Iteration 33500 (16.062 iter/s, 6.22586s/100 iter), loss = 0.0049818
I0122 19:07:39.618254 69145 solver.cpp:285]     Train net output #0: loss = 0.00498159 (* 1 = 0.00498159 loss)
I0122 19:07:39.618263 69145 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 19:07:45.854471 69145 solver.cpp:266] Iteration 33600 (16.036 iter/s, 6.23598s/100 iter), loss = 0.00357744
I0122 19:07:45.854501 69145 solver.cpp:285]     Train net output #0: loss = 0.00357723 (* 1 = 0.00357723 loss)
I0122 19:07:45.854507 69145 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 19:07:52.082147 69145 solver.cpp:266] Iteration 33700 (16.058 iter/s, 6.22741s/100 iter), loss = 0.00237768
I0122 19:07:52.082178 69145 solver.cpp:285]     Train net output #0: loss = 0.00237748 (* 1 = 0.00237748 loss)
I0122 19:07:52.082185 69145 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 19:07:58.301307 69145 solver.cpp:266] Iteration 33800 (16.08 iter/s, 6.21889s/100 iter), loss = 0.00603048
I0122 19:07:58.301339 69145 solver.cpp:285]     Train net output #0: loss = 0.00603028 (* 1 = 0.00603028 loss)
I0122 19:07:58.301345 69145 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 19:08:04.540469 69145 solver.cpp:266] Iteration 33900 (16.0285 iter/s, 6.23889s/100 iter), loss = 0.00400818
I0122 19:08:04.540500 69145 solver.cpp:285]     Train net output #0: loss = 0.00400797 (* 1 = 0.00400797 loss)
I0122 19:08:04.540506 69145 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 19:08:10.705404 69145 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 19:08:12.161201 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900777
I0122 19:08:12.161226 69145 solver.cpp:517]     Test net output #1: loss = 0.372789 (* 1 = 0.372789 loss)
I0122 19:08:12.161231 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900777
I0122 19:08:12.161234 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:08:12.222558 69145 solver.cpp:266] Iteration 34000 (13.0178 iter/s, 7.68177s/100 iter), loss = 0.0038274
I0122 19:08:12.222580 69145 solver.cpp:285]     Train net output #0: loss = 0.00382719 (* 1 = 0.00382719 loss)
I0122 19:08:12.222585 69145 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 19:08:18.440258 69145 solver.cpp:266] Iteration 34100 (16.0838 iter/s, 6.21744s/100 iter), loss = 0.00310146
I0122 19:08:18.440285 69145 solver.cpp:285]     Train net output #0: loss = 0.00310125 (* 1 = 0.00310125 loss)
I0122 19:08:18.440292 69145 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 19:08:24.680754 69145 solver.cpp:266] Iteration 34200 (16.0251 iter/s, 6.24023s/100 iter), loss = 0.00379855
I0122 19:08:24.680783 69145 solver.cpp:285]     Train net output #0: loss = 0.00379834 (* 1 = 0.00379834 loss)
I0122 19:08:24.680789 69145 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 19:08:30.933502 69145 solver.cpp:266] Iteration 34300 (15.9937 iter/s, 6.25248s/100 iter), loss = 0.00470679
I0122 19:08:30.933531 69145 solver.cpp:285]     Train net output #0: loss = 0.00470658 (* 1 = 0.00470658 loss)
I0122 19:08:30.933537 69145 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 19:08:37.164685 69145 solver.cpp:266] Iteration 34400 (16.049 iter/s, 6.23092s/100 iter), loss = 0.0313107
I0122 19:08:37.164714 69145 solver.cpp:285]     Train net output #0: loss = 0.0313105 (* 1 = 0.0313105 loss)
I0122 19:08:37.164721 69145 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 19:08:43.382979 69145 solver.cpp:266] Iteration 34500 (16.0823 iter/s, 6.21803s/100 iter), loss = 0.00388902
I0122 19:08:43.383054 69145 solver.cpp:285]     Train net output #0: loss = 0.00388881 (* 1 = 0.00388881 loss)
I0122 19:08:43.383061 69145 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 19:08:49.614552 69145 solver.cpp:266] Iteration 34600 (16.0481 iter/s, 6.23126s/100 iter), loss = 0.00843176
I0122 19:08:49.614579 69145 solver.cpp:285]     Train net output #0: loss = 0.00843156 (* 1 = 0.00843156 loss)
I0122 19:08:49.614585 69145 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 19:08:55.855515 69145 solver.cpp:266] Iteration 34700 (16.0239 iter/s, 6.2407s/100 iter), loss = 0.00510287
I0122 19:08:55.855545 69145 solver.cpp:285]     Train net output #0: loss = 0.00510266 (* 1 = 0.00510266 loss)
I0122 19:08:55.855551 69145 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 19:09:02.090443 69145 solver.cpp:266] Iteration 34800 (16.0394 iter/s, 6.23466s/100 iter), loss = 0.00377942
I0122 19:09:02.090474 69145 solver.cpp:285]     Train net output #0: loss = 0.00377922 (* 1 = 0.00377922 loss)
I0122 19:09:02.090481 69145 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 19:09:08.312611 69145 solver.cpp:266] Iteration 34900 (16.0723 iter/s, 6.2219s/100 iter), loss = 0.00779891
I0122 19:09:08.312641 69145 solver.cpp:285]     Train net output #0: loss = 0.0077987 (* 1 = 0.0077987 loss)
I0122 19:09:08.312649 69145 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 19:09:14.480334 69145 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 19:09:15.936331 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900666
I0122 19:09:15.936363 69145 solver.cpp:517]     Test net output #1: loss = 0.372827 (* 1 = 0.372827 loss)
I0122 19:09:15.936367 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900666
I0122 19:09:15.936370 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:09:15.997558 69145 solver.cpp:266] Iteration 35000 (13.013 iter/s, 7.68463s/100 iter), loss = 0.00513111
I0122 19:09:15.997581 69145 solver.cpp:285]     Train net output #0: loss = 0.0051309 (* 1 = 0.0051309 loss)
I0122 19:09:15.997587 69145 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 19:09:22.200019 69145 solver.cpp:266] Iteration 35100 (16.1233 iter/s, 6.2022s/100 iter), loss = 0.00575878
I0122 19:09:22.200060 69145 solver.cpp:285]     Train net output #0: loss = 0.00575857 (* 1 = 0.00575857 loss)
I0122 19:09:22.200067 69145 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 19:09:28.435714 69145 solver.cpp:266] Iteration 35200 (16.0374 iter/s, 6.23542s/100 iter), loss = 0.00444998
I0122 19:09:28.435744 69145 solver.cpp:285]     Train net output #0: loss = 0.00444977 (* 1 = 0.00444977 loss)
I0122 19:09:28.435750 69145 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 19:09:34.658777 69145 solver.cpp:266] Iteration 35300 (16.0699 iter/s, 6.2228s/100 iter), loss = 0.00391778
I0122 19:09:34.658807 69145 solver.cpp:285]     Train net output #0: loss = 0.00391758 (* 1 = 0.00391758 loss)
I0122 19:09:34.658813 69145 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 19:09:40.907910 69145 solver.cpp:266] Iteration 35400 (16.0029 iter/s, 6.24886s/100 iter), loss = 0.0052375
I0122 19:09:40.907940 69145 solver.cpp:285]     Train net output #0: loss = 0.00523729 (* 1 = 0.00523729 loss)
I0122 19:09:40.907946 69145 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 19:09:47.142557 69145 solver.cpp:266] Iteration 35500 (16.0401 iter/s, 6.23438s/100 iter), loss = 0.0055128
I0122 19:09:47.142628 69145 solver.cpp:285]     Train net output #0: loss = 0.00551259 (* 1 = 0.00551259 loss)
I0122 19:09:47.142635 69145 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 19:09:53.366888 69145 solver.cpp:266] Iteration 35600 (16.0668 iter/s, 6.22402s/100 iter), loss = 0.00851738
I0122 19:09:53.366917 69145 solver.cpp:285]     Train net output #0: loss = 0.00851718 (* 1 = 0.00851718 loss)
I0122 19:09:53.366924 69145 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 19:09:59.608755 69145 solver.cpp:266] Iteration 35700 (16.0215 iter/s, 6.2416s/100 iter), loss = 0.00580729
I0122 19:09:59.608786 69145 solver.cpp:285]     Train net output #0: loss = 0.00580708 (* 1 = 0.00580708 loss)
I0122 19:09:59.608793 69145 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 19:10:05.829383 69145 solver.cpp:266] Iteration 35800 (16.0762 iter/s, 6.22036s/100 iter), loss = 0.00358378
I0122 19:10:05.829413 69145 solver.cpp:285]     Train net output #0: loss = 0.00358358 (* 1 = 0.00358358 loss)
I0122 19:10:05.829421 69145 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 19:10:12.069706 69145 solver.cpp:266] Iteration 35900 (16.0255 iter/s, 6.24005s/100 iter), loss = 0.00407481
I0122 19:10:12.069736 69145 solver.cpp:285]     Train net output #0: loss = 0.00407461 (* 1 = 0.00407461 loss)
I0122 19:10:12.069742 69145 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 19:10:18.234153 69145 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 19:10:19.693449 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900333
I0122 19:10:19.693477 69145 solver.cpp:517]     Test net output #1: loss = 0.372809 (* 1 = 0.372809 loss)
I0122 19:10:19.693481 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900333
I0122 19:10:19.693486 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:10:19.754627 69145 solver.cpp:266] Iteration 36000 (13.013 iter/s, 7.6846s/100 iter), loss = 0.00294428
I0122 19:10:19.754649 69145 solver.cpp:285]     Train net output #0: loss = 0.00294408 (* 1 = 0.00294408 loss)
I0122 19:10:19.754657 69145 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 19:10:25.972995 69145 solver.cpp:266] Iteration 36100 (16.0821 iter/s, 6.21809s/100 iter), loss = 0.00449352
I0122 19:10:25.973026 69145 solver.cpp:285]     Train net output #0: loss = 0.00449332 (* 1 = 0.00449332 loss)
I0122 19:10:25.973031 69145 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 19:10:32.205791 69145 solver.cpp:266] Iteration 36200 (16.0449 iter/s, 6.23253s/100 iter), loss = 0.00407195
I0122 19:10:32.205822 69145 solver.cpp:285]     Train net output #0: loss = 0.00407175 (* 1 = 0.00407175 loss)
I0122 19:10:32.205828 69145 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 19:10:38.433881 69145 solver.cpp:266] Iteration 36300 (16.057 iter/s, 6.22782s/100 iter), loss = 0.00802813
I0122 19:10:38.433913 69145 solver.cpp:285]     Train net output #0: loss = 0.00802792 (* 1 = 0.00802792 loss)
I0122 19:10:38.433920 69145 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 19:10:44.653179 69145 solver.cpp:266] Iteration 36400 (16.0797 iter/s, 6.21903s/100 iter), loss = 0.00408315
I0122 19:10:44.653210 69145 solver.cpp:285]     Train net output #0: loss = 0.00408295 (* 1 = 0.00408295 loss)
I0122 19:10:44.653216 69145 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 19:10:50.883814 69145 solver.cpp:266] Iteration 36500 (16.0504 iter/s, 6.23037s/100 iter), loss = 0.00466982
I0122 19:10:50.883920 69145 solver.cpp:285]     Train net output #0: loss = 0.00466961 (* 1 = 0.00466961 loss)
I0122 19:10:50.883927 69145 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 19:10:57.104588 69145 solver.cpp:266] Iteration 36600 (16.0761 iter/s, 6.22043s/100 iter), loss = 0.00434633
I0122 19:10:57.104619 69145 solver.cpp:285]     Train net output #0: loss = 0.00434612 (* 1 = 0.00434612 loss)
I0122 19:10:57.104624 69145 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 19:11:03.355813 69145 solver.cpp:266] Iteration 36700 (15.9976 iter/s, 6.25096s/100 iter), loss = 0.00433394
I0122 19:11:03.355845 69145 solver.cpp:285]     Train net output #0: loss = 0.00433373 (* 1 = 0.00433373 loss)
I0122 19:11:03.355852 69145 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 19:11:09.596411 69145 solver.cpp:266] Iteration 36800 (16.0248 iter/s, 6.24033s/100 iter), loss = 0.00515317
I0122 19:11:09.596441 69145 solver.cpp:285]     Train net output #0: loss = 0.00515297 (* 1 = 0.00515297 loss)
I0122 19:11:09.596446 69145 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 19:11:15.824357 69145 solver.cpp:266] Iteration 36900 (16.0574 iter/s, 6.22768s/100 iter), loss = 0.00419261
I0122 19:11:15.824386 69145 solver.cpp:285]     Train net output #0: loss = 0.00419241 (* 1 = 0.00419241 loss)
I0122 19:11:15.824393 69145 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 19:11:22.001909 69145 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 19:11:23.444895 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900555
I0122 19:11:23.444919 69145 solver.cpp:517]     Test net output #1: loss = 0.373094 (* 1 = 0.373094 loss)
I0122 19:11:23.444924 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900555
I0122 19:11:23.444928 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:11:23.506501 69145 solver.cpp:266] Iteration 37000 (13.0177 iter/s, 7.68183s/100 iter), loss = 0.00870052
I0122 19:11:23.506523 69145 solver.cpp:285]     Train net output #0: loss = 0.00870031 (* 1 = 0.00870031 loss)
I0122 19:11:23.506530 69145 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 19:11:29.725060 69145 solver.cpp:266] Iteration 37100 (16.0816 iter/s, 6.2183s/100 iter), loss = 0.00339388
I0122 19:11:29.725091 69145 solver.cpp:285]     Train net output #0: loss = 0.00339367 (* 1 = 0.00339367 loss)
I0122 19:11:29.725097 69145 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 19:11:35.945868 69145 solver.cpp:266] Iteration 37200 (16.0758 iter/s, 6.22054s/100 iter), loss = 0.0060778
I0122 19:11:35.945897 69145 solver.cpp:285]     Train net output #0: loss = 0.00607759 (* 1 = 0.00607759 loss)
I0122 19:11:35.945921 69145 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 19:11:42.192831 69145 solver.cpp:266] Iteration 37300 (16.0085 iter/s, 6.24669s/100 iter), loss = 0.00442582
I0122 19:11:42.192862 69145 solver.cpp:285]     Train net output #0: loss = 0.00442562 (* 1 = 0.00442562 loss)
I0122 19:11:42.192867 69145 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 19:11:48.438733 69145 solver.cpp:266] Iteration 37400 (16.0112 iter/s, 6.24563s/100 iter), loss = 0.00301128
I0122 19:11:48.438763 69145 solver.cpp:285]     Train net output #0: loss = 0.00301107 (* 1 = 0.00301107 loss)
I0122 19:11:48.438769 69145 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 19:11:54.656886 69145 solver.cpp:266] Iteration 37500 (16.0826 iter/s, 6.21789s/100 iter), loss = 0.00555172
I0122 19:11:54.656949 69145 solver.cpp:285]     Train net output #0: loss = 0.00555151 (* 1 = 0.00555151 loss)
I0122 19:11:54.656955 69145 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 19:12:00.889080 69145 solver.cpp:266] Iteration 37600 (16.0465 iter/s, 6.23189s/100 iter), loss = 0.00780876
I0122 19:12:00.889109 69145 solver.cpp:285]     Train net output #0: loss = 0.00780855 (* 1 = 0.00780855 loss)
I0122 19:12:00.889116 69145 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 19:12:07.118474 69145 solver.cpp:266] Iteration 37700 (16.0536 iter/s, 6.22913s/100 iter), loss = 0.00586247
I0122 19:12:07.118505 69145 solver.cpp:285]     Train net output #0: loss = 0.00586226 (* 1 = 0.00586226 loss)
I0122 19:12:07.118511 69145 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 19:12:13.337558 69145 solver.cpp:266] Iteration 37800 (16.0802 iter/s, 6.21882s/100 iter), loss = 0.00414719
I0122 19:12:13.337587 69145 solver.cpp:285]     Train net output #0: loss = 0.00414699 (* 1 = 0.00414699 loss)
I0122 19:12:13.337594 69145 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 19:12:19.569681 69145 solver.cpp:266] Iteration 37900 (16.0466 iter/s, 6.23186s/100 iter), loss = 0.00459571
I0122 19:12:19.569712 69145 solver.cpp:285]     Train net output #0: loss = 0.0045955 (* 1 = 0.0045955 loss)
I0122 19:12:19.569718 69145 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 19:12:25.735893 69145 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 19:12:27.193557 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900111
I0122 19:12:27.193593 69145 solver.cpp:517]     Test net output #1: loss = 0.372836 (* 1 = 0.372836 loss)
I0122 19:12:27.193598 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900111
I0122 19:12:27.193600 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:12:27.255524 69145 solver.cpp:266] Iteration 38000 (13.0115 iter/s, 7.68552s/100 iter), loss = 0.0054882
I0122 19:12:27.255547 69145 solver.cpp:285]     Train net output #0: loss = 0.005488 (* 1 = 0.005488 loss)
I0122 19:12:27.255553 69145 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 19:12:33.481138 69145 solver.cpp:266] Iteration 38100 (16.0633 iter/s, 6.22535s/100 iter), loss = 0.00304361
I0122 19:12:33.481168 69145 solver.cpp:285]     Train net output #0: loss = 0.00304341 (* 1 = 0.00304341 loss)
I0122 19:12:33.481174 69145 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 19:12:39.705482 69145 solver.cpp:266] Iteration 38200 (16.0666 iter/s, 6.22407s/100 iter), loss = 0.00844681
I0122 19:12:39.705510 69145 solver.cpp:285]     Train net output #0: loss = 0.00844661 (* 1 = 0.00844661 loss)
I0122 19:12:39.705516 69145 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 19:12:45.930701 69145 solver.cpp:266] Iteration 38300 (16.0644 iter/s, 6.22495s/100 iter), loss = 0.00443228
I0122 19:12:45.930732 69145 solver.cpp:285]     Train net output #0: loss = 0.00443208 (* 1 = 0.00443208 loss)
I0122 19:12:45.930738 69145 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 19:12:52.168452 69145 solver.cpp:266] Iteration 38400 (16.0321 iter/s, 6.23748s/100 iter), loss = 0.0206381
I0122 19:12:52.168483 69145 solver.cpp:285]     Train net output #0: loss = 0.0206379 (* 1 = 0.0206379 loss)
I0122 19:12:52.168488 69145 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 19:12:58.398521 69145 solver.cpp:266] Iteration 38500 (16.0519 iter/s, 6.2298s/100 iter), loss = 0.00563641
I0122 19:12:58.398586 69145 solver.cpp:285]     Train net output #0: loss = 0.00563621 (* 1 = 0.00563621 loss)
I0122 19:12:58.398592 69145 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 19:13:04.629983 69145 solver.cpp:266] Iteration 38600 (16.0484 iter/s, 6.23116s/100 iter), loss = 0.00670227
I0122 19:13:04.630012 69145 solver.cpp:285]     Train net output #0: loss = 0.00670206 (* 1 = 0.00670206 loss)
I0122 19:13:04.630018 69145 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 19:13:10.869527 69145 solver.cpp:266] Iteration 38700 (16.0275 iter/s, 6.23928s/100 iter), loss = 0.00817714
I0122 19:13:10.869556 69145 solver.cpp:285]     Train net output #0: loss = 0.00817693 (* 1 = 0.00817693 loss)
I0122 19:13:10.869561 69145 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 19:13:17.088529 69145 solver.cpp:266] Iteration 38800 (16.0804 iter/s, 6.21873s/100 iter), loss = 0.00343983
I0122 19:13:17.088562 69145 solver.cpp:285]     Train net output #0: loss = 0.00343963 (* 1 = 0.00343963 loss)
I0122 19:13:17.088567 69145 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 19:13:23.319814 69145 solver.cpp:266] Iteration 38900 (16.0488 iter/s, 6.23101s/100 iter), loss = 0.00436188
I0122 19:13:23.319844 69145 solver.cpp:285]     Train net output #0: loss = 0.00436168 (* 1 = 0.00436168 loss)
I0122 19:13:23.319850 69145 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 19:13:29.502377 69145 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 19:13:30.958107 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900333
I0122 19:13:30.958134 69145 solver.cpp:517]     Test net output #1: loss = 0.373085 (* 1 = 0.373085 loss)
I0122 19:13:30.958139 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900333
I0122 19:13:30.958142 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:13:31.020231 69145 solver.cpp:266] Iteration 39000 (12.9868 iter/s, 7.7001s/100 iter), loss = 0.00383462
I0122 19:13:31.020251 69145 solver.cpp:285]     Train net output #0: loss = 0.00383441 (* 1 = 0.00383441 loss)
I0122 19:13:31.020258 69145 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 19:13:37.231577 69145 solver.cpp:266] Iteration 39100 (16.1002 iter/s, 6.21109s/100 iter), loss = 0.00510041
I0122 19:13:37.231607 69145 solver.cpp:285]     Train net output #0: loss = 0.00510021 (* 1 = 0.00510021 loss)
I0122 19:13:37.231613 69145 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 19:13:43.448618 69145 solver.cpp:266] Iteration 39200 (16.0855 iter/s, 6.21677s/100 iter), loss = 0.0040364
I0122 19:13:43.448647 69145 solver.cpp:285]     Train net output #0: loss = 0.00403619 (* 1 = 0.00403619 loss)
I0122 19:13:43.448653 69145 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 19:13:49.692749 69145 solver.cpp:266] Iteration 39300 (16.0157 iter/s, 6.24386s/100 iter), loss = 0.00698737
I0122 19:13:49.692780 69145 solver.cpp:285]     Train net output #0: loss = 0.00698717 (* 1 = 0.00698717 loss)
I0122 19:13:49.692785 69145 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 19:13:55.920614 69145 solver.cpp:266] Iteration 39400 (16.0576 iter/s, 6.2276s/100 iter), loss = 0.00318784
I0122 19:13:55.920645 69145 solver.cpp:285]     Train net output #0: loss = 0.00318764 (* 1 = 0.00318764 loss)
I0122 19:13:55.920651 69145 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 19:14:02.156721 69145 solver.cpp:266] Iteration 39500 (16.0363 iter/s, 6.23584s/100 iter), loss = 0.00710206
I0122 19:14:02.156805 69145 solver.cpp:285]     Train net output #0: loss = 0.00710185 (* 1 = 0.00710185 loss)
I0122 19:14:02.156811 69145 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 19:14:08.387197 69145 solver.cpp:266] Iteration 39600 (16.051 iter/s, 6.23016s/100 iter), loss = 0.0115146
I0122 19:14:08.387226 69145 solver.cpp:285]     Train net output #0: loss = 0.0115144 (* 1 = 0.0115144 loss)
I0122 19:14:08.387233 69145 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 19:14:14.626250 69145 solver.cpp:266] Iteration 39700 (16.0288 iter/s, 6.23878s/100 iter), loss = 0.00425099
I0122 19:14:14.626278 69145 solver.cpp:285]     Train net output #0: loss = 0.00425078 (* 1 = 0.00425078 loss)
I0122 19:14:14.626283 69145 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 19:14:20.868403 69145 solver.cpp:266] Iteration 39800 (16.0208 iter/s, 6.24189s/100 iter), loss = 0.00685801
I0122 19:14:20.868432 69145 solver.cpp:285]     Train net output #0: loss = 0.0068578 (* 1 = 0.0068578 loss)
I0122 19:14:20.868439 69145 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 19:14:27.082568 69145 solver.cpp:266] Iteration 39900 (16.093 iter/s, 6.2139s/100 iter), loss = 0.00568237
I0122 19:14:27.082598 69145 solver.cpp:285]     Train net output #0: loss = 0.00568217 (* 1 = 0.00568217 loss)
I0122 19:14:27.082604 69145 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 19:14:33.244953 69145 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/snapshots/_iter_40000.caffemodel
I0122 19:14:33.290894 69145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.2/snapshots/_iter_40000.solverstate
I0122 19:14:33.320433 69145 solver.cpp:378] Iteration 40000, loss = 0.00266304
I0122 19:14:33.320454 69145 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 19:14:34.771314 69145 solver.cpp:517]     Test net output #0: accuracy = 0.900333
I0122 19:14:34.771340 69145 solver.cpp:517]     Test net output #1: loss = 0.372919 (* 1 = 0.372919 loss)
I0122 19:14:34.771345 69145 solver.cpp:517]     Test net output #2: top-1 = 0.900333
I0122 19:14:34.771348 69145 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:14:34.771353 69145 solver.cpp:386] Optimization Done (15.6805 iter/s).
I0122 19:14:34.771358 69145 caffe_interface.cpp:530] Optimization Done.

## compression: third run
$PRUNE_ROOT/deephi_compress compress -config ${WORK_DIR}/config3.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_compress3_miniGoogleNet.txt
I0122 19:14:35.386523 69630 pruning_runner.cpp:190] Sens info found, use it.
I0122 19:14:35.419668 69630 pruning_runner.cpp:217] Start compressing, please wait...
I0122 19:14:36.831792 69630 pruning_runner.cpp:264] Compression complete 0.0118422%
I0122 19:14:37.479979 69630 pruning_runner.cpp:264] Compression complete 0.0236816%
I0122 19:14:38.129945 69630 pruning_runner.cpp:264] Compression complete 50.0118%
I0122 19:14:38.773844 69630 pruning_runner.cpp:264] Compression complete 66.6772%
I0122 19:14:39.415786 69630 caffe_interface.cpp:66] Use GPU with device ID 0
I0122 19:14:39.416129 69630 caffe_interface.cpp:70] GPU device name: Quadro P6000
I0122 19:14:39.417323 69630 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 19:14:39.417850 69630 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 19:14:39.418135 69630 layer_factory.hpp:77] Creating layer data
I0122 19:14:39.418169 69630 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:39.418534 69630 net.cpp:94] Creating Layer data
I0122 19:14:39.418540 69630 net.cpp:409] data -> data
I0122 19:14:39.418548 69630 net.cpp:409] data -> label
I0122 19:14:39.419550 70118 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 19:14:39.419582 70118 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 19:14:39.419715 69630 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 19:14:39.419790 69630 data_layer.cpp:83] output data size: 50,3,32,32
I0122 19:14:39.422266 69630 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:39.422302 69630 net.cpp:144] Setting up data
I0122 19:14:39.422314 69630 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 19:14:39.422317 69630 net.cpp:151] Top shape: 50 (50)
I0122 19:14:39.422320 69630 net.cpp:159] Memory required for data: 614600
I0122 19:14:39.422323 69630 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 19:14:39.422330 69630 net.cpp:94] Creating Layer label_data_1_split
I0122 19:14:39.422333 69630 net.cpp:435] label_data_1_split <- label
I0122 19:14:39.422349 69630 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 19:14:39.422358 69630 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 19:14:39.422364 69630 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 19:14:39.422369 69630 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 19:14:39.422452 69630 net.cpp:144] Setting up label_data_1_split
I0122 19:14:39.422459 69630 net.cpp:151] Top shape: 50 (50)
I0122 19:14:39.422462 69630 net.cpp:151] Top shape: 50 (50)
I0122 19:14:39.422466 69630 net.cpp:151] Top shape: 50 (50)
I0122 19:14:39.422469 69630 net.cpp:151] Top shape: 50 (50)
I0122 19:14:39.422472 69630 net.cpp:159] Memory required for data: 615400
I0122 19:14:39.422475 69630 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:14:39.422485 69630 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:14:39.422489 69630 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:14:39.422495 69630 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:14:39.424022 69630 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:14:39.424034 69630 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:39.424037 69630 net.cpp:159] Memory required for data: 20276200
I0122 19:14:39.424048 69630 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:14:39.424058 69630 net.cpp:94] Creating Layer conv1/bn1
I0122 19:14:39.424062 69630 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:14:39.424067 69630 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:14:39.424747 69630 net.cpp:144] Setting up conv1/bn1
I0122 19:14:39.424754 69630 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:39.424757 69630 net.cpp:159] Memory required for data: 39937000
I0122 19:14:39.424767 69630 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:14:39.424775 69630 net.cpp:94] Creating Layer conv1/relu1
I0122 19:14:39.424779 69630 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:14:39.424783 69630 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:14:39.424789 69630 net.cpp:144] Setting up conv1/relu1
I0122 19:14:39.424793 69630 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:39.424795 69630 net.cpp:159] Memory required for data: 59597800
I0122 19:14:39.424798 69630 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:39.424803 69630 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:39.424806 69630 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:14:39.424810 69630 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:39.424815 69630 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:39.424880 69630 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:39.424887 69630 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:39.424892 69630 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:39.424895 69630 net.cpp:159] Memory required for data: 98919400
I0122 19:14:39.424897 69630 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:14:39.424906 69630 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:14:39.424911 69630 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:39.424916 69630 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:14:39.425218 69630 net.cpp:144] Setting up inception_2a/1x1
I0122 19:14:39.425225 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.425228 69630 net.cpp:159] Memory required for data: 105473000
I0122 19:14:39.425235 69630 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:14:39.425242 69630 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:14:39.425247 69630 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:14:39.425253 69630 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:14:39.426007 69630 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:14:39.426013 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.426017 69630 net.cpp:159] Memory required for data: 112026600
I0122 19:14:39.426036 69630 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:14:39.426043 69630 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:14:39.426046 69630 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:14:39.426051 69630 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:14:39.426057 69630 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:14:39.426060 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.426064 69630 net.cpp:159] Memory required for data: 118580200
I0122 19:14:39.426082 69630 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:14:39.426091 69630 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:14:39.426095 69630 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:39.426101 69630 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:14:39.427140 69630 net.cpp:144] Setting up inception_2a/3x3
I0122 19:14:39.427152 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.427155 69630 net.cpp:159] Memory required for data: 125133800
I0122 19:14:39.427162 69630 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:14:39.427171 69630 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:14:39.427175 69630 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:14:39.427181 69630 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:14:39.427829 69630 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:14:39.427837 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.427840 69630 net.cpp:159] Memory required for data: 131687400
I0122 19:14:39.427851 69630 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:14:39.427860 69630 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:14:39.427863 69630 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:14:39.427867 69630 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:14:39.427875 69630 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:14:39.427878 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.427882 69630 net.cpp:159] Memory required for data: 138241000
I0122 19:14:39.427886 69630 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:14:39.427891 69630 net.cpp:94] Creating Layer inception_2a/output
I0122 19:14:39.427892 69630 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:14:39.427897 69630 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:14:39.427902 69630 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:14:39.427923 69630 net.cpp:144] Setting up inception_2a/output
I0122 19:14:39.427928 69630 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:39.427932 69630 net.cpp:159] Memory required for data: 151348200
I0122 19:14:39.427934 69630 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:39.427939 69630 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:39.427942 69630 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:14:39.427947 69630 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:39.427953 69630 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:39.428009 69630 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:14:39.428014 69630 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:39.428019 69630 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:39.428020 69630 net.cpp:159] Memory required for data: 177562600
I0122 19:14:39.428023 69630 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:14:39.428030 69630 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:14:39.428036 69630 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:39.428052 69630 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:14:39.428270 69630 net.cpp:144] Setting up inception_3a/1x1
I0122 19:14:39.428277 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.428280 69630 net.cpp:159] Memory required for data: 184116200
I0122 19:14:39.428285 69630 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:14:39.428292 69630 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:14:39.428295 69630 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:14:39.428301 69630 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:14:39.428957 69630 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:14:39.428964 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.428967 69630 net.cpp:159] Memory required for data: 190669800
I0122 19:14:39.428977 69630 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:14:39.428982 69630 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:14:39.428987 69630 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:14:39.428992 69630 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:14:39.428999 69630 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:14:39.429003 69630 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:39.429006 69630 net.cpp:159] Memory required for data: 197223400
I0122 19:14:39.429008 69630 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:14:39.429016 69630 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:14:39.429019 69630 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:39.429026 69630 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:14:39.429404 69630 net.cpp:144] Setting up inception_3a/3x3
I0122 19:14:39.429411 69630 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:39.429415 69630 net.cpp:159] Memory required for data: 207053800
I0122 19:14:39.429420 69630 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:14:39.429427 69630 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:14:39.429431 69630 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:14:39.429436 69630 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:14:39.430106 69630 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:14:39.430114 69630 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:39.430117 69630 net.cpp:159] Memory required for data: 216884200
I0122 19:14:39.430128 69630 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:14:39.430135 69630 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:14:39.430140 69630 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:14:39.430145 69630 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:14:39.430151 69630 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:14:39.430155 69630 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:39.430157 69630 net.cpp:159] Memory required for data: 226714600
I0122 19:14:39.430161 69630 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:14:39.430166 69630 net.cpp:94] Creating Layer inception_3a/output
I0122 19:14:39.430169 69630 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:14:39.430174 69630 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:14:39.430179 69630 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:14:39.430200 69630 net.cpp:144] Setting up inception_3a/output
I0122 19:14:39.430207 69630 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:39.430209 69630 net.cpp:159] Memory required for data: 243098600
I0122 19:14:39.430212 69630 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:39.430217 69630 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:39.430219 69630 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:14:39.430236 69630 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:39.430243 69630 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:39.430300 69630 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:14:39.430306 69630 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:39.430310 69630 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:39.430313 69630 net.cpp:159] Memory required for data: 275866600
I0122 19:14:39.430317 69630 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:14:39.430325 69630 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:14:39.430331 69630 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:39.430337 69630 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:14:39.430867 69630 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:14:39.430874 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.430877 69630 net.cpp:159] Memory required for data: 279962600
I0122 19:14:39.430883 69630 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:14:39.430891 69630 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:14:39.430893 69630 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:14:39.430898 69630 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:39.431617 69630 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:14:39.431623 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.431627 69630 net.cpp:159] Memory required for data: 284058600
I0122 19:14:39.431634 69630 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:14:39.431641 69630 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:14:39.431645 69630 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:14:39.431649 69630 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:39.431655 69630 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:14:39.431659 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.431663 69630 net.cpp:159] Memory required for data: 288154600
I0122 19:14:39.431665 69630 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:14:39.431671 69630 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:14:39.431677 69630 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:39.431682 69630 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:14:39.431721 69630 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:14:39.431726 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.431730 69630 net.cpp:159] Memory required for data: 292250600
I0122 19:14:39.431732 69630 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:14:39.431737 69630 net.cpp:94] Creating Layer downsample_4/output
I0122 19:14:39.431741 69630 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:14:39.431746 69630 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:14:39.431751 69630 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:14:39.431767 69630 net.cpp:144] Setting up downsample_4/output
I0122 19:14:39.431772 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.431776 69630 net.cpp:159] Memory required for data: 300442600
I0122 19:14:39.431778 69630 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:39.431782 69630 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:39.431785 69630 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:14:39.431790 69630 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:39.431797 69630 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:39.431833 69630 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:14:39.431839 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.431843 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.431846 69630 net.cpp:159] Memory required for data: 316826600
I0122 19:14:39.431849 69630 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:14:39.431856 69630 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:14:39.431859 69630 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:39.431864 69630 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:14:39.432178 69630 net.cpp:144] Setting up inception_5a/1x1
I0122 19:14:39.432184 69630 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:39.432188 69630 net.cpp:159] Memory required for data: 322561000
I0122 19:14:39.432193 69630 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:14:39.432199 69630 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:14:39.432202 69630 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:14:39.432209 69630 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:14:39.432902 69630 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:14:39.432909 69630 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:39.432911 69630 net.cpp:159] Memory required for data: 328295400
I0122 19:14:39.432919 69630 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:14:39.432927 69630 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:14:39.432931 69630 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:14:39.432935 69630 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:14:39.432943 69630 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:14:39.432950 69630 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:39.432953 69630 net.cpp:159] Memory required for data: 334029800
I0122 19:14:39.432956 69630 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:14:39.432965 69630 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:14:39.432972 69630 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:39.432977 69630 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:14:39.433593 69630 net.cpp:144] Setting up inception_5a/3x3
I0122 19:14:39.433601 69630 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:39.433604 69630 net.cpp:159] Memory required for data: 336487400
I0122 19:14:39.433610 69630 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:14:39.433619 69630 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:14:39.433622 69630 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:14:39.433629 69630 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:14:39.434330 69630 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:14:39.434337 69630 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:39.434341 69630 net.cpp:159] Memory required for data: 338945000
I0122 19:14:39.434350 69630 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:14:39.434355 69630 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:14:39.434357 69630 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:14:39.434362 69630 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:14:39.434368 69630 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:14:39.434371 69630 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:39.434376 69630 net.cpp:159] Memory required for data: 341402600
I0122 19:14:39.434378 69630 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:14:39.434383 69630 net.cpp:94] Creating Layer inception_5a/output
I0122 19:14:39.434386 69630 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:14:39.434389 69630 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:14:39.434406 69630 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:14:39.434427 69630 net.cpp:144] Setting up inception_5a/output
I0122 19:14:39.434432 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.434434 69630 net.cpp:159] Memory required for data: 349594600
I0122 19:14:39.434437 69630 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:39.434442 69630 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:39.434445 69630 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:14:39.434450 69630 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:39.434456 69630 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:39.434528 69630 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:14:39.434535 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.434537 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.434540 69630 net.cpp:159] Memory required for data: 365978600
I0122 19:14:39.434543 69630 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:14:39.434551 69630 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:14:39.434556 69630 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:39.434561 69630 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:14:39.435533 69630 net.cpp:144] Setting up inception_6a/1x1
I0122 19:14:39.435544 69630 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:39.435546 69630 net.cpp:159] Memory required for data: 370893800
I0122 19:14:39.435554 69630 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:14:39.435560 69630 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:14:39.435565 69630 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:14:39.435572 69630 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:14:39.436178 69630 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:14:39.436185 69630 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:39.436188 69630 net.cpp:159] Memory required for data: 375809000
I0122 19:14:39.436197 69630 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:14:39.436204 69630 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:14:39.436208 69630 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:14:39.436211 69630 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:14:39.436218 69630 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:14:39.436223 69630 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:39.436225 69630 net.cpp:159] Memory required for data: 380724200
I0122 19:14:39.436228 69630 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:14:39.436235 69630 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:14:39.436240 69630 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:39.436245 69630 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:14:39.437579 69630 net.cpp:144] Setting up inception_6a/3x3
I0122 19:14:39.437592 69630 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:39.437594 69630 net.cpp:159] Memory required for data: 384001000
I0122 19:14:39.437605 69630 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:14:39.437613 69630 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:14:39.437616 69630 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:14:39.437623 69630 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:14:39.438236 69630 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:14:39.438244 69630 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:39.438247 69630 net.cpp:159] Memory required for data: 387277800
I0122 19:14:39.438267 69630 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:14:39.438272 69630 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:14:39.438275 69630 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:14:39.438282 69630 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:14:39.438288 69630 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:14:39.438292 69630 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:39.438294 69630 net.cpp:159] Memory required for data: 390554600
I0122 19:14:39.438297 69630 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:14:39.438302 69630 net.cpp:94] Creating Layer inception_6a/output
I0122 19:14:39.438305 69630 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:14:39.438310 69630 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:14:39.438314 69630 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:14:39.438335 69630 net.cpp:144] Setting up inception_6a/output
I0122 19:14:39.438340 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.438344 69630 net.cpp:159] Memory required for data: 398746600
I0122 19:14:39.438345 69630 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:39.438351 69630 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:39.438354 69630 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:14:39.438359 69630 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:39.438366 69630 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:39.438395 69630 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:14:39.438400 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.438405 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.438406 69630 net.cpp:159] Memory required for data: 415130600
I0122 19:14:39.438410 69630 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:14:39.438417 69630 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:14:39.438422 69630 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:39.438427 69630 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:14:39.438707 69630 net.cpp:144] Setting up inception_7a/1x1
I0122 19:14:39.438714 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.438715 69630 net.cpp:159] Memory required for data: 419226600
I0122 19:14:39.438721 69630 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:14:39.438727 69630 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:14:39.438730 69630 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:14:39.438735 69630 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:14:39.439338 69630 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:14:39.439347 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.439348 69630 net.cpp:159] Memory required for data: 423322600
I0122 19:14:39.439357 69630 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:14:39.439365 69630 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:14:39.439368 69630 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:14:39.439373 69630 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:14:39.439379 69630 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:14:39.439383 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.439386 69630 net.cpp:159] Memory required for data: 427418600
I0122 19:14:39.439389 69630 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:14:39.439396 69630 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:14:39.439399 69630 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:39.439415 69630 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:14:39.440255 69630 net.cpp:144] Setting up inception_7a/3x3
I0122 19:14:39.440263 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.440265 69630 net.cpp:159] Memory required for data: 431514600
I0122 19:14:39.440271 69630 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:14:39.440279 69630 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:14:39.440284 69630 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:14:39.440289 69630 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:14:39.440908 69630 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:14:39.440914 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.440917 69630 net.cpp:159] Memory required for data: 435610600
I0122 19:14:39.440924 69630 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:14:39.440932 69630 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:14:39.440935 69630 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:14:39.440939 69630 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:14:39.440945 69630 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:14:39.440949 69630 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:39.440953 69630 net.cpp:159] Memory required for data: 439706600
I0122 19:14:39.440955 69630 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:14:39.440959 69630 net.cpp:94] Creating Layer inception_7a/output
I0122 19:14:39.440963 69630 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:14:39.440966 69630 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:14:39.440970 69630 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:14:39.440987 69630 net.cpp:144] Setting up inception_7a/output
I0122 19:14:39.440994 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.440995 69630 net.cpp:159] Memory required for data: 447898600
I0122 19:14:39.440999 69630 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:39.441004 69630 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:39.441006 69630 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:14:39.441010 69630 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:39.441016 69630 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:39.441041 69630 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:14:39.441047 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.441051 69630 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:39.441053 69630 net.cpp:159] Memory required for data: 464282600
I0122 19:14:39.441056 69630 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:14:39.441064 69630 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:14:39.441069 69630 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:39.441074 69630 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:14:39.441325 69630 net.cpp:144] Setting up inception_8a/1x1
I0122 19:14:39.441332 69630 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:39.441334 69630 net.cpp:159] Memory required for data: 466740200
I0122 19:14:39.441339 69630 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:14:39.441345 69630 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:14:39.441349 69630 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:14:39.441354 69630 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:14:39.441983 69630 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:14:39.441990 69630 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:39.441994 69630 net.cpp:159] Memory required for data: 469197800
I0122 19:14:39.442013 69630 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:14:39.442018 69630 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:14:39.442021 69630 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:14:39.442026 69630 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:14:39.442032 69630 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:14:39.442039 69630 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:39.442041 69630 net.cpp:159] Memory required for data: 471655400
I0122 19:14:39.442044 69630 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:14:39.442051 69630 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:14:39.442056 69630 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:39.442062 69630 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:14:39.443644 69630 net.cpp:144] Setting up inception_8a/3x3
I0122 19:14:39.443655 69630 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:39.443657 69630 net.cpp:159] Memory required for data: 476570600
I0122 19:14:39.443662 69630 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:14:39.443670 69630 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:14:39.443691 69630 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:14:39.443696 69630 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:14:39.444322 69630 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:14:39.444329 69630 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:39.444332 69630 net.cpp:159] Memory required for data: 481485800
I0122 19:14:39.444340 69630 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:14:39.444345 69630 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:14:39.444350 69630 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:14:39.444353 69630 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:14:39.444360 69630 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:14:39.444363 69630 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:39.444366 69630 net.cpp:159] Memory required for data: 486401000
I0122 19:14:39.444370 69630 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:14:39.444375 69630 net.cpp:94] Creating Layer inception_8a/output
I0122 19:14:39.444377 69630 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:14:39.444381 69630 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:14:39.444386 69630 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:14:39.444403 69630 net.cpp:144] Setting up inception_8a/output
I0122 19:14:39.444408 69630 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:39.444411 69630 net.cpp:159] Memory required for data: 493773800
I0122 19:14:39.444414 69630 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:39.444418 69630 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:39.444422 69630 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:14:39.444427 69630 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:39.444433 69630 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:39.444458 69630 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:14:39.444463 69630 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:39.444468 69630 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:39.444470 69630 net.cpp:159] Memory required for data: 508519400
I0122 19:14:39.444473 69630 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:14:39.444480 69630 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:14:39.444486 69630 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:39.444502 69630 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:14:39.446036 69630 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:14:39.446048 69630 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:39.446053 69630 net.cpp:159] Memory required for data: 509748200
I0122 19:14:39.446058 69630 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:14:39.446065 69630 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:14:39.446069 69630 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:14:39.446091 69630 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:39.446732 69630 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:14:39.446738 69630 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:39.446741 69630 net.cpp:159] Memory required for data: 510977000
I0122 19:14:39.446750 69630 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:14:39.446758 69630 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:14:39.446760 69630 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:14:39.446764 69630 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:39.446771 69630 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:14:39.446775 69630 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:39.446779 69630 net.cpp:159] Memory required for data: 512205800
I0122 19:14:39.446781 69630 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:14:39.446789 69630 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:14:39.446791 69630 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:39.446796 69630 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:14:39.446825 69630 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:14:39.446830 69630 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 19:14:39.446833 69630 net.cpp:159] Memory required for data: 514049000
I0122 19:14:39.446836 69630 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:14:39.446842 69630 net.cpp:94] Creating Layer downsample_9/output
I0122 19:14:39.446847 69630 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:14:39.446851 69630 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:14:39.446856 69630 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:14:39.446872 69630 net.cpp:144] Setting up downsample_9/output
I0122 19:14:39.446878 69630 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:39.446882 69630 net.cpp:159] Memory required for data: 517121000
I0122 19:14:39.446884 69630 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:39.446888 69630 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:39.446892 69630 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:14:39.446897 69630 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:39.446902 69630 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:39.446928 69630 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:14:39.446934 69630 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:39.446938 69630 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:39.446940 69630 net.cpp:159] Memory required for data: 523265000
I0122 19:14:39.446943 69630 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:14:39.446950 69630 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:14:39.446955 69630 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:39.446960 69630 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:14:39.447412 69630 net.cpp:144] Setting up inception_10a/1x1
I0122 19:14:39.447430 69630 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:39.447433 69630 net.cpp:159] Memory required for data: 525517800
I0122 19:14:39.447438 69630 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:14:39.447445 69630 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:14:39.447450 69630 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:14:39.447456 69630 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:14:39.448092 69630 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:14:39.448098 69630 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:39.448102 69630 net.cpp:159] Memory required for data: 527770600
I0122 19:14:39.448109 69630 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:14:39.448117 69630 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:14:39.448119 69630 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:14:39.448124 69630 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:14:39.448129 69630 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:14:39.448133 69630 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:39.448135 69630 net.cpp:159] Memory required for data: 530023400
I0122 19:14:39.448138 69630 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:14:39.448146 69630 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:14:39.448150 69630 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:39.448156 69630 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:14:39.450623 69630 net.cpp:144] Setting up inception_10a/3x3
I0122 19:14:39.450634 69630 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:39.450636 69630 net.cpp:159] Memory required for data: 532071400
I0122 19:14:39.450641 69630 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:14:39.450649 69630 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:14:39.450652 69630 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:14:39.450657 69630 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:14:39.451287 69630 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:14:39.451294 69630 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:39.451297 69630 net.cpp:159] Memory required for data: 534119400
I0122 19:14:39.451305 69630 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:14:39.451310 69630 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:14:39.451316 69630 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:14:39.451321 69630 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:14:39.451326 69630 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:14:39.451330 69630 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:39.451333 69630 net.cpp:159] Memory required for data: 536167400
I0122 19:14:39.451336 69630 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:14:39.451340 69630 net.cpp:94] Creating Layer inception_10a/output
I0122 19:14:39.451344 69630 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:14:39.451347 69630 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:14:39.451351 69630 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:14:39.451369 69630 net.cpp:144] Setting up inception_10a/output
I0122 19:14:39.451373 69630 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:39.451377 69630 net.cpp:159] Memory required for data: 540468200
I0122 19:14:39.451380 69630 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:39.451385 69630 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:39.451387 69630 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:14:39.451392 69630 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:39.451411 69630 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:39.451436 69630 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:14:39.451442 69630 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:39.451445 69630 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:39.451448 69630 net.cpp:159] Memory required for data: 549069800
I0122 19:14:39.451450 69630 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:14:39.451458 69630 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:14:39.451463 69630 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:39.451468 69630 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:14:39.452000 69630 net.cpp:144] Setting up inception_11a/1x1
I0122 19:14:39.452008 69630 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:39.452010 69630 net.cpp:159] Memory required for data: 551322600
I0122 19:14:39.452015 69630 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:14:39.452023 69630 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:14:39.452025 69630 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:14:39.452030 69630 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:14:39.452656 69630 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:14:39.452662 69630 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:39.452666 69630 net.cpp:159] Memory required for data: 553575400
I0122 19:14:39.452673 69630 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:14:39.452682 69630 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:14:39.452684 69630 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:14:39.452688 69630 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:14:39.452694 69630 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:14:39.452698 69630 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:39.452700 69630 net.cpp:159] Memory required for data: 555828200
I0122 19:14:39.452703 69630 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:14:39.452710 69630 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:14:39.452713 69630 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:39.452718 69630 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:14:39.456328 69630 net.cpp:144] Setting up inception_11a/3x3
I0122 19:14:39.456341 69630 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:39.456342 69630 net.cpp:159] Memory required for data: 557876200
I0122 19:14:39.456347 69630 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:14:39.456369 69630 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:14:39.456373 69630 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:14:39.456378 69630 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:14:39.456995 69630 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:14:39.457002 69630 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:39.457005 69630 net.cpp:159] Memory required for data: 559924200
I0122 19:14:39.457020 69630 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:14:39.457026 69630 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:14:39.457029 69630 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:14:39.457034 69630 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:14:39.457041 69630 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:14:39.457043 69630 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:39.457046 69630 net.cpp:159] Memory required for data: 561972200
I0122 19:14:39.457049 69630 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:14:39.457053 69630 net.cpp:94] Creating Layer inception_11a/output
I0122 19:14:39.457067 69630 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:14:39.457070 69630 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:14:39.457077 69630 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:14:39.457094 69630 net.cpp:144] Setting up inception_11a/output
I0122 19:14:39.457099 69630 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:39.457103 69630 net.cpp:159] Memory required for data: 566273000
I0122 19:14:39.457105 69630 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:14:39.457111 69630 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:14:39.457114 69630 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:14:39.457118 69630 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:14:39.457137 69630 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:14:39.457142 69630 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:14:39.457145 69630 net.cpp:159] Memory required for data: 566340200
I0122 19:14:39.457149 69630 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:14:39.457154 69630 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:14:39.457156 69630 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:14:39.457160 69630 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:14:39.457177 69630 net.cpp:144] Setting up drop_8x8_s1
I0122 19:14:39.457183 69630 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:14:39.457186 69630 net.cpp:159] Memory required for data: 566407400
I0122 19:14:39.457188 69630 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:14:39.457195 69630 net.cpp:94] Creating Layer loss/classifier
I0122 19:14:39.457198 69630 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:14:39.457202 69630 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:14:39.457334 69630 net.cpp:144] Setting up loss/classifier
I0122 19:14:39.457340 69630 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:39.457343 69630 net.cpp:159] Memory required for data: 566409400
I0122 19:14:39.457348 69630 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 19:14:39.457353 69630 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 19:14:39.457356 69630 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 19:14:39.457361 69630 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 19:14:39.457371 69630 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 19:14:39.457376 69630 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 19:14:39.457382 69630 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 19:14:39.457428 69630 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 19:14:39.457433 69630 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:39.457437 69630 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:39.457440 69630 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:39.457443 69630 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:39.457446 69630 net.cpp:159] Memory required for data: 566417400
I0122 19:14:39.457448 69630 layer_factory.hpp:77] Creating layer loss
I0122 19:14:39.457453 69630 net.cpp:94] Creating Layer loss
I0122 19:14:39.457456 69630 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 19:14:39.457460 69630 net.cpp:435] loss <- label_data_1_split_0
I0122 19:14:39.457465 69630 net.cpp:409] loss -> loss
I0122 19:14:39.457473 69630 layer_factory.hpp:77] Creating layer loss
I0122 19:14:39.457543 69630 net.cpp:144] Setting up loss
I0122 19:14:39.457548 69630 net.cpp:151] Top shape: (1)
I0122 19:14:39.457551 69630 net.cpp:154]     with loss weight 1
I0122 19:14:39.457561 69630 net.cpp:159] Memory required for data: 566417404
I0122 19:14:39.457564 69630 layer_factory.hpp:77] Creating layer accuracy
I0122 19:14:39.457571 69630 net.cpp:94] Creating Layer accuracy
I0122 19:14:39.457572 69630 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 19:14:39.457583 69630 net.cpp:435] accuracy <- label_data_1_split_1
I0122 19:14:39.457589 69630 net.cpp:409] accuracy -> accuracy
I0122 19:14:39.457599 69630 net.cpp:144] Setting up accuracy
I0122 19:14:39.457604 69630 net.cpp:151] Top shape: (1)
I0122 19:14:39.457607 69630 net.cpp:159] Memory required for data: 566417408
I0122 19:14:39.457610 69630 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 19:14:39.457614 69630 net.cpp:94] Creating Layer accuracy-top1
I0122 19:14:39.457617 69630 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 19:14:39.457620 69630 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 19:14:39.457625 69630 net.cpp:409] accuracy-top1 -> top-1
I0122 19:14:39.457631 69630 net.cpp:144] Setting up accuracy-top1
I0122 19:14:39.457634 69630 net.cpp:151] Top shape: (1)
I0122 19:14:39.457636 69630 net.cpp:159] Memory required for data: 566417412
I0122 19:14:39.457640 69630 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 19:14:39.457644 69630 net.cpp:94] Creating Layer accuracy-top5
I0122 19:14:39.457648 69630 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 19:14:39.457650 69630 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 19:14:39.457655 69630 net.cpp:409] accuracy-top5 -> top-5
I0122 19:14:39.457661 69630 net.cpp:144] Setting up accuracy-top5
I0122 19:14:39.457667 69630 net.cpp:151] Top shape: (1)
I0122 19:14:39.457669 69630 net.cpp:159] Memory required for data: 566417416
I0122 19:14:39.457672 69630 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 19:14:39.457676 69630 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 19:14:39.457679 69630 net.cpp:222] accuracy does not need backward computation.
I0122 19:14:39.457682 69630 net.cpp:220] loss needs backward computation.
I0122 19:14:39.457686 69630 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 19:14:39.457690 69630 net.cpp:220] loss/classifier needs backward computation.
I0122 19:14:39.457693 69630 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:14:39.457695 69630 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:14:39.457700 69630 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:14:39.457702 69630 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:14:39.457705 69630 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:14:39.457707 69630 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:14:39.457711 69630 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:14:39.457715 69630 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:14:39.457717 69630 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:14:39.457720 69630 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:14:39.457725 69630 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:14:39.457727 69630 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:14:39.457731 69630 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:14:39.457733 69630 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:14:39.457737 69630 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:14:39.457739 69630 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:14:39.457742 69630 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:14:39.457746 69630 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:14:39.457749 69630 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:14:39.457752 69630 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:14:39.457756 69630 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:14:39.457758 69630 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:14:39.457767 69630 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:14:39.457772 69630 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:14:39.457774 69630 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:14:39.457778 69630 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:14:39.457782 69630 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:14:39.457785 69630 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:14:39.457788 69630 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:14:39.457792 69630 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:14:39.457794 69630 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:14:39.457798 69630 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:14:39.457800 69630 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:14:39.457804 69630 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:14:39.457808 69630 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:14:39.457810 69630 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:14:39.457813 69630 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:14:39.457816 69630 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:14:39.457819 69630 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:14:39.457823 69630 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:14:39.457826 69630 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:14:39.457829 69630 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:14:39.457834 69630 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:14:39.457835 69630 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:14:39.457839 69630 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:14:39.457841 69630 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:14:39.457844 69630 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:14:39.457847 69630 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:14:39.457850 69630 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:14:39.457854 69630 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:14:39.457857 69630 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:14:39.457860 69630 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:14:39.457864 69630 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:14:39.457866 69630 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:14:39.457870 69630 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:14:39.457873 69630 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:14:39.457876 69630 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:14:39.457880 69630 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:14:39.457883 69630 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:14:39.457886 69630 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:14:39.457888 69630 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:14:39.457892 69630 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:14:39.457896 69630 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:14:39.457900 69630 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:14:39.457901 69630 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:14:39.457916 69630 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:14:39.457926 69630 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:14:39.457928 69630 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:14:39.457931 69630 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:14:39.457934 69630 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:14:39.457938 69630 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:14:39.457942 69630 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:14:39.457944 69630 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:14:39.457947 69630 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:14:39.457952 69630 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:14:39.457954 69630 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:14:39.457958 69630 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:14:39.457962 69630 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:14:39.457965 69630 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:14:39.457968 69630 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:14:39.457970 69630 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:14:39.457974 69630 net.cpp:222] label_data_1_split does not need backward computation.
I0122 19:14:39.457979 69630 net.cpp:222] data does not need backward computation.
I0122 19:14:39.457981 69630 net.cpp:264] This network produces output accuracy
I0122 19:14:39.457984 69630 net.cpp:264] This network produces output loss
I0122 19:14:39.457988 69630 net.cpp:264] This network produces output top-1
I0122 19:14:39.457991 69630 net.cpp:264] This network produces output top-5
I0122 19:14:39.458055 69630 net.cpp:284] Network initialization done.
I0122 19:14:39.460682 69630 caffe_interface.cpp:363] Running for 180 iterations.
I0122 19:14:39.484228 69630 caffe_interface.cpp:125] Batch 0, accuracy = 0.88
I0122 19:14:39.484246 69630 caffe_interface.cpp:125] Batch 0, loss = 0.384279
I0122 19:14:39.484251 69630 caffe_interface.cpp:125] Batch 0, top-1 = 0.88
I0122 19:14:39.484254 69630 caffe_interface.cpp:125] Batch 0, top-5 = 1
I0122 19:14:39.494204 69630 caffe_interface.cpp:125] Batch 1, accuracy = 0.88
I0122 19:14:39.494217 69630 caffe_interface.cpp:125] Batch 1, loss = 0.414368
I0122 19:14:39.494220 69630 caffe_interface.cpp:125] Batch 1, top-1 = 0.88
I0122 19:14:39.494223 69630 caffe_interface.cpp:125] Batch 1, top-5 = 1
I0122 19:14:39.502749 69630 caffe_interface.cpp:125] Batch 2, accuracy = 0.96
I0122 19:14:39.502760 69630 caffe_interface.cpp:125] Batch 2, loss = 0.122113
I0122 19:14:39.502764 69630 caffe_interface.cpp:125] Batch 2, top-1 = 0.96
I0122 19:14:39.502768 69630 caffe_interface.cpp:125] Batch 2, top-5 = 1
I0122 19:14:39.511258 69630 caffe_interface.cpp:125] Batch 3, accuracy = 0.9
I0122 19:14:39.511270 69630 caffe_interface.cpp:125] Batch 3, loss = 1.02532
I0122 19:14:39.511273 69630 caffe_interface.cpp:125] Batch 3, top-1 = 0.9
I0122 19:14:39.511276 69630 caffe_interface.cpp:125] Batch 3, top-5 = 0.98
I0122 19:14:39.520885 69630 caffe_interface.cpp:125] Batch 4, accuracy = 0.94
I0122 19:14:39.520893 69630 caffe_interface.cpp:125] Batch 4, loss = 0.218609
I0122 19:14:39.520896 69630 caffe_interface.cpp:125] Batch 4, top-1 = 0.94
I0122 19:14:39.520900 69630 caffe_interface.cpp:125] Batch 4, top-5 = 0.98
I0122 19:14:39.529387 69630 caffe_interface.cpp:125] Batch 5, accuracy = 0.9
I0122 19:14:39.529398 69630 caffe_interface.cpp:125] Batch 5, loss = 0.18523
I0122 19:14:39.529402 69630 caffe_interface.cpp:125] Batch 5, top-1 = 0.9
I0122 19:14:39.529404 69630 caffe_interface.cpp:125] Batch 5, top-5 = 1
I0122 19:14:39.537889 69630 caffe_interface.cpp:125] Batch 6, accuracy = 0.94
I0122 19:14:39.537899 69630 caffe_interface.cpp:125] Batch 6, loss = 0.211324
I0122 19:14:39.537902 69630 caffe_interface.cpp:125] Batch 6, top-1 = 0.94
I0122 19:14:39.537921 69630 caffe_interface.cpp:125] Batch 6, top-5 = 1
I0122 19:14:39.546409 69630 caffe_interface.cpp:125] Batch 7, accuracy = 0.98
I0122 19:14:39.546420 69630 caffe_interface.cpp:125] Batch 7, loss = 0.0376778
I0122 19:14:39.546424 69630 caffe_interface.cpp:125] Batch 7, top-1 = 0.98
I0122 19:14:39.546427 69630 caffe_interface.cpp:125] Batch 7, top-5 = 1
I0122 19:14:39.556030 69630 caffe_interface.cpp:125] Batch 8, accuracy = 0.84
I0122 19:14:39.556041 69630 caffe_interface.cpp:125] Batch 8, loss = 0.751615
I0122 19:14:39.556043 69630 caffe_interface.cpp:125] Batch 8, top-1 = 0.84
I0122 19:14:39.556046 69630 caffe_interface.cpp:125] Batch 8, top-5 = 1
I0122 19:14:39.564515 69630 caffe_interface.cpp:125] Batch 9, accuracy = 0.88
I0122 19:14:39.564525 69630 caffe_interface.cpp:125] Batch 9, loss = 0.354222
I0122 19:14:39.564529 69630 caffe_interface.cpp:125] Batch 9, top-1 = 0.88
I0122 19:14:39.564532 69630 caffe_interface.cpp:125] Batch 9, top-5 = 0.98
I0122 19:14:39.573007 69630 caffe_interface.cpp:125] Batch 10, accuracy = 0.9
I0122 19:14:39.573017 69630 caffe_interface.cpp:125] Batch 10, loss = 0.6381
I0122 19:14:39.573020 69630 caffe_interface.cpp:125] Batch 10, top-1 = 0.9
I0122 19:14:39.573024 69630 caffe_interface.cpp:125] Batch 10, top-5 = 0.98
I0122 19:14:39.581486 69630 caffe_interface.cpp:125] Batch 11, accuracy = 0.9
I0122 19:14:39.581496 69630 caffe_interface.cpp:125] Batch 11, loss = 0.5548
I0122 19:14:39.581501 69630 caffe_interface.cpp:125] Batch 11, top-1 = 0.9
I0122 19:14:39.581503 69630 caffe_interface.cpp:125] Batch 11, top-5 = 1
I0122 19:14:39.591050 69630 caffe_interface.cpp:125] Batch 12, accuracy = 0.9
I0122 19:14:39.591061 69630 caffe_interface.cpp:125] Batch 12, loss = 0.349526
I0122 19:14:39.591064 69630 caffe_interface.cpp:125] Batch 12, top-1 = 0.9
I0122 19:14:39.591068 69630 caffe_interface.cpp:125] Batch 12, top-5 = 1
I0122 19:14:39.599541 69630 caffe_interface.cpp:125] Batch 13, accuracy = 0.84
I0122 19:14:39.599552 69630 caffe_interface.cpp:125] Batch 13, loss = 0.580994
I0122 19:14:39.599556 69630 caffe_interface.cpp:125] Batch 13, top-1 = 0.84
I0122 19:14:39.599560 69630 caffe_interface.cpp:125] Batch 13, top-5 = 0.98
I0122 19:14:39.608065 69630 caffe_interface.cpp:125] Batch 14, accuracy = 0.96
I0122 19:14:39.608075 69630 caffe_interface.cpp:125] Batch 14, loss = 0.297118
I0122 19:14:39.608079 69630 caffe_interface.cpp:125] Batch 14, top-1 = 0.96
I0122 19:14:39.608083 69630 caffe_interface.cpp:125] Batch 14, top-5 = 1
I0122 19:14:39.616556 69630 caffe_interface.cpp:125] Batch 15, accuracy = 0.94
I0122 19:14:39.616566 69630 caffe_interface.cpp:125] Batch 15, loss = 0.213294
I0122 19:14:39.616569 69630 caffe_interface.cpp:125] Batch 15, top-1 = 0.94
I0122 19:14:39.616572 69630 caffe_interface.cpp:125] Batch 15, top-5 = 1
I0122 19:14:39.625950 69630 caffe_interface.cpp:125] Batch 16, accuracy = 0.92
I0122 19:14:39.625960 69630 caffe_interface.cpp:125] Batch 16, loss = 0.203387
I0122 19:14:39.625963 69630 caffe_interface.cpp:125] Batch 16, top-1 = 0.92
I0122 19:14:39.625965 69630 caffe_interface.cpp:125] Batch 16, top-5 = 1
I0122 19:14:39.634431 69630 caffe_interface.cpp:125] Batch 17, accuracy = 0.92
I0122 19:14:39.634441 69630 caffe_interface.cpp:125] Batch 17, loss = 0.159984
I0122 19:14:39.634445 69630 caffe_interface.cpp:125] Batch 17, top-1 = 0.92
I0122 19:14:39.634447 69630 caffe_interface.cpp:125] Batch 17, top-5 = 1
I0122 19:14:39.642928 69630 caffe_interface.cpp:125] Batch 18, accuracy = 0.84
I0122 19:14:39.642938 69630 caffe_interface.cpp:125] Batch 18, loss = 0.462952
I0122 19:14:39.642941 69630 caffe_interface.cpp:125] Batch 18, top-1 = 0.84
I0122 19:14:39.642944 69630 caffe_interface.cpp:125] Batch 18, top-5 = 1
I0122 19:14:39.651418 69630 caffe_interface.cpp:125] Batch 19, accuracy = 0.94
I0122 19:14:39.651428 69630 caffe_interface.cpp:125] Batch 19, loss = 0.22684
I0122 19:14:39.651432 69630 caffe_interface.cpp:125] Batch 19, top-1 = 0.94
I0122 19:14:39.651434 69630 caffe_interface.cpp:125] Batch 19, top-5 = 1
I0122 19:14:39.661006 69630 caffe_interface.cpp:125] Batch 20, accuracy = 0.9
I0122 19:14:39.661027 69630 caffe_interface.cpp:125] Batch 20, loss = 0.480997
I0122 19:14:39.661031 69630 caffe_interface.cpp:125] Batch 20, top-1 = 0.9
I0122 19:14:39.661033 69630 caffe_interface.cpp:125] Batch 20, top-5 = 1
I0122 19:14:39.669517 69630 caffe_interface.cpp:125] Batch 21, accuracy = 0.86
I0122 19:14:39.669528 69630 caffe_interface.cpp:125] Batch 21, loss = 0.535819
I0122 19:14:39.669530 69630 caffe_interface.cpp:125] Batch 21, top-1 = 0.86
I0122 19:14:39.669533 69630 caffe_interface.cpp:125] Batch 21, top-5 = 1
I0122 19:14:39.678033 69630 caffe_interface.cpp:125] Batch 22, accuracy = 0.96
I0122 19:14:39.678043 69630 caffe_interface.cpp:125] Batch 22, loss = 0.263209
I0122 19:14:39.678047 69630 caffe_interface.cpp:125] Batch 22, top-1 = 0.96
I0122 19:14:39.678050 69630 caffe_interface.cpp:125] Batch 22, top-5 = 0.98
I0122 19:14:39.686560 69630 caffe_interface.cpp:125] Batch 23, accuracy = 0.96
I0122 19:14:39.686570 69630 caffe_interface.cpp:125] Batch 23, loss = 0.16709
I0122 19:14:39.686573 69630 caffe_interface.cpp:125] Batch 23, top-1 = 0.96
I0122 19:14:39.686576 69630 caffe_interface.cpp:125] Batch 23, top-5 = 1
I0122 19:14:39.696130 69630 caffe_interface.cpp:125] Batch 24, accuracy = 0.94
I0122 19:14:39.696141 69630 caffe_interface.cpp:125] Batch 24, loss = 0.275754
I0122 19:14:39.696144 69630 caffe_interface.cpp:125] Batch 24, top-1 = 0.94
I0122 19:14:39.696147 69630 caffe_interface.cpp:125] Batch 24, top-5 = 1
I0122 19:14:39.707108 69630 caffe_interface.cpp:125] Batch 25, accuracy = 0.92
I0122 19:14:39.707123 69630 caffe_interface.cpp:125] Batch 25, loss = 0.246709
I0122 19:14:39.707126 69630 caffe_interface.cpp:125] Batch 25, top-1 = 0.92
I0122 19:14:39.707129 69630 caffe_interface.cpp:125] Batch 25, top-5 = 0.98
I0122 19:14:39.715137 69630 caffe_interface.cpp:125] Batch 26, accuracy = 0.84
I0122 19:14:39.715148 69630 caffe_interface.cpp:125] Batch 26, loss = 0.647645
I0122 19:14:39.715152 69630 caffe_interface.cpp:125] Batch 26, top-1 = 0.84
I0122 19:14:39.715155 69630 caffe_interface.cpp:125] Batch 26, top-5 = 1
I0122 19:14:39.724226 69630 caffe_interface.cpp:125] Batch 27, accuracy = 0.9
I0122 19:14:39.724236 69630 caffe_interface.cpp:125] Batch 27, loss = 0.212231
I0122 19:14:39.724238 69630 caffe_interface.cpp:125] Batch 27, top-1 = 0.9
I0122 19:14:39.724241 69630 caffe_interface.cpp:125] Batch 27, top-5 = 1
I0122 19:14:39.732219 69630 caffe_interface.cpp:125] Batch 28, accuracy = 0.9
I0122 19:14:39.732230 69630 caffe_interface.cpp:125] Batch 28, loss = 0.325806
I0122 19:14:39.732234 69630 caffe_interface.cpp:125] Batch 28, top-1 = 0.9
I0122 19:14:39.732237 69630 caffe_interface.cpp:125] Batch 28, top-5 = 1
I0122 19:14:39.740206 69630 caffe_interface.cpp:125] Batch 29, accuracy = 0.98
I0122 19:14:39.740216 69630 caffe_interface.cpp:125] Batch 29, loss = 0.184955
I0122 19:14:39.740219 69630 caffe_interface.cpp:125] Batch 29, top-1 = 0.98
I0122 19:14:39.740222 69630 caffe_interface.cpp:125] Batch 29, top-5 = 1
I0122 19:14:39.748191 69630 caffe_interface.cpp:125] Batch 30, accuracy = 0.96
I0122 19:14:39.748203 69630 caffe_interface.cpp:125] Batch 30, loss = 0.211889
I0122 19:14:39.748206 69630 caffe_interface.cpp:125] Batch 30, top-1 = 0.96
I0122 19:14:39.748208 69630 caffe_interface.cpp:125] Batch 30, top-5 = 1
I0122 19:14:39.757323 69630 caffe_interface.cpp:125] Batch 31, accuracy = 0.96
I0122 19:14:39.757333 69630 caffe_interface.cpp:125] Batch 31, loss = 0.177692
I0122 19:14:39.757336 69630 caffe_interface.cpp:125] Batch 31, top-1 = 0.96
I0122 19:14:39.757339 69630 caffe_interface.cpp:125] Batch 31, top-5 = 1
I0122 19:14:39.765311 69630 caffe_interface.cpp:125] Batch 32, accuracy = 0.88
I0122 19:14:39.765321 69630 caffe_interface.cpp:125] Batch 32, loss = 0.347588
I0122 19:14:39.765324 69630 caffe_interface.cpp:125] Batch 32, top-1 = 0.88
I0122 19:14:39.765327 69630 caffe_interface.cpp:125] Batch 32, top-5 = 1
I0122 19:14:39.773365 69630 caffe_interface.cpp:125] Batch 33, accuracy = 0.8
I0122 19:14:39.773376 69630 caffe_interface.cpp:125] Batch 33, loss = 0.978685
I0122 19:14:39.773391 69630 caffe_interface.cpp:125] Batch 33, top-1 = 0.8
I0122 19:14:39.773396 69630 caffe_interface.cpp:125] Batch 33, top-5 = 0.98
I0122 19:14:39.781390 69630 caffe_interface.cpp:125] Batch 34, accuracy = 0.9
I0122 19:14:39.781400 69630 caffe_interface.cpp:125] Batch 34, loss = 0.225577
I0122 19:14:39.781404 69630 caffe_interface.cpp:125] Batch 34, top-1 = 0.9
I0122 19:14:39.781407 69630 caffe_interface.cpp:125] Batch 34, top-5 = 1
I0122 19:14:39.790516 69630 caffe_interface.cpp:125] Batch 35, accuracy = 0.9
I0122 19:14:39.790527 69630 caffe_interface.cpp:125] Batch 35, loss = 0.356978
I0122 19:14:39.790530 69630 caffe_interface.cpp:125] Batch 35, top-1 = 0.9
I0122 19:14:39.790534 69630 caffe_interface.cpp:125] Batch 35, top-5 = 1
I0122 19:14:39.798535 69630 caffe_interface.cpp:125] Batch 36, accuracy = 0.98
I0122 19:14:39.798544 69630 caffe_interface.cpp:125] Batch 36, loss = 0.181175
I0122 19:14:39.798547 69630 caffe_interface.cpp:125] Batch 36, top-1 = 0.98
I0122 19:14:39.798550 69630 caffe_interface.cpp:125] Batch 36, top-5 = 1
I0122 19:14:39.806541 69630 caffe_interface.cpp:125] Batch 37, accuracy = 0.92
I0122 19:14:39.806550 69630 caffe_interface.cpp:125] Batch 37, loss = 0.240443
I0122 19:14:39.806553 69630 caffe_interface.cpp:125] Batch 37, top-1 = 0.92
I0122 19:14:39.806556 69630 caffe_interface.cpp:125] Batch 37, top-5 = 1
I0122 19:14:39.814548 69630 caffe_interface.cpp:125] Batch 38, accuracy = 0.94
I0122 19:14:39.814556 69630 caffe_interface.cpp:125] Batch 38, loss = 0.214981
I0122 19:14:39.814560 69630 caffe_interface.cpp:125] Batch 38, top-1 = 0.94
I0122 19:14:39.814563 69630 caffe_interface.cpp:125] Batch 38, top-5 = 1
I0122 19:14:39.823676 69630 caffe_interface.cpp:125] Batch 39, accuracy = 0.86
I0122 19:14:39.823686 69630 caffe_interface.cpp:125] Batch 39, loss = 0.504568
I0122 19:14:39.823690 69630 caffe_interface.cpp:125] Batch 39, top-1 = 0.86
I0122 19:14:39.823693 69630 caffe_interface.cpp:125] Batch 39, top-5 = 1
I0122 19:14:39.831658 69630 caffe_interface.cpp:125] Batch 40, accuracy = 0.98
I0122 19:14:39.831668 69630 caffe_interface.cpp:125] Batch 40, loss = 0.120813
I0122 19:14:39.831671 69630 caffe_interface.cpp:125] Batch 40, top-1 = 0.98
I0122 19:14:39.831674 69630 caffe_interface.cpp:125] Batch 40, top-5 = 1
I0122 19:14:39.839664 69630 caffe_interface.cpp:125] Batch 41, accuracy = 0.8
I0122 19:14:39.839674 69630 caffe_interface.cpp:125] Batch 41, loss = 0.568479
I0122 19:14:39.839678 69630 caffe_interface.cpp:125] Batch 41, top-1 = 0.8
I0122 19:14:39.839680 69630 caffe_interface.cpp:125] Batch 41, top-5 = 1
I0122 19:14:39.847684 69630 caffe_interface.cpp:125] Batch 42, accuracy = 0.84
I0122 19:14:39.847694 69630 caffe_interface.cpp:125] Batch 42, loss = 0.46857
I0122 19:14:39.847697 69630 caffe_interface.cpp:125] Batch 42, top-1 = 0.84
I0122 19:14:39.847700 69630 caffe_interface.cpp:125] Batch 42, top-5 = 0.98
I0122 19:14:39.856791 69630 caffe_interface.cpp:125] Batch 43, accuracy = 0.92
I0122 19:14:39.856801 69630 caffe_interface.cpp:125] Batch 43, loss = 0.320948
I0122 19:14:39.856803 69630 caffe_interface.cpp:125] Batch 43, top-1 = 0.92
I0122 19:14:39.856806 69630 caffe_interface.cpp:125] Batch 43, top-5 = 1
I0122 19:14:39.864784 69630 caffe_interface.cpp:125] Batch 44, accuracy = 0.9
I0122 19:14:39.864794 69630 caffe_interface.cpp:125] Batch 44, loss = 0.36456
I0122 19:14:39.864797 69630 caffe_interface.cpp:125] Batch 44, top-1 = 0.9
I0122 19:14:39.864800 69630 caffe_interface.cpp:125] Batch 44, top-5 = 1
I0122 19:14:39.872788 69630 caffe_interface.cpp:125] Batch 45, accuracy = 0.9
I0122 19:14:39.872798 69630 caffe_interface.cpp:125] Batch 45, loss = 0.447157
I0122 19:14:39.872802 69630 caffe_interface.cpp:125] Batch 45, top-1 = 0.9
I0122 19:14:39.872804 69630 caffe_interface.cpp:125] Batch 45, top-5 = 1
I0122 19:14:39.880765 69630 caffe_interface.cpp:125] Batch 46, accuracy = 0.92
I0122 19:14:39.880775 69630 caffe_interface.cpp:125] Batch 46, loss = 0.171796
I0122 19:14:39.880779 69630 caffe_interface.cpp:125] Batch 46, top-1 = 0.92
I0122 19:14:39.880782 69630 caffe_interface.cpp:125] Batch 46, top-5 = 1
I0122 19:14:39.889894 69630 caffe_interface.cpp:125] Batch 47, accuracy = 0.94
I0122 19:14:39.889909 69630 caffe_interface.cpp:125] Batch 47, loss = 0.244548
I0122 19:14:39.889911 69630 caffe_interface.cpp:125] Batch 47, top-1 = 0.94
I0122 19:14:39.889914 69630 caffe_interface.cpp:125] Batch 47, top-5 = 1
I0122 19:14:39.897917 69630 caffe_interface.cpp:125] Batch 48, accuracy = 0.94
I0122 19:14:39.897927 69630 caffe_interface.cpp:125] Batch 48, loss = 0.213031
I0122 19:14:39.897929 69630 caffe_interface.cpp:125] Batch 48, top-1 = 0.94
I0122 19:14:39.897933 69630 caffe_interface.cpp:125] Batch 48, top-5 = 1
I0122 19:14:39.905899 69630 caffe_interface.cpp:125] Batch 49, accuracy = 0.88
I0122 19:14:39.905911 69630 caffe_interface.cpp:125] Batch 49, loss = 0.402353
I0122 19:14:39.905915 69630 caffe_interface.cpp:125] Batch 49, top-1 = 0.88
I0122 19:14:39.905917 69630 caffe_interface.cpp:125] Batch 49, top-5 = 1
I0122 19:14:39.913923 69630 caffe_interface.cpp:125] Batch 50, accuracy = 0.9
I0122 19:14:39.913934 69630 caffe_interface.cpp:125] Batch 50, loss = 0.365969
I0122 19:14:39.913938 69630 caffe_interface.cpp:125] Batch 50, top-1 = 0.9
I0122 19:14:39.913940 69630 caffe_interface.cpp:125] Batch 50, top-5 = 1
I0122 19:14:39.922988 69630 caffe_interface.cpp:125] Batch 51, accuracy = 0.92
I0122 19:14:39.922996 69630 caffe_interface.cpp:125] Batch 51, loss = 0.296779
I0122 19:14:39.922999 69630 caffe_interface.cpp:125] Batch 51, top-1 = 0.92
I0122 19:14:39.923002 69630 caffe_interface.cpp:125] Batch 51, top-5 = 1
I0122 19:14:39.930971 69630 caffe_interface.cpp:125] Batch 52, accuracy = 0.88
I0122 19:14:39.930981 69630 caffe_interface.cpp:125] Batch 52, loss = 0.505942
I0122 19:14:39.930984 69630 caffe_interface.cpp:125] Batch 52, top-1 = 0.88
I0122 19:14:39.930987 69630 caffe_interface.cpp:125] Batch 52, top-5 = 1
I0122 19:14:39.938966 69630 caffe_interface.cpp:125] Batch 53, accuracy = 0.82
I0122 19:14:39.938977 69630 caffe_interface.cpp:125] Batch 53, loss = 0.51261
I0122 19:14:39.938980 69630 caffe_interface.cpp:125] Batch 53, top-1 = 0.82
I0122 19:14:39.938983 69630 caffe_interface.cpp:125] Batch 53, top-5 = 1
I0122 19:14:39.946961 69630 caffe_interface.cpp:125] Batch 54, accuracy = 0.88
I0122 19:14:39.946971 69630 caffe_interface.cpp:125] Batch 54, loss = 0.430423
I0122 19:14:39.946974 69630 caffe_interface.cpp:125] Batch 54, top-1 = 0.88
I0122 19:14:39.946977 69630 caffe_interface.cpp:125] Batch 54, top-5 = 1
I0122 19:14:39.956025 69630 caffe_interface.cpp:125] Batch 55, accuracy = 0.94
I0122 19:14:39.956035 69630 caffe_interface.cpp:125] Batch 55, loss = 0.204965
I0122 19:14:39.956039 69630 caffe_interface.cpp:125] Batch 55, top-1 = 0.94
I0122 19:14:39.956043 69630 caffe_interface.cpp:125] Batch 55, top-5 = 1
I0122 19:14:39.963982 69630 caffe_interface.cpp:125] Batch 56, accuracy = 0.86
I0122 19:14:39.963992 69630 caffe_interface.cpp:125] Batch 56, loss = 0.466284
I0122 19:14:39.963996 69630 caffe_interface.cpp:125] Batch 56, top-1 = 0.86
I0122 19:14:39.963999 69630 caffe_interface.cpp:125] Batch 56, top-5 = 0.98
I0122 19:14:39.971940 69630 caffe_interface.cpp:125] Batch 57, accuracy = 0.96
I0122 19:14:39.971951 69630 caffe_interface.cpp:125] Batch 57, loss = 0.210549
I0122 19:14:39.971956 69630 caffe_interface.cpp:125] Batch 57, top-1 = 0.96
I0122 19:14:39.971958 69630 caffe_interface.cpp:125] Batch 57, top-5 = 1
I0122 19:14:39.979893 69630 caffe_interface.cpp:125] Batch 58, accuracy = 0.9
I0122 19:14:39.979903 69630 caffe_interface.cpp:125] Batch 58, loss = 0.322598
I0122 19:14:39.979907 69630 caffe_interface.cpp:125] Batch 58, top-1 = 0.9
I0122 19:14:39.979909 69630 caffe_interface.cpp:125] Batch 58, top-5 = 0.98
I0122 19:14:39.988939 69630 caffe_interface.cpp:125] Batch 59, accuracy = 0.88
I0122 19:14:39.988948 69630 caffe_interface.cpp:125] Batch 59, loss = 0.544179
I0122 19:14:39.988951 69630 caffe_interface.cpp:125] Batch 59, top-1 = 0.88
I0122 19:14:39.988955 69630 caffe_interface.cpp:125] Batch 59, top-5 = 1
I0122 19:14:39.996907 69630 caffe_interface.cpp:125] Batch 60, accuracy = 0.92
I0122 19:14:39.996927 69630 caffe_interface.cpp:125] Batch 60, loss = 0.127329
I0122 19:14:39.996932 69630 caffe_interface.cpp:125] Batch 60, top-1 = 0.92
I0122 19:14:39.996934 69630 caffe_interface.cpp:125] Batch 60, top-5 = 1
I0122 19:14:40.004902 69630 caffe_interface.cpp:125] Batch 61, accuracy = 0.82
I0122 19:14:40.004912 69630 caffe_interface.cpp:125] Batch 61, loss = 0.869944
I0122 19:14:40.004916 69630 caffe_interface.cpp:125] Batch 61, top-1 = 0.82
I0122 19:14:40.004918 69630 caffe_interface.cpp:125] Batch 61, top-5 = 0.96
I0122 19:14:40.012874 69630 caffe_interface.cpp:125] Batch 62, accuracy = 0.8
I0122 19:14:40.012884 69630 caffe_interface.cpp:125] Batch 62, loss = 0.733924
I0122 19:14:40.012888 69630 caffe_interface.cpp:125] Batch 62, top-1 = 0.8
I0122 19:14:40.012892 69630 caffe_interface.cpp:125] Batch 62, top-5 = 1
I0122 19:14:40.021867 69630 caffe_interface.cpp:125] Batch 63, accuracy = 0.9
I0122 19:14:40.021875 69630 caffe_interface.cpp:125] Batch 63, loss = 0.308093
I0122 19:14:40.021878 69630 caffe_interface.cpp:125] Batch 63, top-1 = 0.9
I0122 19:14:40.021880 69630 caffe_interface.cpp:125] Batch 63, top-5 = 1
I0122 19:14:40.029819 69630 caffe_interface.cpp:125] Batch 64, accuracy = 0.92
I0122 19:14:40.029829 69630 caffe_interface.cpp:125] Batch 64, loss = 0.209025
I0122 19:14:40.029832 69630 caffe_interface.cpp:125] Batch 64, top-1 = 0.92
I0122 19:14:40.029835 69630 caffe_interface.cpp:125] Batch 64, top-5 = 1
I0122 19:14:40.037806 69630 caffe_interface.cpp:125] Batch 65, accuracy = 0.94
I0122 19:14:40.037817 69630 caffe_interface.cpp:125] Batch 65, loss = 0.195779
I0122 19:14:40.037820 69630 caffe_interface.cpp:125] Batch 65, top-1 = 0.94
I0122 19:14:40.037822 69630 caffe_interface.cpp:125] Batch 65, top-5 = 1
I0122 19:14:40.045789 69630 caffe_interface.cpp:125] Batch 66, accuracy = 0.88
I0122 19:14:40.045799 69630 caffe_interface.cpp:125] Batch 66, loss = 0.61714
I0122 19:14:40.045804 69630 caffe_interface.cpp:125] Batch 66, top-1 = 0.88
I0122 19:14:40.045806 69630 caffe_interface.cpp:125] Batch 66, top-5 = 0.98
I0122 19:14:40.054687 69630 caffe_interface.cpp:125] Batch 67, accuracy = 0.86
I0122 19:14:40.054698 69630 caffe_interface.cpp:125] Batch 67, loss = 0.588639
I0122 19:14:40.054702 69630 caffe_interface.cpp:125] Batch 67, top-1 = 0.86
I0122 19:14:40.054704 69630 caffe_interface.cpp:125] Batch 67, top-5 = 1
I0122 19:14:40.062669 69630 caffe_interface.cpp:125] Batch 68, accuracy = 0.94
I0122 19:14:40.062680 69630 caffe_interface.cpp:125] Batch 68, loss = 0.10784
I0122 19:14:40.062682 69630 caffe_interface.cpp:125] Batch 68, top-1 = 0.94
I0122 19:14:40.062685 69630 caffe_interface.cpp:125] Batch 68, top-5 = 1
I0122 19:14:40.070652 69630 caffe_interface.cpp:125] Batch 69, accuracy = 0.96
I0122 19:14:40.070662 69630 caffe_interface.cpp:125] Batch 69, loss = 0.0746927
I0122 19:14:40.070667 69630 caffe_interface.cpp:125] Batch 69, top-1 = 0.96
I0122 19:14:40.070668 69630 caffe_interface.cpp:125] Batch 69, top-5 = 1
I0122 19:14:40.078621 69630 caffe_interface.cpp:125] Batch 70, accuracy = 0.88
I0122 19:14:40.078631 69630 caffe_interface.cpp:125] Batch 70, loss = 0.420376
I0122 19:14:40.078635 69630 caffe_interface.cpp:125] Batch 70, top-1 = 0.88
I0122 19:14:40.078639 69630 caffe_interface.cpp:125] Batch 70, top-5 = 1
I0122 19:14:40.087546 69630 caffe_interface.cpp:125] Batch 71, accuracy = 0.86
I0122 19:14:40.087555 69630 caffe_interface.cpp:125] Batch 71, loss = 0.506554
I0122 19:14:40.087558 69630 caffe_interface.cpp:125] Batch 71, top-1 = 0.86
I0122 19:14:40.087561 69630 caffe_interface.cpp:125] Batch 71, top-5 = 0.98
I0122 19:14:40.095535 69630 caffe_interface.cpp:125] Batch 72, accuracy = 0.9
I0122 19:14:40.095544 69630 caffe_interface.cpp:125] Batch 72, loss = 0.358107
I0122 19:14:40.095548 69630 caffe_interface.cpp:125] Batch 72, top-1 = 0.9
I0122 19:14:40.095551 69630 caffe_interface.cpp:125] Batch 72, top-5 = 0.96
I0122 19:14:40.103525 69630 caffe_interface.cpp:125] Batch 73, accuracy = 0.94
I0122 19:14:40.103536 69630 caffe_interface.cpp:125] Batch 73, loss = 0.403441
I0122 19:14:40.103549 69630 caffe_interface.cpp:125] Batch 73, top-1 = 0.94
I0122 19:14:40.103554 69630 caffe_interface.cpp:125] Batch 73, top-5 = 1
I0122 19:14:40.111506 69630 caffe_interface.cpp:125] Batch 74, accuracy = 0.82
I0122 19:14:40.111516 69630 caffe_interface.cpp:125] Batch 74, loss = 0.793345
I0122 19:14:40.111519 69630 caffe_interface.cpp:125] Batch 74, top-1 = 0.82
I0122 19:14:40.111522 69630 caffe_interface.cpp:125] Batch 74, top-5 = 1
I0122 19:14:40.119473 69630 caffe_interface.cpp:125] Batch 75, accuracy = 0.94
I0122 19:14:40.119484 69630 caffe_interface.cpp:125] Batch 75, loss = 0.443941
I0122 19:14:40.119488 69630 caffe_interface.cpp:125] Batch 75, top-1 = 0.94
I0122 19:14:40.119491 69630 caffe_interface.cpp:125] Batch 75, top-5 = 1
I0122 19:14:40.128270 69630 caffe_interface.cpp:125] Batch 76, accuracy = 0.9
I0122 19:14:40.128279 69630 caffe_interface.cpp:125] Batch 76, loss = 0.46699
I0122 19:14:40.128283 69630 caffe_interface.cpp:125] Batch 76, top-1 = 0.9
I0122 19:14:40.128285 69630 caffe_interface.cpp:125] Batch 76, top-5 = 1
I0122 19:14:40.136258 69630 caffe_interface.cpp:125] Batch 77, accuracy = 0.94
I0122 19:14:40.136268 69630 caffe_interface.cpp:125] Batch 77, loss = 0.226198
I0122 19:14:40.136272 69630 caffe_interface.cpp:125] Batch 77, top-1 = 0.94
I0122 19:14:40.136276 69630 caffe_interface.cpp:125] Batch 77, top-5 = 1
I0122 19:14:40.144937 69630 caffe_interface.cpp:125] Batch 78, accuracy = 0.96
I0122 19:14:40.144949 69630 caffe_interface.cpp:125] Batch 78, loss = 0.132355
I0122 19:14:40.144953 69630 caffe_interface.cpp:125] Batch 78, top-1 = 0.96
I0122 19:14:40.144956 69630 caffe_interface.cpp:125] Batch 78, top-5 = 1
I0122 19:14:40.153872 69630 caffe_interface.cpp:125] Batch 79, accuracy = 0.96
I0122 19:14:40.153883 69630 caffe_interface.cpp:125] Batch 79, loss = 0.238593
I0122 19:14:40.153887 69630 caffe_interface.cpp:125] Batch 79, top-1 = 0.96
I0122 19:14:40.153890 69630 caffe_interface.cpp:125] Batch 79, top-5 = 1
I0122 19:14:40.161921 69630 caffe_interface.cpp:125] Batch 80, accuracy = 0.88
I0122 19:14:40.161933 69630 caffe_interface.cpp:125] Batch 80, loss = 0.359708
I0122 19:14:40.161936 69630 caffe_interface.cpp:125] Batch 80, top-1 = 0.88
I0122 19:14:40.161939 69630 caffe_interface.cpp:125] Batch 80, top-5 = 1
I0122 19:14:40.169898 69630 caffe_interface.cpp:125] Batch 81, accuracy = 0.8
I0122 19:14:40.169915 69630 caffe_interface.cpp:125] Batch 81, loss = 0.47364
I0122 19:14:40.169919 69630 caffe_interface.cpp:125] Batch 81, top-1 = 0.8
I0122 19:14:40.169921 69630 caffe_interface.cpp:125] Batch 81, top-5 = 1
I0122 19:14:40.177867 69630 caffe_interface.cpp:125] Batch 82, accuracy = 0.9
I0122 19:14:40.177878 69630 caffe_interface.cpp:125] Batch 82, loss = 0.342239
I0122 19:14:40.177882 69630 caffe_interface.cpp:125] Batch 82, top-1 = 0.9
I0122 19:14:40.177886 69630 caffe_interface.cpp:125] Batch 82, top-5 = 0.98
I0122 19:14:40.186776 69630 caffe_interface.cpp:125] Batch 83, accuracy = 0.88
I0122 19:14:40.186787 69630 caffe_interface.cpp:125] Batch 83, loss = 0.453956
I0122 19:14:40.186790 69630 caffe_interface.cpp:125] Batch 83, top-1 = 0.88
I0122 19:14:40.186794 69630 caffe_interface.cpp:125] Batch 83, top-5 = 1
I0122 19:14:40.194774 69630 caffe_interface.cpp:125] Batch 84, accuracy = 0.84
I0122 19:14:40.194785 69630 caffe_interface.cpp:125] Batch 84, loss = 0.598324
I0122 19:14:40.194789 69630 caffe_interface.cpp:125] Batch 84, top-1 = 0.84
I0122 19:14:40.194792 69630 caffe_interface.cpp:125] Batch 84, top-5 = 0.98
I0122 19:14:40.202742 69630 caffe_interface.cpp:125] Batch 85, accuracy = 0.84
I0122 19:14:40.202752 69630 caffe_interface.cpp:125] Batch 85, loss = 0.499521
I0122 19:14:40.202755 69630 caffe_interface.cpp:125] Batch 85, top-1 = 0.84
I0122 19:14:40.202759 69630 caffe_interface.cpp:125] Batch 85, top-5 = 1
I0122 19:14:40.210700 69630 caffe_interface.cpp:125] Batch 86, accuracy = 0.96
I0122 19:14:40.210710 69630 caffe_interface.cpp:125] Batch 86, loss = 0.119152
I0122 19:14:40.210713 69630 caffe_interface.cpp:125] Batch 86, top-1 = 0.96
I0122 19:14:40.210716 69630 caffe_interface.cpp:125] Batch 86, top-5 = 1
I0122 19:14:40.219609 69630 caffe_interface.cpp:125] Batch 87, accuracy = 0.88
I0122 19:14:40.219617 69630 caffe_interface.cpp:125] Batch 87, loss = 0.349633
I0122 19:14:40.219620 69630 caffe_interface.cpp:125] Batch 87, top-1 = 0.88
I0122 19:14:40.219624 69630 caffe_interface.cpp:125] Batch 87, top-5 = 1
I0122 19:14:40.227578 69630 caffe_interface.cpp:125] Batch 88, accuracy = 0.88
I0122 19:14:40.227588 69630 caffe_interface.cpp:125] Batch 88, loss = 0.38942
I0122 19:14:40.227592 69630 caffe_interface.cpp:125] Batch 88, top-1 = 0.88
I0122 19:14:40.227596 69630 caffe_interface.cpp:125] Batch 88, top-5 = 1
I0122 19:14:40.235532 69630 caffe_interface.cpp:125] Batch 89, accuracy = 0.84
I0122 19:14:40.235543 69630 caffe_interface.cpp:125] Batch 89, loss = 0.438801
I0122 19:14:40.235545 69630 caffe_interface.cpp:125] Batch 89, top-1 = 0.84
I0122 19:14:40.235548 69630 caffe_interface.cpp:125] Batch 89, top-5 = 1
I0122 19:14:40.243512 69630 caffe_interface.cpp:125] Batch 90, accuracy = 0.88
I0122 19:14:40.243522 69630 caffe_interface.cpp:125] Batch 90, loss = 0.424929
I0122 19:14:40.243526 69630 caffe_interface.cpp:125] Batch 90, top-1 = 0.88
I0122 19:14:40.243530 69630 caffe_interface.cpp:125] Batch 90, top-5 = 0.98
I0122 19:14:40.252429 69630 caffe_interface.cpp:125] Batch 91, accuracy = 0.86
I0122 19:14:40.252436 69630 caffe_interface.cpp:125] Batch 91, loss = 0.505257
I0122 19:14:40.252439 69630 caffe_interface.cpp:125] Batch 91, top-1 = 0.86
I0122 19:14:40.252441 69630 caffe_interface.cpp:125] Batch 91, top-5 = 1
I0122 19:14:40.260416 69630 caffe_interface.cpp:125] Batch 92, accuracy = 0.88
I0122 19:14:40.260426 69630 caffe_interface.cpp:125] Batch 92, loss = 0.489536
I0122 19:14:40.260429 69630 caffe_interface.cpp:125] Batch 92, top-1 = 0.88
I0122 19:14:40.260432 69630 caffe_interface.cpp:125] Batch 92, top-5 = 0.96
I0122 19:14:40.268373 69630 caffe_interface.cpp:125] Batch 93, accuracy = 0.9
I0122 19:14:40.268383 69630 caffe_interface.cpp:125] Batch 93, loss = 0.329941
I0122 19:14:40.268385 69630 caffe_interface.cpp:125] Batch 93, top-1 = 0.9
I0122 19:14:40.268388 69630 caffe_interface.cpp:125] Batch 93, top-5 = 1
I0122 19:14:40.276361 69630 caffe_interface.cpp:125] Batch 94, accuracy = 0.84
I0122 19:14:40.276371 69630 caffe_interface.cpp:125] Batch 94, loss = 0.60225
I0122 19:14:40.276376 69630 caffe_interface.cpp:125] Batch 94, top-1 = 0.84
I0122 19:14:40.276378 69630 caffe_interface.cpp:125] Batch 94, top-5 = 0.98
I0122 19:14:40.285272 69630 caffe_interface.cpp:125] Batch 95, accuracy = 0.94
I0122 19:14:40.285281 69630 caffe_interface.cpp:125] Batch 95, loss = 0.271206
I0122 19:14:40.285285 69630 caffe_interface.cpp:125] Batch 95, top-1 = 0.94
I0122 19:14:40.285287 69630 caffe_interface.cpp:125] Batch 95, top-5 = 0.98
I0122 19:14:40.293259 69630 caffe_interface.cpp:125] Batch 96, accuracy = 0.86
I0122 19:14:40.293269 69630 caffe_interface.cpp:125] Batch 96, loss = 0.807446
I0122 19:14:40.293273 69630 caffe_interface.cpp:125] Batch 96, top-1 = 0.86
I0122 19:14:40.293277 69630 caffe_interface.cpp:125] Batch 96, top-5 = 0.98
I0122 19:14:40.301223 69630 caffe_interface.cpp:125] Batch 97, accuracy = 0.9
I0122 19:14:40.301232 69630 caffe_interface.cpp:125] Batch 97, loss = 0.374701
I0122 19:14:40.301236 69630 caffe_interface.cpp:125] Batch 97, top-1 = 0.9
I0122 19:14:40.301239 69630 caffe_interface.cpp:125] Batch 97, top-5 = 0.98
I0122 19:14:40.309203 69630 caffe_interface.cpp:125] Batch 98, accuracy = 0.88
I0122 19:14:40.309213 69630 caffe_interface.cpp:125] Batch 98, loss = 0.473043
I0122 19:14:40.309216 69630 caffe_interface.cpp:125] Batch 98, top-1 = 0.88
I0122 19:14:40.309219 69630 caffe_interface.cpp:125] Batch 98, top-5 = 1
I0122 19:14:40.318112 69630 caffe_interface.cpp:125] Batch 99, accuracy = 0.92
I0122 19:14:40.318123 69630 caffe_interface.cpp:125] Batch 99, loss = 0.461939
I0122 19:14:40.318126 69630 caffe_interface.cpp:125] Batch 99, top-1 = 0.92
I0122 19:14:40.318130 69630 caffe_interface.cpp:125] Batch 99, top-5 = 1
I0122 19:14:40.326058 69630 caffe_interface.cpp:125] Batch 100, accuracy = 0.88
I0122 19:14:40.326078 69630 caffe_interface.cpp:125] Batch 100, loss = 0.21789
I0122 19:14:40.326082 69630 caffe_interface.cpp:125] Batch 100, top-1 = 0.88
I0122 19:14:40.326086 69630 caffe_interface.cpp:125] Batch 100, top-5 = 1
I0122 19:14:40.334059 69630 caffe_interface.cpp:125] Batch 101, accuracy = 0.88
I0122 19:14:40.334069 69630 caffe_interface.cpp:125] Batch 101, loss = 0.284141
I0122 19:14:40.334074 69630 caffe_interface.cpp:125] Batch 101, top-1 = 0.88
I0122 19:14:40.334076 69630 caffe_interface.cpp:125] Batch 101, top-5 = 1
I0122 19:14:40.342073 69630 caffe_interface.cpp:125] Batch 102, accuracy = 0.86
I0122 19:14:40.342083 69630 caffe_interface.cpp:125] Batch 102, loss = 0.874542
I0122 19:14:40.342087 69630 caffe_interface.cpp:125] Batch 102, top-1 = 0.86
I0122 19:14:40.342089 69630 caffe_interface.cpp:125] Batch 102, top-5 = 0.98
I0122 19:14:40.350977 69630 caffe_interface.cpp:125] Batch 103, accuracy = 0.92
I0122 19:14:40.350986 69630 caffe_interface.cpp:125] Batch 103, loss = 0.244105
I0122 19:14:40.350991 69630 caffe_interface.cpp:125] Batch 103, top-1 = 0.92
I0122 19:14:40.350993 69630 caffe_interface.cpp:125] Batch 103, top-5 = 1
I0122 19:14:40.358945 69630 caffe_interface.cpp:125] Batch 104, accuracy = 0.92
I0122 19:14:40.358955 69630 caffe_interface.cpp:125] Batch 104, loss = 0.464256
I0122 19:14:40.358959 69630 caffe_interface.cpp:125] Batch 104, top-1 = 0.92
I0122 19:14:40.358961 69630 caffe_interface.cpp:125] Batch 104, top-5 = 1
I0122 19:14:40.366926 69630 caffe_interface.cpp:125] Batch 105, accuracy = 0.9
I0122 19:14:40.366935 69630 caffe_interface.cpp:125] Batch 105, loss = 0.39317
I0122 19:14:40.366938 69630 caffe_interface.cpp:125] Batch 105, top-1 = 0.9
I0122 19:14:40.366941 69630 caffe_interface.cpp:125] Batch 105, top-5 = 1
I0122 19:14:40.374898 69630 caffe_interface.cpp:125] Batch 106, accuracy = 0.9
I0122 19:14:40.374907 69630 caffe_interface.cpp:125] Batch 106, loss = 0.428995
I0122 19:14:40.374910 69630 caffe_interface.cpp:125] Batch 106, top-1 = 0.9
I0122 19:14:40.374913 69630 caffe_interface.cpp:125] Batch 106, top-5 = 1
I0122 19:14:40.382874 69630 caffe_interface.cpp:125] Batch 107, accuracy = 0.9
I0122 19:14:40.382884 69630 caffe_interface.cpp:125] Batch 107, loss = 0.339172
I0122 19:14:40.382889 69630 caffe_interface.cpp:125] Batch 107, top-1 = 0.9
I0122 19:14:40.382891 69630 caffe_interface.cpp:125] Batch 107, top-5 = 1
I0122 19:14:40.391851 69630 caffe_interface.cpp:125] Batch 108, accuracy = 0.88
I0122 19:14:40.391860 69630 caffe_interface.cpp:125] Batch 108, loss = 0.598732
I0122 19:14:40.391863 69630 caffe_interface.cpp:125] Batch 108, top-1 = 0.88
I0122 19:14:40.391866 69630 caffe_interface.cpp:125] Batch 108, top-5 = 1
I0122 19:14:40.399827 69630 caffe_interface.cpp:125] Batch 109, accuracy = 0.88
I0122 19:14:40.399837 69630 caffe_interface.cpp:125] Batch 109, loss = 0.561395
I0122 19:14:40.399840 69630 caffe_interface.cpp:125] Batch 109, top-1 = 0.88
I0122 19:14:40.399843 69630 caffe_interface.cpp:125] Batch 109, top-5 = 0.98
I0122 19:14:40.407815 69630 caffe_interface.cpp:125] Batch 110, accuracy = 0.88
I0122 19:14:40.407826 69630 caffe_interface.cpp:125] Batch 110, loss = 0.426272
I0122 19:14:40.407829 69630 caffe_interface.cpp:125] Batch 110, top-1 = 0.88
I0122 19:14:40.407832 69630 caffe_interface.cpp:125] Batch 110, top-5 = 1
I0122 19:14:40.415781 69630 caffe_interface.cpp:125] Batch 111, accuracy = 0.86
I0122 19:14:40.415791 69630 caffe_interface.cpp:125] Batch 111, loss = 0.769481
I0122 19:14:40.415796 69630 caffe_interface.cpp:125] Batch 111, top-1 = 0.86
I0122 19:14:40.415797 69630 caffe_interface.cpp:125] Batch 111, top-5 = 0.98
I0122 19:14:40.424860 69630 caffe_interface.cpp:125] Batch 112, accuracy = 0.92
I0122 19:14:40.424870 69630 caffe_interface.cpp:125] Batch 112, loss = 0.229921
I0122 19:14:40.424873 69630 caffe_interface.cpp:125] Batch 112, top-1 = 0.92
I0122 19:14:40.424875 69630 caffe_interface.cpp:125] Batch 112, top-5 = 1
I0122 19:14:40.432816 69630 caffe_interface.cpp:125] Batch 113, accuracy = 0.84
I0122 19:14:40.432826 69630 caffe_interface.cpp:125] Batch 113, loss = 0.605709
I0122 19:14:40.432839 69630 caffe_interface.cpp:125] Batch 113, top-1 = 0.84
I0122 19:14:40.432842 69630 caffe_interface.cpp:125] Batch 113, top-5 = 1
I0122 19:14:40.440807 69630 caffe_interface.cpp:125] Batch 114, accuracy = 0.86
I0122 19:14:40.440817 69630 caffe_interface.cpp:125] Batch 114, loss = 0.546773
I0122 19:14:40.440821 69630 caffe_interface.cpp:125] Batch 114, top-1 = 0.86
I0122 19:14:40.440824 69630 caffe_interface.cpp:125] Batch 114, top-5 = 1
I0122 19:14:40.448776 69630 caffe_interface.cpp:125] Batch 115, accuracy = 0.96
I0122 19:14:40.448786 69630 caffe_interface.cpp:125] Batch 115, loss = 0.17447
I0122 19:14:40.448791 69630 caffe_interface.cpp:125] Batch 115, top-1 = 0.96
I0122 19:14:40.448793 69630 caffe_interface.cpp:125] Batch 115, top-5 = 1
I0122 19:14:40.457828 69630 caffe_interface.cpp:125] Batch 116, accuracy = 0.88
I0122 19:14:40.457836 69630 caffe_interface.cpp:125] Batch 116, loss = 0.391582
I0122 19:14:40.457839 69630 caffe_interface.cpp:125] Batch 116, top-1 = 0.88
I0122 19:14:40.457842 69630 caffe_interface.cpp:125] Batch 116, top-5 = 0.98
I0122 19:14:40.465801 69630 caffe_interface.cpp:125] Batch 117, accuracy = 0.84
I0122 19:14:40.465811 69630 caffe_interface.cpp:125] Batch 117, loss = 0.501491
I0122 19:14:40.465813 69630 caffe_interface.cpp:125] Batch 117, top-1 = 0.84
I0122 19:14:40.465816 69630 caffe_interface.cpp:125] Batch 117, top-5 = 0.98
I0122 19:14:40.473763 69630 caffe_interface.cpp:125] Batch 118, accuracy = 0.94
I0122 19:14:40.473774 69630 caffe_interface.cpp:125] Batch 118, loss = 0.39051
I0122 19:14:40.473778 69630 caffe_interface.cpp:125] Batch 118, top-1 = 0.94
I0122 19:14:40.473780 69630 caffe_interface.cpp:125] Batch 118, top-5 = 1
I0122 19:14:40.481760 69630 caffe_interface.cpp:125] Batch 119, accuracy = 0.84
I0122 19:14:40.481768 69630 caffe_interface.cpp:125] Batch 119, loss = 0.693423
I0122 19:14:40.481772 69630 caffe_interface.cpp:125] Batch 119, top-1 = 0.84
I0122 19:14:40.481775 69630 caffe_interface.cpp:125] Batch 119, top-5 = 1
I0122 19:14:40.490855 69630 caffe_interface.cpp:125] Batch 120, accuracy = 0.86
I0122 19:14:40.490864 69630 caffe_interface.cpp:125] Batch 120, loss = 0.391599
I0122 19:14:40.490867 69630 caffe_interface.cpp:125] Batch 120, top-1 = 0.86
I0122 19:14:40.490870 69630 caffe_interface.cpp:125] Batch 120, top-5 = 0.98
I0122 19:14:40.498850 69630 caffe_interface.cpp:125] Batch 121, accuracy = 0.86
I0122 19:14:40.498859 69630 caffe_interface.cpp:125] Batch 121, loss = 0.743563
I0122 19:14:40.498863 69630 caffe_interface.cpp:125] Batch 121, top-1 = 0.86
I0122 19:14:40.498867 69630 caffe_interface.cpp:125] Batch 121, top-5 = 0.98
I0122 19:14:40.506798 69630 caffe_interface.cpp:125] Batch 122, accuracy = 0.92
I0122 19:14:40.506808 69630 caffe_interface.cpp:125] Batch 122, loss = 0.225884
I0122 19:14:40.506812 69630 caffe_interface.cpp:125] Batch 122, top-1 = 0.92
I0122 19:14:40.506815 69630 caffe_interface.cpp:125] Batch 122, top-5 = 1
I0122 19:14:40.514739 69630 caffe_interface.cpp:125] Batch 123, accuracy = 0.84
I0122 19:14:40.514748 69630 caffe_interface.cpp:125] Batch 123, loss = 0.384944
I0122 19:14:40.514752 69630 caffe_interface.cpp:125] Batch 123, top-1 = 0.84
I0122 19:14:40.514755 69630 caffe_interface.cpp:125] Batch 123, top-5 = 1
I0122 19:14:40.523797 69630 caffe_interface.cpp:125] Batch 124, accuracy = 0.88
I0122 19:14:40.523808 69630 caffe_interface.cpp:125] Batch 124, loss = 0.293317
I0122 19:14:40.523811 69630 caffe_interface.cpp:125] Batch 124, top-1 = 0.88
I0122 19:14:40.523814 69630 caffe_interface.cpp:125] Batch 124, top-5 = 1
I0122 19:14:40.531769 69630 caffe_interface.cpp:125] Batch 125, accuracy = 0.88
I0122 19:14:40.531780 69630 caffe_interface.cpp:125] Batch 125, loss = 0.475116
I0122 19:14:40.531782 69630 caffe_interface.cpp:125] Batch 125, top-1 = 0.88
I0122 19:14:40.531785 69630 caffe_interface.cpp:125] Batch 125, top-5 = 0.98
I0122 19:14:40.539991 69630 caffe_interface.cpp:125] Batch 126, accuracy = 0.88
I0122 19:14:40.540004 69630 caffe_interface.cpp:125] Batch 126, loss = 0.78012
I0122 19:14:40.540016 69630 caffe_interface.cpp:125] Batch 126, top-1 = 0.88
I0122 19:14:40.540019 69630 caffe_interface.cpp:125] Batch 126, top-5 = 1
I0122 19:14:40.548408 69630 caffe_interface.cpp:125] Batch 127, accuracy = 0.84
I0122 19:14:40.548420 69630 caffe_interface.cpp:125] Batch 127, loss = 0.330863
I0122 19:14:40.548424 69630 caffe_interface.cpp:125] Batch 127, top-1 = 0.84
I0122 19:14:40.548426 69630 caffe_interface.cpp:125] Batch 127, top-5 = 1
I0122 19:14:40.557440 69630 caffe_interface.cpp:125] Batch 128, accuracy = 0.9
I0122 19:14:40.557449 69630 caffe_interface.cpp:125] Batch 128, loss = 0.253583
I0122 19:14:40.557451 69630 caffe_interface.cpp:125] Batch 128, top-1 = 0.9
I0122 19:14:40.557454 69630 caffe_interface.cpp:125] Batch 128, top-5 = 1
I0122 19:14:40.565402 69630 caffe_interface.cpp:125] Batch 129, accuracy = 0.84
I0122 19:14:40.565412 69630 caffe_interface.cpp:125] Batch 129, loss = 0.788577
I0122 19:14:40.565416 69630 caffe_interface.cpp:125] Batch 129, top-1 = 0.84
I0122 19:14:40.565419 69630 caffe_interface.cpp:125] Batch 129, top-5 = 0.96
I0122 19:14:40.573376 69630 caffe_interface.cpp:125] Batch 130, accuracy = 0.84
I0122 19:14:40.573386 69630 caffe_interface.cpp:125] Batch 130, loss = 0.4779
I0122 19:14:40.573390 69630 caffe_interface.cpp:125] Batch 130, top-1 = 0.84
I0122 19:14:40.573392 69630 caffe_interface.cpp:125] Batch 130, top-5 = 1
I0122 19:14:40.581346 69630 caffe_interface.cpp:125] Batch 131, accuracy = 0.88
I0122 19:14:40.581357 69630 caffe_interface.cpp:125] Batch 131, loss = 0.529545
I0122 19:14:40.581360 69630 caffe_interface.cpp:125] Batch 131, top-1 = 0.88
I0122 19:14:40.581363 69630 caffe_interface.cpp:125] Batch 131, top-5 = 0.96
I0122 19:14:40.590389 69630 caffe_interface.cpp:125] Batch 132, accuracy = 0.86
I0122 19:14:40.590399 69630 caffe_interface.cpp:125] Batch 132, loss = 0.715223
I0122 19:14:40.590401 69630 caffe_interface.cpp:125] Batch 132, top-1 = 0.86
I0122 19:14:40.590404 69630 caffe_interface.cpp:125] Batch 132, top-5 = 0.98
I0122 19:14:40.598371 69630 caffe_interface.cpp:125] Batch 133, accuracy = 0.84
I0122 19:14:40.598379 69630 caffe_interface.cpp:125] Batch 133, loss = 0.460114
I0122 19:14:40.598383 69630 caffe_interface.cpp:125] Batch 133, top-1 = 0.84
I0122 19:14:40.598387 69630 caffe_interface.cpp:125] Batch 133, top-5 = 1
I0122 19:14:40.606323 69630 caffe_interface.cpp:125] Batch 134, accuracy = 0.88
I0122 19:14:40.606333 69630 caffe_interface.cpp:125] Batch 134, loss = 0.673624
I0122 19:14:40.606336 69630 caffe_interface.cpp:125] Batch 134, top-1 = 0.88
I0122 19:14:40.606339 69630 caffe_interface.cpp:125] Batch 134, top-5 = 0.98
I0122 19:14:40.614305 69630 caffe_interface.cpp:125] Batch 135, accuracy = 0.86
I0122 19:14:40.614315 69630 caffe_interface.cpp:125] Batch 135, loss = 0.5984
I0122 19:14:40.614320 69630 caffe_interface.cpp:125] Batch 135, top-1 = 0.86
I0122 19:14:40.614322 69630 caffe_interface.cpp:125] Batch 135, top-5 = 1
I0122 19:14:40.623358 69630 caffe_interface.cpp:125] Batch 136, accuracy = 0.92
I0122 19:14:40.623368 69630 caffe_interface.cpp:125] Batch 136, loss = 0.185756
I0122 19:14:40.623371 69630 caffe_interface.cpp:125] Batch 136, top-1 = 0.92
I0122 19:14:40.623373 69630 caffe_interface.cpp:125] Batch 136, top-5 = 1
I0122 19:14:40.631304 69630 caffe_interface.cpp:125] Batch 137, accuracy = 0.92
I0122 19:14:40.631314 69630 caffe_interface.cpp:125] Batch 137, loss = 0.24864
I0122 19:14:40.631316 69630 caffe_interface.cpp:125] Batch 137, top-1 = 0.92
I0122 19:14:40.631319 69630 caffe_interface.cpp:125] Batch 137, top-5 = 1
I0122 19:14:40.639261 69630 caffe_interface.cpp:125] Batch 138, accuracy = 0.88
I0122 19:14:40.639271 69630 caffe_interface.cpp:125] Batch 138, loss = 0.399934
I0122 19:14:40.639273 69630 caffe_interface.cpp:125] Batch 138, top-1 = 0.88
I0122 19:14:40.639276 69630 caffe_interface.cpp:125] Batch 138, top-5 = 1
I0122 19:14:40.647207 69630 caffe_interface.cpp:125] Batch 139, accuracy = 0.8
I0122 19:14:40.647217 69630 caffe_interface.cpp:125] Batch 139, loss = 0.874821
I0122 19:14:40.647220 69630 caffe_interface.cpp:125] Batch 139, top-1 = 0.8
I0122 19:14:40.647238 69630 caffe_interface.cpp:125] Batch 139, top-5 = 0.98
I0122 19:14:40.656293 69630 caffe_interface.cpp:125] Batch 140, accuracy = 0.84
I0122 19:14:40.656302 69630 caffe_interface.cpp:125] Batch 140, loss = 0.703641
I0122 19:14:40.656306 69630 caffe_interface.cpp:125] Batch 140, top-1 = 0.84
I0122 19:14:40.656308 69630 caffe_interface.cpp:125] Batch 140, top-5 = 1
I0122 19:14:40.664238 69630 caffe_interface.cpp:125] Batch 141, accuracy = 0.84
I0122 19:14:40.664247 69630 caffe_interface.cpp:125] Batch 141, loss = 0.68846
I0122 19:14:40.664250 69630 caffe_interface.cpp:125] Batch 141, top-1 = 0.84
I0122 19:14:40.664253 69630 caffe_interface.cpp:125] Batch 141, top-5 = 0.98
I0122 19:14:40.672219 69630 caffe_interface.cpp:125] Batch 142, accuracy = 0.94
I0122 19:14:40.672228 69630 caffe_interface.cpp:125] Batch 142, loss = 0.264119
I0122 19:14:40.672232 69630 caffe_interface.cpp:125] Batch 142, top-1 = 0.94
I0122 19:14:40.672235 69630 caffe_interface.cpp:125] Batch 142, top-5 = 0.98
I0122 19:14:40.680181 69630 caffe_interface.cpp:125] Batch 143, accuracy = 0.9
I0122 19:14:40.680191 69630 caffe_interface.cpp:125] Batch 143, loss = 0.281628
I0122 19:14:40.680194 69630 caffe_interface.cpp:125] Batch 143, top-1 = 0.9
I0122 19:14:40.680197 69630 caffe_interface.cpp:125] Batch 143, top-5 = 1
I0122 19:14:40.689186 69630 caffe_interface.cpp:125] Batch 144, accuracy = 0.92
I0122 19:14:40.689195 69630 caffe_interface.cpp:125] Batch 144, loss = 0.29941
I0122 19:14:40.689198 69630 caffe_interface.cpp:125] Batch 144, top-1 = 0.92
I0122 19:14:40.689201 69630 caffe_interface.cpp:125] Batch 144, top-5 = 1
I0122 19:14:40.697186 69630 caffe_interface.cpp:125] Batch 145, accuracy = 0.94
I0122 19:14:40.697196 69630 caffe_interface.cpp:125] Batch 145, loss = 0.31202
I0122 19:14:40.697201 69630 caffe_interface.cpp:125] Batch 145, top-1 = 0.94
I0122 19:14:40.697203 69630 caffe_interface.cpp:125] Batch 145, top-5 = 1
I0122 19:14:40.705153 69630 caffe_interface.cpp:125] Batch 146, accuracy = 0.86
I0122 19:14:40.705163 69630 caffe_interface.cpp:125] Batch 146, loss = 0.643617
I0122 19:14:40.705166 69630 caffe_interface.cpp:125] Batch 146, top-1 = 0.86
I0122 19:14:40.705168 69630 caffe_interface.cpp:125] Batch 146, top-5 = 1
I0122 19:14:40.713131 69630 caffe_interface.cpp:125] Batch 147, accuracy = 0.88
I0122 19:14:40.713142 69630 caffe_interface.cpp:125] Batch 147, loss = 0.326821
I0122 19:14:40.713146 69630 caffe_interface.cpp:125] Batch 147, top-1 = 0.88
I0122 19:14:40.713150 69630 caffe_interface.cpp:125] Batch 147, top-5 = 1
I0122 19:14:40.722132 69630 caffe_interface.cpp:125] Batch 148, accuracy = 0.94
I0122 19:14:40.722141 69630 caffe_interface.cpp:125] Batch 148, loss = 0.212887
I0122 19:14:40.722143 69630 caffe_interface.cpp:125] Batch 148, top-1 = 0.94
I0122 19:14:40.722146 69630 caffe_interface.cpp:125] Batch 148, top-5 = 0.98
I0122 19:14:40.730085 69630 caffe_interface.cpp:125] Batch 149, accuracy = 0.96
I0122 19:14:40.730095 69630 caffe_interface.cpp:125] Batch 149, loss = 0.153237
I0122 19:14:40.730099 69630 caffe_interface.cpp:125] Batch 149, top-1 = 0.96
I0122 19:14:40.730103 69630 caffe_interface.cpp:125] Batch 149, top-5 = 1
I0122 19:14:40.738054 69630 caffe_interface.cpp:125] Batch 150, accuracy = 0.92
I0122 19:14:40.738063 69630 caffe_interface.cpp:125] Batch 150, loss = 0.154991
I0122 19:14:40.738066 69630 caffe_interface.cpp:125] Batch 150, top-1 = 0.92
I0122 19:14:40.738070 69630 caffe_interface.cpp:125] Batch 150, top-5 = 1
I0122 19:14:40.746011 69630 caffe_interface.cpp:125] Batch 151, accuracy = 0.84
I0122 19:14:40.746021 69630 caffe_interface.cpp:125] Batch 151, loss = 0.924735
I0122 19:14:40.746024 69630 caffe_interface.cpp:125] Batch 151, top-1 = 0.84
I0122 19:14:40.746027 69630 caffe_interface.cpp:125] Batch 151, top-5 = 0.98
I0122 19:14:40.755081 69630 caffe_interface.cpp:125] Batch 152, accuracy = 0.9
I0122 19:14:40.755091 69630 caffe_interface.cpp:125] Batch 152, loss = 0.267434
I0122 19:14:40.755095 69630 caffe_interface.cpp:125] Batch 152, top-1 = 0.9
I0122 19:14:40.755107 69630 caffe_interface.cpp:125] Batch 152, top-5 = 1
I0122 19:14:40.763083 69630 caffe_interface.cpp:125] Batch 153, accuracy = 0.92
I0122 19:14:40.763094 69630 caffe_interface.cpp:125] Batch 153, loss = 0.300028
I0122 19:14:40.763098 69630 caffe_interface.cpp:125] Batch 153, top-1 = 0.92
I0122 19:14:40.763101 69630 caffe_interface.cpp:125] Batch 153, top-5 = 1
I0122 19:14:40.771050 69630 caffe_interface.cpp:125] Batch 154, accuracy = 0.88
I0122 19:14:40.771060 69630 caffe_interface.cpp:125] Batch 154, loss = 0.34063
I0122 19:14:40.771064 69630 caffe_interface.cpp:125] Batch 154, top-1 = 0.88
I0122 19:14:40.771067 69630 caffe_interface.cpp:125] Batch 154, top-5 = 1
I0122 19:14:40.779047 69630 caffe_interface.cpp:125] Batch 155, accuracy = 0.86
I0122 19:14:40.779057 69630 caffe_interface.cpp:125] Batch 155, loss = 0.350541
I0122 19:14:40.779059 69630 caffe_interface.cpp:125] Batch 155, top-1 = 0.86
I0122 19:14:40.779062 69630 caffe_interface.cpp:125] Batch 155, top-5 = 1
I0122 19:14:40.788080 69630 caffe_interface.cpp:125] Batch 156, accuracy = 0.9
I0122 19:14:40.788090 69630 caffe_interface.cpp:125] Batch 156, loss = 0.279971
I0122 19:14:40.788094 69630 caffe_interface.cpp:125] Batch 156, top-1 = 0.9
I0122 19:14:40.788097 69630 caffe_interface.cpp:125] Batch 156, top-5 = 1
I0122 19:14:40.796043 69630 caffe_interface.cpp:125] Batch 157, accuracy = 0.96
I0122 19:14:40.796053 69630 caffe_interface.cpp:125] Batch 157, loss = 0.35962
I0122 19:14:40.796056 69630 caffe_interface.cpp:125] Batch 157, top-1 = 0.96
I0122 19:14:40.796059 69630 caffe_interface.cpp:125] Batch 157, top-5 = 1
I0122 19:14:40.804008 69630 caffe_interface.cpp:125] Batch 158, accuracy = 0.84
I0122 19:14:40.804018 69630 caffe_interface.cpp:125] Batch 158, loss = 0.518828
I0122 19:14:40.804020 69630 caffe_interface.cpp:125] Batch 158, top-1 = 0.84
I0122 19:14:40.804023 69630 caffe_interface.cpp:125] Batch 158, top-5 = 1
I0122 19:14:40.811946 69630 caffe_interface.cpp:125] Batch 159, accuracy = 0.92
I0122 19:14:40.811956 69630 caffe_interface.cpp:125] Batch 159, loss = 0.388732
I0122 19:14:40.811959 69630 caffe_interface.cpp:125] Batch 159, top-1 = 0.92
I0122 19:14:40.811962 69630 caffe_interface.cpp:125] Batch 159, top-5 = 1
I0122 19:14:40.820977 69630 caffe_interface.cpp:125] Batch 160, accuracy = 0.9
I0122 19:14:40.820986 69630 caffe_interface.cpp:125] Batch 160, loss = 0.173905
I0122 19:14:40.820989 69630 caffe_interface.cpp:125] Batch 160, top-1 = 0.9
I0122 19:14:40.820992 69630 caffe_interface.cpp:125] Batch 160, top-5 = 1
I0122 19:14:40.828912 69630 caffe_interface.cpp:125] Batch 161, accuracy = 0.9
I0122 19:14:40.828922 69630 caffe_interface.cpp:125] Batch 161, loss = 0.375658
I0122 19:14:40.828924 69630 caffe_interface.cpp:125] Batch 161, top-1 = 0.9
I0122 19:14:40.828927 69630 caffe_interface.cpp:125] Batch 161, top-5 = 1
I0122 19:14:40.836863 69630 caffe_interface.cpp:125] Batch 162, accuracy = 0.9
I0122 19:14:40.836872 69630 caffe_interface.cpp:125] Batch 162, loss = 0.505252
I0122 19:14:40.836877 69630 caffe_interface.cpp:125] Batch 162, top-1 = 0.9
I0122 19:14:40.836880 69630 caffe_interface.cpp:125] Batch 162, top-5 = 1
I0122 19:14:40.844851 69630 caffe_interface.cpp:125] Batch 163, accuracy = 0.94
I0122 19:14:40.844859 69630 caffe_interface.cpp:125] Batch 163, loss = 0.172928
I0122 19:14:40.844863 69630 caffe_interface.cpp:125] Batch 163, top-1 = 0.94
I0122 19:14:40.844866 69630 caffe_interface.cpp:125] Batch 163, top-5 = 1
I0122 19:14:40.853778 69630 caffe_interface.cpp:125] Batch 164, accuracy = 0.78
I0122 19:14:40.853788 69630 caffe_interface.cpp:125] Batch 164, loss = 0.653707
I0122 19:14:40.853790 69630 caffe_interface.cpp:125] Batch 164, top-1 = 0.78
I0122 19:14:40.853793 69630 caffe_interface.cpp:125] Batch 164, top-5 = 1
I0122 19:14:40.861750 69630 caffe_interface.cpp:125] Batch 165, accuracy = 0.9
I0122 19:14:40.861760 69630 caffe_interface.cpp:125] Batch 165, loss = 0.312298
I0122 19:14:40.861764 69630 caffe_interface.cpp:125] Batch 165, top-1 = 0.9
I0122 19:14:40.861768 69630 caffe_interface.cpp:125] Batch 165, top-5 = 1
I0122 19:14:40.869786 69630 caffe_interface.cpp:125] Batch 166, accuracy = 0.9
I0122 19:14:40.869797 69630 caffe_interface.cpp:125] Batch 166, loss = 0.286801
I0122 19:14:40.869801 69630 caffe_interface.cpp:125] Batch 166, top-1 = 0.9
I0122 19:14:40.869803 69630 caffe_interface.cpp:125] Batch 166, top-5 = 0.98
I0122 19:14:40.877768 69630 caffe_interface.cpp:125] Batch 167, accuracy = 0.88
I0122 19:14:40.877779 69630 caffe_interface.cpp:125] Batch 167, loss = 0.296639
I0122 19:14:40.877781 69630 caffe_interface.cpp:125] Batch 167, top-1 = 0.88
I0122 19:14:40.877784 69630 caffe_interface.cpp:125] Batch 167, top-5 = 0.98
I0122 19:14:40.886642 69630 caffe_interface.cpp:125] Batch 168, accuracy = 0.92
I0122 19:14:40.886652 69630 caffe_interface.cpp:125] Batch 168, loss = 0.367817
I0122 19:14:40.886656 69630 caffe_interface.cpp:125] Batch 168, top-1 = 0.92
I0122 19:14:40.886658 69630 caffe_interface.cpp:125] Batch 168, top-5 = 1
I0122 19:14:40.894626 69630 caffe_interface.cpp:125] Batch 169, accuracy = 0.9
I0122 19:14:40.894636 69630 caffe_interface.cpp:125] Batch 169, loss = 0.552763
I0122 19:14:40.894640 69630 caffe_interface.cpp:125] Batch 169, top-1 = 0.9
I0122 19:14:40.894644 69630 caffe_interface.cpp:125] Batch 169, top-5 = 0.98
I0122 19:14:40.902582 69630 caffe_interface.cpp:125] Batch 170, accuracy = 0.94
I0122 19:14:40.902592 69630 caffe_interface.cpp:125] Batch 170, loss = 0.220599
I0122 19:14:40.902596 69630 caffe_interface.cpp:125] Batch 170, top-1 = 0.94
I0122 19:14:40.902598 69630 caffe_interface.cpp:125] Batch 170, top-5 = 1
I0122 19:14:40.910578 69630 caffe_interface.cpp:125] Batch 171, accuracy = 0.96
I0122 19:14:40.910588 69630 caffe_interface.cpp:125] Batch 171, loss = 0.126989
I0122 19:14:40.910591 69630 caffe_interface.cpp:125] Batch 171, top-1 = 0.96
I0122 19:14:40.910594 69630 caffe_interface.cpp:125] Batch 171, top-5 = 1
I0122 19:14:40.918543 69630 caffe_interface.cpp:125] Batch 172, accuracy = 0.84
I0122 19:14:40.918552 69630 caffe_interface.cpp:125] Batch 172, loss = 0.48777
I0122 19:14:40.918555 69630 caffe_interface.cpp:125] Batch 172, top-1 = 0.84
I0122 19:14:40.918558 69630 caffe_interface.cpp:125] Batch 172, top-5 = 0.98
I0122 19:14:40.927357 69630 caffe_interface.cpp:125] Batch 173, accuracy = 0.92
I0122 19:14:40.927367 69630 caffe_interface.cpp:125] Batch 173, loss = 0.254489
I0122 19:14:40.927371 69630 caffe_interface.cpp:125] Batch 173, top-1 = 0.92
I0122 19:14:40.927373 69630 caffe_interface.cpp:125] Batch 173, top-5 = 1
I0122 19:14:40.935345 69630 caffe_interface.cpp:125] Batch 174, accuracy = 0.9
I0122 19:14:40.935356 69630 caffe_interface.cpp:125] Batch 174, loss = 0.230766
I0122 19:14:40.935360 69630 caffe_interface.cpp:125] Batch 174, top-1 = 0.9
I0122 19:14:40.935362 69630 caffe_interface.cpp:125] Batch 174, top-5 = 1
I0122 19:14:40.943325 69630 caffe_interface.cpp:125] Batch 175, accuracy = 0.88
I0122 19:14:40.943334 69630 caffe_interface.cpp:125] Batch 175, loss = 0.477015
I0122 19:14:40.943337 69630 caffe_interface.cpp:125] Batch 175, top-1 = 0.88
I0122 19:14:40.943341 69630 caffe_interface.cpp:125] Batch 175, top-5 = 1
I0122 19:14:40.951297 69630 caffe_interface.cpp:125] Batch 176, accuracy = 0.84
I0122 19:14:40.951308 69630 caffe_interface.cpp:125] Batch 176, loss = 0.895328
I0122 19:14:40.951310 69630 caffe_interface.cpp:125] Batch 176, top-1 = 0.84
I0122 19:14:40.951313 69630 caffe_interface.cpp:125] Batch 176, top-5 = 0.98
I0122 19:14:40.960286 69630 caffe_interface.cpp:125] Batch 177, accuracy = 0.88
I0122 19:14:40.960295 69630 caffe_interface.cpp:125] Batch 177, loss = 0.259881
I0122 19:14:40.960299 69630 caffe_interface.cpp:125] Batch 177, top-1 = 0.88
I0122 19:14:40.960301 69630 caffe_interface.cpp:125] Batch 177, top-5 = 1
I0122 19:14:40.968276 69630 caffe_interface.cpp:125] Batch 178, accuracy = 0.88
I0122 19:14:40.968286 69630 caffe_interface.cpp:125] Batch 178, loss = 0.314844
I0122 19:14:40.968289 69630 caffe_interface.cpp:125] Batch 178, top-1 = 0.88
I0122 19:14:40.968292 69630 caffe_interface.cpp:125] Batch 178, top-5 = 1
I0122 19:14:40.976265 69630 caffe_interface.cpp:125] Batch 179, accuracy = 0.88
I0122 19:14:40.976285 69630 caffe_interface.cpp:125] Batch 179, loss = 0.350082
I0122 19:14:40.976290 69630 caffe_interface.cpp:125] Batch 179, top-1 = 0.88
I0122 19:14:40.976292 69630 caffe_interface.cpp:125] Batch 179, top-5 = 1
I0122 19:14:40.976295 69630 caffe_interface.cpp:130] Loss: 0.399975
I0122 19:14:40.976300 69630 caffe_interface.cpp:142] accuracy = 0.893888
I0122 19:14:40.976306 69630 caffe_interface.cpp:142] loss = 0.399975 (* 1 = 0.399975 loss)
I0122 19:14:40.976311 69630 caffe_interface.cpp:142] top-1 = 0.893888
I0122 19:14:40.976315 69630 caffe_interface.cpp:142] top-5 = 0.994445
I0122 19:14:41.137490 69630 pruning_runner.cpp:306] pruning done, output model: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/sparse.caffemodel
I0122 19:14:41.137511 69630 pruning_runner.cpp:320] summary of REGULAR compression with rate 0.3:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.897777736    | 0.893888235    | -0.00388950109 |
+-------------------------------------------------------------------+
| Weights        | 1652899        | 1186265        | -28.231245%    |
+-------------------------------------------------------------------+
| Operations     | 533938176      | 374163584      | -29.9238033%   |
+-------------------------------------------------------------------+
To fine-tune the compressed model, please run:
deephi_compress finetune -config cifar10/deephi/miniGoogleNet/pruning/config3.prototxt
## fine-tuning: third run
$PRUNE_ROOT/deephi_compress finetune -config ${WORK_DIR}/config3.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_finetune3_miniGoogleNet.txt
I0122 19:14:41.375304 70150 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt
I0122 19:14:41.551424 70150 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 19:14:41.551930 70150 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24778440704, dev_info[0]: total=25620447232 free=24778440704
I0122 19:14:41.551941 70150 caffe_interface.cpp:493] Using GPUs 0
I0122 19:14:41.552222 70150 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 19:14:42.139788 70150 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt"
type: "SGD"
I0122 19:14:42.139899 70150 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt
I0122 19:14:42.140473 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 19:14:42.140502 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 19:14:42.140506 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 19:14:42.140508 70150 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 19:14:42.141005 70150 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 19:14:42.141247 70150 layer_factory.hpp:77] Creating layer data
I0122 19:14:42.141350 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.142292 70150 net.cpp:94] Creating Layer data
I0122 19:14:42.142309 70150 net.cpp:409] data -> data
I0122 19:14:42.142320 70150 net.cpp:409] data -> label
I0122 19:14:42.143688 70189 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 19:14:42.143739 70189 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 19:14:42.143823 70150 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 19:14:42.143903 70150 data_layer.cpp:83] output data size: 128,3,32,32
I0122 19:14:42.151445 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.151490 70150 net.cpp:144] Setting up data
I0122 19:14:42.151497 70150 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 19:14:42.151501 70150 net.cpp:151] Top shape: 128 (128)
I0122 19:14:42.151504 70150 net.cpp:159] Memory required for data: 1573376
I0122 19:14:42.151509 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:14:42.151520 70150 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:14:42.151525 70150 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:14:42.151537 70150 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:14:42.153069 70150 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:14:42.153080 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153084 70150 net.cpp:159] Memory required for data: 51905024
I0122 19:14:42.153096 70150 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:14:42.153103 70150 net.cpp:94] Creating Layer conv1/bn1
I0122 19:14:42.153106 70150 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:14:42.153111 70150 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.153709 70150 net.cpp:144] Setting up conv1/bn1
I0122 19:14:42.153717 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153719 70150 net.cpp:159] Memory required for data: 102236672
I0122 19:14:42.153730 70150 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:14:42.153738 70150 net.cpp:94] Creating Layer conv1/relu1
I0122 19:14:42.153740 70150 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:14:42.153744 70150 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.153754 70150 net.cpp:144] Setting up conv1/relu1
I0122 19:14:42.153771 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153774 70150 net.cpp:159] Memory required for data: 152568320
I0122 19:14:42.153777 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.153784 70150 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.153785 70150 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:14:42.153790 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.153796 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.153823 70150 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.153828 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153832 70150 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:14:42.153836 70150 net.cpp:159] Memory required for data: 253231616
I0122 19:14:42.153838 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:14:42.153846 70150 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:14:42.153848 70150 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.153852 70150 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:14:42.154078 70150 net.cpp:144] Setting up inception_2a/1x1
I0122 19:14:42.154085 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.154088 70150 net.cpp:159] Memory required for data: 270008832
I0122 19:14:42.154094 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:14:42.154100 70150 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:14:42.154105 70150 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:14:42.154110 70150 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.155262 70150 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:14:42.155268 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.155270 70150 net.cpp:159] Memory required for data: 286786048
I0122 19:14:42.155277 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:14:42.155282 70150 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:14:42.155284 70150 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:14:42.155287 70150 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.155292 70150 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:14:42.155295 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.155297 70150 net.cpp:159] Memory required for data: 303563264
I0122 19:14:42.155299 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:14:42.155306 70150 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:14:42.155309 70150 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.155314 70150 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:14:42.156498 70150 net.cpp:144] Setting up inception_2a/3x3
I0122 19:14:42.156508 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.156512 70150 net.cpp:159] Memory required for data: 320340480
I0122 19:14:42.156518 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:14:42.156525 70150 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:14:42.156529 70150 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:14:42.156534 70150 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.157393 70150 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:14:42.157399 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.157403 70150 net.cpp:159] Memory required for data: 337117696
I0122 19:14:42.157414 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:14:42.157421 70150 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:14:42.157424 70150 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:14:42.157428 70150 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.157446 70150 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:14:42.157451 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.157470 70150 net.cpp:159] Memory required for data: 353894912
I0122 19:14:42.157472 70150 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:14:42.157477 70150 net.cpp:94] Creating Layer inception_2a/output
I0122 19:14:42.157480 70150 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:14:42.157485 70150 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:14:42.157488 70150 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:14:42.157507 70150 net.cpp:144] Setting up inception_2a/output
I0122 19:14:42.157513 70150 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:14:42.157516 70150 net.cpp:159] Memory required for data: 387449344
I0122 19:14:42.157518 70150 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.157522 70150 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.157526 70150 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:14:42.157531 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.157537 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.157565 70150 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.157570 70150 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:14:42.157575 70150 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:14:42.157577 70150 net.cpp:159] Memory required for data: 454558208
I0122 19:14:42.157580 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:14:42.157588 70150 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:14:42.157590 70150 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.157595 70150 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:14:42.157825 70150 net.cpp:144] Setting up inception_3a/1x1
I0122 19:14:42.157832 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.157835 70150 net.cpp:159] Memory required for data: 471335424
I0122 19:14:42.157840 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:14:42.157846 70150 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:14:42.157850 70150 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:14:42.157855 70150 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.158495 70150 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:14:42.158502 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.158506 70150 net.cpp:159] Memory required for data: 488112640
I0122 19:14:42.158514 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:14:42.158519 70150 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:14:42.158522 70150 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:14:42.158527 70150 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.158533 70150 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:14:42.158538 70150 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:14:42.158541 70150 net.cpp:159] Memory required for data: 504889856
I0122 19:14:42.158545 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:14:42.158553 70150 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:14:42.158556 70150 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.158562 70150 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:14:42.158939 70150 net.cpp:144] Setting up inception_3a/3x3
I0122 19:14:42.158946 70150 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:14:42.158949 70150 net.cpp:159] Memory required for data: 530055680
I0122 19:14:42.158963 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:14:42.158970 70150 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:14:42.158973 70150 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:14:42.158978 70150 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.159631 70150 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:14:42.159637 70150 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:14:42.159641 70150 net.cpp:159] Memory required for data: 555221504
I0122 19:14:42.159651 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:14:42.159657 70150 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:14:42.159662 70150 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:14:42.159665 70150 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.159672 70150 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:14:42.159677 70150 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:14:42.159680 70150 net.cpp:159] Memory required for data: 580387328
I0122 19:14:42.159682 70150 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:14:42.159687 70150 net.cpp:94] Creating Layer inception_3a/output
I0122 19:14:42.159689 70150 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:14:42.159694 70150 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:14:42.159699 70150 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:14:42.159718 70150 net.cpp:144] Setting up inception_3a/output
I0122 19:14:42.159724 70150 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:14:42.159727 70150 net.cpp:159] Memory required for data: 622330368
I0122 19:14:42.159730 70150 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.159735 70150 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.159739 70150 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:14:42.159744 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.159750 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.159778 70150 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.159785 70150 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:14:42.159788 70150 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:14:42.159790 70150 net.cpp:159] Memory required for data: 706216448
I0122 19:14:42.159793 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:14:42.159801 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:14:42.159806 70150 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.159811 70150 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:14:42.160526 70150 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:14:42.160533 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.160537 70150 net.cpp:159] Memory required for data: 716702208
I0122 19:14:42.160543 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:14:42.160552 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:14:42.160557 70150 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:14:42.160563 70150 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.161218 70150 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:14:42.161224 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.161228 70150 net.cpp:159] Memory required for data: 727187968
I0122 19:14:42.161237 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:14:42.161240 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:14:42.161243 70150 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:14:42.161258 70150 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.161265 70150 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:14:42.161269 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.161272 70150 net.cpp:159] Memory required for data: 737673728
I0122 19:14:42.161274 70150 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:14:42.161281 70150 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:14:42.161284 70150 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.161290 70150 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:14:42.161331 70150 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:14:42.161339 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.161340 70150 net.cpp:159] Memory required for data: 748159488
I0122 19:14:42.161343 70150 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:14:42.161348 70150 net.cpp:94] Creating Layer downsample_4/output
I0122 19:14:42.161352 70150 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:14:42.161355 70150 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:14:42.161365 70150 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:14:42.161383 70150 net.cpp:144] Setting up downsample_4/output
I0122 19:14:42.161389 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.161392 70150 net.cpp:159] Memory required for data: 769131008
I0122 19:14:42.161396 70150 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.161399 70150 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.161402 70150 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:14:42.161408 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.161414 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.161443 70150 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.161450 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.161453 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.161458 70150 net.cpp:159] Memory required for data: 811074048
I0122 19:14:42.161460 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:14:42.161469 70150 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:14:42.161473 70150 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.161478 70150 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:14:42.161831 70150 net.cpp:144] Setting up inception_5a/1x1
I0122 19:14:42.161839 70150 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:14:42.161841 70150 net.cpp:159] Memory required for data: 825754112
I0122 19:14:42.161847 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:14:42.161855 70150 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:14:42.161861 70150 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:14:42.161866 70150 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.162623 70150 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:14:42.162631 70150 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:14:42.162634 70150 net.cpp:159] Memory required for data: 840434176
I0122 19:14:42.162642 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:14:42.162648 70150 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:14:42.162653 70150 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:14:42.162658 70150 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.162664 70150 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:14:42.162668 70150 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:14:42.162679 70150 net.cpp:159] Memory required for data: 855114240
I0122 19:14:42.162683 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:14:42.162691 70150 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:14:42.162696 70150 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.162703 70150 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:14:42.163427 70150 net.cpp:144] Setting up inception_5a/3x3
I0122 19:14:42.163435 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.163437 70150 net.cpp:159] Memory required for data: 861405696
I0122 19:14:42.163444 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:14:42.163453 70150 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:14:42.163460 70150 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:14:42.163465 70150 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.164132 70150 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:14:42.164140 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.164144 70150 net.cpp:159] Memory required for data: 867697152
I0122 19:14:42.164151 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:14:42.164160 70150 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:14:42.164165 70150 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:14:42.164170 70150 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.164175 70150 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:14:42.164180 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.164182 70150 net.cpp:159] Memory required for data: 873988608
I0122 19:14:42.164186 70150 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:14:42.164191 70150 net.cpp:94] Creating Layer inception_5a/output
I0122 19:14:42.164196 70150 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:14:42.164199 70150 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:14:42.164204 70150 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:14:42.164227 70150 net.cpp:144] Setting up inception_5a/output
I0122 19:14:42.164232 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.164235 70150 net.cpp:159] Memory required for data: 894960128
I0122 19:14:42.164237 70150 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.164242 70150 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.164245 70150 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:14:42.164252 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.164258 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.164288 70150 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.164294 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.164299 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.164301 70150 net.cpp:159] Memory required for data: 936903168
I0122 19:14:42.164304 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:14:42.164311 70150 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:14:42.164317 70150 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.164324 70150 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:14:42.165309 70150 net.cpp:144] Setting up inception_6a/1x1
I0122 19:14:42.165319 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.165323 70150 net.cpp:159] Memory required for data: 949486080
I0122 19:14:42.165328 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:14:42.165336 70150 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:14:42.165350 70150 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:14:42.165359 70150 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.166234 70150 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:14:42.166241 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.166244 70150 net.cpp:159] Memory required for data: 962068992
I0122 19:14:42.166254 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:14:42.166262 70150 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:14:42.166265 70150 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:14:42.166270 70150 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.166280 70150 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:14:42.166285 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.166288 70150 net.cpp:159] Memory required for data: 974651904
I0122 19:14:42.166290 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:14:42.166302 70150 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:14:42.166307 70150 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.166313 70150 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:14:42.167083 70150 net.cpp:144] Setting up inception_6a/3x3
I0122 19:14:42.167093 70150 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:14:42.167094 70150 net.cpp:159] Memory required for data: 983040512
I0122 19:14:42.167106 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:14:42.167117 70150 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:14:42.167122 70150 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:14:42.167130 70150 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.167791 70150 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:14:42.167798 70150 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:14:42.167801 70150 net.cpp:159] Memory required for data: 991429120
I0122 19:14:42.167809 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:14:42.167815 70150 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:14:42.167819 70150 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:14:42.167824 70150 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.167829 70150 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:14:42.167834 70150 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:14:42.167837 70150 net.cpp:159] Memory required for data: 999817728
I0122 19:14:42.167840 70150 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:14:42.167846 70150 net.cpp:94] Creating Layer inception_6a/output
I0122 19:14:42.167851 70150 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:14:42.167855 70150 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:14:42.167860 70150 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:14:42.167879 70150 net.cpp:144] Setting up inception_6a/output
I0122 19:14:42.167886 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.167887 70150 net.cpp:159] Memory required for data: 1020789248
I0122 19:14:42.167891 70150 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.167897 70150 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.167901 70150 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:14:42.167906 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.167912 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.167942 70150 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.167948 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.167960 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.167963 70150 net.cpp:159] Memory required for data: 1062732288
I0122 19:14:42.167965 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:14:42.167976 70150 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:14:42.167981 70150 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.167986 70150 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:14:42.168411 70150 net.cpp:144] Setting up inception_7a/1x1
I0122 19:14:42.168419 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.168423 70150 net.cpp:159] Memory required for data: 1073218048
I0122 19:14:42.168428 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:14:42.168437 70150 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:14:42.168439 70150 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:14:42.168445 70150 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.169121 70150 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:14:42.169127 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.169131 70150 net.cpp:159] Memory required for data: 1083703808
I0122 19:14:42.169138 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:14:42.169144 70150 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:14:42.169147 70150 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:14:42.169152 70150 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.169157 70150 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:14:42.169162 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.169164 70150 net.cpp:159] Memory required for data: 1094189568
I0122 19:14:42.169167 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:14:42.169178 70150 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:14:42.169185 70150 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.169193 70150 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:14:42.170140 70150 net.cpp:144] Setting up inception_7a/3x3
I0122 19:14:42.170148 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.170151 70150 net.cpp:159] Memory required for data: 1104675328
I0122 19:14:42.170156 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:14:42.170166 70150 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:14:42.170168 70150 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:14:42.170176 70150 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.171054 70150 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:14:42.171061 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.171063 70150 net.cpp:159] Memory required for data: 1115161088
I0122 19:14:42.171072 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:14:42.171077 70150 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:14:42.171080 70150 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:14:42.171087 70150 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.171092 70150 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:14:42.171098 70150 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:14:42.171100 70150 net.cpp:159] Memory required for data: 1125646848
I0122 19:14:42.171103 70150 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:14:42.171108 70150 net.cpp:94] Creating Layer inception_7a/output
I0122 19:14:42.171111 70150 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:14:42.171115 70150 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:14:42.171120 70150 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:14:42.171144 70150 net.cpp:144] Setting up inception_7a/output
I0122 19:14:42.171150 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.171162 70150 net.cpp:159] Memory required for data: 1146618368
I0122 19:14:42.171165 70150 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.171172 70150 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.171175 70150 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:14:42.171191 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.171209 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.171241 70150 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.171245 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.171249 70150 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:14:42.171252 70150 net.cpp:159] Memory required for data: 1188561408
I0122 19:14:42.171254 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:14:42.171264 70150 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:14:42.171268 70150 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.171274 70150 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:14:42.171552 70150 net.cpp:144] Setting up inception_8a/1x1
I0122 19:14:42.171560 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.171561 70150 net.cpp:159] Memory required for data: 1194852864
I0122 19:14:42.171566 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:14:42.171574 70150 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:14:42.171577 70150 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:14:42.171583 70150 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.172258 70150 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:14:42.172267 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.172269 70150 net.cpp:159] Memory required for data: 1201144320
I0122 19:14:42.172277 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:14:42.172281 70150 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:14:42.172286 70150 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:14:42.172291 70150 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.172297 70150 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:14:42.172300 70150 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:14:42.172303 70150 net.cpp:159] Memory required for data: 1207435776
I0122 19:14:42.172307 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:14:42.172314 70150 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:14:42.172319 70150 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.172327 70150 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:14:42.174026 70150 net.cpp:144] Setting up inception_8a/3x3
I0122 19:14:42.174037 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.174041 70150 net.cpp:159] Memory required for data: 1220018688
I0122 19:14:42.174047 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:14:42.174057 70150 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:14:42.174062 70150 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:14:42.174070 70150 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.174759 70150 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:14:42.174767 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.174769 70150 net.cpp:159] Memory required for data: 1232601600
I0122 19:14:42.174777 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:14:42.174784 70150 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:14:42.174787 70150 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:14:42.174803 70150 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.174811 70150 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:14:42.174816 70150 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:14:42.174819 70150 net.cpp:159] Memory required for data: 1245184512
I0122 19:14:42.174821 70150 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:14:42.174826 70150 net.cpp:94] Creating Layer inception_8a/output
I0122 19:14:42.174829 70150 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:14:42.174834 70150 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:14:42.174840 70150 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:14:42.174860 70150 net.cpp:144] Setting up inception_8a/output
I0122 19:14:42.174865 70150 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:14:42.174868 70150 net.cpp:159] Memory required for data: 1264058880
I0122 19:14:42.174870 70150 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.174875 70150 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.174880 70150 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:14:42.174887 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.174896 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.174926 70150 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.174932 70150 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:14:42.174935 70150 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:14:42.174938 70150 net.cpp:159] Memory required for data: 1301807616
I0122 19:14:42.174940 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:14:42.174950 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:14:42.174955 70150 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.174962 70150 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:14:42.175921 70150 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:14:42.175930 70150 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:14:42.175933 70150 net.cpp:159] Memory required for data: 1304953344
I0122 19:14:42.175938 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:14:42.175947 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:14:42.175953 70150 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:14:42.175961 70150 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.176642 70150 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:14:42.176650 70150 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:14:42.176652 70150 net.cpp:159] Memory required for data: 1308099072
I0122 19:14:42.176661 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:14:42.176666 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:14:42.176668 70150 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:14:42.176676 70150 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.176683 70150 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:14:42.176687 70150 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:14:42.176690 70150 net.cpp:159] Memory required for data: 1311244800
I0122 19:14:42.176693 70150 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:14:42.176698 70150 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:14:42.176702 70150 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.176708 70150 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:14:42.176740 70150 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:14:42.176757 70150 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 19:14:42.176760 70150 net.cpp:159] Memory required for data: 1315963392
I0122 19:14:42.176764 70150 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:14:42.176769 70150 net.cpp:94] Creating Layer downsample_9/output
I0122 19:14:42.176771 70150 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:14:42.176775 70150 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:14:42.176781 70150 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:14:42.176800 70150 net.cpp:144] Setting up downsample_9/output
I0122 19:14:42.176805 70150 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:14:42.176807 70150 net.cpp:159] Memory required for data: 1323827712
I0122 19:14:42.176810 70150 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.176821 70150 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.176826 70150 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:14:42.176831 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.176837 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.176868 70150 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.176874 70150 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:14:42.176877 70150 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:14:42.176880 70150 net.cpp:159] Memory required for data: 1339556352
I0122 19:14:42.176884 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:14:42.176893 70150 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:14:42.176898 70150 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.176905 70150 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:14:42.177371 70150 net.cpp:144] Setting up inception_10a/1x1
I0122 19:14:42.177378 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.177381 70150 net.cpp:159] Memory required for data: 1345323520
I0122 19:14:42.177386 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:14:42.177393 70150 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:14:42.177398 70150 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:14:42.177405 70150 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.178077 70150 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:14:42.178086 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.178088 70150 net.cpp:159] Memory required for data: 1351090688
I0122 19:14:42.178095 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:14:42.178102 70150 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:14:42.178104 70150 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:14:42.178109 70150 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.178115 70150 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:14:42.178120 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.178124 70150 net.cpp:159] Memory required for data: 1356857856
I0122 19:14:42.178126 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:14:42.178134 70150 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:14:42.178138 70150 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.178144 70150 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:14:42.181342 70150 net.cpp:144] Setting up inception_10a/3x3
I0122 19:14:42.181354 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.181357 70150 net.cpp:159] Memory required for data: 1362100736
I0122 19:14:42.181362 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:14:42.181381 70150 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:14:42.181385 70150 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:14:42.181391 70150 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.182055 70150 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:14:42.182063 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.182066 70150 net.cpp:159] Memory required for data: 1367343616
I0122 19:14:42.182075 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:14:42.182081 70150 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:14:42.182086 70150 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:14:42.182091 70150 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.182098 70150 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:14:42.182104 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.182107 70150 net.cpp:159] Memory required for data: 1372586496
I0122 19:14:42.182109 70150 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:14:42.182116 70150 net.cpp:94] Creating Layer inception_10a/output
I0122 19:14:42.182119 70150 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:14:42.182122 70150 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:14:42.182127 70150 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:14:42.182147 70150 net.cpp:144] Setting up inception_10a/output
I0122 19:14:42.182152 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.182155 70150 net.cpp:159] Memory required for data: 1383596544
I0122 19:14:42.182158 70150 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.182163 70150 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.182168 70150 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:14:42.182173 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.182178 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.182206 70150 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.182212 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.182216 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.182219 70150 net.cpp:159] Memory required for data: 1405616640
I0122 19:14:42.182221 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:14:42.182231 70150 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:14:42.182236 70150 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.182241 70150 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:14:42.182804 70150 net.cpp:144] Setting up inception_11a/1x1
I0122 19:14:42.182811 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.182814 70150 net.cpp:159] Memory required for data: 1411383808
I0122 19:14:42.182821 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:14:42.182828 70150 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:14:42.182833 70150 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:14:42.182840 70150 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.183512 70150 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:14:42.183519 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.183522 70150 net.cpp:159] Memory required for data: 1417150976
I0122 19:14:42.183531 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:14:42.183534 70150 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:14:42.183537 70150 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:14:42.183553 70150 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.183560 70150 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:14:42.183564 70150 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:14:42.183568 70150 net.cpp:159] Memory required for data: 1422918144
I0122 19:14:42.183570 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:14:42.183579 70150 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:14:42.183584 70150 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.183590 70150 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:14:42.187325 70150 net.cpp:144] Setting up inception_11a/3x3
I0122 19:14:42.187336 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.187340 70150 net.cpp:159] Memory required for data: 1428161024
I0122 19:14:42.187345 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:14:42.187368 70150 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:14:42.187371 70150 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:14:42.187378 70150 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.188063 70150 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:14:42.188072 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.188076 70150 net.cpp:159] Memory required for data: 1433403904
I0122 19:14:42.188096 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:14:42.188102 70150 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:14:42.188107 70150 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:14:42.188110 70150 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.188117 70150 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:14:42.188120 70150 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:14:42.188123 70150 net.cpp:159] Memory required for data: 1438646784
I0122 19:14:42.188127 70150 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:14:42.188133 70150 net.cpp:94] Creating Layer inception_11a/output
I0122 19:14:42.188138 70150 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:14:42.188141 70150 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:14:42.188146 70150 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:14:42.188165 70150 net.cpp:144] Setting up inception_11a/output
I0122 19:14:42.188170 70150 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:14:42.188174 70150 net.cpp:159] Memory required for data: 1449656832
I0122 19:14:42.188175 70150 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:14:42.188181 70150 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:14:42.188184 70150 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:14:42.188191 70150 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:14:42.188215 70150 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:14:42.188220 70150 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:14:42.188223 70150 net.cpp:159] Memory required for data: 1449828864
I0122 19:14:42.188226 70150 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:14:42.188231 70150 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:14:42.188235 70150 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:14:42.188239 70150 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:14:42.188257 70150 net.cpp:144] Setting up drop_8x8_s1
I0122 19:14:42.188264 70150 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:14:42.188266 70150 net.cpp:159] Memory required for data: 1450000896
I0122 19:14:42.188269 70150 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:14:42.188275 70150 net.cpp:94] Creating Layer loss/classifier
I0122 19:14:42.188280 70150 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:14:42.188287 70150 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:14:42.188424 70150 net.cpp:144] Setting up loss/classifier
I0122 19:14:42.188439 70150 net.cpp:151] Top shape: 128 10 (1280)
I0122 19:14:42.188442 70150 net.cpp:159] Memory required for data: 1450006016
I0122 19:14:42.188447 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.188453 70150 net.cpp:94] Creating Layer loss
I0122 19:14:42.188459 70150 net.cpp:435] loss <- loss/classifier
I0122 19:14:42.188462 70150 net.cpp:435] loss <- label
I0122 19:14:42.188467 70150 net.cpp:409] loss -> loss
I0122 19:14:42.188474 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.188550 70150 net.cpp:144] Setting up loss
I0122 19:14:42.188556 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.188560 70150 net.cpp:154]     with loss weight 1
I0122 19:14:42.188568 70150 net.cpp:159] Memory required for data: 1450006020
I0122 19:14:42.188572 70150 net.cpp:220] loss needs backward computation.
I0122 19:14:42.188580 70150 net.cpp:220] loss/classifier needs backward computation.
I0122 19:14:42.188583 70150 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:14:42.188586 70150 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:14:42.188591 70150 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:14:42.188593 70150 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:14:42.188596 70150 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:14:42.188598 70150 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:14:42.188602 70150 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:14:42.188604 70150 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:14:42.188607 70150 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:14:42.188611 70150 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:14:42.188614 70150 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:14:42.188617 70150 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:14:42.188621 70150 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:14:42.188623 70150 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:14:42.188627 70150 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:14:42.188629 70150 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:14:42.188632 70150 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:14:42.188635 70150 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:14:42.188639 70150 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:14:42.188642 70150 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:14:42.188645 70150 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.188648 70150 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.188652 70150 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:14:42.188654 70150 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:14:42.188657 70150 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:14:42.188661 70150 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:14:42.188664 70150 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:14:42.188668 70150 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:14:42.188670 70150 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:14:42.188673 70150 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:14:42.188678 70150 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:14:42.188680 70150 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:14:42.188683 70150 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:14:42.188688 70150 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:14:42.188697 70150 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:14:42.188700 70150 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:14:42.188704 70150 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:14:42.188706 70150 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:14:42.188710 70150 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:14:42.188714 70150 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:14:42.188717 70150 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:14:42.188721 70150 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:14:42.188724 70150 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:14:42.188729 70150 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:14:42.188730 70150 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:14:42.188733 70150 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:14:42.188737 70150 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:14:42.188740 70150 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:14:42.188743 70150 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:14:42.188747 70150 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:14:42.188750 70150 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:14:42.188753 70150 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:14:42.188756 70150 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:14:42.188760 70150 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:14:42.188762 70150 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:14:42.188766 70150 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:14:42.188769 70150 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:14:42.188773 70150 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:14:42.188777 70150 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.188779 70150 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.188782 70150 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:14:42.188787 70150 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:14:42.188791 70150 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:14:42.188796 70150 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:14:42.188798 70150 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:14:42.188800 70150 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:14:42.188804 70150 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:14:42.188807 70150 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:14:42.188810 70150 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:14:42.188813 70150 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:14:42.188817 70150 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:14:42.188820 70150 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:14:42.188823 70150 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:14:42.188827 70150 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:14:42.188829 70150 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:14:42.188832 70150 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:14:42.188835 70150 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:14:42.188838 70150 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:14:42.188848 70150 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:14:42.188851 70150 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:14:42.188853 70150 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:14:42.188858 70150 net.cpp:222] data does not need backward computation.
I0122 19:14:42.188861 70150 net.cpp:264] This network produces output loss
I0122 19:14:42.188923 70150 net.cpp:284] Network initialization done.
I0122 19:14:42.189815 70150 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/net_finetune.prototxt
I0122 19:14:42.189896 70150 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 19:14:42.190554 70150 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 19:14:42.190876 70150 layer_factory.hpp:77] Creating layer data
I0122 19:14:42.190917 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.191743 70150 net.cpp:94] Creating Layer data
I0122 19:14:42.191753 70150 net.cpp:409] data -> data
I0122 19:14:42.191761 70150 net.cpp:409] data -> label
I0122 19:14:42.192740 70219 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 19:14:42.192773 70219 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 19:14:42.192869 70150 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 19:14:42.192966 70150 data_layer.cpp:83] output data size: 50,3,32,32
I0122 19:14:42.195981 70150 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:14:42.196034 70150 net.cpp:144] Setting up data
I0122 19:14:42.196043 70150 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 19:14:42.196045 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196048 70150 net.cpp:159] Memory required for data: 614600
I0122 19:14:42.196051 70150 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 19:14:42.196059 70150 net.cpp:94] Creating Layer label_data_1_split
I0122 19:14:42.196066 70150 net.cpp:435] label_data_1_split <- label
I0122 19:14:42.196074 70150 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 19:14:42.196081 70150 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 19:14:42.196090 70150 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 19:14:42.196096 70150 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 19:14:42.196207 70150 net.cpp:144] Setting up label_data_1_split
I0122 19:14:42.196213 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196216 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196219 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196223 70150 net.cpp:151] Top shape: 50 (50)
I0122 19:14:42.196224 70150 net.cpp:159] Memory required for data: 615400
I0122 19:14:42.196228 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:14:42.196238 70150 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:14:42.196243 70150 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:14:42.196249 70150 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:14:42.196609 70150 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:14:42.196614 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.196617 70150 net.cpp:159] Memory required for data: 20276200
I0122 19:14:42.196625 70150 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:14:42.196633 70150 net.cpp:94] Creating Layer conv1/bn1
I0122 19:14:42.196636 70150 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:14:42.196651 70150 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.197336 70150 net.cpp:144] Setting up conv1/bn1
I0122 19:14:42.197346 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197348 70150 net.cpp:159] Memory required for data: 39937000
I0122 19:14:42.197360 70150 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:14:42.197366 70150 net.cpp:94] Creating Layer conv1/relu1
I0122 19:14:42.197371 70150 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:14:42.197376 70150 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:14:42.197381 70150 net.cpp:144] Setting up conv1/relu1
I0122 19:14:42.197384 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197387 70150 net.cpp:159] Memory required for data: 59597800
I0122 19:14:42.197389 70150 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.197394 70150 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.197397 70150 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:14:42.197402 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.197408 70150 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.197439 70150 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:14:42.197444 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197449 70150 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:14:42.197451 70150 net.cpp:159] Memory required for data: 98919400
I0122 19:14:42.197453 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:14:42.197461 70150 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:14:42.197468 70150 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:14:42.197474 70150 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:14:42.198083 70150 net.cpp:144] Setting up inception_2a/1x1
I0122 19:14:42.198091 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.198094 70150 net.cpp:159] Memory required for data: 105473000
I0122 19:14:42.198102 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:14:42.198109 70150 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:14:42.198114 70150 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:14:42.198122 70150 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.198987 70150 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:14:42.198994 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.198997 70150 net.cpp:159] Memory required for data: 112026600
I0122 19:14:42.199005 70150 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:14:42.199012 70150 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:14:42.199017 70150 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:14:42.199023 70150 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:14:42.199029 70150 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:14:42.199035 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.199038 70150 net.cpp:159] Memory required for data: 118580200
I0122 19:14:42.199040 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:14:42.199049 70150 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:14:42.199054 70150 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:14:42.199061 70150 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:14:42.199514 70150 net.cpp:144] Setting up inception_2a/3x3
I0122 19:14:42.199522 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.199525 70150 net.cpp:159] Memory required for data: 125133800
I0122 19:14:42.199530 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:14:42.199537 70150 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:14:42.199542 70150 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:14:42.199558 70150 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.200270 70150 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:14:42.200278 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.200282 70150 net.cpp:159] Memory required for data: 131687400
I0122 19:14:42.200294 70150 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:14:42.200306 70150 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:14:42.200312 70150 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:14:42.200317 70150 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:14:42.200323 70150 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:14:42.200326 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.200330 70150 net.cpp:159] Memory required for data: 138241000
I0122 19:14:42.200332 70150 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:14:42.200337 70150 net.cpp:94] Creating Layer inception_2a/output
I0122 19:14:42.200340 70150 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:14:42.200343 70150 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:14:42.200350 70150 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:14:42.200371 70150 net.cpp:144] Setting up inception_2a/output
I0122 19:14:42.200376 70150 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:42.200378 70150 net.cpp:159] Memory required for data: 151348200
I0122 19:14:42.200381 70150 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.200387 70150 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.200389 70150 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:14:42.200395 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.200402 70150 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.200438 70150 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:14:42.200443 70150 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:42.200448 70150 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:14:42.200450 70150 net.cpp:159] Memory required for data: 177562600
I0122 19:14:42.200454 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:14:42.200464 70150 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:14:42.200467 70150 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:14:42.200476 70150 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:14:42.200803 70150 net.cpp:144] Setting up inception_3a/1x1
I0122 19:14:42.200810 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.200814 70150 net.cpp:159] Memory required for data: 184116200
I0122 19:14:42.200819 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:14:42.200827 70150 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:14:42.200830 70150 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:14:42.200837 70150 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.201571 70150 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:14:42.201577 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.201581 70150 net.cpp:159] Memory required for data: 190669800
I0122 19:14:42.201587 70150 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:14:42.201596 70150 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:14:42.201601 70150 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:14:42.201607 70150 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:14:42.201613 70150 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:14:42.201622 70150 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:14:42.201625 70150 net.cpp:159] Memory required for data: 197223400
I0122 19:14:42.201637 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:14:42.201647 70150 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:14:42.201651 70150 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:14:42.201658 70150 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:14:42.202730 70150 net.cpp:144] Setting up inception_3a/3x3
I0122 19:14:42.202744 70150 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:42.202747 70150 net.cpp:159] Memory required for data: 207053800
I0122 19:14:42.202754 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:14:42.202761 70150 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:14:42.202767 70150 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:14:42.202776 70150 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.203550 70150 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:14:42.203557 70150 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:42.203559 70150 net.cpp:159] Memory required for data: 216884200
I0122 19:14:42.203573 70150 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:14:42.203583 70150 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:14:42.203585 70150 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:14:42.203591 70150 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:14:42.203598 70150 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:14:42.203606 70150 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:14:42.203609 70150 net.cpp:159] Memory required for data: 226714600
I0122 19:14:42.203613 70150 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:14:42.203629 70150 net.cpp:94] Creating Layer inception_3a/output
I0122 19:14:42.203634 70150 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:14:42.203637 70150 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:14:42.203641 70150 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:14:42.203716 70150 net.cpp:144] Setting up inception_3a/output
I0122 19:14:42.203722 70150 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:42.203724 70150 net.cpp:159] Memory required for data: 243098600
I0122 19:14:42.203727 70150 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.203733 70150 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.203737 70150 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:14:42.203742 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.203748 70150 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.203780 70150 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:14:42.203785 70150 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:42.203789 70150 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:14:42.203791 70150 net.cpp:159] Memory required for data: 275866600
I0122 19:14:42.203794 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:14:42.203804 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:14:42.203807 70150 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:14:42.203814 70150 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:14:42.204380 70150 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:14:42.204387 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.204390 70150 net.cpp:159] Memory required for data: 279962600
I0122 19:14:42.204394 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:14:42.204402 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:14:42.204406 70150 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:14:42.204425 70150 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.205252 70150 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:14:42.205260 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.205262 70150 net.cpp:159] Memory required for data: 284058600
I0122 19:14:42.205271 70150 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:14:42.205279 70150 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:14:42.205283 70150 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:14:42.205287 70150 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:14:42.205293 70150 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:14:42.205299 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.205303 70150 net.cpp:159] Memory required for data: 288154600
I0122 19:14:42.205305 70150 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:14:42.205312 70150 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:14:42.205315 70150 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:14:42.205320 70150 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:14:42.205360 70150 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:14:42.205365 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.205368 70150 net.cpp:159] Memory required for data: 292250600
I0122 19:14:42.205371 70150 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:14:42.205379 70150 net.cpp:94] Creating Layer downsample_4/output
I0122 19:14:42.205382 70150 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:14:42.205385 70150 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:14:42.205391 70150 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:14:42.205422 70150 net.cpp:144] Setting up downsample_4/output
I0122 19:14:42.205427 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.205430 70150 net.cpp:159] Memory required for data: 300442600
I0122 19:14:42.205433 70150 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.205440 70150 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.205443 70150 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:14:42.205447 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.205454 70150 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.205484 70150 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:14:42.205489 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.205493 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.205497 70150 net.cpp:159] Memory required for data: 316826600
I0122 19:14:42.205498 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:14:42.205508 70150 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:14:42.205513 70150 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:14:42.205518 70150 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:14:42.205868 70150 net.cpp:144] Setting up inception_5a/1x1
I0122 19:14:42.205874 70150 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:42.205878 70150 net.cpp:159] Memory required for data: 322561000
I0122 19:14:42.205883 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:14:42.205890 70150 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:14:42.205893 70150 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:14:42.205899 70150 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.206701 70150 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:14:42.206717 70150 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:42.206718 70150 net.cpp:159] Memory required for data: 328295400
I0122 19:14:42.206727 70150 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:14:42.206733 70150 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:14:42.206745 70150 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:14:42.206753 70150 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:14:42.206758 70150 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:14:42.206768 70150 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:14:42.206769 70150 net.cpp:159] Memory required for data: 334029800
I0122 19:14:42.206773 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:14:42.206781 70150 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:14:42.206787 70150 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:14:42.206794 70150 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:14:42.207470 70150 net.cpp:144] Setting up inception_5a/3x3
I0122 19:14:42.207478 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.207481 70150 net.cpp:159] Memory required for data: 336487400
I0122 19:14:42.207486 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:14:42.207499 70150 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:14:42.207505 70150 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:14:42.207514 70150 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.208293 70150 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:14:42.208299 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.208302 70150 net.cpp:159] Memory required for data: 338945000
I0122 19:14:42.208310 70150 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:14:42.208315 70150 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:14:42.208318 70150 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:14:42.208334 70150 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:14:42.208340 70150 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:14:42.208354 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.208357 70150 net.cpp:159] Memory required for data: 341402600
I0122 19:14:42.208359 70150 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:14:42.208364 70150 net.cpp:94] Creating Layer inception_5a/output
I0122 19:14:42.208367 70150 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:14:42.208370 70150 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:14:42.208377 70150 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:14:42.208401 70150 net.cpp:144] Setting up inception_5a/output
I0122 19:14:42.208406 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.208410 70150 net.cpp:159] Memory required for data: 349594600
I0122 19:14:42.208411 70150 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.208417 70150 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.208421 70150 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:14:42.208426 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.208436 70150 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.208508 70150 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:14:42.208514 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.208518 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.208520 70150 net.cpp:159] Memory required for data: 365978600
I0122 19:14:42.208523 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:14:42.208541 70150 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:14:42.208544 70150 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:14:42.208551 70150 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:14:42.208897 70150 net.cpp:144] Setting up inception_6a/1x1
I0122 19:14:42.208904 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.208906 70150 net.cpp:159] Memory required for data: 370893800
I0122 19:14:42.208911 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:14:42.208921 70150 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:14:42.208925 70150 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:14:42.208930 70150 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.209705 70150 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:14:42.209713 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.209715 70150 net.cpp:159] Memory required for data: 375809000
I0122 19:14:42.209723 70150 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:14:42.209729 70150 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:14:42.209733 70150 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:14:42.209738 70150 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:14:42.209744 70150 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:14:42.209748 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.209751 70150 net.cpp:159] Memory required for data: 380724200
I0122 19:14:42.209753 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:14:42.209762 70150 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:14:42.209769 70150 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:14:42.209774 70150 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:14:42.211207 70150 net.cpp:144] Setting up inception_6a/3x3
I0122 19:14:42.211220 70150 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:42.211223 70150 net.cpp:159] Memory required for data: 384001000
I0122 19:14:42.211236 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:14:42.211246 70150 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:14:42.211256 70150 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:14:42.211262 70150 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.212087 70150 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:14:42.212095 70150 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:42.212098 70150 net.cpp:159] Memory required for data: 387277800
I0122 19:14:42.212106 70150 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:14:42.212112 70150 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:14:42.212116 70150 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:14:42.212121 70150 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:14:42.212128 70150 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:14:42.212134 70150 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:14:42.212137 70150 net.cpp:159] Memory required for data: 390554600
I0122 19:14:42.212141 70150 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:14:42.212146 70150 net.cpp:94] Creating Layer inception_6a/output
I0122 19:14:42.212148 70150 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:14:42.212152 70150 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:14:42.212158 70150 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:14:42.212177 70150 net.cpp:144] Setting up inception_6a/output
I0122 19:14:42.212183 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.212186 70150 net.cpp:159] Memory required for data: 398746600
I0122 19:14:42.212189 70150 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.212193 70150 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.212206 70150 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:14:42.212213 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.212220 70150 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.212251 70150 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:14:42.212258 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.212262 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.212265 70150 net.cpp:159] Memory required for data: 415130600
I0122 19:14:42.212267 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:14:42.212276 70150 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:14:42.212280 70150 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:14:42.212285 70150 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:14:42.212599 70150 net.cpp:144] Setting up inception_7a/1x1
I0122 19:14:42.212605 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.212607 70150 net.cpp:159] Memory required for data: 419226600
I0122 19:14:42.212612 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:14:42.212620 70150 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:14:42.212625 70150 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:14:42.212632 70150 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.213335 70150 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:14:42.213342 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.213346 70150 net.cpp:159] Memory required for data: 423322600
I0122 19:14:42.213353 70150 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:14:42.213361 70150 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:14:42.213364 70150 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:14:42.213369 70150 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:14:42.213376 70150 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:14:42.213378 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.213382 70150 net.cpp:159] Memory required for data: 427418600
I0122 19:14:42.213384 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:14:42.213392 70150 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:14:42.213397 70150 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:14:42.213403 70150 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:14:42.214288 70150 net.cpp:144] Setting up inception_7a/3x3
I0122 19:14:42.214298 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.214300 70150 net.cpp:159] Memory required for data: 431514600
I0122 19:14:42.214305 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:14:42.214313 70150 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:14:42.214316 70150 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:14:42.214323 70150 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.215016 70150 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:14:42.215025 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.215029 70150 net.cpp:159] Memory required for data: 435610600
I0122 19:14:42.215036 70150 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:14:42.215040 70150 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:14:42.215044 70150 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:14:42.215049 70150 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:14:42.215054 70150 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:14:42.215059 70150 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:14:42.215061 70150 net.cpp:159] Memory required for data: 439706600
I0122 19:14:42.215073 70150 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:14:42.215080 70150 net.cpp:94] Creating Layer inception_7a/output
I0122 19:14:42.215081 70150 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:14:42.215086 70150 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:14:42.215090 70150 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:14:42.215114 70150 net.cpp:144] Setting up inception_7a/output
I0122 19:14:42.215119 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.215123 70150 net.cpp:159] Memory required for data: 447898600
I0122 19:14:42.215126 70150 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.215131 70150 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.215134 70150 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:14:42.215139 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.215147 70150 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.215178 70150 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:14:42.215184 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.215188 70150 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:14:42.215190 70150 net.cpp:159] Memory required for data: 464282600
I0122 19:14:42.215193 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:14:42.215201 70150 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:14:42.215206 70150 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:14:42.215212 70150 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:14:42.215497 70150 net.cpp:144] Setting up inception_8a/1x1
I0122 19:14:42.215502 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.215507 70150 net.cpp:159] Memory required for data: 466740200
I0122 19:14:42.215510 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:14:42.215518 70150 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:14:42.215521 70150 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:14:42.215528 70150 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.216217 70150 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:14:42.216223 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.216226 70150 net.cpp:159] Memory required for data: 469197800
I0122 19:14:42.216234 70150 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:14:42.216238 70150 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:14:42.216241 70150 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:14:42.216248 70150 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:14:42.216258 70150 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:14:42.216260 70150 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:14:42.216264 70150 net.cpp:159] Memory required for data: 471655400
I0122 19:14:42.216265 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:14:42.216274 70150 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:14:42.216277 70150 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:14:42.216284 70150 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:14:42.217921 70150 net.cpp:144] Setting up inception_8a/3x3
I0122 19:14:42.217931 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.217934 70150 net.cpp:159] Memory required for data: 476570600
I0122 19:14:42.217939 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:14:42.217948 70150 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:14:42.217952 70150 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:14:42.217968 70150 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.218691 70150 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:14:42.218698 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.218703 70150 net.cpp:159] Memory required for data: 481485800
I0122 19:14:42.218709 70150 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:14:42.218716 70150 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:14:42.218719 70150 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:14:42.218725 70150 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:14:42.218732 70150 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:14:42.218737 70150 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:14:42.218740 70150 net.cpp:159] Memory required for data: 486401000
I0122 19:14:42.218744 70150 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:14:42.218749 70150 net.cpp:94] Creating Layer inception_8a/output
I0122 19:14:42.218750 70150 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:14:42.218755 70150 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:14:42.218761 70150 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:14:42.218780 70150 net.cpp:144] Setting up inception_8a/output
I0122 19:14:42.218786 70150 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:42.218788 70150 net.cpp:159] Memory required for data: 493773800
I0122 19:14:42.218792 70150 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.218796 70150 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.218799 70150 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:14:42.218806 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.218812 70150 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.218842 70150 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:14:42.218847 70150 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:42.218852 70150 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:14:42.218855 70150 net.cpp:159] Memory required for data: 508519400
I0122 19:14:42.218858 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:14:42.218866 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:14:42.218871 70150 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:14:42.218878 70150 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:14:42.220443 70150 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:14:42.220453 70150 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:42.220455 70150 net.cpp:159] Memory required for data: 509748200
I0122 19:14:42.220461 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:14:42.220469 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:14:42.220474 70150 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:14:42.220479 70150 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.221211 70150 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:14:42.221218 70150 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:42.221222 70150 net.cpp:159] Memory required for data: 510977000
I0122 19:14:42.221230 70150 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:14:42.221235 70150 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:14:42.221238 70150 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:14:42.221244 70150 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:14:42.221251 70150 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:14:42.221264 70150 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:14:42.221266 70150 net.cpp:159] Memory required for data: 512205800
I0122 19:14:42.221269 70150 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:14:42.221276 70150 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:14:42.221282 70150 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:14:42.221287 70150 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:14:42.221320 70150 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:14:42.221326 70150 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 19:14:42.221329 70150 net.cpp:159] Memory required for data: 514049000
I0122 19:14:42.221333 70150 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:14:42.221341 70150 net.cpp:94] Creating Layer downsample_9/output
I0122 19:14:42.221345 70150 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:14:42.221350 70150 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:14:42.221355 70150 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:14:42.221372 70150 net.cpp:144] Setting up downsample_9/output
I0122 19:14:42.221377 70150 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:42.221381 70150 net.cpp:159] Memory required for data: 517121000
I0122 19:14:42.221385 70150 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.221390 70150 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.221392 70150 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:14:42.221398 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.221405 70150 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.221436 70150 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:14:42.221442 70150 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:42.221446 70150 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:14:42.221448 70150 net.cpp:159] Memory required for data: 523265000
I0122 19:14:42.221451 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:14:42.221460 70150 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:14:42.221465 70150 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:14:42.221472 70150 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:14:42.221956 70150 net.cpp:144] Setting up inception_10a/1x1
I0122 19:14:42.221963 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.221967 70150 net.cpp:159] Memory required for data: 525517800
I0122 19:14:42.221972 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:14:42.221981 70150 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:14:42.221984 70150 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:14:42.221992 70150 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.222699 70150 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:14:42.222707 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.222709 70150 net.cpp:159] Memory required for data: 527770600
I0122 19:14:42.222718 70150 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:14:42.222723 70150 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:14:42.222729 70150 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:14:42.222734 70150 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:14:42.222743 70150 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:14:42.222748 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.222750 70150 net.cpp:159] Memory required for data: 530023400
I0122 19:14:42.222754 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:14:42.222770 70150 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:14:42.222775 70150 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:14:42.222782 70150 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:14:42.225301 70150 net.cpp:144] Setting up inception_10a/3x3
I0122 19:14:42.225311 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.225313 70150 net.cpp:159] Memory required for data: 532071400
I0122 19:14:42.225318 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:14:42.225325 70150 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:14:42.225329 70150 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:14:42.225335 70150 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.226068 70150 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:14:42.226075 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.226079 70150 net.cpp:159] Memory required for data: 534119400
I0122 19:14:42.226088 70150 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:14:42.226092 70150 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:14:42.226095 70150 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:14:42.226101 70150 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:14:42.226109 70150 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:14:42.226114 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.226116 70150 net.cpp:159] Memory required for data: 536167400
I0122 19:14:42.226119 70150 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:14:42.226125 70150 net.cpp:94] Creating Layer inception_10a/output
I0122 19:14:42.226127 70150 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:14:42.226130 70150 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:14:42.226138 70150 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:14:42.226161 70150 net.cpp:144] Setting up inception_10a/output
I0122 19:14:42.226166 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.226171 70150 net.cpp:159] Memory required for data: 540468200
I0122 19:14:42.226173 70150 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.226178 70150 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.226181 70150 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:14:42.226186 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.226193 70150 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.226225 70150 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:14:42.226231 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.226234 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.226238 70150 net.cpp:159] Memory required for data: 549069800
I0122 19:14:42.226240 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:14:42.226248 70150 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:14:42.226251 70150 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:14:42.226258 70150 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:14:42.226835 70150 net.cpp:144] Setting up inception_11a/1x1
I0122 19:14:42.226842 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.226845 70150 net.cpp:159] Memory required for data: 551322600
I0122 19:14:42.226851 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:14:42.226860 70150 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:14:42.226864 70150 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:14:42.226871 70150 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.227596 70150 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:14:42.227602 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.227605 70150 net.cpp:159] Memory required for data: 553575400
I0122 19:14:42.227613 70150 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:14:42.227619 70150 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:14:42.227622 70150 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:14:42.227628 70150 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:14:42.227634 70150 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:14:42.227640 70150 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:14:42.227643 70150 net.cpp:159] Memory required for data: 555828200
I0122 19:14:42.227645 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:14:42.227654 70150 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:14:42.227659 70150 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:14:42.227666 70150 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:14:42.231405 70150 net.cpp:144] Setting up inception_11a/3x3
I0122 19:14:42.231416 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.231420 70150 net.cpp:159] Memory required for data: 557876200
I0122 19:14:42.231425 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:14:42.231432 70150 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:14:42.231436 70150 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:14:42.231441 70150 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.232162 70150 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:14:42.232169 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.232173 70150 net.cpp:159] Memory required for data: 559924200
I0122 19:14:42.232197 70150 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:14:42.232204 70150 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:14:42.232208 70150 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:14:42.232213 70150 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:14:42.232219 70150 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:14:42.232223 70150 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:14:42.232225 70150 net.cpp:159] Memory required for data: 561972200
I0122 19:14:42.232228 70150 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:14:42.232234 70150 net.cpp:94] Creating Layer inception_11a/output
I0122 19:14:42.232235 70150 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:14:42.232239 70150 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:14:42.232246 70150 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:14:42.232265 70150 net.cpp:144] Setting up inception_11a/output
I0122 19:14:42.232271 70150 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:14:42.232273 70150 net.cpp:159] Memory required for data: 566273000
I0122 19:14:42.232276 70150 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:14:42.232283 70150 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:14:42.232286 70150 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:14:42.232292 70150 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:14:42.232311 70150 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:14:42.232317 70150 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:14:42.232319 70150 net.cpp:159] Memory required for data: 566340200
I0122 19:14:42.232322 70150 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:14:42.232328 70150 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:14:42.232332 70150 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:14:42.232338 70150 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:14:42.232359 70150 net.cpp:144] Setting up drop_8x8_s1
I0122 19:14:42.232363 70150 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:14:42.232376 70150 net.cpp:159] Memory required for data: 566407400
I0122 19:14:42.232379 70150 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:14:42.232386 70150 net.cpp:94] Creating Layer loss/classifier
I0122 19:14:42.232389 70150 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:14:42.232395 70150 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:14:42.232544 70150 net.cpp:144] Setting up loss/classifier
I0122 19:14:42.232550 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232553 70150 net.cpp:159] Memory required for data: 566409400
I0122 19:14:42.232558 70150 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 19:14:42.232564 70150 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 19:14:42.232568 70150 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 19:14:42.232573 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 19:14:42.232579 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 19:14:42.232586 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 19:14:42.232592 70150 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 19:14:42.232646 70150 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 19:14:42.232651 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232655 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232657 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232661 70150 net.cpp:151] Top shape: 50 10 (500)
I0122 19:14:42.232663 70150 net.cpp:159] Memory required for data: 566417400
I0122 19:14:42.232666 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.232671 70150 net.cpp:94] Creating Layer loss
I0122 19:14:42.232673 70150 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 19:14:42.232677 70150 net.cpp:435] loss <- label_data_1_split_0
I0122 19:14:42.232683 70150 net.cpp:409] loss -> loss
I0122 19:14:42.232690 70150 layer_factory.hpp:77] Creating layer loss
I0122 19:14:42.232772 70150 net.cpp:144] Setting up loss
I0122 19:14:42.232777 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232780 70150 net.cpp:154]     with loss weight 1
I0122 19:14:42.232791 70150 net.cpp:159] Memory required for data: 566417404
I0122 19:14:42.232795 70150 layer_factory.hpp:77] Creating layer accuracy
I0122 19:14:42.232800 70150 net.cpp:94] Creating Layer accuracy
I0122 19:14:42.232803 70150 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 19:14:42.232807 70150 net.cpp:435] accuracy <- label_data_1_split_1
I0122 19:14:42.232813 70150 net.cpp:409] accuracy -> accuracy
I0122 19:14:42.232825 70150 net.cpp:144] Setting up accuracy
I0122 19:14:42.232831 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232834 70150 net.cpp:159] Memory required for data: 566417408
I0122 19:14:42.232836 70150 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 19:14:42.232841 70150 net.cpp:94] Creating Layer accuracy-top1
I0122 19:14:42.232844 70150 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 19:14:42.232848 70150 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 19:14:42.232852 70150 net.cpp:409] accuracy-top1 -> top-1
I0122 19:14:42.232858 70150 net.cpp:144] Setting up accuracy-top1
I0122 19:14:42.232861 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232864 70150 net.cpp:159] Memory required for data: 566417412
I0122 19:14:42.232867 70150 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 19:14:42.232873 70150 net.cpp:94] Creating Layer accuracy-top5
I0122 19:14:42.232875 70150 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 19:14:42.232879 70150 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 19:14:42.232883 70150 net.cpp:409] accuracy-top5 -> top-5
I0122 19:14:42.232897 70150 net.cpp:144] Setting up accuracy-top5
I0122 19:14:42.232899 70150 net.cpp:151] Top shape: (1)
I0122 19:14:42.232901 70150 net.cpp:159] Memory required for data: 566417416
I0122 19:14:42.232904 70150 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 19:14:42.232908 70150 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 19:14:42.232913 70150 net.cpp:222] accuracy does not need backward computation.
I0122 19:14:42.232915 70150 net.cpp:220] loss needs backward computation.
I0122 19:14:42.232919 70150 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 19:14:42.232923 70150 net.cpp:220] loss/classifier needs backward computation.
I0122 19:14:42.232925 70150 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:14:42.232928 70150 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:14:42.232931 70150 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:14:42.232935 70150 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:14:42.232939 70150 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:14:42.232941 70150 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:14:42.232944 70150 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:14:42.232947 70150 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:14:42.232950 70150 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:14:42.232954 70150 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:14:42.232956 70150 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:14:42.232960 70150 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:14:42.232964 70150 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:14:42.232966 70150 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:14:42.232969 70150 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:14:42.232972 70150 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:14:42.232975 70150 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:14:42.232978 70150 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:14:42.232981 70150 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:14:42.232985 70150 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:14:42.232988 70150 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.232991 70150 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.232995 70150 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:14:42.232997 70150 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:14:42.233000 70150 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:14:42.233005 70150 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:14:42.233007 70150 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:14:42.233011 70150 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:14:42.233013 70150 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:14:42.233016 70150 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:14:42.233019 70150 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:14:42.233022 70150 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:14:42.233026 70150 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:14:42.233029 70150 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:14:42.233032 70150 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:14:42.233036 70150 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:14:42.233041 70150 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:14:42.233048 70150 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:14:42.233050 70150 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:14:42.233054 70150 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:14:42.233057 70150 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:14:42.233062 70150 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:14:42.233064 70150 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:14:42.233067 70150 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:14:42.233070 70150 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:14:42.233074 70150 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:14:42.233076 70150 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:14:42.233080 70150 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:14:42.233083 70150 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:14:42.233086 70150 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:14:42.233089 70150 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:14:42.233093 70150 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:14:42.233096 70150 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:14:42.233098 70150 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:14:42.233103 70150 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:14:42.233105 70150 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:14:42.233109 70150 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:14:42.233114 70150 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:14:42.233116 70150 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:14:42.233120 70150 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:14:42.233124 70150 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:14:42.233126 70150 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:14:42.233130 70150 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:14:42.233134 70150 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:14:42.233136 70150 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:14:42.233139 70150 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:14:42.233144 70150 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:14:42.233146 70150 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:14:42.233150 70150 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:14:42.233152 70150 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:14:42.233155 70150 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:14:42.233160 70150 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:14:42.233162 70150 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:14:42.233165 70150 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:14:42.233167 70150 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:14:42.233171 70150 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:14:42.233175 70150 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:14:42.233177 70150 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:14:42.233180 70150 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:14:42.233184 70150 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:14:42.233187 70150 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:14:42.233199 70150 net.cpp:222] label_data_1_split does not need backward computation.
I0122 19:14:42.233203 70150 net.cpp:222] data does not need backward computation.
I0122 19:14:42.233206 70150 net.cpp:264] This network produces output accuracy
I0122 19:14:42.233209 70150 net.cpp:264] This network produces output loss
I0122 19:14:42.233212 70150 net.cpp:264] This network produces output top-1
I0122 19:14:42.233217 70150 net.cpp:264] This network produces output top-5
I0122 19:14:42.233286 70150 net.cpp:284] Network initialization done.
I0122 19:14:42.233621 70150 solver.cpp:63] Solver scaffolding done.
I0122 19:14:42.238093 70150 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/sparse.caffemodel
I0122 19:14:42.282122 70150 caffe_interface.cpp:527] Starting Optimization
I0122 19:14:42.282140 70150 solver.cpp:335] Solving 
I0122 19:14:42.282142 70150 solver.cpp:336] Learning Rate Policy: step
I0122 19:14:42.284685 70150 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 19:14:43.738059 70150 solver.cpp:517]     Test net output #0: accuracy = 0.893888
I0122 19:14:43.738085 70150 solver.cpp:517]     Test net output #1: loss = 0.399975 (* 1 = 0.399975 loss)
I0122 19:14:43.738090 70150 solver.cpp:517]     Test net output #2: top-1 = 0.893888
I0122 19:14:43.738092 70150 solver.cpp:517]     Test net output #3: top-5 = 0.994445
I0122 19:14:43.818171 70150 solver.cpp:266] Iteration 0 (0 iter/s, 1.53593s/100 iter), loss = 0.00423868
I0122 19:14:43.818205 70150 solver.cpp:285]     Train net output #0: loss = 0.00423868 (* 1 = 0.00423868 loss)
I0122 19:14:43.818222 70150 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 19:14:49.940099 70150 solver.cpp:266] Iteration 100 (16.3354 iter/s, 6.12166s/100 iter), loss = 1.25813
I0122 19:14:49.940126 70150 solver.cpp:285]     Train net output #0: loss = 1.25813 (* 1 = 1.25813 loss)
I0122 19:14:49.940132 70150 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 19:14:56.055441 70150 solver.cpp:266] Iteration 200 (16.353 iter/s, 6.11508s/100 iter), loss = 1.11228
I0122 19:14:56.055467 70150 solver.cpp:285]     Train net output #0: loss = 1.11228 (* 1 = 1.11228 loss)
I0122 19:14:56.055474 70150 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 19:15:02.184532 70150 solver.cpp:266] Iteration 300 (16.3163 iter/s, 6.12883s/100 iter), loss = 0.929449
I0122 19:15:02.184561 70150 solver.cpp:285]     Train net output #0: loss = 0.929449 (* 1 = 0.929449 loss)
I0122 19:15:02.184567 70150 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 19:15:08.317096 70150 solver.cpp:266] Iteration 400 (16.3071 iter/s, 6.1323s/100 iter), loss = 0.795218
I0122 19:15:08.317124 70150 solver.cpp:285]     Train net output #0: loss = 0.795218 (* 1 = 0.795218 loss)
I0122 19:15:08.317129 70150 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 19:15:14.488174 70150 solver.cpp:266] Iteration 500 (16.2053 iter/s, 6.17081s/100 iter), loss = 0.950878
I0122 19:15:14.488265 70150 solver.cpp:285]     Train net output #0: loss = 0.950878 (* 1 = 0.950878 loss)
I0122 19:15:14.488273 70150 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 19:15:20.691821 70150 solver.cpp:266] Iteration 600 (16.1204 iter/s, 6.20332s/100 iter), loss = 0.672483
I0122 19:15:20.691862 70150 solver.cpp:285]     Train net output #0: loss = 0.672483 (* 1 = 0.672483 loss)
I0122 19:15:20.691869 70150 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 19:15:26.917599 70150 solver.cpp:266] Iteration 700 (16.063 iter/s, 6.2255s/100 iter), loss = 0.838136
I0122 19:15:26.917627 70150 solver.cpp:285]     Train net output #0: loss = 0.838136 (* 1 = 0.838136 loss)
I0122 19:15:26.917634 70150 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 19:15:33.142577 70150 solver.cpp:266] Iteration 800 (16.065 iter/s, 6.22471s/100 iter), loss = 0.767428
I0122 19:15:33.142617 70150 solver.cpp:285]     Train net output #0: loss = 0.767428 (* 1 = 0.767428 loss)
I0122 19:15:33.142623 70150 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 19:15:39.360252 70150 solver.cpp:266] Iteration 900 (16.0839 iter/s, 6.2174s/100 iter), loss = 0.549655
I0122 19:15:39.360280 70150 solver.cpp:285]     Train net output #0: loss = 0.549655 (* 1 = 0.549655 loss)
I0122 19:15:39.360285 70150 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 19:15:45.525362 70150 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 19:15:46.975481 70150 solver.cpp:517]     Test net output #0: accuracy = 0.274778
I0122 19:15:46.975505 70150 solver.cpp:517]     Test net output #1: loss = 5.34173 (* 1 = 5.34173 loss)
I0122 19:15:46.975510 70150 solver.cpp:517]     Test net output #2: top-1 = 0.274778
I0122 19:15:46.975513 70150 solver.cpp:517]     Test net output #3: top-5 = 0.860444
I0122 19:15:47.037056 70150 solver.cpp:266] Iteration 1000 (13.0268 iter/s, 7.67649s/100 iter), loss = 0.734602
I0122 19:15:47.037077 70150 solver.cpp:285]     Train net output #0: loss = 0.734602 (* 1 = 0.734602 loss)
I0122 19:15:47.037083 70150 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 19:15:53.268682 70150 solver.cpp:266] Iteration 1100 (16.0478 iter/s, 6.23137s/100 iter), loss = 0.665912
I0122 19:15:53.268708 70150 solver.cpp:285]     Train net output #0: loss = 0.665912 (* 1 = 0.665912 loss)
I0122 19:15:53.268714 70150 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 19:15:59.480968 70150 solver.cpp:266] Iteration 1200 (16.0978 iter/s, 6.21202s/100 iter), loss = 0.5749
I0122 19:15:59.480996 70150 solver.cpp:285]     Train net output #0: loss = 0.5749 (* 1 = 0.5749 loss)
I0122 19:15:59.481003 70150 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 19:16:05.700275 70150 solver.cpp:266] Iteration 1300 (16.0796 iter/s, 6.21904s/100 iter), loss = 0.602998
I0122 19:16:05.700304 70150 solver.cpp:285]     Train net output #0: loss = 0.602998 (* 1 = 0.602998 loss)
I0122 19:16:05.700310 70150 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 19:16:11.930851 70150 solver.cpp:266] Iteration 1400 (16.0506 iter/s, 6.23031s/100 iter), loss = 0.54741
I0122 19:16:11.930878 70150 solver.cpp:285]     Train net output #0: loss = 0.54741 (* 1 = 0.54741 loss)
I0122 19:16:11.930884 70150 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 19:16:18.155632 70150 solver.cpp:266] Iteration 1500 (16.0655 iter/s, 6.22451s/100 iter), loss = 0.442638
I0122 19:16:18.155691 70150 solver.cpp:285]     Train net output #0: loss = 0.442638 (* 1 = 0.442638 loss)
I0122 19:16:18.155699 70150 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 19:16:24.384464 70150 solver.cpp:266] Iteration 1600 (16.0551 iter/s, 6.22854s/100 iter), loss = 0.636615
I0122 19:16:24.384488 70150 solver.cpp:285]     Train net output #0: loss = 0.636615 (* 1 = 0.636615 loss)
I0122 19:16:24.384493 70150 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 19:16:30.604219 70150 solver.cpp:266] Iteration 1700 (16.0785 iter/s, 6.21949s/100 iter), loss = 0.46785
I0122 19:16:30.604249 70150 solver.cpp:285]     Train net output #0: loss = 0.46785 (* 1 = 0.46785 loss)
I0122 19:16:30.604254 70150 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 19:16:36.814716 70150 solver.cpp:266] Iteration 1800 (16.1025 iter/s, 6.21023s/100 iter), loss = 0.484275
I0122 19:16:36.814745 70150 solver.cpp:285]     Train net output #0: loss = 0.484275 (* 1 = 0.484275 loss)
I0122 19:16:36.814751 70150 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 19:16:43.046514 70150 solver.cpp:266] Iteration 1900 (16.0474 iter/s, 6.23153s/100 iter), loss = 0.500228
I0122 19:16:43.046540 70150 solver.cpp:285]     Train net output #0: loss = 0.500228 (* 1 = 0.500228 loss)
I0122 19:16:43.046546 70150 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 19:16:49.212767 70150 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 19:16:50.664784 70150 solver.cpp:517]     Test net output #0: accuracy = 0.482556
I0122 19:16:50.664809 70150 solver.cpp:517]     Test net output #1: loss = 1.45698 (* 1 = 1.45698 loss)
I0122 19:16:50.664814 70150 solver.cpp:517]     Test net output #2: top-1 = 0.482556
I0122 19:16:50.664819 70150 solver.cpp:517]     Test net output #3: top-5 = 0.898333
I0122 19:16:50.726555 70150 solver.cpp:266] Iteration 2000 (13.0213 iter/s, 7.67973s/100 iter), loss = 0.508224
I0122 19:16:50.726574 70150 solver.cpp:285]     Train net output #0: loss = 0.508224 (* 1 = 0.508224 loss)
I0122 19:16:50.726580 70150 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 19:16:56.929675 70150 solver.cpp:266] Iteration 2100 (16.1216 iter/s, 6.20286s/100 iter), loss = 0.626684
I0122 19:16:56.929703 70150 solver.cpp:285]     Train net output #0: loss = 0.626684 (* 1 = 0.626684 loss)
I0122 19:16:56.929709 70150 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 19:17:03.153697 70150 solver.cpp:266] Iteration 2200 (16.0675 iter/s, 6.22375s/100 iter), loss = 0.383567
I0122 19:17:03.153724 70150 solver.cpp:285]     Train net output #0: loss = 0.383567 (* 1 = 0.383567 loss)
I0122 19:17:03.153730 70150 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 19:17:09.391223 70150 solver.cpp:266] Iteration 2300 (16.0327 iter/s, 6.23726s/100 iter), loss = 0.586729
I0122 19:17:09.391252 70150 solver.cpp:285]     Train net output #0: loss = 0.586729 (* 1 = 0.586729 loss)
I0122 19:17:09.391258 70150 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 19:17:15.616552 70150 solver.cpp:266] Iteration 2400 (16.0641 iter/s, 6.22506s/100 iter), loss = 0.49179
I0122 19:17:15.616580 70150 solver.cpp:285]     Train net output #0: loss = 0.49179 (* 1 = 0.49179 loss)
I0122 19:17:15.616586 70150 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 19:17:21.854074 70150 solver.cpp:266] Iteration 2500 (16.0327 iter/s, 6.23726s/100 iter), loss = 0.522156
I0122 19:17:21.854161 70150 solver.cpp:285]     Train net output #0: loss = 0.522156 (* 1 = 0.522156 loss)
I0122 19:17:21.854167 70150 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 19:17:28.088827 70150 solver.cpp:266] Iteration 2600 (16.04 iter/s, 6.23443s/100 iter), loss = 0.450405
I0122 19:17:28.088855 70150 solver.cpp:285]     Train net output #0: loss = 0.450405 (* 1 = 0.450405 loss)
I0122 19:17:28.088858 70150 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 19:17:34.314723 70150 solver.cpp:266] Iteration 2700 (16.0626 iter/s, 6.22563s/100 iter), loss = 0.605673
I0122 19:17:34.314751 70150 solver.cpp:285]     Train net output #0: loss = 0.605673 (* 1 = 0.605673 loss)
I0122 19:17:34.314756 70150 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 19:17:40.544445 70150 solver.cpp:266] Iteration 2800 (16.0528 iter/s, 6.22945s/100 iter), loss = 0.651193
I0122 19:17:40.544473 70150 solver.cpp:285]     Train net output #0: loss = 0.651193 (* 1 = 0.651193 loss)
I0122 19:17:40.544478 70150 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 19:17:46.769840 70150 solver.cpp:266] Iteration 2900 (16.0639 iter/s, 6.22513s/100 iter), loss = 0.5326
I0122 19:17:46.769868 70150 solver.cpp:285]     Train net output #0: loss = 0.5326 (* 1 = 0.5326 loss)
I0122 19:17:46.769874 70150 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 19:17:52.944090 70150 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 19:17:54.390592 70150 solver.cpp:517]     Test net output #0: accuracy = 0.584556
I0122 19:17:54.390617 70150 solver.cpp:517]     Test net output #1: loss = 1.17491 (* 1 = 1.17491 loss)
I0122 19:17:54.390621 70150 solver.cpp:517]     Test net output #2: top-1 = 0.584556
I0122 19:17:54.390625 70150 solver.cpp:517]     Test net output #3: top-5 = 0.944667
I0122 19:17:54.452087 70150 solver.cpp:266] Iteration 3000 (13.0176 iter/s, 7.68193s/100 iter), loss = 0.511255
I0122 19:17:54.452118 70150 solver.cpp:285]     Train net output #0: loss = 0.511255 (* 1 = 0.511255 loss)
I0122 19:17:54.452126 70150 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 19:18:00.660567 70150 solver.cpp:266] Iteration 3100 (16.1077 iter/s, 6.20821s/100 iter), loss = 0.424389
I0122 19:18:00.660594 70150 solver.cpp:285]     Train net output #0: loss = 0.424389 (* 1 = 0.424389 loss)
I0122 19:18:00.660599 70150 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 19:18:06.887193 70150 solver.cpp:266] Iteration 3200 (16.0607 iter/s, 6.22636s/100 iter), loss = 0.53792
I0122 19:18:06.887221 70150 solver.cpp:285]     Train net output #0: loss = 0.53792 (* 1 = 0.53792 loss)
I0122 19:18:06.887228 70150 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 19:18:13.107560 70150 solver.cpp:266] Iteration 3300 (16.0769 iter/s, 6.2201s/100 iter), loss = 0.382567
I0122 19:18:13.107589 70150 solver.cpp:285]     Train net output #0: loss = 0.382567 (* 1 = 0.382567 loss)
I0122 19:18:13.107594 70150 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 19:18:19.319162 70150 solver.cpp:266] Iteration 3400 (16.0996 iter/s, 6.21134s/100 iter), loss = 0.527776
I0122 19:18:19.319190 70150 solver.cpp:285]     Train net output #0: loss = 0.527776 (* 1 = 0.527776 loss)
I0122 19:18:19.319195 70150 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 19:18:25.540992 70150 solver.cpp:266] Iteration 3500 (16.0731 iter/s, 6.22157s/100 iter), loss = 0.444462
I0122 19:18:25.541069 70150 solver.cpp:285]     Train net output #0: loss = 0.444462 (* 1 = 0.444462 loss)
I0122 19:18:25.541075 70150 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 19:18:31.779860 70150 solver.cpp:266] Iteration 3600 (16.0294 iter/s, 6.23855s/100 iter), loss = 0.606412
I0122 19:18:31.779887 70150 solver.cpp:285]     Train net output #0: loss = 0.606412 (* 1 = 0.606412 loss)
I0122 19:18:31.779893 70150 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 19:18:37.974907 70150 solver.cpp:266] Iteration 3700 (16.1426 iter/s, 6.19478s/100 iter), loss = 0.460023
I0122 19:18:37.974934 70150 solver.cpp:285]     Train net output #0: loss = 0.460023 (* 1 = 0.460023 loss)
I0122 19:18:37.974941 70150 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 19:18:44.204859 70150 solver.cpp:266] Iteration 3800 (16.0522 iter/s, 6.22969s/100 iter), loss = 0.443886
I0122 19:18:44.204885 70150 solver.cpp:285]     Train net output #0: loss = 0.443886 (* 1 = 0.443886 loss)
I0122 19:18:44.204891 70150 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 19:18:50.446863 70150 solver.cpp:266] Iteration 3900 (16.0212 iter/s, 6.24174s/100 iter), loss = 0.452235
I0122 19:18:50.446890 70150 solver.cpp:285]     Train net output #0: loss = 0.452235 (* 1 = 0.452235 loss)
I0122 19:18:50.446897 70150 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 19:18:56.600204 70150 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 19:18:58.051595 70150 solver.cpp:517]     Test net output #0: accuracy = 0.477111
I0122 19:18:58.051620 70150 solver.cpp:517]     Test net output #1: loss = 1.48279 (* 1 = 1.48279 loss)
I0122 19:18:58.051623 70150 solver.cpp:517]     Test net output #2: top-1 = 0.477111
I0122 19:18:58.051626 70150 solver.cpp:517]     Test net output #3: top-5 = 0.904555
I0122 19:18:58.113306 70150 solver.cpp:266] Iteration 4000 (13.0444 iter/s, 7.66613s/100 iter), loss = 0.560308
I0122 19:18:58.113325 70150 solver.cpp:285]     Train net output #0: loss = 0.560308 (* 1 = 0.560308 loss)
I0122 19:18:58.113332 70150 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 19:19:04.330579 70150 solver.cpp:266] Iteration 4100 (16.0849 iter/s, 6.21702s/100 iter), loss = 0.430297
I0122 19:19:04.330606 70150 solver.cpp:285]     Train net output #0: loss = 0.430297 (* 1 = 0.430297 loss)
I0122 19:19:04.330612 70150 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 19:19:10.551937 70150 solver.cpp:266] Iteration 4200 (16.0743 iter/s, 6.22109s/100 iter), loss = 0.478692
I0122 19:19:10.551965 70150 solver.cpp:285]     Train net output #0: loss = 0.478692 (* 1 = 0.478692 loss)
I0122 19:19:10.551971 70150 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 19:19:16.774919 70150 solver.cpp:266] Iteration 4300 (16.0701 iter/s, 6.22272s/100 iter), loss = 0.552574
I0122 19:19:16.774947 70150 solver.cpp:285]     Train net output #0: loss = 0.552574 (* 1 = 0.552574 loss)
I0122 19:19:16.774953 70150 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 19:19:22.996904 70150 solver.cpp:266] Iteration 4400 (16.0727 iter/s, 6.22172s/100 iter), loss = 0.595786
I0122 19:19:22.996932 70150 solver.cpp:285]     Train net output #0: loss = 0.595786 (* 1 = 0.595786 loss)
I0122 19:19:22.996937 70150 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 19:19:29.214701 70150 solver.cpp:266] Iteration 4500 (16.0836 iter/s, 6.21753s/100 iter), loss = 0.432837
I0122 19:19:29.214778 70150 solver.cpp:285]     Train net output #0: loss = 0.432837 (* 1 = 0.432837 loss)
I0122 19:19:29.214785 70150 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 19:19:35.435325 70150 solver.cpp:266] Iteration 4600 (16.0764 iter/s, 6.22031s/100 iter), loss = 0.65526
I0122 19:19:35.435353 70150 solver.cpp:285]     Train net output #0: loss = 0.65526 (* 1 = 0.65526 loss)
I0122 19:19:35.435359 70150 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 19:19:41.649689 70150 solver.cpp:266] Iteration 4700 (16.0924 iter/s, 6.2141s/100 iter), loss = 0.567955
I0122 19:19:41.649718 70150 solver.cpp:285]     Train net output #0: loss = 0.567955 (* 1 = 0.567955 loss)
I0122 19:19:41.649722 70150 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 19:19:47.868736 70150 solver.cpp:266] Iteration 4800 (16.0803 iter/s, 6.21878s/100 iter), loss = 0.485153
I0122 19:19:47.868764 70150 solver.cpp:285]     Train net output #0: loss = 0.485153 (* 1 = 0.485153 loss)
I0122 19:19:47.868769 70150 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 19:19:54.091894 70150 solver.cpp:266] Iteration 4900 (16.0697 iter/s, 6.22289s/100 iter), loss = 0.661399
I0122 19:19:54.091922 70150 solver.cpp:285]     Train net output #0: loss = 0.661399 (* 1 = 0.661399 loss)
I0122 19:19:54.091928 70150 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 19:20:00.239329 70150 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 19:20:01.690448 70150 solver.cpp:517]     Test net output #0: accuracy = 0.356333
I0122 19:20:01.690471 70150 solver.cpp:517]     Test net output #1: loss = 2.54482 (* 1 = 2.54482 loss)
I0122 19:20:01.690475 70150 solver.cpp:517]     Test net output #2: top-1 = 0.356333
I0122 19:20:01.690479 70150 solver.cpp:517]     Test net output #3: top-5 = 0.825111
I0122 19:20:01.753614 70150 solver.cpp:266] Iteration 5000 (13.0524 iter/s, 7.6614s/100 iter), loss = 0.675043
I0122 19:20:01.753634 70150 solver.cpp:285]     Train net output #0: loss = 0.675043 (* 1 = 0.675043 loss)
I0122 19:20:01.753640 70150 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 19:20:07.981106 70150 solver.cpp:266] Iteration 5100 (16.0585 iter/s, 6.22723s/100 iter), loss = 0.459239
I0122 19:20:07.981133 70150 solver.cpp:285]     Train net output #0: loss = 0.459239 (* 1 = 0.459239 loss)
I0122 19:20:07.981138 70150 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 19:20:14.205879 70150 solver.cpp:266] Iteration 5200 (16.0655 iter/s, 6.22451s/100 iter), loss = 0.525893
I0122 19:20:14.205910 70150 solver.cpp:285]     Train net output #0: loss = 0.525893 (* 1 = 0.525893 loss)
I0122 19:20:14.205917 70150 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 19:20:20.418462 70150 solver.cpp:266] Iteration 5300 (16.0971 iter/s, 6.21231s/100 iter), loss = 0.566218
I0122 19:20:20.418491 70150 solver.cpp:285]     Train net output #0: loss = 0.566218 (* 1 = 0.566218 loss)
I0122 19:20:20.418496 70150 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 19:20:26.668099 70150 solver.cpp:266] Iteration 5400 (16.0016 iter/s, 6.24937s/100 iter), loss = 0.604607
I0122 19:20:26.668128 70150 solver.cpp:285]     Train net output #0: loss = 0.604607 (* 1 = 0.604607 loss)
I0122 19:20:26.668133 70150 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 19:20:32.874366 70150 solver.cpp:266] Iteration 5500 (16.1134 iter/s, 6.206s/100 iter), loss = 0.466477
I0122 19:20:32.874428 70150 solver.cpp:285]     Train net output #0: loss = 0.466477 (* 1 = 0.466477 loss)
I0122 19:20:32.874433 70150 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 19:20:39.093215 70150 solver.cpp:266] Iteration 5600 (16.0809 iter/s, 6.21855s/100 iter), loss = 0.431836
I0122 19:20:39.093243 70150 solver.cpp:285]     Train net output #0: loss = 0.431836 (* 1 = 0.431836 loss)
I0122 19:20:39.093248 70150 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 19:20:45.320828 70150 solver.cpp:266] Iteration 5700 (16.0582 iter/s, 6.22735s/100 iter), loss = 0.261399
I0122 19:20:45.320857 70150 solver.cpp:285]     Train net output #0: loss = 0.261399 (* 1 = 0.261399 loss)
I0122 19:20:45.320861 70150 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 19:20:51.538655 70150 solver.cpp:266] Iteration 5800 (16.0835 iter/s, 6.21756s/100 iter), loss = 0.612623
I0122 19:20:51.538683 70150 solver.cpp:285]     Train net output #0: loss = 0.612623 (* 1 = 0.612623 loss)
I0122 19:20:51.538689 70150 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 19:20:57.759114 70150 solver.cpp:266] Iteration 5900 (16.0767 iter/s, 6.22019s/100 iter), loss = 0.55342
I0122 19:20:57.759140 70150 solver.cpp:285]     Train net output #0: loss = 0.55342 (* 1 = 0.55342 loss)
I0122 19:20:57.759145 70150 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 19:21:03.925514 70150 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 19:21:05.377826 70150 solver.cpp:517]     Test net output #0: accuracy = 0.610334
I0122 19:21:05.377851 70150 solver.cpp:517]     Test net output #1: loss = 1.08865 (* 1 = 1.08865 loss)
I0122 19:21:05.377856 70150 solver.cpp:517]     Test net output #2: top-1 = 0.610334
I0122 19:21:05.377859 70150 solver.cpp:517]     Test net output #3: top-5 = 0.945556
I0122 19:21:05.440246 70150 solver.cpp:266] Iteration 6000 (13.0195 iter/s, 7.68082s/100 iter), loss = 0.663952
I0122 19:21:05.440265 70150 solver.cpp:285]     Train net output #0: loss = 0.663952 (* 1 = 0.663952 loss)
I0122 19:21:05.440271 70150 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 19:21:11.664819 70150 solver.cpp:266] Iteration 6100 (16.066 iter/s, 6.22432s/100 iter), loss = 0.374827
I0122 19:21:11.664845 70150 solver.cpp:285]     Train net output #0: loss = 0.374827 (* 1 = 0.374827 loss)
I0122 19:21:11.664850 70150 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 19:21:17.880829 70150 solver.cpp:266] Iteration 6200 (16.0882 iter/s, 6.21575s/100 iter), loss = 0.418449
I0122 19:21:17.880858 70150 solver.cpp:285]     Train net output #0: loss = 0.418449 (* 1 = 0.418449 loss)
I0122 19:21:17.880863 70150 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 19:21:24.107398 70150 solver.cpp:266] Iteration 6300 (16.0609 iter/s, 6.2263s/100 iter), loss = 0.412811
I0122 19:21:24.107427 70150 solver.cpp:285]     Train net output #0: loss = 0.412811 (* 1 = 0.412811 loss)
I0122 19:21:24.107434 70150 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 19:21:30.322089 70150 solver.cpp:266] Iteration 6400 (16.0916 iter/s, 6.21442s/100 iter), loss = 0.553206
I0122 19:21:30.322114 70150 solver.cpp:285]     Train net output #0: loss = 0.553206 (* 1 = 0.553206 loss)
I0122 19:21:30.322119 70150 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 19:21:36.549777 70150 solver.cpp:266] Iteration 6500 (16.058 iter/s, 6.22742s/100 iter), loss = 0.726911
I0122 19:21:36.549839 70150 solver.cpp:285]     Train net output #0: loss = 0.726911 (* 1 = 0.726911 loss)
I0122 19:21:36.549846 70150 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 19:21:42.757158 70150 solver.cpp:266] Iteration 6600 (16.1106 iter/s, 6.20708s/100 iter), loss = 0.547003
I0122 19:21:42.757186 70150 solver.cpp:285]     Train net output #0: loss = 0.547003 (* 1 = 0.547003 loss)
I0122 19:21:42.757191 70150 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 19:21:48.989859 70150 solver.cpp:266] Iteration 6700 (16.0451 iter/s, 6.23243s/100 iter), loss = 0.366781
I0122 19:21:48.989886 70150 solver.cpp:285]     Train net output #0: loss = 0.366781 (* 1 = 0.366781 loss)
I0122 19:21:48.989892 70150 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 19:21:55.213654 70150 solver.cpp:266] Iteration 6800 (16.0681 iter/s, 6.22353s/100 iter), loss = 0.445867
I0122 19:21:55.213681 70150 solver.cpp:285]     Train net output #0: loss = 0.445867 (* 1 = 0.445867 loss)
I0122 19:21:55.213686 70150 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 19:22:01.435297 70150 solver.cpp:266] Iteration 6900 (16.0736 iter/s, 6.22138s/100 iter), loss = 0.47588
I0122 19:22:01.435325 70150 solver.cpp:285]     Train net output #0: loss = 0.47588 (* 1 = 0.47588 loss)
I0122 19:22:01.435331 70150 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 19:22:07.595698 70150 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 19:22:09.046017 70150 solver.cpp:517]     Test net output #0: accuracy = 0.543333
I0122 19:22:09.046042 70150 solver.cpp:517]     Test net output #1: loss = 1.41143 (* 1 = 1.41143 loss)
I0122 19:22:09.046046 70150 solver.cpp:517]     Test net output #2: top-1 = 0.543333
I0122 19:22:09.046049 70150 solver.cpp:517]     Test net output #3: top-5 = 0.899
I0122 19:22:09.107784 70150 solver.cpp:266] Iteration 7000 (13.0341 iter/s, 7.67217s/100 iter), loss = 0.367308
I0122 19:22:09.107803 70150 solver.cpp:285]     Train net output #0: loss = 0.367308 (* 1 = 0.367308 loss)
I0122 19:22:09.107810 70150 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 19:22:15.338147 70150 solver.cpp:266] Iteration 7100 (16.0511 iter/s, 6.2301s/100 iter), loss = 0.642479
I0122 19:22:15.338176 70150 solver.cpp:285]     Train net output #0: loss = 0.642479 (* 1 = 0.642479 loss)
I0122 19:22:15.338181 70150 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 19:22:21.555619 70150 solver.cpp:266] Iteration 7200 (16.0844 iter/s, 6.21721s/100 iter), loss = 0.412763
I0122 19:22:21.555646 70150 solver.cpp:285]     Train net output #0: loss = 0.412763 (* 1 = 0.412763 loss)
I0122 19:22:21.555652 70150 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 19:22:27.783730 70150 solver.cpp:266] Iteration 7300 (16.0569 iter/s, 6.22785s/100 iter), loss = 0.509895
I0122 19:22:27.783759 70150 solver.cpp:285]     Train net output #0: loss = 0.509895 (* 1 = 0.509895 loss)
I0122 19:22:27.783764 70150 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 19:22:34.000885 70150 solver.cpp:266] Iteration 7400 (16.0852 iter/s, 6.21689s/100 iter), loss = 0.422114
I0122 19:22:34.000914 70150 solver.cpp:285]     Train net output #0: loss = 0.422114 (* 1 = 0.422114 loss)
I0122 19:22:34.000919 70150 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 19:22:40.211117 70150 solver.cpp:266] Iteration 7500 (16.1031 iter/s, 6.20997s/100 iter), loss = 0.447746
I0122 19:22:40.211179 70150 solver.cpp:285]     Train net output #0: loss = 0.447746 (* 1 = 0.447746 loss)
I0122 19:22:40.211184 70150 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 19:22:46.441730 70150 solver.cpp:266] Iteration 7600 (16.0506 iter/s, 6.23031s/100 iter), loss = 0.420806
I0122 19:22:46.441756 70150 solver.cpp:285]     Train net output #0: loss = 0.420806 (* 1 = 0.420806 loss)
I0122 19:22:46.441762 70150 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 19:22:52.677601 70150 solver.cpp:266] Iteration 7700 (16.0369 iter/s, 6.23561s/100 iter), loss = 0.50006
I0122 19:22:52.677628 70150 solver.cpp:285]     Train net output #0: loss = 0.50006 (* 1 = 0.50006 loss)
I0122 19:22:52.677634 70150 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 19:22:58.916968 70150 solver.cpp:266] Iteration 7800 (16.028 iter/s, 6.2391s/100 iter), loss = 0.413227
I0122 19:22:58.916995 70150 solver.cpp:285]     Train net output #0: loss = 0.413227 (* 1 = 0.413227 loss)
I0122 19:22:58.917001 70150 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 19:23:05.122239 70150 solver.cpp:266] Iteration 7900 (16.116 iter/s, 6.20501s/100 iter), loss = 0.566429
I0122 19:23:05.122268 70150 solver.cpp:285]     Train net output #0: loss = 0.566429 (* 1 = 0.566429 loss)
I0122 19:23:05.122273 70150 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 19:23:11.272780 70150 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 19:23:12.719866 70150 solver.cpp:517]     Test net output #0: accuracy = 0.620667
I0122 19:23:12.719892 70150 solver.cpp:517]     Test net output #1: loss = 1.08059 (* 1 = 1.08059 loss)
I0122 19:23:12.719895 70150 solver.cpp:517]     Test net output #2: top-1 = 0.620667
I0122 19:23:12.719898 70150 solver.cpp:517]     Test net output #3: top-5 = 0.962667
I0122 19:23:12.781333 70150 solver.cpp:266] Iteration 8000 (13.0569 iter/s, 7.65878s/100 iter), loss = 0.428761
I0122 19:23:12.781353 70150 solver.cpp:285]     Train net output #0: loss = 0.428761 (* 1 = 0.428761 loss)
I0122 19:23:12.781359 70150 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 19:23:19.006014 70150 solver.cpp:266] Iteration 8100 (16.0657 iter/s, 6.22442s/100 iter), loss = 0.53741
I0122 19:23:19.006042 70150 solver.cpp:285]     Train net output #0: loss = 0.53741 (* 1 = 0.53741 loss)
I0122 19:23:19.006047 70150 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 19:23:25.214885 70150 solver.cpp:266] Iteration 8200 (16.1067 iter/s, 6.20861s/100 iter), loss = 0.459828
I0122 19:23:25.214915 70150 solver.cpp:285]     Train net output #0: loss = 0.459828 (* 1 = 0.459828 loss)
I0122 19:23:25.214920 70150 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 19:23:31.433703 70150 solver.cpp:266] Iteration 8300 (16.0809 iter/s, 6.21855s/100 iter), loss = 0.465649
I0122 19:23:31.433732 70150 solver.cpp:285]     Train net output #0: loss = 0.465649 (* 1 = 0.465649 loss)
I0122 19:23:31.433738 70150 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 19:23:37.641274 70150 solver.cpp:266] Iteration 8400 (16.1101 iter/s, 6.2073s/100 iter), loss = 0.324254
I0122 19:23:37.641304 70150 solver.cpp:285]     Train net output #0: loss = 0.324254 (* 1 = 0.324254 loss)
I0122 19:23:37.641309 70150 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 19:23:43.863898 70150 solver.cpp:266] Iteration 8500 (16.0711 iter/s, 6.22236s/100 iter), loss = 0.605635
I0122 19:23:43.864020 70150 solver.cpp:285]     Train net output #0: loss = 0.605635 (* 1 = 0.605635 loss)
I0122 19:23:43.864027 70150 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 19:23:50.082763 70150 solver.cpp:266] Iteration 8600 (16.081 iter/s, 6.21851s/100 iter), loss = 0.3013
I0122 19:23:50.082792 70150 solver.cpp:285]     Train net output #0: loss = 0.3013 (* 1 = 0.3013 loss)
I0122 19:23:50.082796 70150 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 19:23:56.306480 70150 solver.cpp:266] Iteration 8700 (16.0683 iter/s, 6.22345s/100 iter), loss = 0.494012
I0122 19:23:56.306509 70150 solver.cpp:285]     Train net output #0: loss = 0.494012 (* 1 = 0.494012 loss)
I0122 19:23:56.306514 70150 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 19:24:02.521104 70150 solver.cpp:266] Iteration 8800 (16.0918 iter/s, 6.21436s/100 iter), loss = 0.474666
I0122 19:24:02.521144 70150 solver.cpp:285]     Train net output #0: loss = 0.474666 (* 1 = 0.474666 loss)
I0122 19:24:02.521149 70150 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 19:24:08.760970 70150 solver.cpp:266] Iteration 8900 (16.0267 iter/s, 6.23959s/100 iter), loss = 0.514508
I0122 19:24:08.760998 70150 solver.cpp:285]     Train net output #0: loss = 0.514508 (* 1 = 0.514508 loss)
I0122 19:24:08.761004 70150 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 19:24:14.908576 70150 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 19:24:16.365938 70150 solver.cpp:517]     Test net output #0: accuracy = 0.600556
I0122 19:24:16.365963 70150 solver.cpp:517]     Test net output #1: loss = 1.31525 (* 1 = 1.31525 loss)
I0122 19:24:16.365968 70150 solver.cpp:517]     Test net output #2: top-1 = 0.600556
I0122 19:24:16.365988 70150 solver.cpp:517]     Test net output #3: top-5 = 0.910556
I0122 19:24:16.427012 70150 solver.cpp:266] Iteration 9000 (13.0451 iter/s, 7.66573s/100 iter), loss = 0.432712
I0122 19:24:16.427031 70150 solver.cpp:285]     Train net output #0: loss = 0.432712 (* 1 = 0.432712 loss)
I0122 19:24:16.427038 70150 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 19:24:22.649243 70150 solver.cpp:266] Iteration 9100 (16.0721 iter/s, 6.22197s/100 iter), loss = 0.380256
I0122 19:24:22.649271 70150 solver.cpp:285]     Train net output #0: loss = 0.380256 (* 1 = 0.380256 loss)
I0122 19:24:22.649276 70150 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 19:24:28.852450 70150 solver.cpp:266] Iteration 9200 (16.1214 iter/s, 6.20294s/100 iter), loss = 0.617243
I0122 19:24:28.852478 70150 solver.cpp:285]     Train net output #0: loss = 0.617243 (* 1 = 0.617243 loss)
I0122 19:24:28.852483 70150 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 19:24:35.068184 70150 solver.cpp:266] Iteration 9300 (16.0889 iter/s, 6.21547s/100 iter), loss = 0.441609
I0122 19:24:35.068212 70150 solver.cpp:285]     Train net output #0: loss = 0.441609 (* 1 = 0.441609 loss)
I0122 19:24:35.068217 70150 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 19:24:41.291199 70150 solver.cpp:266] Iteration 9400 (16.0701 iter/s, 6.22275s/100 iter), loss = 0.40118
I0122 19:24:41.291229 70150 solver.cpp:285]     Train net output #0: loss = 0.40118 (* 1 = 0.40118 loss)
I0122 19:24:41.291234 70150 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 19:24:47.528439 70150 solver.cpp:266] Iteration 9500 (16.0334 iter/s, 6.23697s/100 iter), loss = 0.354021
I0122 19:24:47.528519 70150 solver.cpp:285]     Train net output #0: loss = 0.354021 (* 1 = 0.354021 loss)
I0122 19:24:47.528525 70150 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 19:24:53.736138 70150 solver.cpp:266] Iteration 9600 (16.1098 iter/s, 6.20738s/100 iter), loss = 0.441208
I0122 19:24:53.736166 70150 solver.cpp:285]     Train net output #0: loss = 0.441208 (* 1 = 0.441208 loss)
I0122 19:24:53.736171 70150 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 19:24:59.973932 70150 solver.cpp:266] Iteration 9700 (16.032 iter/s, 6.23753s/100 iter), loss = 0.361417
I0122 19:24:59.973959 70150 solver.cpp:285]     Train net output #0: loss = 0.361417 (* 1 = 0.361417 loss)
I0122 19:24:59.973965 70150 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 19:25:06.182102 70150 solver.cpp:266] Iteration 9800 (16.1085 iter/s, 6.2079s/100 iter), loss = 0.298844
I0122 19:25:06.182130 70150 solver.cpp:285]     Train net output #0: loss = 0.298844 (* 1 = 0.298844 loss)
I0122 19:25:06.182137 70150 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 19:25:12.411068 70150 solver.cpp:266] Iteration 9900 (16.0547 iter/s, 6.2287s/100 iter), loss = 0.615343
I0122 19:25:12.411096 70150 solver.cpp:285]     Train net output #0: loss = 0.615343 (* 1 = 0.615343 loss)
I0122 19:25:12.411101 70150 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 19:25:18.560156 70150 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 19:25:20.013784 70150 solver.cpp:517]     Test net output #0: accuracy = 0.625334
I0122 19:25:20.013808 70150 solver.cpp:517]     Test net output #1: loss = 1.04104 (* 1 = 1.04104 loss)
I0122 19:25:20.013813 70150 solver.cpp:517]     Test net output #2: top-1 = 0.625334
I0122 19:25:20.013816 70150 solver.cpp:517]     Test net output #3: top-5 = 0.968
I0122 19:25:20.076792 70150 solver.cpp:266] Iteration 10000 (13.0456 iter/s, 7.66541s/100 iter), loss = 0.56636
I0122 19:25:20.076812 70150 solver.cpp:285]     Train net output #0: loss = 0.56636 (* 1 = 0.56636 loss)
I0122 19:25:20.076817 70150 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 19:25:26.284796 70150 solver.cpp:266] Iteration 10100 (16.1089 iter/s, 6.20775s/100 iter), loss = 0.388755
I0122 19:25:26.284826 70150 solver.cpp:285]     Train net output #0: loss = 0.388755 (* 1 = 0.388755 loss)
I0122 19:25:26.284832 70150 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 19:25:32.505280 70150 solver.cpp:266] Iteration 10200 (16.0766 iter/s, 6.22022s/100 iter), loss = 0.363727
I0122 19:25:32.505308 70150 solver.cpp:285]     Train net output #0: loss = 0.363727 (* 1 = 0.363727 loss)
I0122 19:25:32.505314 70150 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 19:25:38.715667 70150 solver.cpp:266] Iteration 10300 (16.1027 iter/s, 6.21012s/100 iter), loss = 0.253103
I0122 19:25:38.715695 70150 solver.cpp:285]     Train net output #0: loss = 0.253103 (* 1 = 0.253103 loss)
I0122 19:25:38.715703 70150 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 19:25:44.938701 70150 solver.cpp:266] Iteration 10400 (16.07 iter/s, 6.22277s/100 iter), loss = 0.325292
I0122 19:25:44.938730 70150 solver.cpp:285]     Train net output #0: loss = 0.325292 (* 1 = 0.325292 loss)
I0122 19:25:44.938735 70150 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 19:25:51.150843 70150 solver.cpp:266] Iteration 10500 (16.0982 iter/s, 6.21187s/100 iter), loss = 0.224911
I0122 19:25:51.150900 70150 solver.cpp:285]     Train net output #0: loss = 0.224911 (* 1 = 0.224911 loss)
I0122 19:25:51.150907 70150 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 19:25:57.373355 70150 solver.cpp:266] Iteration 10600 (16.0714 iter/s, 6.22222s/100 iter), loss = 0.277413
I0122 19:25:57.373384 70150 solver.cpp:285]     Train net output #0: loss = 0.277413 (* 1 = 0.277413 loss)
I0122 19:25:57.373389 70150 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 19:26:03.599154 70150 solver.cpp:266] Iteration 10700 (16.0629 iter/s, 6.22553s/100 iter), loss = 0.36948
I0122 19:26:03.599184 70150 solver.cpp:285]     Train net output #0: loss = 0.36948 (* 1 = 0.36948 loss)
I0122 19:26:03.599189 70150 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 19:26:09.820917 70150 solver.cpp:266] Iteration 10800 (16.0733 iter/s, 6.2215s/100 iter), loss = 0.134858
I0122 19:26:09.820946 70150 solver.cpp:285]     Train net output #0: loss = 0.134858 (* 1 = 0.134858 loss)
I0122 19:26:09.820951 70150 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 19:26:16.040807 70150 solver.cpp:266] Iteration 10900 (16.0781 iter/s, 6.21962s/100 iter), loss = 0.25409
I0122 19:26:16.040834 70150 solver.cpp:285]     Train net output #0: loss = 0.25409 (* 1 = 0.25409 loss)
I0122 19:26:16.040840 70150 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 19:26:22.202950 70150 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 19:26:23.645543 70150 solver.cpp:517]     Test net output #0: accuracy = 0.762555
I0122 19:26:23.645568 70150 solver.cpp:517]     Test net output #1: loss = 0.781333 (* 1 = 0.781333 loss)
I0122 19:26:23.645573 70150 solver.cpp:517]     Test net output #2: top-1 = 0.762555
I0122 19:26:23.645576 70150 solver.cpp:517]     Test net output #3: top-5 = 0.968667
I0122 19:26:23.707342 70150 solver.cpp:266] Iteration 11000 (13.0442 iter/s, 7.66622s/100 iter), loss = 0.221403
I0122 19:26:23.707362 70150 solver.cpp:285]     Train net output #0: loss = 0.221403 (* 1 = 0.221403 loss)
I0122 19:26:23.707368 70150 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 19:26:29.923468 70150 solver.cpp:266] Iteration 11100 (16.0879 iter/s, 6.21587s/100 iter), loss = 0.135854
I0122 19:26:29.923496 70150 solver.cpp:285]     Train net output #0: loss = 0.135854 (* 1 = 0.135854 loss)
I0122 19:26:29.923501 70150 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 19:26:36.159714 70150 solver.cpp:266] Iteration 11200 (16.036 iter/s, 6.23598s/100 iter), loss = 0.169898
I0122 19:26:36.159741 70150 solver.cpp:285]     Train net output #0: loss = 0.169898 (* 1 = 0.169898 loss)
I0122 19:26:36.159746 70150 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 19:26:42.380164 70150 solver.cpp:266] Iteration 11300 (16.0767 iter/s, 6.22019s/100 iter), loss = 0.170482
I0122 19:26:42.380192 70150 solver.cpp:285]     Train net output #0: loss = 0.170482 (* 1 = 0.170482 loss)
I0122 19:26:42.380198 70150 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 19:26:48.597903 70150 solver.cpp:266] Iteration 11400 (16.0837 iter/s, 6.21747s/100 iter), loss = 0.123951
I0122 19:26:48.597931 70150 solver.cpp:285]     Train net output #0: loss = 0.123951 (* 1 = 0.123951 loss)
I0122 19:26:48.597937 70150 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 19:26:54.799692 70150 solver.cpp:266] Iteration 11500 (16.1251 iter/s, 6.20152s/100 iter), loss = 0.145438
I0122 19:26:54.799760 70150 solver.cpp:285]     Train net output #0: loss = 0.145438 (* 1 = 0.145438 loss)
I0122 19:26:54.799767 70150 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 19:27:01.022464 70150 solver.cpp:266] Iteration 11600 (16.0708 iter/s, 6.22247s/100 iter), loss = 0.206715
I0122 19:27:01.022491 70150 solver.cpp:285]     Train net output #0: loss = 0.206715 (* 1 = 0.206715 loss)
I0122 19:27:01.022497 70150 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 19:27:07.238479 70150 solver.cpp:266] Iteration 11700 (16.0882 iter/s, 6.21575s/100 iter), loss = 0.167745
I0122 19:27:07.238507 70150 solver.cpp:285]     Train net output #0: loss = 0.167745 (* 1 = 0.167745 loss)
I0122 19:27:07.238513 70150 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 19:27:13.459792 70150 solver.cpp:266] Iteration 11800 (16.0745 iter/s, 6.22105s/100 iter), loss = 0.245001
I0122 19:27:13.459821 70150 solver.cpp:285]     Train net output #0: loss = 0.245001 (* 1 = 0.245001 loss)
I0122 19:27:13.459826 70150 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 19:27:19.675848 70150 solver.cpp:266] Iteration 11900 (16.0881 iter/s, 6.21579s/100 iter), loss = 0.114138
I0122 19:27:19.675878 70150 solver.cpp:285]     Train net output #0: loss = 0.114138 (* 1 = 0.114138 loss)
I0122 19:27:19.675882 70150 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 19:27:25.830821 70150 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 19:27:27.280431 70150 solver.cpp:517]     Test net output #0: accuracy = 0.627667
I0122 19:27:27.280455 70150 solver.cpp:517]     Test net output #1: loss = 1.1647 (* 1 = 1.1647 loss)
I0122 19:27:27.280459 70150 solver.cpp:517]     Test net output #2: top-1 = 0.627667
I0122 19:27:27.280462 70150 solver.cpp:517]     Test net output #3: top-5 = 0.924555
I0122 19:27:27.343180 70150 solver.cpp:266] Iteration 12000 (13.0429 iter/s, 7.66701s/100 iter), loss = 0.162135
I0122 19:27:27.343199 70150 solver.cpp:285]     Train net output #0: loss = 0.162135 (* 1 = 0.162135 loss)
I0122 19:27:27.343206 70150 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 19:27:33.571576 70150 solver.cpp:266] Iteration 12100 (16.0562 iter/s, 6.22814s/100 iter), loss = 0.153156
I0122 19:27:33.571604 70150 solver.cpp:285]     Train net output #0: loss = 0.153156 (* 1 = 0.153156 loss)
I0122 19:27:33.571609 70150 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 19:27:39.790396 70150 solver.cpp:266] Iteration 12200 (16.0809 iter/s, 6.21856s/100 iter), loss = 0.12169
I0122 19:27:39.790424 70150 solver.cpp:285]     Train net output #0: loss = 0.12169 (* 1 = 0.12169 loss)
I0122 19:27:39.790429 70150 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 19:27:46.013109 70150 solver.cpp:266] Iteration 12300 (16.0708 iter/s, 6.22245s/100 iter), loss = 0.15634
I0122 19:27:46.013135 70150 solver.cpp:285]     Train net output #0: loss = 0.15634 (* 1 = 0.15634 loss)
I0122 19:27:46.013141 70150 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 19:27:52.246809 70150 solver.cpp:266] Iteration 12400 (16.0425 iter/s, 6.23343s/100 iter), loss = 0.0855931
I0122 19:27:52.246836 70150 solver.cpp:285]     Train net output #0: loss = 0.0855932 (* 1 = 0.0855932 loss)
I0122 19:27:52.246841 70150 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 19:27:58.458202 70150 solver.cpp:266] Iteration 12500 (16.1001 iter/s, 6.21113s/100 iter), loss = 0.120416
I0122 19:27:58.458307 70150 solver.cpp:285]     Train net output #0: loss = 0.120416 (* 1 = 0.120416 loss)
I0122 19:27:58.458313 70150 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 19:28:04.689791 70150 solver.cpp:266] Iteration 12600 (16.0481 iter/s, 6.23125s/100 iter), loss = 0.100138
I0122 19:28:04.689821 70150 solver.cpp:285]     Train net output #0: loss = 0.100138 (* 1 = 0.100138 loss)
I0122 19:28:04.689826 70150 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 19:28:10.916849 70150 solver.cpp:266] Iteration 12700 (16.0596 iter/s, 6.22679s/100 iter), loss = 0.155736
I0122 19:28:10.916878 70150 solver.cpp:285]     Train net output #0: loss = 0.155736 (* 1 = 0.155736 loss)
I0122 19:28:10.916884 70150 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 19:28:17.120147 70150 solver.cpp:266] Iteration 12800 (16.1211 iter/s, 6.20303s/100 iter), loss = 0.15678
I0122 19:28:17.120177 70150 solver.cpp:285]     Train net output #0: loss = 0.156781 (* 1 = 0.156781 loss)
I0122 19:28:17.120182 70150 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 19:28:23.334728 70150 solver.cpp:266] Iteration 12900 (16.0919 iter/s, 6.21431s/100 iter), loss = 0.0421701
I0122 19:28:23.334754 70150 solver.cpp:285]     Train net output #0: loss = 0.0421702 (* 1 = 0.0421702 loss)
I0122 19:28:23.334760 70150 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 19:28:29.504596 70150 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 19:28:30.959388 70150 solver.cpp:517]     Test net output #0: accuracy = 0.666445
I0122 19:28:30.959414 70150 solver.cpp:517]     Test net output #1: loss = 1.05614 (* 1 = 1.05614 loss)
I0122 19:28:30.959419 70150 solver.cpp:517]     Test net output #2: top-1 = 0.666445
I0122 19:28:30.959422 70150 solver.cpp:517]     Test net output #3: top-5 = 0.937889
I0122 19:28:31.021075 70150 solver.cpp:266] Iteration 13000 (13.0106 iter/s, 7.68603s/100 iter), loss = 0.124309
I0122 19:28:31.021095 70150 solver.cpp:285]     Train net output #0: loss = 0.124309 (* 1 = 0.124309 loss)
I0122 19:28:31.021100 70150 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 19:28:37.247654 70150 solver.cpp:266] Iteration 13100 (16.0608 iter/s, 6.22632s/100 iter), loss = 0.108597
I0122 19:28:37.247681 70150 solver.cpp:285]     Train net output #0: loss = 0.108597 (* 1 = 0.108597 loss)
I0122 19:28:37.247686 70150 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 19:28:43.448292 70150 solver.cpp:266] Iteration 13200 (16.1281 iter/s, 6.20037s/100 iter), loss = 0.137022
I0122 19:28:43.448319 70150 solver.cpp:285]     Train net output #0: loss = 0.137022 (* 1 = 0.137022 loss)
I0122 19:28:43.448325 70150 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 19:28:49.669896 70150 solver.cpp:266] Iteration 13300 (16.0737 iter/s, 6.22134s/100 iter), loss = 0.141365
I0122 19:28:49.669926 70150 solver.cpp:285]     Train net output #0: loss = 0.141365 (* 1 = 0.141365 loss)
I0122 19:28:49.669932 70150 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 19:28:55.889130 70150 solver.cpp:266] Iteration 13400 (16.0798 iter/s, 6.21897s/100 iter), loss = 0.106572
I0122 19:28:55.889170 70150 solver.cpp:285]     Train net output #0: loss = 0.106572 (* 1 = 0.106572 loss)
I0122 19:28:55.889178 70150 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 19:29:02.108470 70150 solver.cpp:266] Iteration 13500 (16.0796 iter/s, 6.21906s/100 iter), loss = 0.140567
I0122 19:29:02.108546 70150 solver.cpp:285]     Train net output #0: loss = 0.140567 (* 1 = 0.140567 loss)
I0122 19:29:02.108552 70150 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 19:29:08.333077 70150 solver.cpp:266] Iteration 13600 (16.0661 iter/s, 6.2243s/100 iter), loss = 0.0664153
I0122 19:29:08.333106 70150 solver.cpp:285]     Train net output #0: loss = 0.0664154 (* 1 = 0.0664154 loss)
I0122 19:29:08.333111 70150 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 19:29:14.552700 70150 solver.cpp:266] Iteration 13700 (16.0788 iter/s, 6.21936s/100 iter), loss = 0.0876411
I0122 19:29:14.552726 70150 solver.cpp:285]     Train net output #0: loss = 0.0876411 (* 1 = 0.0876411 loss)
I0122 19:29:14.552731 70150 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 19:29:20.767001 70150 solver.cpp:266] Iteration 13800 (16.0926 iter/s, 6.21404s/100 iter), loss = 0.0924054
I0122 19:29:20.767029 70150 solver.cpp:285]     Train net output #0: loss = 0.0924055 (* 1 = 0.0924055 loss)
I0122 19:29:20.767033 70150 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 19:29:26.975220 70150 solver.cpp:266] Iteration 13900 (16.1084 iter/s, 6.20795s/100 iter), loss = 0.0624133
I0122 19:29:26.975250 70150 solver.cpp:285]     Train net output #0: loss = 0.0624134 (* 1 = 0.0624134 loss)
I0122 19:29:26.975255 70150 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 19:29:33.136056 70150 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 19:29:34.586225 70150 solver.cpp:517]     Test net output #0: accuracy = 0.737
I0122 19:29:34.586251 70150 solver.cpp:517]     Test net output #1: loss = 0.83262 (* 1 = 0.83262 loss)
I0122 19:29:34.586256 70150 solver.cpp:517]     Test net output #2: top-1 = 0.737
I0122 19:29:34.586259 70150 solver.cpp:517]     Test net output #3: top-5 = 0.962778
I0122 19:29:34.647413 70150 solver.cpp:266] Iteration 14000 (13.0346 iter/s, 7.67187s/100 iter), loss = 0.0434508
I0122 19:29:34.647434 70150 solver.cpp:285]     Train net output #0: loss = 0.0434508 (* 1 = 0.0434508 loss)
I0122 19:29:34.647439 70150 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 19:29:40.849295 70150 solver.cpp:266] Iteration 14100 (16.1248 iter/s, 6.20162s/100 iter), loss = 0.0902235
I0122 19:29:40.849323 70150 solver.cpp:285]     Train net output #0: loss = 0.0902235 (* 1 = 0.0902235 loss)
I0122 19:29:40.849328 70150 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 19:29:47.067126 70150 solver.cpp:266] Iteration 14200 (16.0835 iter/s, 6.21757s/100 iter), loss = 0.096448
I0122 19:29:47.067154 70150 solver.cpp:285]     Train net output #0: loss = 0.096448 (* 1 = 0.096448 loss)
I0122 19:29:47.067160 70150 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 19:29:53.284965 70150 solver.cpp:266] Iteration 14300 (16.0834 iter/s, 6.21757s/100 iter), loss = 0.0584663
I0122 19:29:53.284994 70150 solver.cpp:285]     Train net output #0: loss = 0.0584663 (* 1 = 0.0584663 loss)
I0122 19:29:53.285001 70150 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 19:29:59.493878 70150 solver.cpp:266] Iteration 14400 (16.1066 iter/s, 6.20865s/100 iter), loss = 0.0615307
I0122 19:29:59.493908 70150 solver.cpp:285]     Train net output #0: loss = 0.0615307 (* 1 = 0.0615307 loss)
I0122 19:29:59.493916 70150 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 19:30:05.728168 70150 solver.cpp:266] Iteration 14500 (16.041 iter/s, 6.23402s/100 iter), loss = 0.065477
I0122 19:30:05.728245 70150 solver.cpp:285]     Train net output #0: loss = 0.065477 (* 1 = 0.065477 loss)
I0122 19:30:05.728251 70150 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 19:30:11.942858 70150 solver.cpp:266] Iteration 14600 (16.0917 iter/s, 6.21438s/100 iter), loss = 0.0744797
I0122 19:30:11.942886 70150 solver.cpp:285]     Train net output #0: loss = 0.0744797 (* 1 = 0.0744797 loss)
I0122 19:30:11.942893 70150 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 19:30:18.166646 70150 solver.cpp:266] Iteration 14700 (16.0681 iter/s, 6.22352s/100 iter), loss = 0.0409808
I0122 19:30:18.166674 70150 solver.cpp:285]     Train net output #0: loss = 0.0409808 (* 1 = 0.0409808 loss)
I0122 19:30:18.166682 70150 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 19:30:24.395748 70150 solver.cpp:266] Iteration 14800 (16.0544 iter/s, 6.22883s/100 iter), loss = 0.0967879
I0122 19:30:24.395777 70150 solver.cpp:285]     Train net output #0: loss = 0.0967879 (* 1 = 0.0967879 loss)
I0122 19:30:24.395783 70150 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 19:30:30.616502 70150 solver.cpp:266] Iteration 14900 (16.0759 iter/s, 6.22048s/100 iter), loss = 0.0984037
I0122 19:30:30.616530 70150 solver.cpp:285]     Train net output #0: loss = 0.0984038 (* 1 = 0.0984038 loss)
I0122 19:30:30.616535 70150 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 19:30:36.781687 70150 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 19:30:38.237386 70150 solver.cpp:517]     Test net output #0: accuracy = 0.801889
I0122 19:30:38.237411 70150 solver.cpp:517]     Test net output #1: loss = 0.634521 (* 1 = 0.634521 loss)
I0122 19:30:38.237416 70150 solver.cpp:517]     Test net output #2: top-1 = 0.801889
I0122 19:30:38.237419 70150 solver.cpp:517]     Test net output #3: top-5 = 0.977111
I0122 19:30:38.299099 70150 solver.cpp:266] Iteration 15000 (13.017 iter/s, 7.68228s/100 iter), loss = 0.0904752
I0122 19:30:38.299119 70150 solver.cpp:285]     Train net output #0: loss = 0.0904752 (* 1 = 0.0904752 loss)
I0122 19:30:38.299125 70150 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 19:30:44.492694 70150 solver.cpp:266] Iteration 15100 (16.1464 iter/s, 6.19334s/100 iter), loss = 0.0657369
I0122 19:30:44.492722 70150 solver.cpp:285]     Train net output #0: loss = 0.0657369 (* 1 = 0.0657369 loss)
I0122 19:30:44.492727 70150 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 19:30:50.707473 70150 solver.cpp:266] Iteration 15200 (16.0914 iter/s, 6.21451s/100 iter), loss = 0.126144
I0122 19:30:50.707499 70150 solver.cpp:285]     Train net output #0: loss = 0.126144 (* 1 = 0.126144 loss)
I0122 19:30:50.707505 70150 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 19:30:56.915509 70150 solver.cpp:266] Iteration 15300 (16.1088 iter/s, 6.20777s/100 iter), loss = 0.108526
I0122 19:30:56.915537 70150 solver.cpp:285]     Train net output #0: loss = 0.108526 (* 1 = 0.108526 loss)
I0122 19:30:56.915544 70150 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 19:31:03.140408 70150 solver.cpp:266] Iteration 15400 (16.0652 iter/s, 6.22463s/100 iter), loss = 0.116298
I0122 19:31:03.140434 70150 solver.cpp:285]     Train net output #0: loss = 0.116298 (* 1 = 0.116298 loss)
I0122 19:31:03.140439 70150 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 19:31:09.361614 70150 solver.cpp:266] Iteration 15500 (16.0747 iter/s, 6.22094s/100 iter), loss = 0.0528261
I0122 19:31:09.361747 70150 solver.cpp:285]     Train net output #0: loss = 0.0528261 (* 1 = 0.0528261 loss)
I0122 19:31:09.361752 70150 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 19:31:15.592190 70150 solver.cpp:266] Iteration 15600 (16.0508 iter/s, 6.23021s/100 iter), loss = 0.0723195
I0122 19:31:15.592218 70150 solver.cpp:285]     Train net output #0: loss = 0.0723195 (* 1 = 0.0723195 loss)
I0122 19:31:15.592224 70150 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 19:31:21.805833 70150 solver.cpp:266] Iteration 15700 (16.0943 iter/s, 6.21338s/100 iter), loss = 0.0724916
I0122 19:31:21.805861 70150 solver.cpp:285]     Train net output #0: loss = 0.0724916 (* 1 = 0.0724916 loss)
I0122 19:31:21.805866 70150 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 19:31:28.019763 70150 solver.cpp:266] Iteration 15800 (16.0936 iter/s, 6.21366s/100 iter), loss = 0.0720787
I0122 19:31:28.019791 70150 solver.cpp:285]     Train net output #0: loss = 0.0720787 (* 1 = 0.0720787 loss)
I0122 19:31:28.019798 70150 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 19:31:34.253968 70150 solver.cpp:266] Iteration 15900 (16.0412 iter/s, 6.23394s/100 iter), loss = 0.176178
I0122 19:31:34.253998 70150 solver.cpp:285]     Train net output #0: loss = 0.176178 (* 1 = 0.176178 loss)
I0122 19:31:34.254004 70150 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 19:31:40.407955 70150 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 19:31:41.857888 70150 solver.cpp:517]     Test net output #0: accuracy = 0.840667
I0122 19:31:41.857918 70150 solver.cpp:517]     Test net output #1: loss = 0.49005 (* 1 = 0.49005 loss)
I0122 19:31:41.857923 70150 solver.cpp:517]     Test net output #2: top-1 = 0.840667
I0122 19:31:41.857926 70150 solver.cpp:517]     Test net output #3: top-5 = 0.986445
I0122 19:31:41.919157 70150 solver.cpp:266] Iteration 16000 (13.0465 iter/s, 7.66487s/100 iter), loss = 0.0579828
I0122 19:31:41.919178 70150 solver.cpp:285]     Train net output #0: loss = 0.0579828 (* 1 = 0.0579828 loss)
I0122 19:31:41.919184 70150 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 19:31:48.134356 70150 solver.cpp:266] Iteration 16100 (16.0903 iter/s, 6.21494s/100 iter), loss = 0.103673
I0122 19:31:48.134384 70150 solver.cpp:285]     Train net output #0: loss = 0.103673 (* 1 = 0.103673 loss)
I0122 19:31:48.134390 70150 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 19:31:54.345978 70150 solver.cpp:266] Iteration 16200 (16.0995 iter/s, 6.21136s/100 iter), loss = 0.0724588
I0122 19:31:54.346006 70150 solver.cpp:285]     Train net output #0: loss = 0.0724588 (* 1 = 0.0724588 loss)
I0122 19:31:54.346012 70150 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 19:32:00.571449 70150 solver.cpp:266] Iteration 16300 (16.0637 iter/s, 6.2252s/100 iter), loss = 0.0824212
I0122 19:32:00.571476 70150 solver.cpp:285]     Train net output #0: loss = 0.0824213 (* 1 = 0.0824213 loss)
I0122 19:32:00.571481 70150 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 19:32:06.794075 70150 solver.cpp:266] Iteration 16400 (16.0711 iter/s, 6.22236s/100 iter), loss = 0.0454191
I0122 19:32:06.794104 70150 solver.cpp:285]     Train net output #0: loss = 0.0454191 (* 1 = 0.0454191 loss)
I0122 19:32:06.794109 70150 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 19:32:13.027962 70150 solver.cpp:266] Iteration 16500 (16.042 iter/s, 6.23362s/100 iter), loss = 0.0880136
I0122 19:32:13.028060 70150 solver.cpp:285]     Train net output #0: loss = 0.0880136 (* 1 = 0.0880136 loss)
I0122 19:32:13.028067 70150 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 19:32:19.257848 70150 solver.cpp:266] Iteration 16600 (16.0525 iter/s, 6.22955s/100 iter), loss = 0.0315357
I0122 19:32:19.257875 70150 solver.cpp:285]     Train net output #0: loss = 0.0315358 (* 1 = 0.0315358 loss)
I0122 19:32:19.257880 70150 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 19:32:25.462321 70150 solver.cpp:266] Iteration 16700 (16.1181 iter/s, 6.20421s/100 iter), loss = 0.0705796
I0122 19:32:25.462348 70150 solver.cpp:285]     Train net output #0: loss = 0.0705796 (* 1 = 0.0705796 loss)
I0122 19:32:25.462353 70150 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 19:32:31.677991 70150 solver.cpp:266] Iteration 16800 (16.0891 iter/s, 6.21541s/100 iter), loss = 0.0564493
I0122 19:32:31.678020 70150 solver.cpp:285]     Train net output #0: loss = 0.0564494 (* 1 = 0.0564494 loss)
I0122 19:32:31.678025 70150 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 19:32:37.885493 70150 solver.cpp:266] Iteration 16900 (16.1102 iter/s, 6.20724s/100 iter), loss = 0.0858311
I0122 19:32:37.885521 70150 solver.cpp:285]     Train net output #0: loss = 0.0858311 (* 1 = 0.0858311 loss)
I0122 19:32:37.885527 70150 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 19:32:44.039489 70150 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 19:32:45.493090 70150 solver.cpp:517]     Test net output #0: accuracy = 0.821778
I0122 19:32:45.493118 70150 solver.cpp:517]     Test net output #1: loss = 0.555862 (* 1 = 0.555862 loss)
I0122 19:32:45.493122 70150 solver.cpp:517]     Test net output #2: top-1 = 0.821778
I0122 19:32:45.493125 70150 solver.cpp:517]     Test net output #3: top-5 = 0.991667
I0122 19:32:45.555742 70150 solver.cpp:266] Iteration 17000 (13.0379 iter/s, 7.66993s/100 iter), loss = 0.0771669
I0122 19:32:45.555763 70150 solver.cpp:285]     Train net output #0: loss = 0.0771669 (* 1 = 0.0771669 loss)
I0122 19:32:45.555768 70150 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 19:32:51.774948 70150 solver.cpp:266] Iteration 17100 (16.0799 iter/s, 6.21895s/100 iter), loss = 0.0969128
I0122 19:32:51.774976 70150 solver.cpp:285]     Train net output #0: loss = 0.0969128 (* 1 = 0.0969128 loss)
I0122 19:32:51.774981 70150 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 19:32:57.985592 70150 solver.cpp:266] Iteration 17200 (16.1021 iter/s, 6.21038s/100 iter), loss = 0.117572
I0122 19:32:57.985621 70150 solver.cpp:285]     Train net output #0: loss = 0.117572 (* 1 = 0.117572 loss)
I0122 19:32:57.985627 70150 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 19:33:04.203012 70150 solver.cpp:266] Iteration 17300 (16.0845 iter/s, 6.21715s/100 iter), loss = 0.0901169
I0122 19:33:04.203039 70150 solver.cpp:285]     Train net output #0: loss = 0.090117 (* 1 = 0.090117 loss)
I0122 19:33:04.203044 70150 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 19:33:10.427541 70150 solver.cpp:266] Iteration 17400 (16.0662 iter/s, 6.22426s/100 iter), loss = 0.127178
I0122 19:33:10.427568 70150 solver.cpp:285]     Train net output #0: loss = 0.127178 (* 1 = 0.127178 loss)
I0122 19:33:10.427574 70150 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 19:33:16.639093 70150 solver.cpp:266] Iteration 17500 (16.0997 iter/s, 6.21129s/100 iter), loss = 0.0653958
I0122 19:33:16.639155 70150 solver.cpp:285]     Train net output #0: loss = 0.0653958 (* 1 = 0.0653958 loss)
I0122 19:33:16.639163 70150 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 19:33:22.863433 70150 solver.cpp:266] Iteration 17600 (16.0667 iter/s, 6.22404s/100 iter), loss = 0.0729783
I0122 19:33:22.863462 70150 solver.cpp:285]     Train net output #0: loss = 0.0729784 (* 1 = 0.0729784 loss)
I0122 19:33:22.863468 70150 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 19:33:29.087450 70150 solver.cpp:266] Iteration 17700 (16.0675 iter/s, 6.22375s/100 iter), loss = 0.0964679
I0122 19:33:29.087478 70150 solver.cpp:285]     Train net output #0: loss = 0.096468 (* 1 = 0.096468 loss)
I0122 19:33:29.087484 70150 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 19:33:35.302762 70150 solver.cpp:266] Iteration 17800 (16.09 iter/s, 6.21505s/100 iter), loss = 0.119218
I0122 19:33:35.302791 70150 solver.cpp:285]     Train net output #0: loss = 0.119218 (* 1 = 0.119218 loss)
I0122 19:33:35.302796 70150 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 19:33:41.514184 70150 solver.cpp:266] Iteration 17900 (16.1001 iter/s, 6.21116s/100 iter), loss = 0.0835027
I0122 19:33:41.514214 70150 solver.cpp:285]     Train net output #0: loss = 0.0835028 (* 1 = 0.0835028 loss)
I0122 19:33:41.514219 70150 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 19:33:47.675092 70150 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 19:33:49.125739 70150 solver.cpp:517]     Test net output #0: accuracy = 0.830889
I0122 19:33:49.125766 70150 solver.cpp:517]     Test net output #1: loss = 0.552905 (* 1 = 0.552905 loss)
I0122 19:33:49.125769 70150 solver.cpp:517]     Test net output #2: top-1 = 0.830889
I0122 19:33:49.125773 70150 solver.cpp:517]     Test net output #3: top-5 = 0.990556
I0122 19:33:49.186766 70150 solver.cpp:266] Iteration 18000 (13.034 iter/s, 7.67226s/100 iter), loss = 0.0980126
I0122 19:33:49.186786 70150 solver.cpp:285]     Train net output #0: loss = 0.0980126 (* 1 = 0.0980126 loss)
I0122 19:33:49.186792 70150 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 19:33:55.391520 70150 solver.cpp:266] Iteration 18100 (16.1173 iter/s, 6.20449s/100 iter), loss = 0.110057
I0122 19:33:55.391546 70150 solver.cpp:285]     Train net output #0: loss = 0.110057 (* 1 = 0.110057 loss)
I0122 19:33:55.391551 70150 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 19:34:01.608678 70150 solver.cpp:266] Iteration 18200 (16.0852 iter/s, 6.2169s/100 iter), loss = 0.021914
I0122 19:34:01.608707 70150 solver.cpp:285]     Train net output #0: loss = 0.0219141 (* 1 = 0.0219141 loss)
I0122 19:34:01.608713 70150 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 19:34:07.829689 70150 solver.cpp:266] Iteration 18300 (16.0753 iter/s, 6.22074s/100 iter), loss = 0.090258
I0122 19:34:07.829715 70150 solver.cpp:285]     Train net output #0: loss = 0.090258 (* 1 = 0.090258 loss)
I0122 19:34:07.829721 70150 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 19:34:14.042291 70150 solver.cpp:266] Iteration 18400 (16.097 iter/s, 6.21234s/100 iter), loss = 0.0899571
I0122 19:34:14.042321 70150 solver.cpp:285]     Train net output #0: loss = 0.0899572 (* 1 = 0.0899572 loss)
I0122 19:34:14.042326 70150 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 19:34:20.243587 70150 solver.cpp:266] Iteration 18500 (16.1264 iter/s, 6.20103s/100 iter), loss = 0.0884359
I0122 19:34:20.243646 70150 solver.cpp:285]     Train net output #0: loss = 0.088436 (* 1 = 0.088436 loss)
I0122 19:34:20.243652 70150 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 19:34:26.464516 70150 solver.cpp:266] Iteration 18600 (16.0755 iter/s, 6.22063s/100 iter), loss = 0.0640559
I0122 19:34:26.464545 70150 solver.cpp:285]     Train net output #0: loss = 0.064056 (* 1 = 0.064056 loss)
I0122 19:34:26.464550 70150 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 19:34:32.685844 70150 solver.cpp:266] Iteration 18700 (16.0744 iter/s, 6.22106s/100 iter), loss = 0.066129
I0122 19:34:32.685875 70150 solver.cpp:285]     Train net output #0: loss = 0.066129 (* 1 = 0.066129 loss)
I0122 19:34:32.685881 70150 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 19:34:38.901546 70150 solver.cpp:266] Iteration 18800 (16.089 iter/s, 6.21543s/100 iter), loss = 0.0862644
I0122 19:34:38.901572 70150 solver.cpp:285]     Train net output #0: loss = 0.0862644 (* 1 = 0.0862644 loss)
I0122 19:34:38.901577 70150 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 19:34:45.125531 70150 solver.cpp:266] Iteration 18900 (16.0676 iter/s, 6.22372s/100 iter), loss = 0.157567
I0122 19:34:45.125558 70150 solver.cpp:285]     Train net output #0: loss = 0.157567 (* 1 = 0.157567 loss)
I0122 19:34:45.125563 70150 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 19:34:51.296509 70150 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 19:34:52.744686 70150 solver.cpp:517]     Test net output #0: accuracy = 0.834
I0122 19:34:52.744710 70150 solver.cpp:517]     Test net output #1: loss = 0.560868 (* 1 = 0.560868 loss)
I0122 19:34:52.744714 70150 solver.cpp:517]     Test net output #2: top-1 = 0.834
I0122 19:34:52.744716 70150 solver.cpp:517]     Test net output #3: top-5 = 0.988445
I0122 19:34:52.807360 70150 solver.cpp:266] Iteration 19000 (13.0183 iter/s, 7.68151s/100 iter), loss = 0.11238
I0122 19:34:52.807380 70150 solver.cpp:285]     Train net output #0: loss = 0.11238 (* 1 = 0.11238 loss)
I0122 19:34:52.807386 70150 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 19:34:59.024546 70150 solver.cpp:266] Iteration 19100 (16.0851 iter/s, 6.21693s/100 iter), loss = 0.0358767
I0122 19:34:59.024574 70150 solver.cpp:285]     Train net output #0: loss = 0.0358768 (* 1 = 0.0358768 loss)
I0122 19:34:59.024577 70150 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 19:35:05.254570 70150 solver.cpp:266] Iteration 19200 (16.052 iter/s, 6.22976s/100 iter), loss = 0.0883437
I0122 19:35:05.254600 70150 solver.cpp:285]     Train net output #0: loss = 0.0883438 (* 1 = 0.0883438 loss)
I0122 19:35:05.254606 70150 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 19:35:11.463620 70150 solver.cpp:266] Iteration 19300 (16.1062 iter/s, 6.20878s/100 iter), loss = 0.0786895
I0122 19:35:11.463649 70150 solver.cpp:285]     Train net output #0: loss = 0.0786896 (* 1 = 0.0786896 loss)
I0122 19:35:11.463654 70150 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 19:35:17.688979 70150 solver.cpp:266] Iteration 19400 (16.064 iter/s, 6.22509s/100 iter), loss = 0.048529
I0122 19:35:17.689007 70150 solver.cpp:285]     Train net output #0: loss = 0.0485291 (* 1 = 0.0485291 loss)
I0122 19:35:17.689013 70150 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 19:35:23.892796 70150 solver.cpp:266] Iteration 19500 (16.1198 iter/s, 6.20355s/100 iter), loss = 0.0561548
I0122 19:35:23.892918 70150 solver.cpp:285]     Train net output #0: loss = 0.0561549 (* 1 = 0.0561549 loss)
I0122 19:35:23.892925 70150 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 19:35:30.112458 70150 solver.cpp:266] Iteration 19600 (16.079 iter/s, 6.2193s/100 iter), loss = 0.116496
I0122 19:35:30.112488 70150 solver.cpp:285]     Train net output #0: loss = 0.116496 (* 1 = 0.116496 loss)
I0122 19:35:30.112493 70150 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 19:35:36.347358 70150 solver.cpp:266] Iteration 19700 (16.0394 iter/s, 6.23463s/100 iter), loss = 0.0556548
I0122 19:35:36.347384 70150 solver.cpp:285]     Train net output #0: loss = 0.055655 (* 1 = 0.055655 loss)
I0122 19:35:36.347390 70150 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 19:35:42.548925 70150 solver.cpp:266] Iteration 19800 (16.1256 iter/s, 6.2013s/100 iter), loss = 0.083052
I0122 19:35:42.548954 70150 solver.cpp:285]     Train net output #0: loss = 0.0830521 (* 1 = 0.0830521 loss)
I0122 19:35:42.548959 70150 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 19:35:48.772580 70150 solver.cpp:266] Iteration 19900 (16.0684 iter/s, 6.22339s/100 iter), loss = 0.100059
I0122 19:35:48.772609 70150 solver.cpp:285]     Train net output #0: loss = 0.100059 (* 1 = 0.100059 loss)
I0122 19:35:48.772615 70150 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 19:35:54.920383 70150 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_20000.caffemodel
I0122 19:35:54.971206 70150 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_20000.solverstate
I0122 19:35:54.978705 70150 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 19:35:56.430891 70150 solver.cpp:517]     Test net output #0: accuracy = 0.855555
I0122 19:35:56.430917 70150 solver.cpp:517]     Test net output #1: loss = 0.46605 (* 1 = 0.46605 loss)
I0122 19:35:56.430922 70150 solver.cpp:517]     Test net output #2: top-1 = 0.855555
I0122 19:35:56.430925 70150 solver.cpp:517]     Test net output #3: top-5 = 0.991889
I0122 19:35:56.491998 70150 solver.cpp:266] Iteration 20000 (12.9549 iter/s, 7.7191s/100 iter), loss = 0.0390945
I0122 19:35:56.492017 70150 solver.cpp:285]     Train net output #0: loss = 0.0390946 (* 1 = 0.0390946 loss)
I0122 19:35:56.492024 70150 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 19:36:02.709403 70150 solver.cpp:266] Iteration 20100 (16.0845 iter/s, 6.21715s/100 iter), loss = 0.0905178
I0122 19:36:02.709430 70150 solver.cpp:285]     Train net output #0: loss = 0.0905179 (* 1 = 0.0905179 loss)
I0122 19:36:02.709435 70150 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 19:36:08.931900 70150 solver.cpp:266] Iteration 20200 (16.0714 iter/s, 6.22223s/100 iter), loss = 0.0556366
I0122 19:36:08.931928 70150 solver.cpp:285]     Train net output #0: loss = 0.0556367 (* 1 = 0.0556367 loss)
I0122 19:36:08.931934 70150 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 19:36:15.150508 70150 solver.cpp:266] Iteration 20300 (16.0815 iter/s, 6.21834s/100 iter), loss = 0.0128
I0122 19:36:15.150537 70150 solver.cpp:285]     Train net output #0: loss = 0.0128001 (* 1 = 0.0128001 loss)
I0122 19:36:15.150543 70150 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 19:36:21.362161 70150 solver.cpp:266] Iteration 20400 (16.0995 iter/s, 6.21139s/100 iter), loss = 0.039436
I0122 19:36:21.362190 70150 solver.cpp:285]     Train net output #0: loss = 0.0394361 (* 1 = 0.0394361 loss)
I0122 19:36:21.362195 70150 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 19:36:27.589540 70150 solver.cpp:266] Iteration 20500 (16.0588 iter/s, 6.22711s/100 iter), loss = 0.0197996
I0122 19:36:27.589614 70150 solver.cpp:285]     Train net output #0: loss = 0.0197997 (* 1 = 0.0197997 loss)
I0122 19:36:27.589620 70150 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 19:36:33.798336 70150 solver.cpp:266] Iteration 20600 (16.107 iter/s, 6.20849s/100 iter), loss = 0.0421147
I0122 19:36:33.798364 70150 solver.cpp:285]     Train net output #0: loss = 0.0421148 (* 1 = 0.0421148 loss)
I0122 19:36:33.798370 70150 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 19:36:40.010828 70150 solver.cpp:266] Iteration 20700 (16.0973 iter/s, 6.21222s/100 iter), loss = 0.0287026
I0122 19:36:40.010856 70150 solver.cpp:285]     Train net output #0: loss = 0.0287027 (* 1 = 0.0287027 loss)
I0122 19:36:40.010862 70150 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 19:36:46.229856 70150 solver.cpp:266] Iteration 20800 (16.0804 iter/s, 6.21876s/100 iter), loss = 0.0311837
I0122 19:36:46.229884 70150 solver.cpp:285]     Train net output #0: loss = 0.0311838 (* 1 = 0.0311838 loss)
I0122 19:36:46.229889 70150 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 19:36:52.441628 70150 solver.cpp:266] Iteration 20900 (16.0992 iter/s, 6.21151s/100 iter), loss = 0.0349463
I0122 19:36:52.441656 70150 solver.cpp:285]     Train net output #0: loss = 0.0349464 (* 1 = 0.0349464 loss)
I0122 19:36:52.441661 70150 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 19:36:58.597787 70150 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 19:37:00.049422 70150 solver.cpp:517]     Test net output #0: accuracy = 0.893111
I0122 19:37:00.049445 70150 solver.cpp:517]     Test net output #1: loss = 0.35508 (* 1 = 0.35508 loss)
I0122 19:37:00.049449 70150 solver.cpp:517]     Test net output #2: top-1 = 0.893111
I0122 19:37:00.049453 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:37:00.113008 70150 solver.cpp:266] Iteration 21000 (13.036 iter/s, 7.67106s/100 iter), loss = 0.0208964
I0122 19:37:00.113029 70150 solver.cpp:285]     Train net output #0: loss = 0.0208966 (* 1 = 0.0208966 loss)
I0122 19:37:00.113034 70150 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 19:37:06.330373 70150 solver.cpp:266] Iteration 21100 (16.0847 iter/s, 6.2171s/100 iter), loss = 0.0349755
I0122 19:37:06.330399 70150 solver.cpp:285]     Train net output #0: loss = 0.0349757 (* 1 = 0.0349757 loss)
I0122 19:37:06.330405 70150 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 19:37:12.552666 70150 solver.cpp:266] Iteration 21200 (16.0719 iter/s, 6.22203s/100 iter), loss = 0.0209821
I0122 19:37:12.552695 70150 solver.cpp:285]     Train net output #0: loss = 0.0209823 (* 1 = 0.0209823 loss)
I0122 19:37:12.552700 70150 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 19:37:18.777735 70150 solver.cpp:266] Iteration 21300 (16.0648 iter/s, 6.2248s/100 iter), loss = 0.0224267
I0122 19:37:18.777763 70150 solver.cpp:285]     Train net output #0: loss = 0.0224268 (* 1 = 0.0224268 loss)
I0122 19:37:18.777770 70150 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 19:37:24.985726 70150 solver.cpp:266] Iteration 21400 (16.109 iter/s, 6.20772s/100 iter), loss = 0.0171163
I0122 19:37:24.985755 70150 solver.cpp:285]     Train net output #0: loss = 0.0171164 (* 1 = 0.0171164 loss)
I0122 19:37:24.985760 70150 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 19:37:31.202812 70150 solver.cpp:266] Iteration 21500 (16.0854 iter/s, 6.21682s/100 iter), loss = 0.0141914
I0122 19:37:31.202888 70150 solver.cpp:285]     Train net output #0: loss = 0.0141915 (* 1 = 0.0141915 loss)
I0122 19:37:31.202895 70150 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 19:37:37.425863 70150 solver.cpp:266] Iteration 21600 (16.0701 iter/s, 6.22274s/100 iter), loss = 0.0105316
I0122 19:37:37.425891 70150 solver.cpp:285]     Train net output #0: loss = 0.0105317 (* 1 = 0.0105317 loss)
I0122 19:37:37.425897 70150 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 19:37:43.637696 70150 solver.cpp:266] Iteration 21700 (16.099 iter/s, 6.21157s/100 iter), loss = 0.0328662
I0122 19:37:43.637725 70150 solver.cpp:285]     Train net output #0: loss = 0.0328663 (* 1 = 0.0328663 loss)
I0122 19:37:43.637732 70150 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 19:37:49.869005 70150 solver.cpp:266] Iteration 21800 (16.0487 iter/s, 6.23104s/100 iter), loss = 0.0108618
I0122 19:37:49.869033 70150 solver.cpp:285]     Train net output #0: loss = 0.0108619 (* 1 = 0.0108619 loss)
I0122 19:37:49.869040 70150 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 19:37:56.089406 70150 solver.cpp:266] Iteration 21900 (16.0768 iter/s, 6.22013s/100 iter), loss = 0.0329153
I0122 19:37:56.089434 70150 solver.cpp:285]     Train net output #0: loss = 0.0329154 (* 1 = 0.0329154 loss)
I0122 19:37:56.089439 70150 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 19:38:02.228863 70150 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 19:38:03.689090 70150 solver.cpp:517]     Test net output #0: accuracy = 0.894
I0122 19:38:03.689118 70150 solver.cpp:517]     Test net output #1: loss = 0.35629 (* 1 = 0.35629 loss)
I0122 19:38:03.689122 70150 solver.cpp:517]     Test net output #2: top-1 = 0.894
I0122 19:38:03.689126 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:38:03.750754 70150 solver.cpp:266] Iteration 22000 (13.0531 iter/s, 7.66103s/100 iter), loss = 0.00883062
I0122 19:38:03.750775 70150 solver.cpp:285]     Train net output #0: loss = 0.00883071 (* 1 = 0.00883071 loss)
I0122 19:38:03.750782 70150 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 19:38:09.960041 70150 solver.cpp:266] Iteration 22100 (16.1056 iter/s, 6.20903s/100 iter), loss = 0.0133934
I0122 19:38:09.960069 70150 solver.cpp:285]     Train net output #0: loss = 0.0133935 (* 1 = 0.0133935 loss)
I0122 19:38:09.960075 70150 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 19:38:16.165992 70150 solver.cpp:266] Iteration 22200 (16.1143 iter/s, 6.20568s/100 iter), loss = 0.0121722
I0122 19:38:16.166018 70150 solver.cpp:285]     Train net output #0: loss = 0.0121723 (* 1 = 0.0121723 loss)
I0122 19:38:16.166023 70150 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 19:38:22.391011 70150 solver.cpp:266] Iteration 22300 (16.0649 iter/s, 6.22475s/100 iter), loss = 0.00731063
I0122 19:38:22.391041 70150 solver.cpp:285]     Train net output #0: loss = 0.00731074 (* 1 = 0.00731074 loss)
I0122 19:38:22.391047 70150 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 19:38:28.607813 70150 solver.cpp:266] Iteration 22400 (16.0861 iter/s, 6.21654s/100 iter), loss = 0.0275765
I0122 19:38:28.607843 70150 solver.cpp:285]     Train net output #0: loss = 0.0275766 (* 1 = 0.0275766 loss)
I0122 19:38:28.607849 70150 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 19:38:34.834848 70150 solver.cpp:266] Iteration 22500 (16.0597 iter/s, 6.22677s/100 iter), loss = 0.0204486
I0122 19:38:34.834928 70150 solver.cpp:285]     Train net output #0: loss = 0.0204488 (* 1 = 0.0204488 loss)
I0122 19:38:34.834934 70150 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 19:38:41.048125 70150 solver.cpp:266] Iteration 22600 (16.0954 iter/s, 6.21296s/100 iter), loss = 0.0124224
I0122 19:38:41.048154 70150 solver.cpp:285]     Train net output #0: loss = 0.0124225 (* 1 = 0.0124225 loss)
I0122 19:38:41.048159 70150 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 19:38:47.277765 70150 solver.cpp:266] Iteration 22700 (16.053 iter/s, 6.22937s/100 iter), loss = 0.00829685
I0122 19:38:47.277794 70150 solver.cpp:285]     Train net output #0: loss = 0.00829695 (* 1 = 0.00829695 loss)
I0122 19:38:47.277801 70150 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 19:38:53.482733 70150 solver.cpp:266] Iteration 22800 (16.1168 iter/s, 6.2047s/100 iter), loss = 0.0150871
I0122 19:38:53.482762 70150 solver.cpp:285]     Train net output #0: loss = 0.0150872 (* 1 = 0.0150872 loss)
I0122 19:38:53.482769 70150 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 19:38:59.703203 70150 solver.cpp:266] Iteration 22900 (16.0766 iter/s, 6.2202s/100 iter), loss = 0.0125403
I0122 19:38:59.703233 70150 solver.cpp:285]     Train net output #0: loss = 0.0125404 (* 1 = 0.0125404 loss)
I0122 19:38:59.703238 70150 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 19:39:05.855891 70150 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 19:39:07.318126 70150 solver.cpp:517]     Test net output #0: accuracy = 0.895889
I0122 19:39:07.318153 70150 solver.cpp:517]     Test net output #1: loss = 0.355898 (* 1 = 0.355898 loss)
I0122 19:39:07.318158 70150 solver.cpp:517]     Test net output #2: top-1 = 0.895889
I0122 19:39:07.318162 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:39:07.379325 70150 solver.cpp:266] Iteration 23000 (13.028 iter/s, 7.6758s/100 iter), loss = 0.013273
I0122 19:39:07.379346 70150 solver.cpp:285]     Train net output #0: loss = 0.0132731 (* 1 = 0.0132731 loss)
I0122 19:39:07.379354 70150 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 19:39:13.590361 70150 solver.cpp:266] Iteration 23100 (16.101 iter/s, 6.21078s/100 iter), loss = 0.0278716
I0122 19:39:13.590389 70150 solver.cpp:285]     Train net output #0: loss = 0.0278717 (* 1 = 0.0278717 loss)
I0122 19:39:13.590394 70150 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 19:39:19.801761 70150 solver.cpp:266] Iteration 23200 (16.1001 iter/s, 6.21113s/100 iter), loss = 0.017362
I0122 19:39:19.801790 70150 solver.cpp:285]     Train net output #0: loss = 0.0173621 (* 1 = 0.0173621 loss)
I0122 19:39:19.801796 70150 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 19:39:26.019927 70150 solver.cpp:266] Iteration 23300 (16.0826 iter/s, 6.2179s/100 iter), loss = 0.011181
I0122 19:39:26.019956 70150 solver.cpp:285]     Train net output #0: loss = 0.0111811 (* 1 = 0.0111811 loss)
I0122 19:39:26.019963 70150 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 19:39:32.245880 70150 solver.cpp:266] Iteration 23400 (16.0625 iter/s, 6.22569s/100 iter), loss = 0.00746509
I0122 19:39:32.245913 70150 solver.cpp:285]     Train net output #0: loss = 0.0074652 (* 1 = 0.0074652 loss)
I0122 19:39:32.245918 70150 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 19:39:38.457939 70150 solver.cpp:266] Iteration 23500 (16.0984 iter/s, 6.21179s/100 iter), loss = 0.00818163
I0122 19:39:38.457999 70150 solver.cpp:285]     Train net output #0: loss = 0.00818174 (* 1 = 0.00818174 loss)
I0122 19:39:38.458005 70150 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 19:39:44.670742 70150 solver.cpp:266] Iteration 23600 (16.0966 iter/s, 6.2125s/100 iter), loss = 0.010044
I0122 19:39:44.670771 70150 solver.cpp:285]     Train net output #0: loss = 0.0100441 (* 1 = 0.0100441 loss)
I0122 19:39:44.670778 70150 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 19:39:50.898322 70150 solver.cpp:266] Iteration 23700 (16.0583 iter/s, 6.22731s/100 iter), loss = 0.0130135
I0122 19:39:50.898351 70150 solver.cpp:285]     Train net output #0: loss = 0.0130136 (* 1 = 0.0130136 loss)
I0122 19:39:50.898357 70150 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 19:39:57.100436 70150 solver.cpp:266] Iteration 23800 (16.1242 iter/s, 6.20185s/100 iter), loss = 0.0168062
I0122 19:39:57.100464 70150 solver.cpp:285]     Train net output #0: loss = 0.0168063 (* 1 = 0.0168063 loss)
I0122 19:39:57.100471 70150 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 19:40:03.314843 70150 solver.cpp:266] Iteration 23900 (16.0923 iter/s, 6.21414s/100 iter), loss = 0.00458494
I0122 19:40:03.314872 70150 solver.cpp:285]     Train net output #0: loss = 0.00458506 (* 1 = 0.00458506 loss)
I0122 19:40:03.314878 70150 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 19:40:09.488466 70150 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 19:40:10.943063 70150 solver.cpp:517]     Test net output #0: accuracy = 0.896111
I0122 19:40:10.943087 70150 solver.cpp:517]     Test net output #1: loss = 0.364683 (* 1 = 0.364683 loss)
I0122 19:40:10.943091 70150 solver.cpp:517]     Test net output #2: top-1 = 0.896111
I0122 19:40:10.943096 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:40:11.004300 70150 solver.cpp:266] Iteration 24000 (13.0054 iter/s, 7.68914s/100 iter), loss = 0.0163786
I0122 19:40:11.004321 70150 solver.cpp:285]     Train net output #0: loss = 0.0163787 (* 1 = 0.0163787 loss)
I0122 19:40:11.004328 70150 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 19:40:17.218783 70150 solver.cpp:266] Iteration 24100 (16.0921 iter/s, 6.21422s/100 iter), loss = 0.00686169
I0122 19:40:17.218813 70150 solver.cpp:285]     Train net output #0: loss = 0.00686181 (* 1 = 0.00686181 loss)
I0122 19:40:17.218819 70150 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 19:40:23.443899 70150 solver.cpp:266] Iteration 24200 (16.0646 iter/s, 6.22485s/100 iter), loss = 0.00461503
I0122 19:40:23.443928 70150 solver.cpp:285]     Train net output #0: loss = 0.00461514 (* 1 = 0.00461514 loss)
I0122 19:40:23.443933 70150 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 19:40:29.661643 70150 solver.cpp:266] Iteration 24300 (16.0837 iter/s, 6.21748s/100 iter), loss = 0.0118496
I0122 19:40:29.661671 70150 solver.cpp:285]     Train net output #0: loss = 0.0118497 (* 1 = 0.0118497 loss)
I0122 19:40:29.661677 70150 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 19:40:35.874075 70150 solver.cpp:266] Iteration 24400 (16.0974 iter/s, 6.21217s/100 iter), loss = 0.00938774
I0122 19:40:35.874104 70150 solver.cpp:285]     Train net output #0: loss = 0.00938786 (* 1 = 0.00938786 loss)
I0122 19:40:35.874110 70150 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 19:40:42.081856 70150 solver.cpp:266] Iteration 24500 (16.1095 iter/s, 6.20751s/100 iter), loss = 0.010699
I0122 19:40:42.081914 70150 solver.cpp:285]     Train net output #0: loss = 0.0106992 (* 1 = 0.0106992 loss)
I0122 19:40:42.081921 70150 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 19:40:48.291522 70150 solver.cpp:266] Iteration 24600 (16.1047 iter/s, 6.20937s/100 iter), loss = 0.00945086
I0122 19:40:48.291551 70150 solver.cpp:285]     Train net output #0: loss = 0.00945098 (* 1 = 0.00945098 loss)
I0122 19:40:48.291556 70150 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 19:40:54.518649 70150 solver.cpp:266] Iteration 24700 (16.0595 iter/s, 6.22686s/100 iter), loss = 0.00888818
I0122 19:40:54.518679 70150 solver.cpp:285]     Train net output #0: loss = 0.00888829 (* 1 = 0.00888829 loss)
I0122 19:40:54.518685 70150 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 19:41:00.749910 70150 solver.cpp:266] Iteration 24800 (16.0488 iter/s, 6.23099s/100 iter), loss = 0.0114981
I0122 19:41:00.749939 70150 solver.cpp:285]     Train net output #0: loss = 0.0114982 (* 1 = 0.0114982 loss)
I0122 19:41:00.749944 70150 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 19:41:06.965870 70150 solver.cpp:266] Iteration 24900 (16.0883 iter/s, 6.21569s/100 iter), loss = 0.0061258
I0122 19:41:06.965899 70150 solver.cpp:285]     Train net output #0: loss = 0.00612592 (* 1 = 0.00612592 loss)
I0122 19:41:06.965907 70150 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 19:41:13.121024 70150 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 19:41:14.567129 70150 solver.cpp:517]     Test net output #0: accuracy = 0.896556
I0122 19:41:14.567154 70150 solver.cpp:517]     Test net output #1: loss = 0.365047 (* 1 = 0.365047 loss)
I0122 19:41:14.567158 70150 solver.cpp:517]     Test net output #2: top-1 = 0.896556
I0122 19:41:14.567162 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:41:14.628885 70150 solver.cpp:266] Iteration 25000 (13.0502 iter/s, 7.6627s/100 iter), loss = 0.00604529
I0122 19:41:14.628904 70150 solver.cpp:285]     Train net output #0: loss = 0.0060454 (* 1 = 0.0060454 loss)
I0122 19:41:14.628911 70150 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 19:41:20.841931 70150 solver.cpp:266] Iteration 25100 (16.0958 iter/s, 6.21279s/100 iter), loss = 0.0105012
I0122 19:41:20.841958 70150 solver.cpp:285]     Train net output #0: loss = 0.0105013 (* 1 = 0.0105013 loss)
I0122 19:41:20.841964 70150 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 19:41:27.057256 70150 solver.cpp:266] Iteration 25200 (16.09 iter/s, 6.21506s/100 iter), loss = 0.0223255
I0122 19:41:27.057282 70150 solver.cpp:285]     Train net output #0: loss = 0.0223257 (* 1 = 0.0223257 loss)
I0122 19:41:27.057288 70150 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 19:41:33.254170 70150 solver.cpp:266] Iteration 25300 (16.1377 iter/s, 6.19665s/100 iter), loss = 0.0190515
I0122 19:41:33.254197 70150 solver.cpp:285]     Train net output #0: loss = 0.0190516 (* 1 = 0.0190516 loss)
I0122 19:41:33.254204 70150 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 19:41:39.460932 70150 solver.cpp:266] Iteration 25400 (16.1121 iter/s, 6.2065s/100 iter), loss = 0.00488548
I0122 19:41:39.460959 70150 solver.cpp:285]     Train net output #0: loss = 0.00488559 (* 1 = 0.00488559 loss)
I0122 19:41:39.460964 70150 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 19:41:45.691339 70150 solver.cpp:266] Iteration 25500 (16.051 iter/s, 6.23014s/100 iter), loss = 0.0082303
I0122 19:41:45.691402 70150 solver.cpp:285]     Train net output #0: loss = 0.00823041 (* 1 = 0.00823041 loss)
I0122 19:41:45.691409 70150 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 19:41:51.914716 70150 solver.cpp:266] Iteration 25600 (16.0692 iter/s, 6.22308s/100 iter), loss = 0.0168281
I0122 19:41:51.914744 70150 solver.cpp:285]     Train net output #0: loss = 0.0168283 (* 1 = 0.0168283 loss)
I0122 19:41:51.914750 70150 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 19:41:58.140595 70150 solver.cpp:266] Iteration 25700 (16.0627 iter/s, 6.22561s/100 iter), loss = 0.00859447
I0122 19:41:58.140622 70150 solver.cpp:285]     Train net output #0: loss = 0.00859458 (* 1 = 0.00859458 loss)
I0122 19:41:58.140628 70150 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 19:42:04.348424 70150 solver.cpp:266] Iteration 25800 (16.1094 iter/s, 6.20756s/100 iter), loss = 0.00760521
I0122 19:42:04.348453 70150 solver.cpp:285]     Train net output #0: loss = 0.00760532 (* 1 = 0.00760532 loss)
I0122 19:42:04.348457 70150 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 19:42:10.567236 70150 solver.cpp:266] Iteration 25900 (16.0809 iter/s, 6.21855s/100 iter), loss = 0.0235795
I0122 19:42:10.567263 70150 solver.cpp:285]     Train net output #0: loss = 0.0235796 (* 1 = 0.0235796 loss)
I0122 19:42:10.567270 70150 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 19:42:16.714184 70150 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 19:42:18.180953 70150 solver.cpp:517]     Test net output #0: accuracy = 0.897
I0122 19:42:18.180977 70150 solver.cpp:517]     Test net output #1: loss = 0.366687 (* 1 = 0.366687 loss)
I0122 19:42:18.180981 70150 solver.cpp:517]     Test net output #2: top-1 = 0.897
I0122 19:42:18.180985 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 19:42:18.243052 70150 solver.cpp:266] Iteration 26000 (13.0285 iter/s, 7.6755s/100 iter), loss = 0.00483005
I0122 19:42:18.243073 70150 solver.cpp:285]     Train net output #0: loss = 0.00483016 (* 1 = 0.00483016 loss)
I0122 19:42:18.243079 70150 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 19:42:24.440557 70150 solver.cpp:266] Iteration 26100 (16.1362 iter/s, 6.19725s/100 iter), loss = 0.0125857
I0122 19:42:24.440582 70150 solver.cpp:285]     Train net output #0: loss = 0.0125858 (* 1 = 0.0125858 loss)
I0122 19:42:24.440587 70150 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 19:42:30.657882 70150 solver.cpp:266] Iteration 26200 (16.0848 iter/s, 6.21706s/100 iter), loss = 0.00612374
I0122 19:42:30.657912 70150 solver.cpp:285]     Train net output #0: loss = 0.00612385 (* 1 = 0.00612385 loss)
I0122 19:42:30.657917 70150 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 19:42:36.881939 70150 solver.cpp:266] Iteration 26300 (16.0674 iter/s, 6.22379s/100 iter), loss = 0.00930021
I0122 19:42:36.881966 70150 solver.cpp:285]     Train net output #0: loss = 0.00930032 (* 1 = 0.00930032 loss)
I0122 19:42:36.881973 70150 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 19:42:43.090756 70150 solver.cpp:266] Iteration 26400 (16.1068 iter/s, 6.20855s/100 iter), loss = 0.00376087
I0122 19:42:43.090785 70150 solver.cpp:285]     Train net output #0: loss = 0.00376098 (* 1 = 0.00376098 loss)
I0122 19:42:43.090790 70150 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 19:42:49.305392 70150 solver.cpp:266] Iteration 26500 (16.0917 iter/s, 6.21437s/100 iter), loss = 0.00665337
I0122 19:42:49.305506 70150 solver.cpp:285]     Train net output #0: loss = 0.00665348 (* 1 = 0.00665348 loss)
I0122 19:42:49.305513 70150 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 19:42:55.527822 70150 solver.cpp:266] Iteration 26600 (16.0718 iter/s, 6.22208s/100 iter), loss = 0.00329714
I0122 19:42:55.527850 70150 solver.cpp:285]     Train net output #0: loss = 0.00329725 (* 1 = 0.00329725 loss)
I0122 19:42:55.527856 70150 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 19:43:01.746975 70150 solver.cpp:266] Iteration 26700 (16.0801 iter/s, 6.21889s/100 iter), loss = 0.00632371
I0122 19:43:01.747004 70150 solver.cpp:285]     Train net output #0: loss = 0.00632381 (* 1 = 0.00632381 loss)
I0122 19:43:01.747009 70150 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 19:43:07.959177 70150 solver.cpp:266] Iteration 26800 (16.098 iter/s, 6.21193s/100 iter), loss = 0.0118378
I0122 19:43:07.959204 70150 solver.cpp:285]     Train net output #0: loss = 0.0118379 (* 1 = 0.0118379 loss)
I0122 19:43:07.959210 70150 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 19:43:14.184235 70150 solver.cpp:266] Iteration 26900 (16.0648 iter/s, 6.22479s/100 iter), loss = 0.00787863
I0122 19:43:14.184264 70150 solver.cpp:285]     Train net output #0: loss = 0.00787873 (* 1 = 0.00787873 loss)
I0122 19:43:14.184270 70150 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 19:43:20.347813 70150 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 19:43:21.801232 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898555
I0122 19:43:21.801257 70150 solver.cpp:517]     Test net output #1: loss = 0.367626 (* 1 = 0.367626 loss)
I0122 19:43:21.801262 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898555
I0122 19:43:21.801265 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:43:21.863291 70150 solver.cpp:266] Iteration 27000 (13.023 iter/s, 7.67874s/100 iter), loss = 0.00437688
I0122 19:43:21.863310 70150 solver.cpp:285]     Train net output #0: loss = 0.00437699 (* 1 = 0.00437699 loss)
I0122 19:43:21.863317 70150 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 19:43:28.068631 70150 solver.cpp:266] Iteration 27100 (16.1158 iter/s, 6.20508s/100 iter), loss = 0.00807521
I0122 19:43:28.068660 70150 solver.cpp:285]     Train net output #0: loss = 0.00807531 (* 1 = 0.00807531 loss)
I0122 19:43:28.068665 70150 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 19:43:34.277794 70150 solver.cpp:266] Iteration 27200 (16.1059 iter/s, 6.2089s/100 iter), loss = 0.00716029
I0122 19:43:34.277822 70150 solver.cpp:285]     Train net output #0: loss = 0.0071604 (* 1 = 0.0071604 loss)
I0122 19:43:34.277827 70150 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 19:43:40.486564 70150 solver.cpp:266] Iteration 27300 (16.1069 iter/s, 6.2085s/100 iter), loss = 0.00691377
I0122 19:43:40.486591 70150 solver.cpp:285]     Train net output #0: loss = 0.00691388 (* 1 = 0.00691388 loss)
I0122 19:43:40.486598 70150 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 19:43:46.706609 70150 solver.cpp:266] Iteration 27400 (16.0777 iter/s, 6.21978s/100 iter), loss = 0.0043936
I0122 19:43:46.706637 70150 solver.cpp:285]     Train net output #0: loss = 0.00439371 (* 1 = 0.00439371 loss)
I0122 19:43:46.706643 70150 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 19:43:52.936846 70150 solver.cpp:266] Iteration 27500 (16.0514 iter/s, 6.22997s/100 iter), loss = 0.00338937
I0122 19:43:52.936967 70150 solver.cpp:285]     Train net output #0: loss = 0.00338948 (* 1 = 0.00338948 loss)
I0122 19:43:52.936975 70150 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 19:43:59.149878 70150 solver.cpp:266] Iteration 27600 (16.0961 iter/s, 6.21267s/100 iter), loss = 0.00435661
I0122 19:43:59.149909 70150 solver.cpp:285]     Train net output #0: loss = 0.00435672 (* 1 = 0.00435672 loss)
I0122 19:43:59.149917 70150 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 19:44:05.353561 70150 solver.cpp:266] Iteration 27700 (16.1201 iter/s, 6.20342s/100 iter), loss = 0.00478638
I0122 19:44:05.353591 70150 solver.cpp:285]     Train net output #0: loss = 0.00478649 (* 1 = 0.00478649 loss)
I0122 19:44:05.353596 70150 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 19:44:11.575939 70150 solver.cpp:266] Iteration 27800 (16.0717 iter/s, 6.22211s/100 iter), loss = 0.00823996
I0122 19:44:11.575968 70150 solver.cpp:285]     Train net output #0: loss = 0.00824007 (* 1 = 0.00824007 loss)
I0122 19:44:11.575974 70150 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 19:44:17.784318 70150 solver.cpp:266] Iteration 27900 (16.108 iter/s, 6.20811s/100 iter), loss = 0.00576458
I0122 19:44:17.784346 70150 solver.cpp:285]     Train net output #0: loss = 0.0057647 (* 1 = 0.0057647 loss)
I0122 19:44:17.784353 70150 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 19:44:23.965171 70150 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 19:44:25.418027 70150 solver.cpp:517]     Test net output #0: accuracy = 0.897222
I0122 19:44:25.418052 70150 solver.cpp:517]     Test net output #1: loss = 0.373937 (* 1 = 0.373937 loss)
I0122 19:44:25.418057 70150 solver.cpp:517]     Test net output #2: top-1 = 0.897222
I0122 19:44:25.418061 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:44:25.480788 70150 solver.cpp:266] Iteration 28000 (12.9935 iter/s, 7.69615s/100 iter), loss = 0.00581858
I0122 19:44:25.480808 70150 solver.cpp:285]     Train net output #0: loss = 0.00581869 (* 1 = 0.00581869 loss)
I0122 19:44:25.480814 70150 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 19:44:31.696087 70150 solver.cpp:266] Iteration 28100 (16.09 iter/s, 6.21504s/100 iter), loss = 0.0031265
I0122 19:44:31.696115 70150 solver.cpp:285]     Train net output #0: loss = 0.00312661 (* 1 = 0.00312661 loss)
I0122 19:44:31.696120 70150 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 19:44:37.907635 70150 solver.cpp:266] Iteration 28200 (16.0997 iter/s, 6.21128s/100 iter), loss = 0.00570234
I0122 19:44:37.907663 70150 solver.cpp:285]     Train net output #0: loss = 0.00570245 (* 1 = 0.00570245 loss)
I0122 19:44:37.907670 70150 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 19:44:44.130863 70150 solver.cpp:266] Iteration 28300 (16.0695 iter/s, 6.22296s/100 iter), loss = 0.00522284
I0122 19:44:44.130892 70150 solver.cpp:285]     Train net output #0: loss = 0.00522296 (* 1 = 0.00522296 loss)
I0122 19:44:44.130897 70150 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 19:44:50.336782 70150 solver.cpp:266] Iteration 28400 (16.1143 iter/s, 6.20565s/100 iter), loss = 0.00928687
I0122 19:44:50.336809 70150 solver.cpp:285]     Train net output #0: loss = 0.00928699 (* 1 = 0.00928699 loss)
I0122 19:44:50.336815 70150 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 19:44:56.556126 70150 solver.cpp:266] Iteration 28500 (16.0796 iter/s, 6.21908s/100 iter), loss = 0.00509278
I0122 19:44:56.556198 70150 solver.cpp:285]     Train net output #0: loss = 0.0050929 (* 1 = 0.0050929 loss)
I0122 19:44:56.556205 70150 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 19:45:02.777241 70150 solver.cpp:266] Iteration 28600 (16.0751 iter/s, 6.22081s/100 iter), loss = 0.0113358
I0122 19:45:02.777271 70150 solver.cpp:285]     Train net output #0: loss = 0.0113359 (* 1 = 0.0113359 loss)
I0122 19:45:02.777276 70150 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 19:45:09.013074 70150 solver.cpp:266] Iteration 28700 (16.037 iter/s, 6.23556s/100 iter), loss = 0.006137
I0122 19:45:09.013103 70150 solver.cpp:285]     Train net output #0: loss = 0.00613712 (* 1 = 0.00613712 loss)
I0122 19:45:09.013109 70150 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 19:45:15.222398 70150 solver.cpp:266] Iteration 28800 (16.1055 iter/s, 6.20906s/100 iter), loss = 0.00495127
I0122 19:45:15.222425 70150 solver.cpp:285]     Train net output #0: loss = 0.00495138 (* 1 = 0.00495138 loss)
I0122 19:45:15.222431 70150 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 19:45:21.429255 70150 solver.cpp:266] Iteration 28900 (16.1119 iter/s, 6.20659s/100 iter), loss = 0.00730286
I0122 19:45:21.429283 70150 solver.cpp:285]     Train net output #0: loss = 0.00730298 (* 1 = 0.00730298 loss)
I0122 19:45:21.429288 70150 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 19:45:27.577875 70150 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 19:45:29.025182 70150 solver.cpp:517]     Test net output #0: accuracy = 0.897889
I0122 19:45:29.025207 70150 solver.cpp:517]     Test net output #1: loss = 0.370851 (* 1 = 0.370851 loss)
I0122 19:45:29.025211 70150 solver.cpp:517]     Test net output #2: top-1 = 0.897889
I0122 19:45:29.025214 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995667
I0122 19:45:29.086731 70150 solver.cpp:266] Iteration 29000 (13.0597 iter/s, 7.65716s/100 iter), loss = 0.00926577
I0122 19:45:29.086751 70150 solver.cpp:285]     Train net output #0: loss = 0.00926589 (* 1 = 0.00926589 loss)
I0122 19:45:29.086757 70150 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 19:45:35.304352 70150 solver.cpp:266] Iteration 29100 (16.084 iter/s, 6.21736s/100 iter), loss = 0.0058046
I0122 19:45:35.304380 70150 solver.cpp:285]     Train net output #0: loss = 0.00580472 (* 1 = 0.00580472 loss)
I0122 19:45:35.304386 70150 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 19:45:41.527976 70150 solver.cpp:266] Iteration 29200 (16.0685 iter/s, 6.22336s/100 iter), loss = 0.00379637
I0122 19:45:41.528004 70150 solver.cpp:285]     Train net output #0: loss = 0.00379649 (* 1 = 0.00379649 loss)
I0122 19:45:41.528010 70150 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 19:45:47.736470 70150 solver.cpp:266] Iteration 29300 (16.1077 iter/s, 6.20823s/100 iter), loss = 0.00576155
I0122 19:45:47.736497 70150 solver.cpp:285]     Train net output #0: loss = 0.00576167 (* 1 = 0.00576167 loss)
I0122 19:45:47.736502 70150 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 19:45:53.946504 70150 solver.cpp:266] Iteration 29400 (16.1037 iter/s, 6.20977s/100 iter), loss = 0.00838575
I0122 19:45:53.946532 70150 solver.cpp:285]     Train net output #0: loss = 0.00838587 (* 1 = 0.00838587 loss)
I0122 19:45:53.946538 70150 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 19:46:00.170878 70150 solver.cpp:266] Iteration 29500 (16.0666 iter/s, 6.22411s/100 iter), loss = 0.00419161
I0122 19:46:00.170940 70150 solver.cpp:285]     Train net output #0: loss = 0.00419173 (* 1 = 0.00419173 loss)
I0122 19:46:00.170948 70150 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 19:46:06.391711 70150 solver.cpp:266] Iteration 29600 (16.0758 iter/s, 6.22053s/100 iter), loss = 0.00806917
I0122 19:46:06.391741 70150 solver.cpp:285]     Train net output #0: loss = 0.00806929 (* 1 = 0.00806929 loss)
I0122 19:46:06.391746 70150 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 19:46:12.610632 70150 solver.cpp:266] Iteration 29700 (16.0806 iter/s, 6.21866s/100 iter), loss = 0.00500866
I0122 19:46:12.610658 70150 solver.cpp:285]     Train net output #0: loss = 0.00500878 (* 1 = 0.00500878 loss)
I0122 19:46:12.610663 70150 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 19:46:18.808943 70150 solver.cpp:266] Iteration 29800 (16.1341 iter/s, 6.19805s/100 iter), loss = 0.00861661
I0122 19:46:18.808971 70150 solver.cpp:285]     Train net output #0: loss = 0.00861673 (* 1 = 0.00861673 loss)
I0122 19:46:18.808977 70150 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 19:46:25.030289 70150 solver.cpp:266] Iteration 29900 (16.0744 iter/s, 6.22108s/100 iter), loss = 0.00454319
I0122 19:46:25.030318 70150 solver.cpp:285]     Train net output #0: loss = 0.00454331 (* 1 = 0.00454331 loss)
I0122 19:46:25.030323 70150 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 19:46:31.187882 70150 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 19:46:32.643746 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898667
I0122 19:46:32.643770 70150 solver.cpp:517]     Test net output #1: loss = 0.368807 (* 1 = 0.368807 loss)
I0122 19:46:32.643774 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898667
I0122 19:46:32.643776 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:46:32.706395 70150 solver.cpp:266] Iteration 30000 (13.028 iter/s, 7.67579s/100 iter), loss = 0.00470067
I0122 19:46:32.706418 70150 solver.cpp:285]     Train net output #0: loss = 0.00470079 (* 1 = 0.00470079 loss)
I0122 19:46:32.706423 70150 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 19:46:38.914158 70150 solver.cpp:266] Iteration 30100 (16.1095 iter/s, 6.2075s/100 iter), loss = 0.00493961
I0122 19:46:38.914186 70150 solver.cpp:285]     Train net output #0: loss = 0.00493973 (* 1 = 0.00493973 loss)
I0122 19:46:38.914191 70150 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 19:46:45.144767 70150 solver.cpp:266] Iteration 30200 (16.0505 iter/s, 6.23034s/100 iter), loss = 0.0094814
I0122 19:46:45.144795 70150 solver.cpp:285]     Train net output #0: loss = 0.00948152 (* 1 = 0.00948152 loss)
I0122 19:46:45.144803 70150 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 19:46:51.349139 70150 solver.cpp:266] Iteration 30300 (16.1184 iter/s, 6.20411s/100 iter), loss = 0.0049786
I0122 19:46:51.349166 70150 solver.cpp:285]     Train net output #0: loss = 0.00497871 (* 1 = 0.00497871 loss)
I0122 19:46:51.349172 70150 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 19:46:57.568737 70150 solver.cpp:266] Iteration 30400 (16.0789 iter/s, 6.21933s/100 iter), loss = 0.00729034
I0122 19:46:57.568768 70150 solver.cpp:285]     Train net output #0: loss = 0.00729045 (* 1 = 0.00729045 loss)
I0122 19:46:57.568773 70150 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 19:47:03.796612 70150 solver.cpp:266] Iteration 30500 (16.0575 iter/s, 6.22761s/100 iter), loss = 0.00502126
I0122 19:47:03.796716 70150 solver.cpp:285]     Train net output #0: loss = 0.00502137 (* 1 = 0.00502137 loss)
I0122 19:47:03.796725 70150 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 19:47:10.013018 70150 solver.cpp:266] Iteration 30600 (16.0873 iter/s, 6.21606s/100 iter), loss = 0.0128749
I0122 19:47:10.013046 70150 solver.cpp:285]     Train net output #0: loss = 0.012875 (* 1 = 0.012875 loss)
I0122 19:47:10.013052 70150 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 19:47:16.220129 70150 solver.cpp:266] Iteration 30700 (16.1112 iter/s, 6.20684s/100 iter), loss = 0.00427631
I0122 19:47:16.220156 70150 solver.cpp:285]     Train net output #0: loss = 0.00427642 (* 1 = 0.00427642 loss)
I0122 19:47:16.220163 70150 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 19:47:22.447544 70150 solver.cpp:266] Iteration 30800 (16.0587 iter/s, 6.22715s/100 iter), loss = 0.00643535
I0122 19:47:22.447572 70150 solver.cpp:285]     Train net output #0: loss = 0.00643547 (* 1 = 0.00643547 loss)
I0122 19:47:22.447578 70150 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 19:47:28.655616 70150 solver.cpp:266] Iteration 30900 (16.1088 iter/s, 6.20781s/100 iter), loss = 0.00482409
I0122 19:47:28.655643 70150 solver.cpp:285]     Train net output #0: loss = 0.0048242 (* 1 = 0.0048242 loss)
I0122 19:47:28.655649 70150 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 19:47:34.811815 70150 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 19:47:36.262728 70150 solver.cpp:517]     Test net output #0: accuracy = 0.899777
I0122 19:47:36.262753 70150 solver.cpp:517]     Test net output #1: loss = 0.374028 (* 1 = 0.374028 loss)
I0122 19:47:36.262758 70150 solver.cpp:517]     Test net output #2: top-1 = 0.899777
I0122 19:47:36.262761 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995333
I0122 19:47:36.324932 70150 solver.cpp:266] Iteration 31000 (13.0395 iter/s, 7.669s/100 iter), loss = 0.00909286
I0122 19:47:36.324964 70150 solver.cpp:285]     Train net output #0: loss = 0.00909297 (* 1 = 0.00909297 loss)
I0122 19:47:36.324971 70150 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 19:47:42.543099 70150 solver.cpp:266] Iteration 31100 (16.0826 iter/s, 6.2179s/100 iter), loss = 0.00319791
I0122 19:47:42.543128 70150 solver.cpp:285]     Train net output #0: loss = 0.00319802 (* 1 = 0.00319802 loss)
I0122 19:47:42.543133 70150 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 19:47:48.747033 70150 solver.cpp:266] Iteration 31200 (16.1195 iter/s, 6.20367s/100 iter), loss = 0.00403034
I0122 19:47:48.747061 70150 solver.cpp:285]     Train net output #0: loss = 0.00403045 (* 1 = 0.00403045 loss)
I0122 19:47:48.747067 70150 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 19:47:54.960762 70150 solver.cpp:266] Iteration 31300 (16.0941 iter/s, 6.21346s/100 iter), loss = 0.0037317
I0122 19:47:54.960801 70150 solver.cpp:285]     Train net output #0: loss = 0.00373181 (* 1 = 0.00373181 loss)
I0122 19:47:54.960808 70150 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 19:48:01.168474 70150 solver.cpp:266] Iteration 31400 (16.1097 iter/s, 6.20744s/100 iter), loss = 0.00585818
I0122 19:48:01.168501 70150 solver.cpp:285]     Train net output #0: loss = 0.00585829 (* 1 = 0.00585829 loss)
I0122 19:48:01.168507 70150 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 19:48:07.395442 70150 solver.cpp:266] Iteration 31500 (16.0599 iter/s, 6.2267s/100 iter), loss = 0.00935338
I0122 19:48:07.395583 70150 solver.cpp:285]     Train net output #0: loss = 0.0093535 (* 1 = 0.0093535 loss)
I0122 19:48:07.395603 70150 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 19:48:13.621448 70150 solver.cpp:266] Iteration 31600 (16.0626 iter/s, 6.22564s/100 iter), loss = 0.00393303
I0122 19:48:13.621475 70150 solver.cpp:285]     Train net output #0: loss = 0.00393314 (* 1 = 0.00393314 loss)
I0122 19:48:13.621481 70150 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 19:48:19.822548 70150 solver.cpp:266] Iteration 31700 (16.1269 iter/s, 6.20084s/100 iter), loss = 0.00454511
I0122 19:48:19.822576 70150 solver.cpp:285]     Train net output #0: loss = 0.00454523 (* 1 = 0.00454523 loss)
I0122 19:48:19.822582 70150 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 19:48:26.034678 70150 solver.cpp:266] Iteration 31800 (16.0982 iter/s, 6.21187s/100 iter), loss = 0.0088902
I0122 19:48:26.034706 70150 solver.cpp:285]     Train net output #0: loss = 0.00889032 (* 1 = 0.00889032 loss)
I0122 19:48:26.034713 70150 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 19:48:32.255187 70150 solver.cpp:266] Iteration 31900 (16.0765 iter/s, 6.22024s/100 iter), loss = 0.0040614
I0122 19:48:32.255214 70150 solver.cpp:285]     Train net output #0: loss = 0.00406152 (* 1 = 0.00406152 loss)
I0122 19:48:32.255220 70150 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 19:48:38.410944 70150 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 19:48:39.860770 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898666
I0122 19:48:39.860795 70150 solver.cpp:517]     Test net output #1: loss = 0.377 (* 1 = 0.377 loss)
I0122 19:48:39.860798 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898666
I0122 19:48:39.860802 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:48:39.922246 70150 solver.cpp:266] Iteration 32000 (13.0433 iter/s, 7.66674s/100 iter), loss = 0.00522233
I0122 19:48:39.922266 70150 solver.cpp:285]     Train net output #0: loss = 0.00522244 (* 1 = 0.00522244 loss)
I0122 19:48:39.922272 70150 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 19:48:46.124562 70150 solver.cpp:266] Iteration 32100 (16.1237 iter/s, 6.20206s/100 iter), loss = 0.00775704
I0122 19:48:46.124589 70150 solver.cpp:285]     Train net output #0: loss = 0.00775716 (* 1 = 0.00775716 loss)
I0122 19:48:46.124595 70150 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 19:48:52.327733 70150 solver.cpp:266] Iteration 32200 (16.1215 iter/s, 6.20291s/100 iter), loss = 0.00522871
I0122 19:48:52.327761 70150 solver.cpp:285]     Train net output #0: loss = 0.00522883 (* 1 = 0.00522883 loss)
I0122 19:48:52.327767 70150 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 19:48:58.537919 70150 solver.cpp:266] Iteration 32300 (16.1033 iter/s, 6.20992s/100 iter), loss = 0.00410707
I0122 19:48:58.537947 70150 solver.cpp:285]     Train net output #0: loss = 0.00410719 (* 1 = 0.00410719 loss)
I0122 19:48:58.537955 70150 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 19:49:04.754902 70150 solver.cpp:266] Iteration 32400 (16.0857 iter/s, 6.21672s/100 iter), loss = 0.00592915
I0122 19:49:04.754930 70150 solver.cpp:285]     Train net output #0: loss = 0.00592927 (* 1 = 0.00592927 loss)
I0122 19:49:04.754936 70150 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 19:49:10.964131 70150 solver.cpp:266] Iteration 32500 (16.1057 iter/s, 6.20896s/100 iter), loss = 0.00525934
I0122 19:49:10.964253 70150 solver.cpp:285]     Train net output #0: loss = 0.00525946 (* 1 = 0.00525946 loss)
I0122 19:49:10.964260 70150 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 19:49:17.186167 70150 solver.cpp:266] Iteration 32600 (16.0728 iter/s, 6.22168s/100 iter), loss = 0.00618377
I0122 19:49:17.186195 70150 solver.cpp:285]     Train net output #0: loss = 0.00618388 (* 1 = 0.00618388 loss)
I0122 19:49:17.186201 70150 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 19:49:23.392019 70150 solver.cpp:266] Iteration 32700 (16.1145 iter/s, 6.20559s/100 iter), loss = 0.00698022
I0122 19:49:23.392048 70150 solver.cpp:285]     Train net output #0: loss = 0.00698034 (* 1 = 0.00698034 loss)
I0122 19:49:23.392055 70150 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 19:49:29.616541 70150 solver.cpp:266] Iteration 32800 (16.0662 iter/s, 6.22426s/100 iter), loss = 0.00377313
I0122 19:49:29.616570 70150 solver.cpp:285]     Train net output #0: loss = 0.00377325 (* 1 = 0.00377325 loss)
I0122 19:49:29.616576 70150 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 19:49:35.837186 70150 solver.cpp:266] Iteration 32900 (16.0762 iter/s, 6.22038s/100 iter), loss = 0.00307026
I0122 19:49:35.837227 70150 solver.cpp:285]     Train net output #0: loss = 0.00307038 (* 1 = 0.00307038 loss)
I0122 19:49:35.837234 70150 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 19:49:41.979615 70150 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 19:49:43.430042 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898555
I0122 19:49:43.430068 70150 solver.cpp:517]     Test net output #1: loss = 0.378238 (* 1 = 0.378238 loss)
I0122 19:49:43.430073 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898555
I0122 19:49:43.430076 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:49:43.491667 70150 solver.cpp:266] Iteration 33000 (13.0648 iter/s, 7.65415s/100 iter), loss = 0.00331975
I0122 19:49:43.491686 70150 solver.cpp:285]     Train net output #0: loss = 0.00331987 (* 1 = 0.00331987 loss)
I0122 19:49:43.491693 70150 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 19:49:49.709844 70150 solver.cpp:266] Iteration 33100 (16.0826 iter/s, 6.21792s/100 iter), loss = 0.00537874
I0122 19:49:49.709873 70150 solver.cpp:285]     Train net output #0: loss = 0.00537886 (* 1 = 0.00537886 loss)
I0122 19:49:49.709879 70150 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 19:49:55.937376 70150 solver.cpp:266] Iteration 33200 (16.0584 iter/s, 6.22727s/100 iter), loss = 0.00196811
I0122 19:49:55.937405 70150 solver.cpp:285]     Train net output #0: loss = 0.00196823 (* 1 = 0.00196823 loss)
I0122 19:49:55.937412 70150 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 19:50:02.172973 70150 solver.cpp:266] Iteration 33300 (16.0376 iter/s, 6.23533s/100 iter), loss = 0.00487675
I0122 19:50:02.173002 70150 solver.cpp:285]     Train net output #0: loss = 0.00487687 (* 1 = 0.00487687 loss)
I0122 19:50:02.173007 70150 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 19:50:08.384338 70150 solver.cpp:266] Iteration 33400 (16.1002 iter/s, 6.2111s/100 iter), loss = 0.00753214
I0122 19:50:08.384366 70150 solver.cpp:285]     Train net output #0: loss = 0.00753226 (* 1 = 0.00753226 loss)
I0122 19:50:08.384371 70150 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 19:50:14.591679 70150 solver.cpp:266] Iteration 33500 (16.1106 iter/s, 6.20708s/100 iter), loss = 0.00540347
I0122 19:50:14.591759 70150 solver.cpp:285]     Train net output #0: loss = 0.00540359 (* 1 = 0.00540359 loss)
I0122 19:50:14.591766 70150 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 19:50:20.813853 70150 solver.cpp:266] Iteration 33600 (16.0724 iter/s, 6.22186s/100 iter), loss = 0.0050367
I0122 19:50:20.813879 70150 solver.cpp:285]     Train net output #0: loss = 0.00503682 (* 1 = 0.00503682 loss)
I0122 19:50:20.813885 70150 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 19:50:27.007165 70150 solver.cpp:266] Iteration 33700 (16.1471 iter/s, 6.19305s/100 iter), loss = 0.00393901
I0122 19:50:27.007194 70150 solver.cpp:285]     Train net output #0: loss = 0.00393913 (* 1 = 0.00393913 loss)
I0122 19:50:27.007200 70150 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 19:50:33.228997 70150 solver.cpp:266] Iteration 33800 (16.0731 iter/s, 6.22156s/100 iter), loss = 0.00792413
I0122 19:50:33.229023 70150 solver.cpp:285]     Train net output #0: loss = 0.00792425 (* 1 = 0.00792425 loss)
I0122 19:50:33.229029 70150 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 19:50:39.468901 70150 solver.cpp:266] Iteration 33900 (16.0266 iter/s, 6.23964s/100 iter), loss = 0.00625323
I0122 19:50:39.468930 70150 solver.cpp:285]     Train net output #0: loss = 0.00625335 (* 1 = 0.00625335 loss)
I0122 19:50:39.468935 70150 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 19:50:45.605279 70150 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 19:50:47.064173 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898444
I0122 19:50:47.064199 70150 solver.cpp:517]     Test net output #1: loss = 0.378746 (* 1 = 0.378746 loss)
I0122 19:50:47.064204 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898444
I0122 19:50:47.064208 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:50:47.125617 70150 solver.cpp:266] Iteration 34000 (13.061 iter/s, 7.6564s/100 iter), loss = 0.00441094
I0122 19:50:47.125638 70150 solver.cpp:285]     Train net output #0: loss = 0.00441107 (* 1 = 0.00441107 loss)
I0122 19:50:47.125645 70150 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 19:50:53.340131 70150 solver.cpp:266] Iteration 34100 (16.092 iter/s, 6.21426s/100 iter), loss = 0.00389687
I0122 19:50:53.340162 70150 solver.cpp:285]     Train net output #0: loss = 0.00389699 (* 1 = 0.00389699 loss)
I0122 19:50:53.340167 70150 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 19:50:59.561499 70150 solver.cpp:266] Iteration 34200 (16.0743 iter/s, 6.2211s/100 iter), loss = 0.00512571
I0122 19:50:59.561528 70150 solver.cpp:285]     Train net output #0: loss = 0.00512584 (* 1 = 0.00512584 loss)
I0122 19:50:59.561534 70150 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 19:51:05.777884 70150 solver.cpp:266] Iteration 34300 (16.0872 iter/s, 6.21612s/100 iter), loss = 0.00708723
I0122 19:51:05.777915 70150 solver.cpp:285]     Train net output #0: loss = 0.00708735 (* 1 = 0.00708735 loss)
I0122 19:51:05.777920 70150 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 19:51:11.990631 70150 solver.cpp:266] Iteration 34400 (16.0966 iter/s, 6.21248s/100 iter), loss = 0.0240946
I0122 19:51:11.990659 70150 solver.cpp:285]     Train net output #0: loss = 0.0240947 (* 1 = 0.0240947 loss)
I0122 19:51:11.990665 70150 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 19:51:18.213773 70150 solver.cpp:266] Iteration 34500 (16.0697 iter/s, 6.22287s/100 iter), loss = 0.00832194
I0122 19:51:18.213848 70150 solver.cpp:285]     Train net output #0: loss = 0.00832206 (* 1 = 0.00832206 loss)
I0122 19:51:18.213855 70150 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 19:51:24.432430 70150 solver.cpp:266] Iteration 34600 (16.0814 iter/s, 6.21834s/100 iter), loss = 0.0111192
I0122 19:51:24.432458 70150 solver.cpp:285]     Train net output #0: loss = 0.0111193 (* 1 = 0.0111193 loss)
I0122 19:51:24.432464 70150 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 19:51:30.649785 70150 solver.cpp:266] Iteration 34700 (16.0847 iter/s, 6.21709s/100 iter), loss = 0.00395112
I0122 19:51:30.649813 70150 solver.cpp:285]     Train net output #0: loss = 0.00395125 (* 1 = 0.00395125 loss)
I0122 19:51:30.649819 70150 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 19:51:36.857863 70150 solver.cpp:266] Iteration 34800 (16.1087 iter/s, 6.20781s/100 iter), loss = 0.00173259
I0122 19:51:36.857892 70150 solver.cpp:285]     Train net output #0: loss = 0.00173272 (* 1 = 0.00173272 loss)
I0122 19:51:36.857897 70150 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 19:51:43.081982 70150 solver.cpp:266] Iteration 34900 (16.0672 iter/s, 6.22385s/100 iter), loss = 0.0162705
I0122 19:51:43.082010 70150 solver.cpp:285]     Train net output #0: loss = 0.0162707 (* 1 = 0.0162707 loss)
I0122 19:51:43.082015 70150 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 19:51:49.244995 70150 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 19:51:50.693311 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898889
I0122 19:51:50.693337 70150 solver.cpp:517]     Test net output #1: loss = 0.378843 (* 1 = 0.378843 loss)
I0122 19:51:50.693342 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898889
I0122 19:51:50.693346 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:51:50.755636 70150 solver.cpp:266] Iteration 35000 (13.0321 iter/s, 7.67334s/100 iter), loss = 0.00684125
I0122 19:51:50.755657 70150 solver.cpp:285]     Train net output #0: loss = 0.00684138 (* 1 = 0.00684138 loss)
I0122 19:51:50.755664 70150 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 19:51:56.977768 70150 solver.cpp:266] Iteration 35100 (16.0723 iter/s, 6.22187s/100 iter), loss = 0.00632922
I0122 19:51:56.977797 70150 solver.cpp:285]     Train net output #0: loss = 0.00632935 (* 1 = 0.00632935 loss)
I0122 19:51:56.977802 70150 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 19:52:03.198464 70150 solver.cpp:266] Iteration 35200 (16.0761 iter/s, 6.22043s/100 iter), loss = 0.00776129
I0122 19:52:03.198491 70150 solver.cpp:285]     Train net output #0: loss = 0.00776141 (* 1 = 0.00776141 loss)
I0122 19:52:03.198498 70150 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 19:52:09.404314 70150 solver.cpp:266] Iteration 35300 (16.1145 iter/s, 6.20559s/100 iter), loss = 0.00572698
I0122 19:52:09.404343 70150 solver.cpp:285]     Train net output #0: loss = 0.0057271 (* 1 = 0.0057271 loss)
I0122 19:52:09.404350 70150 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 19:52:15.610841 70150 solver.cpp:266] Iteration 35400 (16.1128 iter/s, 6.20626s/100 iter), loss = 0.00334044
I0122 19:52:15.610867 70150 solver.cpp:285]     Train net output #0: loss = 0.00334057 (* 1 = 0.00334057 loss)
I0122 19:52:15.610874 70150 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 19:52:21.817446 70150 solver.cpp:266] Iteration 35500 (16.1126 iter/s, 6.20634s/100 iter), loss = 0.00344861
I0122 19:52:21.817564 70150 solver.cpp:285]     Train net output #0: loss = 0.00344873 (* 1 = 0.00344873 loss)
I0122 19:52:21.817571 70150 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 19:52:28.036125 70150 solver.cpp:266] Iteration 35600 (16.0815 iter/s, 6.21832s/100 iter), loss = 0.00470345
I0122 19:52:28.036152 70150 solver.cpp:285]     Train net output #0: loss = 0.00470357 (* 1 = 0.00470357 loss)
I0122 19:52:28.036159 70150 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 19:52:34.248597 70150 solver.cpp:266] Iteration 35700 (16.0973 iter/s, 6.21221s/100 iter), loss = 0.00712676
I0122 19:52:34.248625 70150 solver.cpp:285]     Train net output #0: loss = 0.00712688 (* 1 = 0.00712688 loss)
I0122 19:52:34.248631 70150 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 19:52:40.447438 70150 solver.cpp:266] Iteration 35800 (16.1327 iter/s, 6.19858s/100 iter), loss = 0.0042336
I0122 19:52:40.447465 70150 solver.cpp:285]     Train net output #0: loss = 0.00423372 (* 1 = 0.00423372 loss)
I0122 19:52:40.447471 70150 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 19:52:46.674176 70150 solver.cpp:266] Iteration 35900 (16.0605 iter/s, 6.22647s/100 iter), loss = 0.00498635
I0122 19:52:46.674206 70150 solver.cpp:285]     Train net output #0: loss = 0.00498648 (* 1 = 0.00498648 loss)
I0122 19:52:46.674211 70150 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 19:52:52.824470 70150 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 19:52:54.272326 70150 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 19:52:54.272352 70150 solver.cpp:517]     Test net output #1: loss = 0.379099 (* 1 = 0.379099 loss)
I0122 19:52:54.272356 70150 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 19:52:54.272361 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:52:54.334120 70150 solver.cpp:266] Iteration 36000 (13.0555 iter/s, 7.65963s/100 iter), loss = 0.0051952
I0122 19:52:54.334141 70150 solver.cpp:285]     Train net output #0: loss = 0.00519532 (* 1 = 0.00519532 loss)
I0122 19:52:54.334147 70150 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 19:53:00.546123 70150 solver.cpp:266] Iteration 36100 (16.0985 iter/s, 6.21174s/100 iter), loss = 0.00937422
I0122 19:53:00.546149 70150 solver.cpp:285]     Train net output #0: loss = 0.00937434 (* 1 = 0.00937434 loss)
I0122 19:53:00.546154 70150 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 19:53:06.787921 70150 solver.cpp:266] Iteration 36200 (16.0217 iter/s, 6.24153s/100 iter), loss = 0.00370327
I0122 19:53:06.787950 70150 solver.cpp:285]     Train net output #0: loss = 0.00370339 (* 1 = 0.00370339 loss)
I0122 19:53:06.787955 70150 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 19:53:13.007416 70150 solver.cpp:266] Iteration 36300 (16.0792 iter/s, 6.21923s/100 iter), loss = 0.00713929
I0122 19:53:13.007445 70150 solver.cpp:285]     Train net output #0: loss = 0.00713941 (* 1 = 0.00713941 loss)
I0122 19:53:13.007452 70150 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 19:53:19.217502 70150 solver.cpp:266] Iteration 36400 (16.1035 iter/s, 6.20982s/100 iter), loss = 0.00768716
I0122 19:53:19.217530 70150 solver.cpp:285]     Train net output #0: loss = 0.00768728 (* 1 = 0.00768728 loss)
I0122 19:53:19.217536 70150 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 19:53:25.431821 70150 solver.cpp:266] Iteration 36500 (16.0926 iter/s, 6.21405s/100 iter), loss = 0.00759163
I0122 19:53:25.431929 70150 solver.cpp:285]     Train net output #0: loss = 0.00759176 (* 1 = 0.00759176 loss)
I0122 19:53:25.431936 70150 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 19:53:31.640586 70150 solver.cpp:266] Iteration 36600 (16.1072 iter/s, 6.20842s/100 iter), loss = 0.00697354
I0122 19:53:31.640615 70150 solver.cpp:285]     Train net output #0: loss = 0.00697366 (* 1 = 0.00697366 loss)
I0122 19:53:31.640622 70150 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 19:53:37.849354 70150 solver.cpp:266] Iteration 36700 (16.1069 iter/s, 6.2085s/100 iter), loss = 0.00638892
I0122 19:53:37.849382 70150 solver.cpp:285]     Train net output #0: loss = 0.00638904 (* 1 = 0.00638904 loss)
I0122 19:53:37.849388 70150 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 19:53:44.074949 70150 solver.cpp:266] Iteration 36800 (16.0634 iter/s, 6.22533s/100 iter), loss = 0.0115707
I0122 19:53:44.074976 70150 solver.cpp:285]     Train net output #0: loss = 0.0115708 (* 1 = 0.0115708 loss)
I0122 19:53:44.074982 70150 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 19:53:50.293267 70150 solver.cpp:266] Iteration 36900 (16.0822 iter/s, 6.21805s/100 iter), loss = 0.00880824
I0122 19:53:50.293296 70150 solver.cpp:285]     Train net output #0: loss = 0.00880836 (* 1 = 0.00880836 loss)
I0122 19:53:50.293301 70150 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 19:53:56.454706 70150 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 19:53:57.901545 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898778
I0122 19:53:57.901568 70150 solver.cpp:517]     Test net output #1: loss = 0.379288 (* 1 = 0.379288 loss)
I0122 19:53:57.901573 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898778
I0122 19:53:57.901576 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:53:57.963016 70150 solver.cpp:266] Iteration 37000 (13.0388 iter/s, 7.66943s/100 iter), loss = 0.00514285
I0122 19:53:57.963037 70150 solver.cpp:285]     Train net output #0: loss = 0.00514298 (* 1 = 0.00514298 loss)
I0122 19:53:57.963043 70150 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 19:54:04.177218 70150 solver.cpp:266] Iteration 37100 (16.0928 iter/s, 6.21394s/100 iter), loss = 0.00713336
I0122 19:54:04.177247 70150 solver.cpp:285]     Train net output #0: loss = 0.00713349 (* 1 = 0.00713349 loss)
I0122 19:54:04.177253 70150 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 19:54:10.396308 70150 solver.cpp:266] Iteration 37200 (16.0802 iter/s, 6.21882s/100 iter), loss = 0.00513117
I0122 19:54:10.396335 70150 solver.cpp:285]     Train net output #0: loss = 0.0051313 (* 1 = 0.0051313 loss)
I0122 19:54:10.396342 70150 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 19:54:16.606330 70150 solver.cpp:266] Iteration 37300 (16.1037 iter/s, 6.20976s/100 iter), loss = 0.00704005
I0122 19:54:16.606359 70150 solver.cpp:285]     Train net output #0: loss = 0.00704018 (* 1 = 0.00704018 loss)
I0122 19:54:16.606364 70150 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 19:54:22.812228 70150 solver.cpp:266] Iteration 37400 (16.1144 iter/s, 6.20563s/100 iter), loss = 0.00451495
I0122 19:54:22.812255 70150 solver.cpp:285]     Train net output #0: loss = 0.00451508 (* 1 = 0.00451508 loss)
I0122 19:54:22.812261 70150 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 19:54:29.042784 70150 solver.cpp:266] Iteration 37500 (16.0506 iter/s, 6.23029s/100 iter), loss = 0.00468551
I0122 19:54:29.042886 70150 solver.cpp:285]     Train net output #0: loss = 0.00468564 (* 1 = 0.00468564 loss)
I0122 19:54:29.042892 70150 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 19:54:35.240146 70150 solver.cpp:266] Iteration 37600 (16.1368 iter/s, 6.19702s/100 iter), loss = 0.00749289
I0122 19:54:35.240175 70150 solver.cpp:285]     Train net output #0: loss = 0.00749302 (* 1 = 0.00749302 loss)
I0122 19:54:35.240181 70150 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 19:54:41.462998 70150 solver.cpp:266] Iteration 37700 (16.0705 iter/s, 6.22259s/100 iter), loss = 0.00692974
I0122 19:54:41.463027 70150 solver.cpp:285]     Train net output #0: loss = 0.00692987 (* 1 = 0.00692987 loss)
I0122 19:54:41.463032 70150 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 19:54:47.686713 70150 solver.cpp:266] Iteration 37800 (16.0683 iter/s, 6.22345s/100 iter), loss = 0.00570611
I0122 19:54:47.686741 70150 solver.cpp:285]     Train net output #0: loss = 0.00570624 (* 1 = 0.00570624 loss)
I0122 19:54:47.686748 70150 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 19:54:53.900586 70150 solver.cpp:266] Iteration 37900 (16.0937 iter/s, 6.21361s/100 iter), loss = 0.00460478
I0122 19:54:53.900614 70150 solver.cpp:285]     Train net output #0: loss = 0.00460491 (* 1 = 0.00460491 loss)
I0122 19:54:53.900620 70150 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 19:55:00.045719 70150 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 19:55:01.500828 70150 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 19:55:01.500854 70150 solver.cpp:517]     Test net output #1: loss = 0.379312 (* 1 = 0.379312 loss)
I0122 19:55:01.500859 70150 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 19:55:01.500861 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:55:01.562127 70150 solver.cpp:266] Iteration 38000 (13.0527 iter/s, 7.66123s/100 iter), loss = 0.00984005
I0122 19:55:01.562149 70150 solver.cpp:285]     Train net output #0: loss = 0.00984018 (* 1 = 0.00984018 loss)
I0122 19:55:01.562155 70150 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 19:55:07.776778 70150 solver.cpp:266] Iteration 38100 (16.0917 iter/s, 6.21439s/100 iter), loss = 0.00349904
I0122 19:55:07.776805 70150 solver.cpp:285]     Train net output #0: loss = 0.00349917 (* 1 = 0.00349917 loss)
I0122 19:55:07.776813 70150 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 19:55:13.990429 70150 solver.cpp:266] Iteration 38200 (16.0943 iter/s, 6.21339s/100 iter), loss = 0.00642482
I0122 19:55:13.990458 70150 solver.cpp:285]     Train net output #0: loss = 0.00642495 (* 1 = 0.00642495 loss)
I0122 19:55:13.990463 70150 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 19:55:20.216651 70150 solver.cpp:266] Iteration 38300 (16.0618 iter/s, 6.22596s/100 iter), loss = 0.00320348
I0122 19:55:20.216679 70150 solver.cpp:285]     Train net output #0: loss = 0.00320361 (* 1 = 0.00320361 loss)
I0122 19:55:20.216686 70150 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 19:55:26.433964 70150 solver.cpp:266] Iteration 38400 (16.0848 iter/s, 6.21705s/100 iter), loss = 0.0200862
I0122 19:55:26.433990 70150 solver.cpp:285]     Train net output #0: loss = 0.0200863 (* 1 = 0.0200863 loss)
I0122 19:55:26.433996 70150 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 19:55:32.634124 70150 solver.cpp:266] Iteration 38500 (16.1293 iter/s, 6.1999s/100 iter), loss = 0.00811058
I0122 19:55:32.634224 70150 solver.cpp:285]     Train net output #0: loss = 0.00811071 (* 1 = 0.00811071 loss)
I0122 19:55:32.634232 70150 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 19:55:38.839541 70150 solver.cpp:266] Iteration 38600 (16.1158 iter/s, 6.20508s/100 iter), loss = 0.00468184
I0122 19:55:38.839570 70150 solver.cpp:285]     Train net output #0: loss = 0.00468197 (* 1 = 0.00468197 loss)
I0122 19:55:38.839576 70150 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 19:55:45.046783 70150 solver.cpp:266] Iteration 38700 (16.1109 iter/s, 6.20698s/100 iter), loss = 0.00299491
I0122 19:55:45.046809 70150 solver.cpp:285]     Train net output #0: loss = 0.00299504 (* 1 = 0.00299504 loss)
I0122 19:55:45.046815 70150 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 19:55:51.257177 70150 solver.cpp:266] Iteration 38800 (16.1027 iter/s, 6.21013s/100 iter), loss = 0.00316681
I0122 19:55:51.257205 70150 solver.cpp:285]     Train net output #0: loss = 0.00316694 (* 1 = 0.00316694 loss)
I0122 19:55:51.257211 70150 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 19:55:57.472005 70150 solver.cpp:266] Iteration 38900 (16.0912 iter/s, 6.21456s/100 iter), loss = 0.00517019
I0122 19:55:57.472033 70150 solver.cpp:285]     Train net output #0: loss = 0.00517032 (* 1 = 0.00517032 loss)
I0122 19:55:57.472039 70150 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 19:56:03.647307 70150 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 19:56:05.096380 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898667
I0122 19:56:05.096406 70150 solver.cpp:517]     Test net output #1: loss = 0.379441 (* 1 = 0.379441 loss)
I0122 19:56:05.096411 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898667
I0122 19:56:05.096415 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995556
I0122 19:56:05.158684 70150 solver.cpp:266] Iteration 39000 (13.0101 iter/s, 7.68636s/100 iter), loss = 0.00601964
I0122 19:56:05.158704 70150 solver.cpp:285]     Train net output #0: loss = 0.00601977 (* 1 = 0.00601977 loss)
I0122 19:56:05.158710 70150 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 19:56:11.375030 70150 solver.cpp:266] Iteration 39100 (16.0873 iter/s, 6.21609s/100 iter), loss = 0.004733
I0122 19:56:11.375058 70150 solver.cpp:285]     Train net output #0: loss = 0.00473313 (* 1 = 0.00473313 loss)
I0122 19:56:11.375063 70150 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 19:56:17.591724 70150 solver.cpp:266] Iteration 39200 (16.0864 iter/s, 6.21643s/100 iter), loss = 0.00686415
I0122 19:56:17.591753 70150 solver.cpp:285]     Train net output #0: loss = 0.00686428 (* 1 = 0.00686428 loss)
I0122 19:56:17.591759 70150 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 19:56:23.811558 70150 solver.cpp:266] Iteration 39300 (16.0783 iter/s, 6.21957s/100 iter), loss = 0.00957751
I0122 19:56:23.811586 70150 solver.cpp:285]     Train net output #0: loss = 0.00957764 (* 1 = 0.00957764 loss)
I0122 19:56:23.811592 70150 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 19:56:30.016363 70150 solver.cpp:266] Iteration 39400 (16.1172 iter/s, 6.20454s/100 iter), loss = 0.00373957
I0122 19:56:30.016391 70150 solver.cpp:285]     Train net output #0: loss = 0.0037397 (* 1 = 0.0037397 loss)
I0122 19:56:30.016397 70150 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 19:56:36.239533 70150 solver.cpp:266] Iteration 39500 (16.0697 iter/s, 6.2229s/100 iter), loss = 0.00350312
I0122 19:56:36.239650 70150 solver.cpp:285]     Train net output #0: loss = 0.00350325 (* 1 = 0.00350325 loss)
I0122 19:56:36.239656 70150 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 19:56:42.443735 70150 solver.cpp:266] Iteration 39600 (16.119 iter/s, 6.20385s/100 iter), loss = 0.00655002
I0122 19:56:42.443763 70150 solver.cpp:285]     Train net output #0: loss = 0.00655015 (* 1 = 0.00655015 loss)
I0122 19:56:42.443768 70150 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 19:56:48.665303 70150 solver.cpp:266] Iteration 39700 (16.0738 iter/s, 6.2213s/100 iter), loss = 0.00250925
I0122 19:56:48.665333 70150 solver.cpp:285]     Train net output #0: loss = 0.00250938 (* 1 = 0.00250938 loss)
I0122 19:56:48.665338 70150 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 19:56:54.880671 70150 solver.cpp:266] Iteration 39800 (16.0898 iter/s, 6.2151s/100 iter), loss = 0.0118811
I0122 19:56:54.880699 70150 solver.cpp:285]     Train net output #0: loss = 0.0118812 (* 1 = 0.0118812 loss)
I0122 19:56:54.880705 70150 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 19:57:01.092326 70150 solver.cpp:266] Iteration 39900 (16.0995 iter/s, 6.21139s/100 iter), loss = 0.0093539
I0122 19:57:01.092355 70150 solver.cpp:285]     Train net output #0: loss = 0.00935403 (* 1 = 0.00935403 loss)
I0122 19:57:01.092361 70150 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 19:57:07.249833 70150 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_40000.caffemodel
I0122 19:57:07.292649 70150 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.3/snapshots/_iter_40000.solverstate
I0122 19:57:07.321705 70150 solver.cpp:378] Iteration 40000, loss = 0.00199301
I0122 19:57:07.321735 70150 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 19:57:08.774235 70150 solver.cpp:517]     Test net output #0: accuracy = 0.898444
I0122 19:57:08.774261 70150 solver.cpp:517]     Test net output #1: loss = 0.379542 (* 1 = 0.379542 loss)
I0122 19:57:08.774266 70150 solver.cpp:517]     Test net output #2: top-1 = 0.898444
I0122 19:57:08.774269 70150 solver.cpp:517]     Test net output #3: top-5 = 0.995444
I0122 19:57:08.774273 70150 solver.cpp:386] Optimization Done (15.7561 iter/s).
I0122 19:57:08.774277 70150 caffe_interface.cpp:530] Optimization Done.


## compression: fourth run
$PRUNE_ROOT/deephi_compress compress -config ${WORK_DIR}/config4.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_compress4_miniGoogleNet.txt
I0122 19:57:09.382705 70379 pruning_runner.cpp:190] Sens info found, use it.
I0122 19:57:09.416712 70379 pruning_runner.cpp:217] Start compressing, please wait...
I0122 19:57:10.828539 70379 pruning_runner.cpp:264] Compression complete 0.0107139%
I0122 19:57:11.480240 70379 pruning_runner.cpp:264] Compression complete 50.0054%
I0122 19:57:12.117293 70379 caffe_interface.cpp:66] Use GPU with device ID 0
I0122 19:57:12.117632 70379 caffe_interface.cpp:70] GPU device name: Quadro P6000
I0122 19:57:12.118831 70379 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 19:57:12.119370 70379 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 19:57:12.119659 70379 layer_factory.hpp:77] Creating layer data
I0122 19:57:12.119710 70379 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:12.120086 70379 net.cpp:94] Creating Layer data
I0122 19:57:12.120095 70379 net.cpp:409] data -> data
I0122 19:57:12.120102 70379 net.cpp:409] data -> label
I0122 19:57:12.121075 70686 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 19:57:12.121105 70686 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 19:57:12.121166 70379 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 19:57:12.121235 70379 data_layer.cpp:83] output data size: 50,3,32,32
I0122 19:57:12.123741 70379 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:12.123780 70379 net.cpp:144] Setting up data
I0122 19:57:12.123785 70379 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 19:57:12.123790 70379 net.cpp:151] Top shape: 50 (50)
I0122 19:57:12.123793 70379 net.cpp:159] Memory required for data: 614600
I0122 19:57:12.123796 70379 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 19:57:12.123802 70379 net.cpp:94] Creating Layer label_data_1_split
I0122 19:57:12.123806 70379 net.cpp:435] label_data_1_split <- label
I0122 19:57:12.123811 70379 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 19:57:12.123817 70379 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 19:57:12.123834 70379 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 19:57:12.123842 70379 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 19:57:12.123909 70379 net.cpp:144] Setting up label_data_1_split
I0122 19:57:12.123926 70379 net.cpp:151] Top shape: 50 (50)
I0122 19:57:12.123929 70379 net.cpp:151] Top shape: 50 (50)
I0122 19:57:12.123934 70379 net.cpp:151] Top shape: 50 (50)
I0122 19:57:12.123936 70379 net.cpp:151] Top shape: 50 (50)
I0122 19:57:12.123939 70379 net.cpp:159] Memory required for data: 615400
I0122 19:57:12.123941 70379 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:57:12.123950 70379 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:57:12.123953 70379 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:57:12.123958 70379 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:57:12.125398 70379 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:57:12.125411 70379 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:12.125413 70379 net.cpp:159] Memory required for data: 20276200
I0122 19:57:12.125422 70379 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:57:12.125430 70379 net.cpp:94] Creating Layer conv1/bn1
I0122 19:57:12.125452 70379 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:57:12.125457 70379 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:57:12.126125 70379 net.cpp:144] Setting up conv1/bn1
I0122 19:57:12.126132 70379 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:12.126137 70379 net.cpp:159] Memory required for data: 39937000
I0122 19:57:12.126147 70379 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:57:12.126154 70379 net.cpp:94] Creating Layer conv1/relu1
I0122 19:57:12.126157 70379 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:57:12.126163 70379 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:57:12.126169 70379 net.cpp:144] Setting up conv1/relu1
I0122 19:57:12.126173 70379 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:12.126175 70379 net.cpp:159] Memory required for data: 59597800
I0122 19:57:12.126178 70379 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:12.126183 70379 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:12.126185 70379 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:57:12.126190 70379 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:12.126199 70379 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:12.126251 70379 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:12.126257 70379 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:12.126261 70379 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:12.126265 70379 net.cpp:159] Memory required for data: 98919400
I0122 19:57:12.126267 70379 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:57:12.126274 70379 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:57:12.126279 70379 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:12.126284 70379 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:57:12.126579 70379 net.cpp:144] Setting up inception_2a/1x1
I0122 19:57:12.126585 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.126588 70379 net.cpp:159] Memory required for data: 105473000
I0122 19:57:12.126595 70379 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:57:12.126601 70379 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:57:12.126606 70379 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:57:12.126611 70379 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:57:12.127359 70379 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:57:12.127367 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.127369 70379 net.cpp:159] Memory required for data: 112026600
I0122 19:57:12.127377 70379 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:57:12.127383 70379 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:57:12.127398 70379 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:57:12.127403 70379 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:57:12.127409 70379 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:57:12.127413 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.127416 70379 net.cpp:159] Memory required for data: 118580200
I0122 19:57:12.127418 70379 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:57:12.127425 70379 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:57:12.127429 70379 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:12.127434 70379 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:57:12.128458 70379 net.cpp:144] Setting up inception_2a/3x3
I0122 19:57:12.128468 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.128473 70379 net.cpp:159] Memory required for data: 125133800
I0122 19:57:12.128479 70379 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:57:12.128486 70379 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:57:12.128489 70379 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:57:12.128496 70379 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:57:12.129127 70379 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:57:12.129132 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.129137 70379 net.cpp:159] Memory required for data: 131687400
I0122 19:57:12.129148 70379 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:57:12.129154 70379 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:57:12.129158 70379 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:57:12.129163 70379 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:57:12.129169 70379 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:57:12.129173 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.129175 70379 net.cpp:159] Memory required for data: 138241000
I0122 19:57:12.129179 70379 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:57:12.129184 70379 net.cpp:94] Creating Layer inception_2a/output
I0122 19:57:12.129187 70379 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:57:12.129190 70379 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:57:12.129194 70379 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:57:12.129215 70379 net.cpp:144] Setting up inception_2a/output
I0122 19:57:12.129221 70379 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:12.129223 70379 net.cpp:159] Memory required for data: 151348200
I0122 19:57:12.129226 70379 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:12.129230 70379 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:12.129233 70379 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:57:12.129238 70379 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:12.129245 70379 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:12.129309 70379 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:57:12.129315 70379 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:12.129319 70379 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:12.129321 70379 net.cpp:159] Memory required for data: 177562600
I0122 19:57:12.129324 70379 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:57:12.129333 70379 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:57:12.129336 70379 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:12.129341 70379 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:57:12.129559 70379 net.cpp:144] Setting up inception_3a/1x1
I0122 19:57:12.129575 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.129578 70379 net.cpp:159] Memory required for data: 184116200
I0122 19:57:12.129583 70379 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:57:12.129590 70379 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:57:12.129593 70379 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:57:12.129598 70379 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:57:12.130264 70379 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:57:12.130272 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.130275 70379 net.cpp:159] Memory required for data: 190669800
I0122 19:57:12.130283 70379 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:57:12.130290 70379 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:57:12.130293 70379 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:57:12.130297 70379 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:57:12.130303 70379 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:57:12.130308 70379 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:12.130311 70379 net.cpp:159] Memory required for data: 197223400
I0122 19:57:12.130314 70379 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:57:12.130321 70379 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:57:12.130326 70379 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:12.130331 70379 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:57:12.130714 70379 net.cpp:144] Setting up inception_3a/3x3
I0122 19:57:12.130722 70379 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:12.130726 70379 net.cpp:159] Memory required for data: 207053800
I0122 19:57:12.130731 70379 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:57:12.130738 70379 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:57:12.130740 70379 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:57:12.130744 70379 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:57:12.131384 70379 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:57:12.131392 70379 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:12.131394 70379 net.cpp:159] Memory required for data: 216884200
I0122 19:57:12.131404 70379 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:57:12.131410 70379 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:57:12.131413 70379 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:57:12.131417 70379 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:57:12.131423 70379 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:57:12.131428 70379 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:12.131430 70379 net.cpp:159] Memory required for data: 226714600
I0122 19:57:12.131433 70379 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:57:12.131436 70379 net.cpp:94] Creating Layer inception_3a/output
I0122 19:57:12.131440 70379 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:57:12.131443 70379 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:57:12.131448 70379 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:57:12.131470 70379 net.cpp:144] Setting up inception_3a/output
I0122 19:57:12.131476 70379 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:12.131479 70379 net.cpp:159] Memory required for data: 243098600
I0122 19:57:12.131482 70379 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:12.131486 70379 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:12.131489 70379 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:57:12.131494 70379 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:12.131500 70379 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:12.131572 70379 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:57:12.131578 70379 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:12.131582 70379 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:12.131584 70379 net.cpp:159] Memory required for data: 275866600
I0122 19:57:12.131587 70379 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:57:12.131595 70379 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:57:12.131598 70379 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:12.131604 70379 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:57:12.132133 70379 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:57:12.132140 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.132143 70379 net.cpp:159] Memory required for data: 279962600
I0122 19:57:12.132148 70379 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:57:12.132154 70379 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:57:12.132160 70379 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:57:12.132165 70379 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:12.132902 70379 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:57:12.132910 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.132912 70379 net.cpp:159] Memory required for data: 284058600
I0122 19:57:12.132920 70379 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:57:12.132925 70379 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:57:12.132928 70379 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:57:12.132933 70379 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:12.132939 70379 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:57:12.132943 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.132946 70379 net.cpp:159] Memory required for data: 288154600
I0122 19:57:12.132949 70379 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:57:12.132956 70379 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:57:12.132958 70379 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:12.132963 70379 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:57:12.132997 70379 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:57:12.133002 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.133005 70379 net.cpp:159] Memory required for data: 292250600
I0122 19:57:12.133008 70379 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:57:12.133013 70379 net.cpp:94] Creating Layer downsample_4/output
I0122 19:57:12.133015 70379 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:57:12.133019 70379 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:57:12.133023 70379 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:57:12.133081 70379 net.cpp:144] Setting up downsample_4/output
I0122 19:57:12.133086 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.133090 70379 net.cpp:159] Memory required for data: 300442600
I0122 19:57:12.133091 70379 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:12.133096 70379 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:12.133100 70379 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:57:12.133103 70379 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:12.133110 70379 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:12.133137 70379 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:57:12.133150 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.133154 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.133157 70379 net.cpp:159] Memory required for data: 316826600
I0122 19:57:12.133160 70379 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:57:12.133168 70379 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:57:12.133172 70379 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:12.133175 70379 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:57:12.133493 70379 net.cpp:144] Setting up inception_5a/1x1
I0122 19:57:12.133499 70379 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:12.133502 70379 net.cpp:159] Memory required for data: 322561000
I0122 19:57:12.133507 70379 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:57:12.133513 70379 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:57:12.133517 70379 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:57:12.133522 70379 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:57:12.134210 70379 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:57:12.134218 70379 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:12.134222 70379 net.cpp:159] Memory required for data: 328295400
I0122 19:57:12.134229 70379 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:57:12.134234 70379 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:57:12.134238 70379 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:57:12.134243 70379 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:57:12.134248 70379 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:57:12.134253 70379 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:12.134256 70379 net.cpp:159] Memory required for data: 334029800
I0122 19:57:12.134259 70379 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:57:12.134266 70379 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:57:12.134270 70379 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:12.134276 70379 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:57:12.134896 70379 net.cpp:144] Setting up inception_5a/3x3
I0122 19:57:12.134904 70379 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:12.134907 70379 net.cpp:159] Memory required for data: 336487400
I0122 19:57:12.134912 70379 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:57:12.134920 70379 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:57:12.134924 70379 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:57:12.134930 70379 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:57:12.135617 70379 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:57:12.135622 70379 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:12.135625 70379 net.cpp:159] Memory required for data: 338945000
I0122 19:57:12.135633 70379 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:57:12.135638 70379 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:57:12.135643 70379 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:57:12.135646 70379 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:57:12.135653 70379 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:57:12.135656 70379 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:12.135659 70379 net.cpp:159] Memory required for data: 341402600
I0122 19:57:12.135663 70379 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:57:12.135666 70379 net.cpp:94] Creating Layer inception_5a/output
I0122 19:57:12.135669 70379 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:57:12.135673 70379 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:57:12.135677 70379 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:57:12.135697 70379 net.cpp:144] Setting up inception_5a/output
I0122 19:57:12.135712 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.135716 70379 net.cpp:159] Memory required for data: 349594600
I0122 19:57:12.135718 70379 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:12.135723 70379 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:12.135726 70379 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:57:12.135731 70379 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:12.135737 70379 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:12.135799 70379 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:57:12.135805 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.135809 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.135812 70379 net.cpp:159] Memory required for data: 365978600
I0122 19:57:12.135814 70379 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:57:12.135823 70379 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:57:12.135828 70379 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:12.135833 70379 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:57:12.136798 70379 net.cpp:144] Setting up inception_6a/1x1
I0122 19:57:12.136809 70379 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:12.136811 70379 net.cpp:159] Memory required for data: 370893800
I0122 19:57:12.136817 70379 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:57:12.136826 70379 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:57:12.136831 70379 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:57:12.136837 70379 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:57:12.137455 70379 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:57:12.137462 70379 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:12.137465 70379 net.cpp:159] Memory required for data: 375809000
I0122 19:57:12.137473 70379 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:57:12.137480 70379 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:57:12.137482 70379 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:57:12.137487 70379 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:57:12.137495 70379 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:57:12.137497 70379 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:12.137501 70379 net.cpp:159] Memory required for data: 380724200
I0122 19:57:12.137503 70379 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:57:12.137511 70379 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:57:12.137516 70379 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:12.137521 70379 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:57:12.138865 70379 net.cpp:144] Setting up inception_6a/3x3
I0122 19:57:12.138880 70379 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:12.138881 70379 net.cpp:159] Memory required for data: 384001000
I0122 19:57:12.138892 70379 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:57:12.138902 70379 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:57:12.138906 70379 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:57:12.138911 70379 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:57:12.139537 70379 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:57:12.139545 70379 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:12.139547 70379 net.cpp:159] Memory required for data: 387277800
I0122 19:57:12.139555 70379 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:57:12.139560 70379 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:57:12.139576 70379 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:57:12.139581 70379 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:57:12.139587 70379 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:57:12.139591 70379 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:12.139595 70379 net.cpp:159] Memory required for data: 390554600
I0122 19:57:12.139597 70379 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:57:12.139601 70379 net.cpp:94] Creating Layer inception_6a/output
I0122 19:57:12.139605 70379 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:57:12.139608 70379 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:57:12.139613 70379 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:57:12.139631 70379 net.cpp:144] Setting up inception_6a/output
I0122 19:57:12.139636 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.139639 70379 net.cpp:159] Memory required for data: 398746600
I0122 19:57:12.139642 70379 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:12.139647 70379 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:12.139649 70379 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:57:12.139655 70379 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:12.139662 70379 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:12.139690 70379 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:57:12.139696 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.139700 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.139703 70379 net.cpp:159] Memory required for data: 415130600
I0122 19:57:12.139706 70379 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:57:12.139714 70379 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:57:12.139719 70379 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:12.139724 70379 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:57:12.140008 70379 net.cpp:144] Setting up inception_7a/1x1
I0122 19:57:12.140014 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.140017 70379 net.cpp:159] Memory required for data: 419226600
I0122 19:57:12.140022 70379 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:57:12.140028 70379 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:57:12.140033 70379 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:57:12.140039 70379 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:57:12.140666 70379 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:57:12.140672 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.140676 70379 net.cpp:159] Memory required for data: 423322600
I0122 19:57:12.140683 70379 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:57:12.140689 70379 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:57:12.140692 70379 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:57:12.140697 70379 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:57:12.140703 70379 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:57:12.140707 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.140709 70379 net.cpp:159] Memory required for data: 427418600
I0122 19:57:12.140712 70379 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:57:12.140719 70379 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:57:12.140724 70379 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:12.140730 70379 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:57:12.141582 70379 net.cpp:144] Setting up inception_7a/3x3
I0122 19:57:12.141602 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.141604 70379 net.cpp:159] Memory required for data: 431514600
I0122 19:57:12.141609 70379 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:57:12.141616 70379 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:57:12.141623 70379 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:57:12.141628 70379 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:57:12.142269 70379 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:57:12.142277 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.142280 70379 net.cpp:159] Memory required for data: 435610600
I0122 19:57:12.142288 70379 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:57:12.142293 70379 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:57:12.142297 70379 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:57:12.142302 70379 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:57:12.142307 70379 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:57:12.142311 70379 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:12.142313 70379 net.cpp:159] Memory required for data: 439706600
I0122 19:57:12.142316 70379 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:57:12.142321 70379 net.cpp:94] Creating Layer inception_7a/output
I0122 19:57:12.142324 70379 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:57:12.142328 70379 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:57:12.142333 70379 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:57:12.142350 70379 net.cpp:144] Setting up inception_7a/output
I0122 19:57:12.142356 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.142359 70379 net.cpp:159] Memory required for data: 447898600
I0122 19:57:12.142362 70379 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:12.142366 70379 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:12.142369 70379 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:57:12.142374 70379 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:12.142380 70379 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:12.142406 70379 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:57:12.142411 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.142416 70379 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:12.142418 70379 net.cpp:159] Memory required for data: 464282600
I0122 19:57:12.142421 70379 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:57:12.142428 70379 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:57:12.142431 70379 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:12.142436 70379 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:57:12.142693 70379 net.cpp:144] Setting up inception_8a/1x1
I0122 19:57:12.142699 70379 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:12.142701 70379 net.cpp:159] Memory required for data: 466740200
I0122 19:57:12.142706 70379 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:57:12.142712 70379 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:57:12.142715 70379 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:57:12.142720 70379 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:57:12.143339 70379 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:57:12.143347 70379 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:12.143349 70379 net.cpp:159] Memory required for data: 469197800
I0122 19:57:12.143357 70379 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:57:12.143362 70379 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:57:12.143375 70379 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:57:12.143380 70379 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:57:12.143386 70379 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:57:12.143390 70379 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:12.143393 70379 net.cpp:159] Memory required for data: 471655400
I0122 19:57:12.143395 70379 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:57:12.143402 70379 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:57:12.143409 70379 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:12.143414 70379 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:57:12.145012 70379 net.cpp:144] Setting up inception_8a/3x3
I0122 19:57:12.145025 70379 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:12.145028 70379 net.cpp:159] Memory required for data: 476570600
I0122 19:57:12.145035 70379 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:57:12.145041 70379 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:57:12.145047 70379 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:57:12.145069 70379 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:57:12.145704 70379 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:57:12.145711 70379 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:12.145714 70379 net.cpp:159] Memory required for data: 481485800
I0122 19:57:12.145723 70379 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:57:12.145728 70379 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:57:12.145731 70379 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:57:12.145736 70379 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:57:12.145742 70379 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:57:12.145746 70379 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:12.145748 70379 net.cpp:159] Memory required for data: 486401000
I0122 19:57:12.145751 70379 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:57:12.145756 70379 net.cpp:94] Creating Layer inception_8a/output
I0122 19:57:12.145761 70379 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:57:12.145763 70379 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:57:12.145768 70379 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:57:12.145787 70379 net.cpp:144] Setting up inception_8a/output
I0122 19:57:12.145792 70379 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:12.145794 70379 net.cpp:159] Memory required for data: 493773800
I0122 19:57:12.145797 70379 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:12.145802 70379 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:12.145805 70379 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:57:12.145810 70379 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:12.145817 70379 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:12.145843 70379 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:57:12.145848 70379 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:12.145851 70379 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:12.145854 70379 net.cpp:159] Memory required for data: 508519400
I0122 19:57:12.145857 70379 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:57:12.145865 70379 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:57:12.145869 70379 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:12.145875 70379 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:57:12.147419 70379 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:57:12.147442 70379 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:12.147445 70379 net.cpp:159] Memory required for data: 509748200
I0122 19:57:12.147451 70379 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:57:12.147459 70379 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:57:12.147462 70379 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:57:12.147469 70379 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:12.148133 70379 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:57:12.148140 70379 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:12.148144 70379 net.cpp:159] Memory required for data: 510977000
I0122 19:57:12.148151 70379 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:57:12.148156 70379 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:57:12.148162 70379 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:57:12.148167 70379 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:12.148174 70379 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:57:12.148176 70379 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:12.148180 70379 net.cpp:159] Memory required for data: 512205800
I0122 19:57:12.148182 70379 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:57:12.148187 70379 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:57:12.148191 70379 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:12.148196 70379 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:57:12.148226 70379 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:57:12.148231 70379 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 19:57:12.148234 70379 net.cpp:159] Memory required for data: 514049000
I0122 19:57:12.148237 70379 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:57:12.148244 70379 net.cpp:94] Creating Layer downsample_9/output
I0122 19:57:12.148248 70379 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:57:12.148252 70379 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:57:12.148258 70379 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:57:12.148277 70379 net.cpp:144] Setting up downsample_9/output
I0122 19:57:12.148283 70379 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:12.148285 70379 net.cpp:159] Memory required for data: 517121000
I0122 19:57:12.148289 70379 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:12.148294 70379 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:12.148298 70379 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:57:12.148301 70379 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:12.148308 70379 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:12.148334 70379 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:57:12.148339 70379 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:12.148342 70379 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:12.148346 70379 net.cpp:159] Memory required for data: 523265000
I0122 19:57:12.148349 70379 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:57:12.148356 70379 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:57:12.148358 70379 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:12.148365 70379 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:57:12.148818 70379 net.cpp:144] Setting up inception_10a/1x1
I0122 19:57:12.148825 70379 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:12.148828 70379 net.cpp:159] Memory required for data: 525517800
I0122 19:57:12.148842 70379 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:57:12.148849 70379 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:57:12.148852 70379 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:57:12.148857 70379 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:57:12.149498 70379 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:57:12.149505 70379 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:12.149508 70379 net.cpp:159] Memory required for data: 527770600
I0122 19:57:12.149516 70379 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:57:12.149521 70379 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:57:12.149524 70379 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:57:12.149528 70379 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:57:12.149534 70379 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:57:12.149538 70379 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:12.149540 70379 net.cpp:159] Memory required for data: 530023400
I0122 19:57:12.149544 70379 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:57:12.149550 70379 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:57:12.149556 70379 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:12.149561 70379 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:57:12.152099 70379 net.cpp:144] Setting up inception_10a/3x3
I0122 19:57:12.152112 70379 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:12.152114 70379 net.cpp:159] Memory required for data: 532071400
I0122 19:57:12.152120 70379 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:57:12.152127 70379 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:57:12.152130 70379 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:57:12.152135 70379 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:57:12.152765 70379 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:57:12.152771 70379 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:12.152774 70379 net.cpp:159] Memory required for data: 534119400
I0122 19:57:12.152783 70379 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:57:12.152791 70379 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:57:12.152794 70379 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:57:12.152798 70379 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:57:12.152804 70379 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:57:12.152808 70379 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:12.152810 70379 net.cpp:159] Memory required for data: 536167400
I0122 19:57:12.152813 70379 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:57:12.152818 70379 net.cpp:94] Creating Layer inception_10a/output
I0122 19:57:12.152822 70379 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:57:12.152824 70379 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:57:12.152829 70379 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:57:12.152848 70379 net.cpp:144] Setting up inception_10a/output
I0122 19:57:12.152853 70379 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:12.152855 70379 net.cpp:159] Memory required for data: 540468200
I0122 19:57:12.152858 70379 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:12.152863 70379 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:12.152866 70379 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:57:12.152870 70379 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:12.152876 70379 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:12.152915 70379 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:57:12.152920 70379 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:12.152925 70379 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:12.152926 70379 net.cpp:159] Memory required for data: 549069800
I0122 19:57:12.152930 70379 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:57:12.152936 70379 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:57:12.152940 70379 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:12.152945 70379 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:57:12.153479 70379 net.cpp:144] Setting up inception_11a/1x1
I0122 19:57:12.153486 70379 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:12.153489 70379 net.cpp:159] Memory required for data: 551322600
I0122 19:57:12.153493 70379 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:57:12.153501 70379 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:57:12.153504 70379 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:57:12.153508 70379 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:57:12.154166 70379 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:57:12.154175 70379 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:12.154177 70379 net.cpp:159] Memory required for data: 553575400
I0122 19:57:12.154186 70379 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:57:12.154191 70379 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:57:12.154194 70379 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:57:12.154198 70379 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:57:12.154204 70379 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:57:12.154208 70379 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:12.154211 70379 net.cpp:159] Memory required for data: 555828200
I0122 19:57:12.154214 70379 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:57:12.154222 70379 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:57:12.154227 70379 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:12.154232 70379 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:57:12.157968 70379 net.cpp:144] Setting up inception_11a/3x3
I0122 19:57:12.157981 70379 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:12.157984 70379 net.cpp:159] Memory required for data: 557876200
I0122 19:57:12.157989 70379 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:57:12.157997 70379 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:57:12.158000 70379 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:57:12.158005 70379 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:57:12.158682 70379 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:57:12.158689 70379 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:12.158692 70379 net.cpp:159] Memory required for data: 559924200
I0122 19:57:12.158705 70379 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:57:12.158713 70379 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:57:12.158716 70379 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:57:12.158720 70379 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:57:12.158726 70379 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:57:12.158731 70379 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:12.158733 70379 net.cpp:159] Memory required for data: 561972200
I0122 19:57:12.158736 70379 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:57:12.158740 70379 net.cpp:94] Creating Layer inception_11a/output
I0122 19:57:12.158743 70379 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:57:12.158748 70379 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:57:12.158766 70379 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:57:12.158785 70379 net.cpp:144] Setting up inception_11a/output
I0122 19:57:12.158792 70379 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:12.158795 70379 net.cpp:159] Memory required for data: 566273000
I0122 19:57:12.158797 70379 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:57:12.158802 70379 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:57:12.158807 70379 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:57:12.158812 70379 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:57:12.158830 70379 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:57:12.158835 70379 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:57:12.158838 70379 net.cpp:159] Memory required for data: 566340200
I0122 19:57:12.158841 70379 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:57:12.158846 70379 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:57:12.158849 70379 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:57:12.158854 70379 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:57:12.158871 70379 net.cpp:144] Setting up drop_8x8_s1
I0122 19:57:12.158876 70379 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:57:12.158880 70379 net.cpp:159] Memory required for data: 566407400
I0122 19:57:12.158884 70379 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:57:12.158888 70379 net.cpp:94] Creating Layer loss/classifier
I0122 19:57:12.158891 70379 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:57:12.158896 70379 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:57:12.159032 70379 net.cpp:144] Setting up loss/classifier
I0122 19:57:12.159037 70379 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:12.159040 70379 net.cpp:159] Memory required for data: 566409400
I0122 19:57:12.159045 70379 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 19:57:12.159051 70379 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 19:57:12.159054 70379 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 19:57:12.159059 70379 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 19:57:12.159065 70379 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 19:57:12.159072 70379 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 19:57:12.159077 70379 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 19:57:12.159123 70379 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 19:57:12.159128 70379 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:12.159133 70379 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:12.159137 70379 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:12.159139 70379 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:12.159142 70379 net.cpp:159] Memory required for data: 566417400
I0122 19:57:12.159144 70379 layer_factory.hpp:77] Creating layer loss
I0122 19:57:12.159149 70379 net.cpp:94] Creating Layer loss
I0122 19:57:12.159152 70379 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 19:57:12.159157 70379 net.cpp:435] loss <- label_data_1_split_0
I0122 19:57:12.159162 70379 net.cpp:409] loss -> loss
I0122 19:57:12.159169 70379 layer_factory.hpp:77] Creating layer loss
I0122 19:57:12.159240 70379 net.cpp:144] Setting up loss
I0122 19:57:12.159246 70379 net.cpp:151] Top shape: (1)
I0122 19:57:12.159250 70379 net.cpp:154]     with loss weight 1
I0122 19:57:12.159257 70379 net.cpp:159] Memory required for data: 566417404
I0122 19:57:12.159260 70379 layer_factory.hpp:77] Creating layer accuracy
I0122 19:57:12.159265 70379 net.cpp:94] Creating Layer accuracy
I0122 19:57:12.159271 70379 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 19:57:12.159274 70379 net.cpp:435] accuracy <- label_data_1_split_1
I0122 19:57:12.159279 70379 net.cpp:409] accuracy -> accuracy
I0122 19:57:12.159297 70379 net.cpp:144] Setting up accuracy
I0122 19:57:12.159304 70379 net.cpp:151] Top shape: (1)
I0122 19:57:12.159307 70379 net.cpp:159] Memory required for data: 566417408
I0122 19:57:12.159309 70379 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 19:57:12.159313 70379 net.cpp:94] Creating Layer accuracy-top1
I0122 19:57:12.159317 70379 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 19:57:12.159320 70379 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 19:57:12.159324 70379 net.cpp:409] accuracy-top1 -> top-1
I0122 19:57:12.159330 70379 net.cpp:144] Setting up accuracy-top1
I0122 19:57:12.159334 70379 net.cpp:151] Top shape: (1)
I0122 19:57:12.159337 70379 net.cpp:159] Memory required for data: 566417412
I0122 19:57:12.159339 70379 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 19:57:12.159343 70379 net.cpp:94] Creating Layer accuracy-top5
I0122 19:57:12.159348 70379 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 19:57:12.159350 70379 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 19:57:12.159355 70379 net.cpp:409] accuracy-top5 -> top-5
I0122 19:57:12.159360 70379 net.cpp:144] Setting up accuracy-top5
I0122 19:57:12.159364 70379 net.cpp:151] Top shape: (1)
I0122 19:57:12.159368 70379 net.cpp:159] Memory required for data: 566417416
I0122 19:57:12.159369 70379 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 19:57:12.159373 70379 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 19:57:12.159377 70379 net.cpp:222] accuracy does not need backward computation.
I0122 19:57:12.159380 70379 net.cpp:220] loss needs backward computation.
I0122 19:57:12.159384 70379 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 19:57:12.159389 70379 net.cpp:220] loss/classifier needs backward computation.
I0122 19:57:12.159392 70379 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:57:12.159395 70379 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:57:12.159399 70379 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:57:12.159401 70379 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:57:12.159404 70379 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:57:12.159407 70379 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:57:12.159410 70379 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:57:12.159413 70379 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:57:12.159417 70379 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:57:12.159421 70379 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:57:12.159425 70379 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:57:12.159428 70379 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:57:12.159432 70379 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:57:12.159435 70379 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:57:12.159438 70379 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:57:12.159441 70379 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:57:12.159445 70379 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:57:12.159448 70379 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:57:12.159451 70379 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:57:12.159456 70379 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:57:12.159459 70379 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:57:12.159462 70379 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:57:12.159466 70379 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:57:12.159468 70379 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:57:12.159477 70379 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:57:12.159482 70379 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:57:12.159484 70379 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:57:12.159487 70379 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:57:12.159492 70379 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:57:12.159494 70379 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:57:12.159498 70379 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:57:12.159502 70379 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:57:12.159505 70379 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:57:12.159509 70379 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:57:12.159512 70379 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:57:12.159515 70379 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:57:12.159518 70379 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:57:12.159521 70379 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:57:12.159525 70379 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:57:12.159528 70379 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:57:12.159531 70379 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:57:12.159535 70379 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:57:12.159538 70379 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:57:12.159541 70379 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:57:12.159544 70379 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:57:12.159548 70379 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:57:12.159550 70379 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:57:12.159554 70379 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:57:12.159557 70379 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:57:12.159560 70379 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:57:12.159564 70379 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:57:12.159566 70379 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:57:12.159570 70379 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:57:12.159574 70379 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:57:12.159577 70379 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:57:12.159580 70379 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:57:12.159585 70379 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:57:12.159588 70379 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:57:12.159591 70379 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:57:12.159595 70379 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:57:12.159600 70379 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:57:12.159602 70379 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:57:12.159605 70379 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:57:12.159608 70379 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:57:12.159612 70379 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:57:12.159615 70379 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:57:12.159620 70379 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:57:12.159628 70379 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:57:12.159632 70379 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:57:12.159636 70379 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:57:12.159638 70379 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:57:12.159642 70379 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:57:12.159646 70379 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:57:12.159648 70379 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:57:12.159652 70379 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:57:12.159656 70379 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:57:12.159659 70379 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:57:12.159662 70379 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:57:12.159667 70379 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:57:12.159668 70379 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:57:12.159672 70379 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:57:12.159677 70379 net.cpp:222] label_data_1_split does not need backward computation.
I0122 19:57:12.159680 70379 net.cpp:222] data does not need backward computation.
I0122 19:57:12.159683 70379 net.cpp:264] This network produces output accuracy
I0122 19:57:12.159687 70379 net.cpp:264] This network produces output loss
I0122 19:57:12.159690 70379 net.cpp:264] This network produces output top-1
I0122 19:57:12.159693 70379 net.cpp:264] This network produces output top-5
I0122 19:57:12.159759 70379 net.cpp:284] Network initialization done.
I0122 19:57:12.162379 70379 caffe_interface.cpp:363] Running for 180 iterations.
I0122 19:57:12.187435 70379 caffe_interface.cpp:125] Batch 0, accuracy = 0.88
I0122 19:57:12.187453 70379 caffe_interface.cpp:125] Batch 0, loss = 0.325298
I0122 19:57:12.187456 70379 caffe_interface.cpp:125] Batch 0, top-1 = 0.88
I0122 19:57:12.187460 70379 caffe_interface.cpp:125] Batch 0, top-5 = 0.98
I0122 19:57:12.195973 70379 caffe_interface.cpp:125] Batch 1, accuracy = 0.94
I0122 19:57:12.195986 70379 caffe_interface.cpp:125] Batch 1, loss = 0.290137
I0122 19:57:12.195989 70379 caffe_interface.cpp:125] Batch 1, top-1 = 0.94
I0122 19:57:12.195992 70379 caffe_interface.cpp:125] Batch 1, top-5 = 1
I0122 19:57:12.204458 70379 caffe_interface.cpp:125] Batch 2, accuracy = 0.9
I0122 19:57:12.204469 70379 caffe_interface.cpp:125] Batch 2, loss = 0.277533
I0122 19:57:12.204473 70379 caffe_interface.cpp:125] Batch 2, top-1 = 0.9
I0122 19:57:12.204476 70379 caffe_interface.cpp:125] Batch 2, top-5 = 0.98
I0122 19:57:12.212951 70379 caffe_interface.cpp:125] Batch 3, accuracy = 0.84
I0122 19:57:12.212962 70379 caffe_interface.cpp:125] Batch 3, loss = 0.993526
I0122 19:57:12.212965 70379 caffe_interface.cpp:125] Batch 3, top-1 = 0.84
I0122 19:57:12.212968 70379 caffe_interface.cpp:125] Batch 3, top-5 = 1
I0122 19:57:12.222586 70379 caffe_interface.cpp:125] Batch 4, accuracy = 0.9
I0122 19:57:12.222596 70379 caffe_interface.cpp:125] Batch 4, loss = 0.301324
I0122 19:57:12.222599 70379 caffe_interface.cpp:125] Batch 4, top-1 = 0.9
I0122 19:57:12.222602 70379 caffe_interface.cpp:125] Batch 4, top-5 = 1
I0122 19:57:12.231082 70379 caffe_interface.cpp:125] Batch 5, accuracy = 0.9
I0122 19:57:12.231092 70379 caffe_interface.cpp:125] Batch 5, loss = 0.330222
I0122 19:57:12.231096 70379 caffe_interface.cpp:125] Batch 5, top-1 = 0.9
I0122 19:57:12.231099 70379 caffe_interface.cpp:125] Batch 5, top-5 = 1
I0122 19:57:12.239573 70379 caffe_interface.cpp:125] Batch 6, accuracy = 0.88
I0122 19:57:12.239583 70379 caffe_interface.cpp:125] Batch 6, loss = 0.336125
I0122 19:57:12.239586 70379 caffe_interface.cpp:125] Batch 6, top-1 = 0.88
I0122 19:57:12.239590 70379 caffe_interface.cpp:125] Batch 6, top-5 = 1
I0122 19:57:12.248044 70379 caffe_interface.cpp:125] Batch 7, accuracy = 0.92
I0122 19:57:12.248072 70379 caffe_interface.cpp:125] Batch 7, loss = 0.177248
I0122 19:57:12.248077 70379 caffe_interface.cpp:125] Batch 7, top-1 = 0.92
I0122 19:57:12.248080 70379 caffe_interface.cpp:125] Batch 7, top-5 = 1
I0122 19:57:12.257488 70379 caffe_interface.cpp:125] Batch 8, accuracy = 0.92
I0122 19:57:12.257499 70379 caffe_interface.cpp:125] Batch 8, loss = 0.348645
I0122 19:57:12.257503 70379 caffe_interface.cpp:125] Batch 8, top-1 = 0.92
I0122 19:57:12.257505 70379 caffe_interface.cpp:125] Batch 8, top-5 = 1
I0122 19:57:12.265934 70379 caffe_interface.cpp:125] Batch 9, accuracy = 0.92
I0122 19:57:12.265944 70379 caffe_interface.cpp:125] Batch 9, loss = 0.371031
I0122 19:57:12.265945 70379 caffe_interface.cpp:125] Batch 9, top-1 = 0.92
I0122 19:57:12.265949 70379 caffe_interface.cpp:125] Batch 9, top-5 = 0.98
I0122 19:57:12.274386 70379 caffe_interface.cpp:125] Batch 10, accuracy = 0.88
I0122 19:57:12.274395 70379 caffe_interface.cpp:125] Batch 10, loss = 0.588176
I0122 19:57:12.274397 70379 caffe_interface.cpp:125] Batch 10, top-1 = 0.88
I0122 19:57:12.274401 70379 caffe_interface.cpp:125] Batch 10, top-5 = 0.98
I0122 19:57:12.282888 70379 caffe_interface.cpp:125] Batch 11, accuracy = 0.92
I0122 19:57:12.282898 70379 caffe_interface.cpp:125] Batch 11, loss = 0.451505
I0122 19:57:12.282902 70379 caffe_interface.cpp:125] Batch 11, top-1 = 0.92
I0122 19:57:12.282907 70379 caffe_interface.cpp:125] Batch 11, top-5 = 0.98
I0122 19:57:12.292418 70379 caffe_interface.cpp:125] Batch 12, accuracy = 0.86
I0122 19:57:12.292428 70379 caffe_interface.cpp:125] Batch 12, loss = 0.414137
I0122 19:57:12.292431 70379 caffe_interface.cpp:125] Batch 12, top-1 = 0.86
I0122 19:57:12.292435 70379 caffe_interface.cpp:125] Batch 12, top-5 = 1
I0122 19:57:12.300922 70379 caffe_interface.cpp:125] Batch 13, accuracy = 0.88
I0122 19:57:12.300932 70379 caffe_interface.cpp:125] Batch 13, loss = 0.258844
I0122 19:57:12.300935 70379 caffe_interface.cpp:125] Batch 13, top-1 = 0.88
I0122 19:57:12.300940 70379 caffe_interface.cpp:125] Batch 13, top-5 = 1
I0122 19:57:12.309381 70379 caffe_interface.cpp:125] Batch 14, accuracy = 0.92
I0122 19:57:12.309388 70379 caffe_interface.cpp:125] Batch 14, loss = 0.182742
I0122 19:57:12.309391 70379 caffe_interface.cpp:125] Batch 14, top-1 = 0.92
I0122 19:57:12.309394 70379 caffe_interface.cpp:125] Batch 14, top-5 = 1
I0122 19:57:12.317806 70379 caffe_interface.cpp:125] Batch 15, accuracy = 0.9
I0122 19:57:12.317814 70379 caffe_interface.cpp:125] Batch 15, loss = 0.404396
I0122 19:57:12.317816 70379 caffe_interface.cpp:125] Batch 15, top-1 = 0.9
I0122 19:57:12.317819 70379 caffe_interface.cpp:125] Batch 15, top-5 = 1
I0122 19:57:12.327184 70379 caffe_interface.cpp:125] Batch 16, accuracy = 0.88
I0122 19:57:12.327193 70379 caffe_interface.cpp:125] Batch 16, loss = 0.333685
I0122 19:57:12.327196 70379 caffe_interface.cpp:125] Batch 16, top-1 = 0.88
I0122 19:57:12.327199 70379 caffe_interface.cpp:125] Batch 16, top-5 = 1
I0122 19:57:12.335652 70379 caffe_interface.cpp:125] Batch 17, accuracy = 0.88
I0122 19:57:12.335661 70379 caffe_interface.cpp:125] Batch 17, loss = 0.403571
I0122 19:57:12.335664 70379 caffe_interface.cpp:125] Batch 17, top-1 = 0.88
I0122 19:57:12.335669 70379 caffe_interface.cpp:125] Batch 17, top-5 = 0.98
I0122 19:57:12.344130 70379 caffe_interface.cpp:125] Batch 18, accuracy = 0.88
I0122 19:57:12.344139 70379 caffe_interface.cpp:125] Batch 18, loss = 0.475205
I0122 19:57:12.344142 70379 caffe_interface.cpp:125] Batch 18, top-1 = 0.88
I0122 19:57:12.344146 70379 caffe_interface.cpp:125] Batch 18, top-5 = 1
I0122 19:57:12.352603 70379 caffe_interface.cpp:125] Batch 19, accuracy = 0.94
I0122 19:57:12.352612 70379 caffe_interface.cpp:125] Batch 19, loss = 0.214775
I0122 19:57:12.352615 70379 caffe_interface.cpp:125] Batch 19, top-1 = 0.94
I0122 19:57:12.352618 70379 caffe_interface.cpp:125] Batch 19, top-5 = 1
I0122 19:57:12.361729 70379 caffe_interface.cpp:125] Batch 20, accuracy = 0.88
I0122 19:57:12.361739 70379 caffe_interface.cpp:125] Batch 20, loss = 0.583283
I0122 19:57:12.361742 70379 caffe_interface.cpp:125] Batch 20, top-1 = 0.88
I0122 19:57:12.361757 70379 caffe_interface.cpp:125] Batch 20, top-5 = 1
I0122 19:57:12.369740 70379 caffe_interface.cpp:125] Batch 21, accuracy = 0.86
I0122 19:57:12.369750 70379 caffe_interface.cpp:125] Batch 21, loss = 0.59421
I0122 19:57:12.369752 70379 caffe_interface.cpp:125] Batch 21, top-1 = 0.86
I0122 19:57:12.369756 70379 caffe_interface.cpp:125] Batch 21, top-5 = 1
I0122 19:57:12.377738 70379 caffe_interface.cpp:125] Batch 22, accuracy = 0.94
I0122 19:57:12.377749 70379 caffe_interface.cpp:125] Batch 22, loss = 0.250723
I0122 19:57:12.377753 70379 caffe_interface.cpp:125] Batch 22, top-1 = 0.94
I0122 19:57:12.377755 70379 caffe_interface.cpp:125] Batch 22, top-5 = 0.98
I0122 19:57:12.385735 70379 caffe_interface.cpp:125] Batch 23, accuracy = 0.96
I0122 19:57:12.385745 70379 caffe_interface.cpp:125] Batch 23, loss = 0.193539
I0122 19:57:12.385748 70379 caffe_interface.cpp:125] Batch 23, top-1 = 0.96
I0122 19:57:12.385752 70379 caffe_interface.cpp:125] Batch 23, top-5 = 1
I0122 19:57:12.394798 70379 caffe_interface.cpp:125] Batch 24, accuracy = 0.94
I0122 19:57:12.394809 70379 caffe_interface.cpp:125] Batch 24, loss = 0.242859
I0122 19:57:12.394812 70379 caffe_interface.cpp:125] Batch 24, top-1 = 0.94
I0122 19:57:12.394815 70379 caffe_interface.cpp:125] Batch 24, top-5 = 1
I0122 19:57:12.402788 70379 caffe_interface.cpp:125] Batch 25, accuracy = 0.88
I0122 19:57:12.402797 70379 caffe_interface.cpp:125] Batch 25, loss = 0.343579
I0122 19:57:12.402801 70379 caffe_interface.cpp:125] Batch 25, top-1 = 0.88
I0122 19:57:12.402804 70379 caffe_interface.cpp:125] Batch 25, top-5 = 0.98
I0122 19:57:12.410790 70379 caffe_interface.cpp:125] Batch 26, accuracy = 0.9
I0122 19:57:12.410800 70379 caffe_interface.cpp:125] Batch 26, loss = 0.302282
I0122 19:57:12.410804 70379 caffe_interface.cpp:125] Batch 26, top-1 = 0.9
I0122 19:57:12.410807 70379 caffe_interface.cpp:125] Batch 26, top-5 = 1
I0122 19:57:12.418778 70379 caffe_interface.cpp:125] Batch 27, accuracy = 0.94
I0122 19:57:12.418788 70379 caffe_interface.cpp:125] Batch 27, loss = 0.229973
I0122 19:57:12.418792 70379 caffe_interface.cpp:125] Batch 27, top-1 = 0.94
I0122 19:57:12.418794 70379 caffe_interface.cpp:125] Batch 27, top-5 = 1
I0122 19:57:12.427863 70379 caffe_interface.cpp:125] Batch 28, accuracy = 0.94
I0122 19:57:12.427873 70379 caffe_interface.cpp:125] Batch 28, loss = 0.177805
I0122 19:57:12.427877 70379 caffe_interface.cpp:125] Batch 28, top-1 = 0.94
I0122 19:57:12.427881 70379 caffe_interface.cpp:125] Batch 28, top-5 = 0.98
I0122 19:57:12.435860 70379 caffe_interface.cpp:125] Batch 29, accuracy = 0.96
I0122 19:57:12.435870 70379 caffe_interface.cpp:125] Batch 29, loss = 0.238072
I0122 19:57:12.435874 70379 caffe_interface.cpp:125] Batch 29, top-1 = 0.96
I0122 19:57:12.435878 70379 caffe_interface.cpp:125] Batch 29, top-5 = 1
I0122 19:57:12.443866 70379 caffe_interface.cpp:125] Batch 30, accuracy = 0.94
I0122 19:57:12.443876 70379 caffe_interface.cpp:125] Batch 30, loss = 0.239516
I0122 19:57:12.443879 70379 caffe_interface.cpp:125] Batch 30, top-1 = 0.94
I0122 19:57:12.443883 70379 caffe_interface.cpp:125] Batch 30, top-5 = 1
I0122 19:57:12.451851 70379 caffe_interface.cpp:125] Batch 31, accuracy = 0.86
I0122 19:57:12.451861 70379 caffe_interface.cpp:125] Batch 31, loss = 0.428425
I0122 19:57:12.451865 70379 caffe_interface.cpp:125] Batch 31, top-1 = 0.86
I0122 19:57:12.451869 70379 caffe_interface.cpp:125] Batch 31, top-5 = 1
I0122 19:57:12.460963 70379 caffe_interface.cpp:125] Batch 32, accuracy = 0.86
I0122 19:57:12.460973 70379 caffe_interface.cpp:125] Batch 32, loss = 0.475635
I0122 19:57:12.460975 70379 caffe_interface.cpp:125] Batch 32, top-1 = 0.86
I0122 19:57:12.460979 70379 caffe_interface.cpp:125] Batch 32, top-5 = 1
I0122 19:57:12.468943 70379 caffe_interface.cpp:125] Batch 33, accuracy = 0.82
I0122 19:57:12.468953 70379 caffe_interface.cpp:125] Batch 33, loss = 1.01554
I0122 19:57:12.468956 70379 caffe_interface.cpp:125] Batch 33, top-1 = 0.82
I0122 19:57:12.468960 70379 caffe_interface.cpp:125] Batch 33, top-5 = 0.98
I0122 19:57:12.476935 70379 caffe_interface.cpp:125] Batch 34, accuracy = 0.88
I0122 19:57:12.476945 70379 caffe_interface.cpp:125] Batch 34, loss = 0.436558
I0122 19:57:12.476948 70379 caffe_interface.cpp:125] Batch 34, top-1 = 0.88
I0122 19:57:12.476951 70379 caffe_interface.cpp:125] Batch 34, top-5 = 0.96
I0122 19:57:12.484922 70379 caffe_interface.cpp:125] Batch 35, accuracy = 0.96
I0122 19:57:12.484931 70379 caffe_interface.cpp:125] Batch 35, loss = 0.146904
I0122 19:57:12.484935 70379 caffe_interface.cpp:125] Batch 35, top-1 = 0.96
I0122 19:57:12.484938 70379 caffe_interface.cpp:125] Batch 35, top-5 = 1
I0122 19:57:12.493975 70379 caffe_interface.cpp:125] Batch 36, accuracy = 0.94
I0122 19:57:12.493984 70379 caffe_interface.cpp:125] Batch 36, loss = 0.165306
I0122 19:57:12.493988 70379 caffe_interface.cpp:125] Batch 36, top-1 = 0.94
I0122 19:57:12.493990 70379 caffe_interface.cpp:125] Batch 36, top-5 = 1
I0122 19:57:12.502580 70379 caffe_interface.cpp:125] Batch 37, accuracy = 0.86
I0122 19:57:12.502590 70379 caffe_interface.cpp:125] Batch 37, loss = 0.416882
I0122 19:57:12.502593 70379 caffe_interface.cpp:125] Batch 37, top-1 = 0.86
I0122 19:57:12.502596 70379 caffe_interface.cpp:125] Batch 37, top-5 = 1
I0122 19:57:12.510658 70379 caffe_interface.cpp:125] Batch 38, accuracy = 0.84
I0122 19:57:12.510668 70379 caffe_interface.cpp:125] Batch 38, loss = 0.514581
I0122 19:57:12.510670 70379 caffe_interface.cpp:125] Batch 38, top-1 = 0.84
I0122 19:57:12.510674 70379 caffe_interface.cpp:125] Batch 38, top-5 = 1
I0122 19:57:12.518642 70379 caffe_interface.cpp:125] Batch 39, accuracy = 0.86
I0122 19:57:12.518651 70379 caffe_interface.cpp:125] Batch 39, loss = 0.33517
I0122 19:57:12.518654 70379 caffe_interface.cpp:125] Batch 39, top-1 = 0.86
I0122 19:57:12.518657 70379 caffe_interface.cpp:125] Batch 39, top-5 = 1
I0122 19:57:12.527715 70379 caffe_interface.cpp:125] Batch 40, accuracy = 0.94
I0122 19:57:12.527724 70379 caffe_interface.cpp:125] Batch 40, loss = 0.271196
I0122 19:57:12.527726 70379 caffe_interface.cpp:125] Batch 40, top-1 = 0.94
I0122 19:57:12.527729 70379 caffe_interface.cpp:125] Batch 40, top-5 = 1
I0122 19:57:12.535639 70379 caffe_interface.cpp:125] Batch 41, accuracy = 0.84
I0122 19:57:12.535647 70379 caffe_interface.cpp:125] Batch 41, loss = 0.802614
I0122 19:57:12.535650 70379 caffe_interface.cpp:125] Batch 41, top-1 = 0.84
I0122 19:57:12.535652 70379 caffe_interface.cpp:125] Batch 41, top-5 = 0.98
I0122 19:57:12.543588 70379 caffe_interface.cpp:125] Batch 42, accuracy = 0.84
I0122 19:57:12.543597 70379 caffe_interface.cpp:125] Batch 42, loss = 0.48077
I0122 19:57:12.543601 70379 caffe_interface.cpp:125] Batch 42, top-1 = 0.84
I0122 19:57:12.543604 70379 caffe_interface.cpp:125] Batch 42, top-5 = 0.98
I0122 19:57:12.551584 70379 caffe_interface.cpp:125] Batch 43, accuracy = 0.88
I0122 19:57:12.551594 70379 caffe_interface.cpp:125] Batch 43, loss = 0.299037
I0122 19:57:12.551597 70379 caffe_interface.cpp:125] Batch 43, top-1 = 0.88
I0122 19:57:12.551600 70379 caffe_interface.cpp:125] Batch 43, top-5 = 1
I0122 19:57:12.560652 70379 caffe_interface.cpp:125] Batch 44, accuracy = 0.92
I0122 19:57:12.560659 70379 caffe_interface.cpp:125] Batch 44, loss = 0.280257
I0122 19:57:12.560662 70379 caffe_interface.cpp:125] Batch 44, top-1 = 0.92
I0122 19:57:12.560665 70379 caffe_interface.cpp:125] Batch 44, top-5 = 1
I0122 19:57:12.568627 70379 caffe_interface.cpp:125] Batch 45, accuracy = 0.88
I0122 19:57:12.568637 70379 caffe_interface.cpp:125] Batch 45, loss = 0.36897
I0122 19:57:12.568640 70379 caffe_interface.cpp:125] Batch 45, top-1 = 0.88
I0122 19:57:12.568644 70379 caffe_interface.cpp:125] Batch 45, top-5 = 1
I0122 19:57:12.576555 70379 caffe_interface.cpp:125] Batch 46, accuracy = 0.9
I0122 19:57:12.576565 70379 caffe_interface.cpp:125] Batch 46, loss = 0.285621
I0122 19:57:12.576566 70379 caffe_interface.cpp:125] Batch 46, top-1 = 0.9
I0122 19:57:12.576570 70379 caffe_interface.cpp:125] Batch 46, top-5 = 0.98
I0122 19:57:12.584560 70379 caffe_interface.cpp:125] Batch 47, accuracy = 0.9
I0122 19:57:12.584580 70379 caffe_interface.cpp:125] Batch 47, loss = 0.397635
I0122 19:57:12.584584 70379 caffe_interface.cpp:125] Batch 47, top-1 = 0.9
I0122 19:57:12.584589 70379 caffe_interface.cpp:125] Batch 47, top-5 = 1
I0122 19:57:12.593633 70379 caffe_interface.cpp:125] Batch 48, accuracy = 0.9
I0122 19:57:12.593642 70379 caffe_interface.cpp:125] Batch 48, loss = 0.193233
I0122 19:57:12.593645 70379 caffe_interface.cpp:125] Batch 48, top-1 = 0.9
I0122 19:57:12.593648 70379 caffe_interface.cpp:125] Batch 48, top-5 = 1
I0122 19:57:12.601614 70379 caffe_interface.cpp:125] Batch 49, accuracy = 0.92
I0122 19:57:12.601624 70379 caffe_interface.cpp:125] Batch 49, loss = 0.402857
I0122 19:57:12.601626 70379 caffe_interface.cpp:125] Batch 49, top-1 = 0.92
I0122 19:57:12.601629 70379 caffe_interface.cpp:125] Batch 49, top-5 = 1
I0122 19:57:12.609611 70379 caffe_interface.cpp:125] Batch 50, accuracy = 0.88
I0122 19:57:12.609621 70379 caffe_interface.cpp:125] Batch 50, loss = 0.357354
I0122 19:57:12.609624 70379 caffe_interface.cpp:125] Batch 50, top-1 = 0.88
I0122 19:57:12.609627 70379 caffe_interface.cpp:125] Batch 50, top-5 = 1
I0122 19:57:12.617605 70379 caffe_interface.cpp:125] Batch 51, accuracy = 0.92
I0122 19:57:12.617615 70379 caffe_interface.cpp:125] Batch 51, loss = 0.180947
I0122 19:57:12.617619 70379 caffe_interface.cpp:125] Batch 51, top-1 = 0.92
I0122 19:57:12.617621 70379 caffe_interface.cpp:125] Batch 51, top-5 = 1
I0122 19:57:12.626668 70379 caffe_interface.cpp:125] Batch 52, accuracy = 0.8
I0122 19:57:12.626677 70379 caffe_interface.cpp:125] Batch 52, loss = 0.580413
I0122 19:57:12.626679 70379 caffe_interface.cpp:125] Batch 52, top-1 = 0.8
I0122 19:57:12.626682 70379 caffe_interface.cpp:125] Batch 52, top-5 = 0.98
I0122 19:57:12.634632 70379 caffe_interface.cpp:125] Batch 53, accuracy = 0.82
I0122 19:57:12.634641 70379 caffe_interface.cpp:125] Batch 53, loss = 0.526109
I0122 19:57:12.634644 70379 caffe_interface.cpp:125] Batch 53, top-1 = 0.82
I0122 19:57:12.634649 70379 caffe_interface.cpp:125] Batch 53, top-5 = 1
I0122 19:57:12.642596 70379 caffe_interface.cpp:125] Batch 54, accuracy = 0.9
I0122 19:57:12.642606 70379 caffe_interface.cpp:125] Batch 54, loss = 0.321626
I0122 19:57:12.642608 70379 caffe_interface.cpp:125] Batch 54, top-1 = 0.9
I0122 19:57:12.642611 70379 caffe_interface.cpp:125] Batch 54, top-5 = 1
I0122 19:57:12.650564 70379 caffe_interface.cpp:125] Batch 55, accuracy = 0.94
I0122 19:57:12.650574 70379 caffe_interface.cpp:125] Batch 55, loss = 0.21054
I0122 19:57:12.650578 70379 caffe_interface.cpp:125] Batch 55, top-1 = 0.94
I0122 19:57:12.650580 70379 caffe_interface.cpp:125] Batch 55, top-5 = 1
I0122 19:57:12.659610 70379 caffe_interface.cpp:125] Batch 56, accuracy = 0.86
I0122 19:57:12.659618 70379 caffe_interface.cpp:125] Batch 56, loss = 0.354492
I0122 19:57:12.659621 70379 caffe_interface.cpp:125] Batch 56, top-1 = 0.86
I0122 19:57:12.659626 70379 caffe_interface.cpp:125] Batch 56, top-5 = 0.98
I0122 19:57:12.667557 70379 caffe_interface.cpp:125] Batch 57, accuracy = 0.8
I0122 19:57:12.667567 70379 caffe_interface.cpp:125] Batch 57, loss = 0.757239
I0122 19:57:12.667569 70379 caffe_interface.cpp:125] Batch 57, top-1 = 0.8
I0122 19:57:12.667572 70379 caffe_interface.cpp:125] Batch 57, top-5 = 1
I0122 19:57:12.675508 70379 caffe_interface.cpp:125] Batch 58, accuracy = 0.9
I0122 19:57:12.675518 70379 caffe_interface.cpp:125] Batch 58, loss = 0.334195
I0122 19:57:12.675523 70379 caffe_interface.cpp:125] Batch 58, top-1 = 0.9
I0122 19:57:12.675525 70379 caffe_interface.cpp:125] Batch 58, top-5 = 1
I0122 19:57:12.683454 70379 caffe_interface.cpp:125] Batch 59, accuracy = 0.88
I0122 19:57:12.683462 70379 caffe_interface.cpp:125] Batch 59, loss = 0.474415
I0122 19:57:12.683465 70379 caffe_interface.cpp:125] Batch 59, top-1 = 0.88
I0122 19:57:12.683468 70379 caffe_interface.cpp:125] Batch 59, top-5 = 1
I0122 19:57:12.692515 70379 caffe_interface.cpp:125] Batch 60, accuracy = 0.92
I0122 19:57:12.692526 70379 caffe_interface.cpp:125] Batch 60, loss = 0.261203
I0122 19:57:12.692529 70379 caffe_interface.cpp:125] Batch 60, top-1 = 0.92
I0122 19:57:12.692543 70379 caffe_interface.cpp:125] Batch 60, top-5 = 1
I0122 19:57:12.700469 70379 caffe_interface.cpp:125] Batch 61, accuracy = 0.86
I0122 19:57:12.700479 70379 caffe_interface.cpp:125] Batch 61, loss = 0.584521
I0122 19:57:12.700481 70379 caffe_interface.cpp:125] Batch 61, top-1 = 0.86
I0122 19:57:12.700485 70379 caffe_interface.cpp:125] Batch 61, top-5 = 1
I0122 19:57:12.708415 70379 caffe_interface.cpp:125] Batch 62, accuracy = 0.8
I0122 19:57:12.708425 70379 caffe_interface.cpp:125] Batch 62, loss = 0.403447
I0122 19:57:12.708427 70379 caffe_interface.cpp:125] Batch 62, top-1 = 0.8
I0122 19:57:12.708431 70379 caffe_interface.cpp:125] Batch 62, top-5 = 1
I0122 19:57:12.716365 70379 caffe_interface.cpp:125] Batch 63, accuracy = 0.9
I0122 19:57:12.716374 70379 caffe_interface.cpp:125] Batch 63, loss = 0.370038
I0122 19:57:12.716377 70379 caffe_interface.cpp:125] Batch 63, top-1 = 0.9
I0122 19:57:12.716380 70379 caffe_interface.cpp:125] Batch 63, top-5 = 0.98
I0122 19:57:12.724342 70379 caffe_interface.cpp:125] Batch 64, accuracy = 0.88
I0122 19:57:12.724352 70379 caffe_interface.cpp:125] Batch 64, loss = 0.428756
I0122 19:57:12.724354 70379 caffe_interface.cpp:125] Batch 64, top-1 = 0.88
I0122 19:57:12.724359 70379 caffe_interface.cpp:125] Batch 64, top-5 = 1
I0122 19:57:12.733292 70379 caffe_interface.cpp:125] Batch 65, accuracy = 0.96
I0122 19:57:12.733301 70379 caffe_interface.cpp:125] Batch 65, loss = 0.214856
I0122 19:57:12.733304 70379 caffe_interface.cpp:125] Batch 65, top-1 = 0.96
I0122 19:57:12.733307 70379 caffe_interface.cpp:125] Batch 65, top-5 = 1
I0122 19:57:12.741195 70379 caffe_interface.cpp:125] Batch 66, accuracy = 0.88
I0122 19:57:12.741204 70379 caffe_interface.cpp:125] Batch 66, loss = 0.346775
I0122 19:57:12.741206 70379 caffe_interface.cpp:125] Batch 66, top-1 = 0.88
I0122 19:57:12.741209 70379 caffe_interface.cpp:125] Batch 66, top-5 = 1
I0122 19:57:12.749094 70379 caffe_interface.cpp:125] Batch 67, accuracy = 0.82
I0122 19:57:12.749101 70379 caffe_interface.cpp:125] Batch 67, loss = 0.839251
I0122 19:57:12.749104 70379 caffe_interface.cpp:125] Batch 67, top-1 = 0.82
I0122 19:57:12.749106 70379 caffe_interface.cpp:125] Batch 67, top-5 = 1
I0122 19:57:12.757045 70379 caffe_interface.cpp:125] Batch 68, accuracy = 0.94
I0122 19:57:12.757055 70379 caffe_interface.cpp:125] Batch 68, loss = 0.172254
I0122 19:57:12.757057 70379 caffe_interface.cpp:125] Batch 68, top-1 = 0.94
I0122 19:57:12.757061 70379 caffe_interface.cpp:125] Batch 68, top-5 = 1
I0122 19:57:12.766013 70379 caffe_interface.cpp:125] Batch 69, accuracy = 0.94
I0122 19:57:12.766023 70379 caffe_interface.cpp:125] Batch 69, loss = 0.184937
I0122 19:57:12.766026 70379 caffe_interface.cpp:125] Batch 69, top-1 = 0.94
I0122 19:57:12.766029 70379 caffe_interface.cpp:125] Batch 69, top-5 = 1
I0122 19:57:12.773967 70379 caffe_interface.cpp:125] Batch 70, accuracy = 0.86
I0122 19:57:12.773977 70379 caffe_interface.cpp:125] Batch 70, loss = 0.307128
I0122 19:57:12.773979 70379 caffe_interface.cpp:125] Batch 70, top-1 = 0.86
I0122 19:57:12.773983 70379 caffe_interface.cpp:125] Batch 70, top-5 = 1
I0122 19:57:12.781901 70379 caffe_interface.cpp:125] Batch 71, accuracy = 0.88
I0122 19:57:12.781913 70379 caffe_interface.cpp:125] Batch 71, loss = 0.366598
I0122 19:57:12.781916 70379 caffe_interface.cpp:125] Batch 71, top-1 = 0.88
I0122 19:57:12.781919 70379 caffe_interface.cpp:125] Batch 71, top-5 = 1
I0122 19:57:12.789862 70379 caffe_interface.cpp:125] Batch 72, accuracy = 0.92
I0122 19:57:12.789871 70379 caffe_interface.cpp:125] Batch 72, loss = 0.317366
I0122 19:57:12.789875 70379 caffe_interface.cpp:125] Batch 72, top-1 = 0.92
I0122 19:57:12.789877 70379 caffe_interface.cpp:125] Batch 72, top-5 = 0.98
I0122 19:57:12.798921 70379 caffe_interface.cpp:125] Batch 73, accuracy = 0.94
I0122 19:57:12.798929 70379 caffe_interface.cpp:125] Batch 73, loss = 0.205092
I0122 19:57:12.798933 70379 caffe_interface.cpp:125] Batch 73, top-1 = 0.94
I0122 19:57:12.798935 70379 caffe_interface.cpp:125] Batch 73, top-5 = 0.98
I0122 19:57:12.806850 70379 caffe_interface.cpp:125] Batch 74, accuracy = 0.84
I0122 19:57:12.806859 70379 caffe_interface.cpp:125] Batch 74, loss = 0.656455
I0122 19:57:12.806861 70379 caffe_interface.cpp:125] Batch 74, top-1 = 0.84
I0122 19:57:12.806865 70379 caffe_interface.cpp:125] Batch 74, top-5 = 0.98
I0122 19:57:12.814818 70379 caffe_interface.cpp:125] Batch 75, accuracy = 0.88
I0122 19:57:12.814828 70379 caffe_interface.cpp:125] Batch 75, loss = 0.342393
I0122 19:57:12.814831 70379 caffe_interface.cpp:125] Batch 75, top-1 = 0.88
I0122 19:57:12.814834 70379 caffe_interface.cpp:125] Batch 75, top-5 = 1
I0122 19:57:12.822757 70379 caffe_interface.cpp:125] Batch 76, accuracy = 0.86
I0122 19:57:12.822767 70379 caffe_interface.cpp:125] Batch 76, loss = 0.385779
I0122 19:57:12.822769 70379 caffe_interface.cpp:125] Batch 76, top-1 = 0.86
I0122 19:57:12.822773 70379 caffe_interface.cpp:125] Batch 76, top-5 = 1
I0122 19:57:12.831816 70379 caffe_interface.cpp:125] Batch 77, accuracy = 0.86
I0122 19:57:12.831825 70379 caffe_interface.cpp:125] Batch 77, loss = 0.403291
I0122 19:57:12.831827 70379 caffe_interface.cpp:125] Batch 77, top-1 = 0.86
I0122 19:57:12.831830 70379 caffe_interface.cpp:125] Batch 77, top-5 = 1
I0122 19:57:12.839715 70379 caffe_interface.cpp:125] Batch 78, accuracy = 0.94
I0122 19:57:12.839725 70379 caffe_interface.cpp:125] Batch 78, loss = 0.188355
I0122 19:57:12.839726 70379 caffe_interface.cpp:125] Batch 78, top-1 = 0.94
I0122 19:57:12.839730 70379 caffe_interface.cpp:125] Batch 78, top-5 = 1
I0122 19:57:12.847662 70379 caffe_interface.cpp:125] Batch 79, accuracy = 0.94
I0122 19:57:12.847671 70379 caffe_interface.cpp:125] Batch 79, loss = 0.209242
I0122 19:57:12.847674 70379 caffe_interface.cpp:125] Batch 79, top-1 = 0.94
I0122 19:57:12.847678 70379 caffe_interface.cpp:125] Batch 79, top-5 = 0.98
I0122 19:57:12.855619 70379 caffe_interface.cpp:125] Batch 80, accuracy = 0.9
I0122 19:57:12.855629 70379 caffe_interface.cpp:125] Batch 80, loss = 0.462875
I0122 19:57:12.855633 70379 caffe_interface.cpp:125] Batch 80, top-1 = 0.9
I0122 19:57:12.855636 70379 caffe_interface.cpp:125] Batch 80, top-5 = 1
I0122 19:57:12.864682 70379 caffe_interface.cpp:125] Batch 81, accuracy = 0.84
I0122 19:57:12.864691 70379 caffe_interface.cpp:125] Batch 81, loss = 0.440927
I0122 19:57:12.864696 70379 caffe_interface.cpp:125] Batch 81, top-1 = 0.84
I0122 19:57:12.864699 70379 caffe_interface.cpp:125] Batch 81, top-5 = 1
I0122 19:57:12.872639 70379 caffe_interface.cpp:125] Batch 82, accuracy = 0.84
I0122 19:57:12.872648 70379 caffe_interface.cpp:125] Batch 82, loss = 0.568829
I0122 19:57:12.872653 70379 caffe_interface.cpp:125] Batch 82, top-1 = 0.84
I0122 19:57:12.872656 70379 caffe_interface.cpp:125] Batch 82, top-5 = 0.98
I0122 19:57:12.880617 70379 caffe_interface.cpp:125] Batch 83, accuracy = 0.94
I0122 19:57:12.880627 70379 caffe_interface.cpp:125] Batch 83, loss = 0.327716
I0122 19:57:12.880631 70379 caffe_interface.cpp:125] Batch 83, top-1 = 0.94
I0122 19:57:12.880635 70379 caffe_interface.cpp:125] Batch 83, top-5 = 1
I0122 19:57:12.888566 70379 caffe_interface.cpp:125] Batch 84, accuracy = 0.88
I0122 19:57:12.888574 70379 caffe_interface.cpp:125] Batch 84, loss = 0.521301
I0122 19:57:12.888577 70379 caffe_interface.cpp:125] Batch 84, top-1 = 0.88
I0122 19:57:12.888581 70379 caffe_interface.cpp:125] Batch 84, top-5 = 1
I0122 19:57:12.897886 70379 caffe_interface.cpp:125] Batch 85, accuracy = 0.92
I0122 19:57:12.897895 70379 caffe_interface.cpp:125] Batch 85, loss = 0.269469
I0122 19:57:12.897897 70379 caffe_interface.cpp:125] Batch 85, top-1 = 0.92
I0122 19:57:12.897900 70379 caffe_interface.cpp:125] Batch 85, top-5 = 1
I0122 19:57:12.906177 70379 caffe_interface.cpp:125] Batch 86, accuracy = 0.94
I0122 19:57:12.906185 70379 caffe_interface.cpp:125] Batch 86, loss = 0.227714
I0122 19:57:12.906188 70379 caffe_interface.cpp:125] Batch 86, top-1 = 0.94
I0122 19:57:12.906191 70379 caffe_interface.cpp:125] Batch 86, top-5 = 1
I0122 19:57:12.914361 70379 caffe_interface.cpp:125] Batch 87, accuracy = 0.94
I0122 19:57:12.914381 70379 caffe_interface.cpp:125] Batch 87, loss = 0.202542
I0122 19:57:12.914384 70379 caffe_interface.cpp:125] Batch 87, top-1 = 0.94
I0122 19:57:12.914388 70379 caffe_interface.cpp:125] Batch 87, top-5 = 1
I0122 19:57:12.922343 70379 caffe_interface.cpp:125] Batch 88, accuracy = 0.8
I0122 19:57:12.922353 70379 caffe_interface.cpp:125] Batch 88, loss = 0.550685
I0122 19:57:12.922356 70379 caffe_interface.cpp:125] Batch 88, top-1 = 0.8
I0122 19:57:12.922359 70379 caffe_interface.cpp:125] Batch 88, top-5 = 1
I0122 19:57:12.931432 70379 caffe_interface.cpp:125] Batch 89, accuracy = 0.94
I0122 19:57:12.931440 70379 caffe_interface.cpp:125] Batch 89, loss = 0.27159
I0122 19:57:12.931444 70379 caffe_interface.cpp:125] Batch 89, top-1 = 0.94
I0122 19:57:12.931448 70379 caffe_interface.cpp:125] Batch 89, top-5 = 0.98
I0122 19:57:12.939414 70379 caffe_interface.cpp:125] Batch 90, accuracy = 0.86
I0122 19:57:12.939422 70379 caffe_interface.cpp:125] Batch 90, loss = 0.610752
I0122 19:57:12.939425 70379 caffe_interface.cpp:125] Batch 90, top-1 = 0.86
I0122 19:57:12.939429 70379 caffe_interface.cpp:125] Batch 90, top-5 = 0.98
I0122 19:57:12.947376 70379 caffe_interface.cpp:125] Batch 91, accuracy = 0.9
I0122 19:57:12.947386 70379 caffe_interface.cpp:125] Batch 91, loss = 0.337425
I0122 19:57:12.947389 70379 caffe_interface.cpp:125] Batch 91, top-1 = 0.9
I0122 19:57:12.947392 70379 caffe_interface.cpp:125] Batch 91, top-5 = 1
I0122 19:57:12.955338 70379 caffe_interface.cpp:125] Batch 92, accuracy = 0.84
I0122 19:57:12.955348 70379 caffe_interface.cpp:125] Batch 92, loss = 0.490773
I0122 19:57:12.955351 70379 caffe_interface.cpp:125] Batch 92, top-1 = 0.84
I0122 19:57:12.955354 70379 caffe_interface.cpp:125] Batch 92, top-5 = 0.98
I0122 19:57:12.964377 70379 caffe_interface.cpp:125] Batch 93, accuracy = 0.9
I0122 19:57:12.964385 70379 caffe_interface.cpp:125] Batch 93, loss = 0.319916
I0122 19:57:12.964388 70379 caffe_interface.cpp:125] Batch 93, top-1 = 0.9
I0122 19:57:12.964391 70379 caffe_interface.cpp:125] Batch 93, top-5 = 1
I0122 19:57:12.972326 70379 caffe_interface.cpp:125] Batch 94, accuracy = 0.78
I0122 19:57:12.972334 70379 caffe_interface.cpp:125] Batch 94, loss = 0.853169
I0122 19:57:12.972337 70379 caffe_interface.cpp:125] Batch 94, top-1 = 0.78
I0122 19:57:12.972340 70379 caffe_interface.cpp:125] Batch 94, top-5 = 0.98
I0122 19:57:12.980275 70379 caffe_interface.cpp:125] Batch 95, accuracy = 0.92
I0122 19:57:12.980284 70379 caffe_interface.cpp:125] Batch 95, loss = 0.177503
I0122 19:57:12.980288 70379 caffe_interface.cpp:125] Batch 95, top-1 = 0.92
I0122 19:57:12.980290 70379 caffe_interface.cpp:125] Batch 95, top-5 = 0.98
I0122 19:57:12.988212 70379 caffe_interface.cpp:125] Batch 96, accuracy = 0.82
I0122 19:57:12.988222 70379 caffe_interface.cpp:125] Batch 96, loss = 0.630802
I0122 19:57:12.988226 70379 caffe_interface.cpp:125] Batch 96, top-1 = 0.82
I0122 19:57:12.988229 70379 caffe_interface.cpp:125] Batch 96, top-5 = 0.96
I0122 19:57:12.997270 70379 caffe_interface.cpp:125] Batch 97, accuracy = 0.94
I0122 19:57:12.997278 70379 caffe_interface.cpp:125] Batch 97, loss = 0.233467
I0122 19:57:12.997282 70379 caffe_interface.cpp:125] Batch 97, top-1 = 0.94
I0122 19:57:12.997284 70379 caffe_interface.cpp:125] Batch 97, top-5 = 1
I0122 19:57:13.005167 70379 caffe_interface.cpp:125] Batch 98, accuracy = 0.88
I0122 19:57:13.005174 70379 caffe_interface.cpp:125] Batch 98, loss = 0.424106
I0122 19:57:13.005177 70379 caffe_interface.cpp:125] Batch 98, top-1 = 0.88
I0122 19:57:13.005180 70379 caffe_interface.cpp:125] Batch 98, top-5 = 1
I0122 19:57:13.013090 70379 caffe_interface.cpp:125] Batch 99, accuracy = 0.92
I0122 19:57:13.013099 70379 caffe_interface.cpp:125] Batch 99, loss = 0.59254
I0122 19:57:13.013103 70379 caffe_interface.cpp:125] Batch 99, top-1 = 0.92
I0122 19:57:13.013106 70379 caffe_interface.cpp:125] Batch 99, top-5 = 0.98
I0122 19:57:13.021042 70379 caffe_interface.cpp:125] Batch 100, accuracy = 0.92
I0122 19:57:13.021051 70379 caffe_interface.cpp:125] Batch 100, loss = 0.311744
I0122 19:57:13.021064 70379 caffe_interface.cpp:125] Batch 100, top-1 = 0.92
I0122 19:57:13.021068 70379 caffe_interface.cpp:125] Batch 100, top-5 = 1
I0122 19:57:13.030150 70379 caffe_interface.cpp:125] Batch 101, accuracy = 0.9
I0122 19:57:13.030159 70379 caffe_interface.cpp:125] Batch 101, loss = 0.338897
I0122 19:57:13.030162 70379 caffe_interface.cpp:125] Batch 101, top-1 = 0.9
I0122 19:57:13.030165 70379 caffe_interface.cpp:125] Batch 101, top-5 = 0.98
I0122 19:57:13.038116 70379 caffe_interface.cpp:125] Batch 102, accuracy = 0.76
I0122 19:57:13.038125 70379 caffe_interface.cpp:125] Batch 102, loss = 0.783485
I0122 19:57:13.038128 70379 caffe_interface.cpp:125] Batch 102, top-1 = 0.76
I0122 19:57:13.038132 70379 caffe_interface.cpp:125] Batch 102, top-5 = 1
I0122 19:57:13.046104 70379 caffe_interface.cpp:125] Batch 103, accuracy = 0.96
I0122 19:57:13.046113 70379 caffe_interface.cpp:125] Batch 103, loss = 0.231763
I0122 19:57:13.046118 70379 caffe_interface.cpp:125] Batch 103, top-1 = 0.96
I0122 19:57:13.046121 70379 caffe_interface.cpp:125] Batch 103, top-5 = 0.98
I0122 19:57:13.054082 70379 caffe_interface.cpp:125] Batch 104, accuracy = 0.86
I0122 19:57:13.054091 70379 caffe_interface.cpp:125] Batch 104, loss = 0.46532
I0122 19:57:13.054095 70379 caffe_interface.cpp:125] Batch 104, top-1 = 0.86
I0122 19:57:13.054098 70379 caffe_interface.cpp:125] Batch 104, top-5 = 1
I0122 19:57:13.063143 70379 caffe_interface.cpp:125] Batch 105, accuracy = 0.9
I0122 19:57:13.063151 70379 caffe_interface.cpp:125] Batch 105, loss = 0.365258
I0122 19:57:13.063154 70379 caffe_interface.cpp:125] Batch 105, top-1 = 0.9
I0122 19:57:13.063158 70379 caffe_interface.cpp:125] Batch 105, top-5 = 0.98
I0122 19:57:13.071094 70379 caffe_interface.cpp:125] Batch 106, accuracy = 0.92
I0122 19:57:13.071103 70379 caffe_interface.cpp:125] Batch 106, loss = 0.357143
I0122 19:57:13.071106 70379 caffe_interface.cpp:125] Batch 106, top-1 = 0.92
I0122 19:57:13.071110 70379 caffe_interface.cpp:125] Batch 106, top-5 = 1
I0122 19:57:13.079052 70379 caffe_interface.cpp:125] Batch 107, accuracy = 0.86
I0122 19:57:13.079061 70379 caffe_interface.cpp:125] Batch 107, loss = 0.484558
I0122 19:57:13.079064 70379 caffe_interface.cpp:125] Batch 107, top-1 = 0.86
I0122 19:57:13.079067 70379 caffe_interface.cpp:125] Batch 107, top-5 = 1
I0122 19:57:13.087018 70379 caffe_interface.cpp:125] Batch 108, accuracy = 0.8
I0122 19:57:13.087028 70379 caffe_interface.cpp:125] Batch 108, loss = 0.503895
I0122 19:57:13.087030 70379 caffe_interface.cpp:125] Batch 108, top-1 = 0.8
I0122 19:57:13.087034 70379 caffe_interface.cpp:125] Batch 108, top-5 = 1
I0122 19:57:13.096071 70379 caffe_interface.cpp:125] Batch 109, accuracy = 0.9
I0122 19:57:13.096079 70379 caffe_interface.cpp:125] Batch 109, loss = 0.492178
I0122 19:57:13.096082 70379 caffe_interface.cpp:125] Batch 109, top-1 = 0.9
I0122 19:57:13.096086 70379 caffe_interface.cpp:125] Batch 109, top-5 = 0.98
I0122 19:57:13.104039 70379 caffe_interface.cpp:125] Batch 110, accuracy = 0.9
I0122 19:57:13.104048 70379 caffe_interface.cpp:125] Batch 110, loss = 0.382096
I0122 19:57:13.104051 70379 caffe_interface.cpp:125] Batch 110, top-1 = 0.9
I0122 19:57:13.104054 70379 caffe_interface.cpp:125] Batch 110, top-5 = 1
I0122 19:57:13.112035 70379 caffe_interface.cpp:125] Batch 111, accuracy = 0.84
I0122 19:57:13.112044 70379 caffe_interface.cpp:125] Batch 111, loss = 0.563829
I0122 19:57:13.112047 70379 caffe_interface.cpp:125] Batch 111, top-1 = 0.84
I0122 19:57:13.112051 70379 caffe_interface.cpp:125] Batch 111, top-5 = 1
I0122 19:57:13.119997 70379 caffe_interface.cpp:125] Batch 112, accuracy = 0.94
I0122 19:57:13.120007 70379 caffe_interface.cpp:125] Batch 112, loss = 0.158308
I0122 19:57:13.120009 70379 caffe_interface.cpp:125] Batch 112, top-1 = 0.94
I0122 19:57:13.120013 70379 caffe_interface.cpp:125] Batch 112, top-5 = 1
I0122 19:57:13.129041 70379 caffe_interface.cpp:125] Batch 113, accuracy = 0.88
I0122 19:57:13.129050 70379 caffe_interface.cpp:125] Batch 113, loss = 0.573429
I0122 19:57:13.129053 70379 caffe_interface.cpp:125] Batch 113, top-1 = 0.88
I0122 19:57:13.129067 70379 caffe_interface.cpp:125] Batch 113, top-5 = 0.98
I0122 19:57:13.136998 70379 caffe_interface.cpp:125] Batch 114, accuracy = 0.84
I0122 19:57:13.137007 70379 caffe_interface.cpp:125] Batch 114, loss = 0.598748
I0122 19:57:13.137010 70379 caffe_interface.cpp:125] Batch 114, top-1 = 0.84
I0122 19:57:13.137014 70379 caffe_interface.cpp:125] Batch 114, top-5 = 1
I0122 19:57:13.144959 70379 caffe_interface.cpp:125] Batch 115, accuracy = 0.92
I0122 19:57:13.144970 70379 caffe_interface.cpp:125] Batch 115, loss = 0.165026
I0122 19:57:13.144973 70379 caffe_interface.cpp:125] Batch 115, top-1 = 0.92
I0122 19:57:13.144976 70379 caffe_interface.cpp:125] Batch 115, top-5 = 1
I0122 19:57:13.152938 70379 caffe_interface.cpp:125] Batch 116, accuracy = 0.9
I0122 19:57:13.152948 70379 caffe_interface.cpp:125] Batch 116, loss = 0.355756
I0122 19:57:13.152951 70379 caffe_interface.cpp:125] Batch 116, top-1 = 0.9
I0122 19:57:13.152954 70379 caffe_interface.cpp:125] Batch 116, top-5 = 1
I0122 19:57:13.161972 70379 caffe_interface.cpp:125] Batch 117, accuracy = 0.82
I0122 19:57:13.161981 70379 caffe_interface.cpp:125] Batch 117, loss = 0.466023
I0122 19:57:13.161984 70379 caffe_interface.cpp:125] Batch 117, top-1 = 0.82
I0122 19:57:13.161988 70379 caffe_interface.cpp:125] Batch 117, top-5 = 1
I0122 19:57:13.169946 70379 caffe_interface.cpp:125] Batch 118, accuracy = 0.94
I0122 19:57:13.169956 70379 caffe_interface.cpp:125] Batch 118, loss = 0.22437
I0122 19:57:13.169960 70379 caffe_interface.cpp:125] Batch 118, top-1 = 0.94
I0122 19:57:13.169963 70379 caffe_interface.cpp:125] Batch 118, top-5 = 1
I0122 19:57:13.177898 70379 caffe_interface.cpp:125] Batch 119, accuracy = 0.84
I0122 19:57:13.177914 70379 caffe_interface.cpp:125] Batch 119, loss = 0.739264
I0122 19:57:13.177917 70379 caffe_interface.cpp:125] Batch 119, top-1 = 0.84
I0122 19:57:13.177922 70379 caffe_interface.cpp:125] Batch 119, top-5 = 1
I0122 19:57:13.185895 70379 caffe_interface.cpp:125] Batch 120, accuracy = 0.88
I0122 19:57:13.185909 70379 caffe_interface.cpp:125] Batch 120, loss = 0.585749
I0122 19:57:13.185914 70379 caffe_interface.cpp:125] Batch 120, top-1 = 0.88
I0122 19:57:13.185916 70379 caffe_interface.cpp:125] Batch 120, top-5 = 1
I0122 19:57:13.194923 70379 caffe_interface.cpp:125] Batch 121, accuracy = 0.82
I0122 19:57:13.194932 70379 caffe_interface.cpp:125] Batch 121, loss = 0.349639
I0122 19:57:13.194934 70379 caffe_interface.cpp:125] Batch 121, top-1 = 0.82
I0122 19:57:13.194937 70379 caffe_interface.cpp:125] Batch 121, top-5 = 1
I0122 19:57:13.202896 70379 caffe_interface.cpp:125] Batch 122, accuracy = 0.96
I0122 19:57:13.202906 70379 caffe_interface.cpp:125] Batch 122, loss = 0.252282
I0122 19:57:13.202910 70379 caffe_interface.cpp:125] Batch 122, top-1 = 0.96
I0122 19:57:13.202913 70379 caffe_interface.cpp:125] Batch 122, top-5 = 1
I0122 19:57:13.210866 70379 caffe_interface.cpp:125] Batch 123, accuracy = 0.86
I0122 19:57:13.210875 70379 caffe_interface.cpp:125] Batch 123, loss = 0.357481
I0122 19:57:13.210878 70379 caffe_interface.cpp:125] Batch 123, top-1 = 0.86
I0122 19:57:13.210881 70379 caffe_interface.cpp:125] Batch 123, top-5 = 1
I0122 19:57:13.218842 70379 caffe_interface.cpp:125] Batch 124, accuracy = 0.92
I0122 19:57:13.218852 70379 caffe_interface.cpp:125] Batch 124, loss = 0.218389
I0122 19:57:13.218856 70379 caffe_interface.cpp:125] Batch 124, top-1 = 0.92
I0122 19:57:13.218859 70379 caffe_interface.cpp:125] Batch 124, top-5 = 1
I0122 19:57:13.227865 70379 caffe_interface.cpp:125] Batch 125, accuracy = 0.86
I0122 19:57:13.227874 70379 caffe_interface.cpp:125] Batch 125, loss = 0.588132
I0122 19:57:13.227876 70379 caffe_interface.cpp:125] Batch 125, top-1 = 0.86
I0122 19:57:13.227880 70379 caffe_interface.cpp:125] Batch 125, top-5 = 1
I0122 19:57:13.235805 70379 caffe_interface.cpp:125] Batch 126, accuracy = 0.82
I0122 19:57:13.235815 70379 caffe_interface.cpp:125] Batch 126, loss = 0.669092
I0122 19:57:13.235817 70379 caffe_interface.cpp:125] Batch 126, top-1 = 0.82
I0122 19:57:13.235821 70379 caffe_interface.cpp:125] Batch 126, top-5 = 1
I0122 19:57:13.243773 70379 caffe_interface.cpp:125] Batch 127, accuracy = 0.88
I0122 19:57:13.243783 70379 caffe_interface.cpp:125] Batch 127, loss = 0.581537
I0122 19:57:13.243786 70379 caffe_interface.cpp:125] Batch 127, top-1 = 0.88
I0122 19:57:13.243790 70379 caffe_interface.cpp:125] Batch 127, top-5 = 1
I0122 19:57:13.251704 70379 caffe_interface.cpp:125] Batch 128, accuracy = 0.96
I0122 19:57:13.251713 70379 caffe_interface.cpp:125] Batch 128, loss = 0.202073
I0122 19:57:13.251716 70379 caffe_interface.cpp:125] Batch 128, top-1 = 0.96
I0122 19:57:13.251720 70379 caffe_interface.cpp:125] Batch 128, top-5 = 1
I0122 19:57:13.260746 70379 caffe_interface.cpp:125] Batch 129, accuracy = 0.78
I0122 19:57:13.260756 70379 caffe_interface.cpp:125] Batch 129, loss = 0.572731
I0122 19:57:13.260759 70379 caffe_interface.cpp:125] Batch 129, top-1 = 0.78
I0122 19:57:13.260762 70379 caffe_interface.cpp:125] Batch 129, top-5 = 1
I0122 19:57:13.268685 70379 caffe_interface.cpp:125] Batch 130, accuracy = 0.82
I0122 19:57:13.268695 70379 caffe_interface.cpp:125] Batch 130, loss = 0.781768
I0122 19:57:13.268698 70379 caffe_interface.cpp:125] Batch 130, top-1 = 0.82
I0122 19:57:13.268702 70379 caffe_interface.cpp:125] Batch 130, top-5 = 1
I0122 19:57:13.276635 70379 caffe_interface.cpp:125] Batch 131, accuracy = 0.84
I0122 19:57:13.276645 70379 caffe_interface.cpp:125] Batch 131, loss = 0.484112
I0122 19:57:13.276648 70379 caffe_interface.cpp:125] Batch 131, top-1 = 0.84
I0122 19:57:13.276651 70379 caffe_interface.cpp:125] Batch 131, top-5 = 0.98
I0122 19:57:13.284584 70379 caffe_interface.cpp:125] Batch 132, accuracy = 0.8
I0122 19:57:13.284593 70379 caffe_interface.cpp:125] Batch 132, loss = 0.825889
I0122 19:57:13.284596 70379 caffe_interface.cpp:125] Batch 132, top-1 = 0.8
I0122 19:57:13.284600 70379 caffe_interface.cpp:125] Batch 132, top-5 = 0.98
I0122 19:57:13.293601 70379 caffe_interface.cpp:125] Batch 133, accuracy = 0.88
I0122 19:57:13.293608 70379 caffe_interface.cpp:125] Batch 133, loss = 0.370497
I0122 19:57:13.293612 70379 caffe_interface.cpp:125] Batch 133, top-1 = 0.88
I0122 19:57:13.293614 70379 caffe_interface.cpp:125] Batch 133, top-5 = 0.98
I0122 19:57:13.301561 70379 caffe_interface.cpp:125] Batch 134, accuracy = 0.84
I0122 19:57:13.301571 70379 caffe_interface.cpp:125] Batch 134, loss = 0.573922
I0122 19:57:13.301574 70379 caffe_interface.cpp:125] Batch 134, top-1 = 0.84
I0122 19:57:13.301578 70379 caffe_interface.cpp:125] Batch 134, top-5 = 1
I0122 19:57:13.309520 70379 caffe_interface.cpp:125] Batch 135, accuracy = 0.84
I0122 19:57:13.309530 70379 caffe_interface.cpp:125] Batch 135, loss = 0.832727
I0122 19:57:13.309532 70379 caffe_interface.cpp:125] Batch 135, top-1 = 0.84
I0122 19:57:13.309535 70379 caffe_interface.cpp:125] Batch 135, top-5 = 0.96
I0122 19:57:13.317497 70379 caffe_interface.cpp:125] Batch 136, accuracy = 0.92
I0122 19:57:13.317507 70379 caffe_interface.cpp:125] Batch 136, loss = 0.261136
I0122 19:57:13.317510 70379 caffe_interface.cpp:125] Batch 136, top-1 = 0.92
I0122 19:57:13.317514 70379 caffe_interface.cpp:125] Batch 136, top-5 = 1
I0122 19:57:13.326550 70379 caffe_interface.cpp:125] Batch 137, accuracy = 0.96
I0122 19:57:13.326558 70379 caffe_interface.cpp:125] Batch 137, loss = 0.269635
I0122 19:57:13.326561 70379 caffe_interface.cpp:125] Batch 137, top-1 = 0.96
I0122 19:57:13.326565 70379 caffe_interface.cpp:125] Batch 137, top-5 = 1
I0122 19:57:13.334532 70379 caffe_interface.cpp:125] Batch 138, accuracy = 0.86
I0122 19:57:13.334542 70379 caffe_interface.cpp:125] Batch 138, loss = 0.501607
I0122 19:57:13.334544 70379 caffe_interface.cpp:125] Batch 138, top-1 = 0.86
I0122 19:57:13.334547 70379 caffe_interface.cpp:125] Batch 138, top-5 = 1
I0122 19:57:13.342494 70379 caffe_interface.cpp:125] Batch 139, accuracy = 0.8
I0122 19:57:13.342506 70379 caffe_interface.cpp:125] Batch 139, loss = 0.796975
I0122 19:57:13.342509 70379 caffe_interface.cpp:125] Batch 139, top-1 = 0.8
I0122 19:57:13.342514 70379 caffe_interface.cpp:125] Batch 139, top-5 = 1
I0122 19:57:13.350478 70379 caffe_interface.cpp:125] Batch 140, accuracy = 0.82
I0122 19:57:13.350488 70379 caffe_interface.cpp:125] Batch 140, loss = 0.677645
I0122 19:57:13.350492 70379 caffe_interface.cpp:125] Batch 140, top-1 = 0.82
I0122 19:57:13.350495 70379 caffe_interface.cpp:125] Batch 140, top-5 = 1
I0122 19:57:13.359524 70379 caffe_interface.cpp:125] Batch 141, accuracy = 0.9
I0122 19:57:13.359534 70379 caffe_interface.cpp:125] Batch 141, loss = 0.347164
I0122 19:57:13.359537 70379 caffe_interface.cpp:125] Batch 141, top-1 = 0.9
I0122 19:57:13.359540 70379 caffe_interface.cpp:125] Batch 141, top-5 = 1
I0122 19:57:13.367480 70379 caffe_interface.cpp:125] Batch 142, accuracy = 0.92
I0122 19:57:13.367489 70379 caffe_interface.cpp:125] Batch 142, loss = 0.161492
I0122 19:57:13.367493 70379 caffe_interface.cpp:125] Batch 142, top-1 = 0.92
I0122 19:57:13.367496 70379 caffe_interface.cpp:125] Batch 142, top-5 = 1
I0122 19:57:13.375445 70379 caffe_interface.cpp:125] Batch 143, accuracy = 0.92
I0122 19:57:13.375457 70379 caffe_interface.cpp:125] Batch 143, loss = 0.330266
I0122 19:57:13.375459 70379 caffe_interface.cpp:125] Batch 143, top-1 = 0.92
I0122 19:57:13.375463 70379 caffe_interface.cpp:125] Batch 143, top-5 = 1
I0122 19:57:13.383420 70379 caffe_interface.cpp:125] Batch 144, accuracy = 0.84
I0122 19:57:13.383430 70379 caffe_interface.cpp:125] Batch 144, loss = 0.440418
I0122 19:57:13.383435 70379 caffe_interface.cpp:125] Batch 144, top-1 = 0.84
I0122 19:57:13.383437 70379 caffe_interface.cpp:125] Batch 144, top-5 = 1
I0122 19:57:13.392467 70379 caffe_interface.cpp:125] Batch 145, accuracy = 0.84
I0122 19:57:13.392478 70379 caffe_interface.cpp:125] Batch 145, loss = 0.408032
I0122 19:57:13.392482 70379 caffe_interface.cpp:125] Batch 145, top-1 = 0.84
I0122 19:57:13.392485 70379 caffe_interface.cpp:125] Batch 145, top-5 = 1
I0122 19:57:13.400439 70379 caffe_interface.cpp:125] Batch 146, accuracy = 0.86
I0122 19:57:13.400449 70379 caffe_interface.cpp:125] Batch 146, loss = 0.579714
I0122 19:57:13.400451 70379 caffe_interface.cpp:125] Batch 146, top-1 = 0.86
I0122 19:57:13.400454 70379 caffe_interface.cpp:125] Batch 146, top-5 = 1
I0122 19:57:13.408411 70379 caffe_interface.cpp:125] Batch 147, accuracy = 0.84
I0122 19:57:13.408421 70379 caffe_interface.cpp:125] Batch 147, loss = 0.335724
I0122 19:57:13.408426 70379 caffe_interface.cpp:125] Batch 147, top-1 = 0.84
I0122 19:57:13.408428 70379 caffe_interface.cpp:125] Batch 147, top-5 = 1
I0122 19:57:13.416355 70379 caffe_interface.cpp:125] Batch 148, accuracy = 0.92
I0122 19:57:13.416364 70379 caffe_interface.cpp:125] Batch 148, loss = 0.336717
I0122 19:57:13.416368 70379 caffe_interface.cpp:125] Batch 148, top-1 = 0.92
I0122 19:57:13.416371 70379 caffe_interface.cpp:125] Batch 148, top-5 = 0.98
I0122 19:57:13.425381 70379 caffe_interface.cpp:125] Batch 149, accuracy = 0.92
I0122 19:57:13.425390 70379 caffe_interface.cpp:125] Batch 149, loss = 0.197549
I0122 19:57:13.425395 70379 caffe_interface.cpp:125] Batch 149, top-1 = 0.92
I0122 19:57:13.425398 70379 caffe_interface.cpp:125] Batch 149, top-5 = 1
I0122 19:57:13.433342 70379 caffe_interface.cpp:125] Batch 150, accuracy = 0.9
I0122 19:57:13.433352 70379 caffe_interface.cpp:125] Batch 150, loss = 0.243541
I0122 19:57:13.433357 70379 caffe_interface.cpp:125] Batch 150, top-1 = 0.9
I0122 19:57:13.433359 70379 caffe_interface.cpp:125] Batch 150, top-5 = 1
I0122 19:57:13.441294 70379 caffe_interface.cpp:125] Batch 151, accuracy = 0.82
I0122 19:57:13.441303 70379 caffe_interface.cpp:125] Batch 151, loss = 0.797064
I0122 19:57:13.441308 70379 caffe_interface.cpp:125] Batch 151, top-1 = 0.82
I0122 19:57:13.441311 70379 caffe_interface.cpp:125] Batch 151, top-5 = 1
I0122 19:57:13.449252 70379 caffe_interface.cpp:125] Batch 152, accuracy = 0.88
I0122 19:57:13.449261 70379 caffe_interface.cpp:125] Batch 152, loss = 0.340964
I0122 19:57:13.449265 70379 caffe_interface.cpp:125] Batch 152, top-1 = 0.88
I0122 19:57:13.449268 70379 caffe_interface.cpp:125] Batch 152, top-5 = 1
I0122 19:57:13.458211 70379 caffe_interface.cpp:125] Batch 153, accuracy = 0.92
I0122 19:57:13.458231 70379 caffe_interface.cpp:125] Batch 153, loss = 0.292459
I0122 19:57:13.458235 70379 caffe_interface.cpp:125] Batch 153, top-1 = 0.92
I0122 19:57:13.458240 70379 caffe_interface.cpp:125] Batch 153, top-5 = 1
I0122 19:57:13.466181 70379 caffe_interface.cpp:125] Batch 154, accuracy = 0.9
I0122 19:57:13.466192 70379 caffe_interface.cpp:125] Batch 154, loss = 0.298821
I0122 19:57:13.466194 70379 caffe_interface.cpp:125] Batch 154, top-1 = 0.9
I0122 19:57:13.466197 70379 caffe_interface.cpp:125] Batch 154, top-5 = 1
I0122 19:57:13.474120 70379 caffe_interface.cpp:125] Batch 155, accuracy = 0.9
I0122 19:57:13.474129 70379 caffe_interface.cpp:125] Batch 155, loss = 0.33541
I0122 19:57:13.474133 70379 caffe_interface.cpp:125] Batch 155, top-1 = 0.9
I0122 19:57:13.474138 70379 caffe_interface.cpp:125] Batch 155, top-5 = 1
I0122 19:57:13.482086 70379 caffe_interface.cpp:125] Batch 156, accuracy = 0.88
I0122 19:57:13.482095 70379 caffe_interface.cpp:125] Batch 156, loss = 0.371434
I0122 19:57:13.482098 70379 caffe_interface.cpp:125] Batch 156, top-1 = 0.88
I0122 19:57:13.482102 70379 caffe_interface.cpp:125] Batch 156, top-5 = 0.98
I0122 19:57:13.490948 70379 caffe_interface.cpp:125] Batch 157, accuracy = 0.94
I0122 19:57:13.490957 70379 caffe_interface.cpp:125] Batch 157, loss = 0.319375
I0122 19:57:13.490962 70379 caffe_interface.cpp:125] Batch 157, top-1 = 0.94
I0122 19:57:13.490964 70379 caffe_interface.cpp:125] Batch 157, top-5 = 0.98
I0122 19:57:13.498919 70379 caffe_interface.cpp:125] Batch 158, accuracy = 0.86
I0122 19:57:13.498929 70379 caffe_interface.cpp:125] Batch 158, loss = 0.537644
I0122 19:57:13.498931 70379 caffe_interface.cpp:125] Batch 158, top-1 = 0.86
I0122 19:57:13.498934 70379 caffe_interface.cpp:125] Batch 158, top-5 = 1
I0122 19:57:13.506878 70379 caffe_interface.cpp:125] Batch 159, accuracy = 0.84
I0122 19:57:13.506887 70379 caffe_interface.cpp:125] Batch 159, loss = 0.539063
I0122 19:57:13.506891 70379 caffe_interface.cpp:125] Batch 159, top-1 = 0.84
I0122 19:57:13.506894 70379 caffe_interface.cpp:125] Batch 159, top-5 = 1
I0122 19:57:13.514847 70379 caffe_interface.cpp:125] Batch 160, accuracy = 0.9
I0122 19:57:13.514856 70379 caffe_interface.cpp:125] Batch 160, loss = 0.323434
I0122 19:57:13.514859 70379 caffe_interface.cpp:125] Batch 160, top-1 = 0.9
I0122 19:57:13.514863 70379 caffe_interface.cpp:125] Batch 160, top-5 = 0.98
I0122 19:57:13.523728 70379 caffe_interface.cpp:125] Batch 161, accuracy = 0.9
I0122 19:57:13.523738 70379 caffe_interface.cpp:125] Batch 161, loss = 0.630195
I0122 19:57:13.523742 70379 caffe_interface.cpp:125] Batch 161, top-1 = 0.9
I0122 19:57:13.523746 70379 caffe_interface.cpp:125] Batch 161, top-5 = 1
I0122 19:57:13.531677 70379 caffe_interface.cpp:125] Batch 162, accuracy = 0.84
I0122 19:57:13.531687 70379 caffe_interface.cpp:125] Batch 162, loss = 0.596586
I0122 19:57:13.531690 70379 caffe_interface.cpp:125] Batch 162, top-1 = 0.84
I0122 19:57:13.531694 70379 caffe_interface.cpp:125] Batch 162, top-5 = 1
I0122 19:57:13.539654 70379 caffe_interface.cpp:125] Batch 163, accuracy = 0.86
I0122 19:57:13.539662 70379 caffe_interface.cpp:125] Batch 163, loss = 0.401257
I0122 19:57:13.539665 70379 caffe_interface.cpp:125] Batch 163, top-1 = 0.86
I0122 19:57:13.539669 70379 caffe_interface.cpp:125] Batch 163, top-5 = 1
I0122 19:57:13.547636 70379 caffe_interface.cpp:125] Batch 164, accuracy = 0.76
I0122 19:57:13.547646 70379 caffe_interface.cpp:125] Batch 164, loss = 0.559396
I0122 19:57:13.547649 70379 caffe_interface.cpp:125] Batch 164, top-1 = 0.76
I0122 19:57:13.547653 70379 caffe_interface.cpp:125] Batch 164, top-5 = 1
I0122 19:57:13.556478 70379 caffe_interface.cpp:125] Batch 165, accuracy = 0.9
I0122 19:57:13.556488 70379 caffe_interface.cpp:125] Batch 165, loss = 0.445832
I0122 19:57:13.556491 70379 caffe_interface.cpp:125] Batch 165, top-1 = 0.9
I0122 19:57:13.556494 70379 caffe_interface.cpp:125] Batch 165, top-5 = 1
I0122 19:57:13.564457 70379 caffe_interface.cpp:125] Batch 166, accuracy = 0.9
I0122 19:57:13.564466 70379 caffe_interface.cpp:125] Batch 166, loss = 0.314074
I0122 19:57:13.564479 70379 caffe_interface.cpp:125] Batch 166, top-1 = 0.9
I0122 19:57:13.564482 70379 caffe_interface.cpp:125] Batch 166, top-5 = 1
I0122 19:57:13.572438 70379 caffe_interface.cpp:125] Batch 167, accuracy = 0.86
I0122 19:57:13.572448 70379 caffe_interface.cpp:125] Batch 167, loss = 0.523389
I0122 19:57:13.572451 70379 caffe_interface.cpp:125] Batch 167, top-1 = 0.86
I0122 19:57:13.572454 70379 caffe_interface.cpp:125] Batch 167, top-5 = 1
I0122 19:57:13.580399 70379 caffe_interface.cpp:125] Batch 168, accuracy = 0.94
I0122 19:57:13.580408 70379 caffe_interface.cpp:125] Batch 168, loss = 0.177692
I0122 19:57:13.580411 70379 caffe_interface.cpp:125] Batch 168, top-1 = 0.94
I0122 19:57:13.580415 70379 caffe_interface.cpp:125] Batch 168, top-5 = 1
I0122 19:57:13.589262 70379 caffe_interface.cpp:125] Batch 169, accuracy = 0.9
I0122 19:57:13.589272 70379 caffe_interface.cpp:125] Batch 169, loss = 0.409686
I0122 19:57:13.589277 70379 caffe_interface.cpp:125] Batch 169, top-1 = 0.9
I0122 19:57:13.589280 70379 caffe_interface.cpp:125] Batch 169, top-5 = 0.98
I0122 19:57:13.597206 70379 caffe_interface.cpp:125] Batch 170, accuracy = 0.96
I0122 19:57:13.597216 70379 caffe_interface.cpp:125] Batch 170, loss = 0.138809
I0122 19:57:13.597219 70379 caffe_interface.cpp:125] Batch 170, top-1 = 0.96
I0122 19:57:13.597223 70379 caffe_interface.cpp:125] Batch 170, top-5 = 1
I0122 19:57:13.605165 70379 caffe_interface.cpp:125] Batch 171, accuracy = 0.88
I0122 19:57:13.605175 70379 caffe_interface.cpp:125] Batch 171, loss = 0.257038
I0122 19:57:13.605178 70379 caffe_interface.cpp:125] Batch 171, top-1 = 0.88
I0122 19:57:13.605181 70379 caffe_interface.cpp:125] Batch 171, top-5 = 0.98
I0122 19:57:13.613126 70379 caffe_interface.cpp:125] Batch 172, accuracy = 0.84
I0122 19:57:13.613134 70379 caffe_interface.cpp:125] Batch 172, loss = 0.467247
I0122 19:57:13.613138 70379 caffe_interface.cpp:125] Batch 172, top-1 = 0.84
I0122 19:57:13.613142 70379 caffe_interface.cpp:125] Batch 172, top-5 = 0.98
I0122 19:57:13.622035 70379 caffe_interface.cpp:125] Batch 173, accuracy = 0.98
I0122 19:57:13.622043 70379 caffe_interface.cpp:125] Batch 173, loss = 0.197137
I0122 19:57:13.622046 70379 caffe_interface.cpp:125] Batch 173, top-1 = 0.98
I0122 19:57:13.622051 70379 caffe_interface.cpp:125] Batch 173, top-5 = 1
I0122 19:57:13.630013 70379 caffe_interface.cpp:125] Batch 174, accuracy = 0.84
I0122 19:57:13.630023 70379 caffe_interface.cpp:125] Batch 174, loss = 0.459594
I0122 19:57:13.630028 70379 caffe_interface.cpp:125] Batch 174, top-1 = 0.84
I0122 19:57:13.630030 70379 caffe_interface.cpp:125] Batch 174, top-5 = 1
I0122 19:57:13.637961 70379 caffe_interface.cpp:125] Batch 175, accuracy = 0.84
I0122 19:57:13.637970 70379 caffe_interface.cpp:125] Batch 175, loss = 0.605152
I0122 19:57:13.637975 70379 caffe_interface.cpp:125] Batch 175, top-1 = 0.84
I0122 19:57:13.637979 70379 caffe_interface.cpp:125] Batch 175, top-5 = 1
I0122 19:57:13.645926 70379 caffe_interface.cpp:125] Batch 176, accuracy = 0.82
I0122 19:57:13.645936 70379 caffe_interface.cpp:125] Batch 176, loss = 1.05688
I0122 19:57:13.645939 70379 caffe_interface.cpp:125] Batch 176, top-1 = 0.82
I0122 19:57:13.645943 70379 caffe_interface.cpp:125] Batch 176, top-5 = 0.96
I0122 19:57:13.653879 70379 caffe_interface.cpp:125] Batch 177, accuracy = 0.9
I0122 19:57:13.653889 70379 caffe_interface.cpp:125] Batch 177, loss = 0.414969
I0122 19:57:13.653892 70379 caffe_interface.cpp:125] Batch 177, top-1 = 0.9
I0122 19:57:13.653897 70379 caffe_interface.cpp:125] Batch 177, top-5 = 1
I0122 19:57:13.662842 70379 caffe_interface.cpp:125] Batch 178, accuracy = 0.94
I0122 19:57:13.662850 70379 caffe_interface.cpp:125] Batch 178, loss = 0.167385
I0122 19:57:13.662853 70379 caffe_interface.cpp:125] Batch 178, top-1 = 0.94
I0122 19:57:13.662856 70379 caffe_interface.cpp:125] Batch 178, top-5 = 1
I0122 19:57:13.670825 70379 caffe_interface.cpp:125] Batch 179, accuracy = 0.9
I0122 19:57:13.670835 70379 caffe_interface.cpp:125] Batch 179, loss = 0.311309
I0122 19:57:13.670847 70379 caffe_interface.cpp:125] Batch 179, top-1 = 0.9
I0122 19:57:13.670851 70379 caffe_interface.cpp:125] Batch 179, top-5 = 1
I0122 19:57:13.670855 70379 caffe_interface.cpp:130] Loss: 0.407635
I0122 19:57:13.670858 70379 caffe_interface.cpp:142] accuracy = 0.884888
I0122 19:57:13.670866 70379 caffe_interface.cpp:142] loss = 0.407635 (* 1 = 0.407635 loss)
I0122 19:57:13.670877 70379 caffe_interface.cpp:142] top-1 = 0.884888
I0122 19:57:13.670881 70379 caffe_interface.cpp:142] top-5 = 0.994445
I0122 19:57:13.832850 70379 pruning_runner.cpp:306] pruning done, output model: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/sparse.caffemodel
I0122 19:57:13.832870 70379 pruning_runner.cpp:320] summary of REGULAR compression with rate 0.4:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.897777736    | 0.88488847     | -0.012889266   |
+-------------------------------------------------------------------+
| Weights        | 1652899        | 1008277        | -38.9994812%   |
+-------------------------------------------------------------------+
| Operations     | 533938176      | 322805376      | -39.5425568%   |
+-------------------------------------------------------------------+
To fine-tune the compressed model, please run:
deephi_compress finetune -config cifar10/deephi/miniGoogleNet/pruning/config4.prototxt
## fine-tuning: fourth run
$PRUNE_ROOT/deephi_compress finetune -config ${WORK_DIR}/config4.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_finetune4_miniGoogleNet.txt
I0122 19:57:14.074530 70718 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt
I0122 19:57:14.255364 70718 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 19:57:14.255919 70718 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24778440704, dev_info[0]: total=25620447232 free=24778440704
I0122 19:57:14.255933 70718 caffe_interface.cpp:493] Using GPUs 0
I0122 19:57:14.256209 70718 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 19:57:14.837584 70718 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt"
type: "SGD"
I0122 19:57:14.837694 70718 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt
I0122 19:57:14.838297 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 19:57:14.838327 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 19:57:14.838330 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 19:57:14.838333 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 19:57:14.838850 70718 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 19:57:14.839166 70718 layer_factory.hpp:77] Creating layer data
I0122 19:57:14.839268 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.840065 70718 net.cpp:94] Creating Layer data
I0122 19:57:14.840076 70718 net.cpp:409] data -> data
I0122 19:57:14.840088 70718 net.cpp:409] data -> label
I0122 19:57:14.841506 70757 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 19:57:14.841554 70757 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 19:57:14.841626 70718 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 19:57:14.841704 70718 data_layer.cpp:83] output data size: 128,3,32,32
I0122 19:57:14.849411 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.849478 70718 net.cpp:144] Setting up data
I0122 19:57:14.849486 70718 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 19:57:14.849493 70718 net.cpp:151] Top shape: 128 (128)
I0122 19:57:14.849495 70718 net.cpp:159] Memory required for data: 1573376
I0122 19:57:14.849500 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:57:14.849516 70718 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:57:14.849524 70718 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:57:14.849544 70718 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:57:14.851593 70718 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:57:14.851608 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.851611 70718 net.cpp:159] Memory required for data: 51905024
I0122 19:57:14.851644 70718 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:57:14.851655 70718 net.cpp:94] Creating Layer conv1/bn1
I0122 19:57:14.851658 70718 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:57:14.851667 70718 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.852416 70718 net.cpp:144] Setting up conv1/bn1
I0122 19:57:14.852427 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852430 70718 net.cpp:159] Memory required for data: 102236672
I0122 19:57:14.852445 70718 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:57:14.852455 70718 net.cpp:94] Creating Layer conv1/relu1
I0122 19:57:14.852458 70718 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:57:14.852464 70718 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.852478 70718 net.cpp:144] Setting up conv1/relu1
I0122 19:57:14.852494 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852497 70718 net.cpp:159] Memory required for data: 152568320
I0122 19:57:14.852501 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.852510 70718 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.852516 70718 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:57:14.852522 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.852530 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.852571 70718 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.852579 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852584 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852587 70718 net.cpp:159] Memory required for data: 253231616
I0122 19:57:14.852592 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:57:14.852602 70718 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:57:14.852607 70718 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.852613 70718 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:57:14.853647 70718 net.cpp:144] Setting up inception_2a/1x1
I0122 19:57:14.853660 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.853663 70718 net.cpp:159] Memory required for data: 270008832
I0122 19:57:14.853672 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:57:14.853683 70718 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:57:14.853688 70718 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:57:14.853694 70718 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.854457 70718 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:57:14.854466 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.854468 70718 net.cpp:159] Memory required for data: 286786048
I0122 19:57:14.854477 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:57:14.854483 70718 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:57:14.854488 70718 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:57:14.854495 70718 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.854516 70718 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:57:14.854521 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.854524 70718 net.cpp:159] Memory required for data: 303563264
I0122 19:57:14.854527 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:57:14.854539 70718 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:57:14.854545 70718 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.854554 70718 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:57:14.855700 70718 net.cpp:144] Setting up inception_2a/3x3
I0122 19:57:14.855711 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.855715 70718 net.cpp:159] Memory required for data: 320340480
I0122 19:57:14.855721 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:57:14.855729 70718 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:57:14.855732 70718 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:57:14.855741 70718 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.856446 70718 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:57:14.856453 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.856457 70718 net.cpp:159] Memory required for data: 337117696
I0122 19:57:14.856472 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:57:14.856478 70718 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:57:14.856482 70718 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:57:14.856487 70718 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.856518 70718 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:57:14.856523 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.856525 70718 net.cpp:159] Memory required for data: 353894912
I0122 19:57:14.856528 70718 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:57:14.856534 70718 net.cpp:94] Creating Layer inception_2a/output
I0122 19:57:14.856540 70718 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:57:14.856545 70718 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:57:14.856552 70718 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:57:14.856580 70718 net.cpp:144] Setting up inception_2a/output
I0122 19:57:14.856590 70718 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:57:14.856593 70718 net.cpp:159] Memory required for data: 387449344
I0122 19:57:14.856597 70718 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.856602 70718 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.856606 70718 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:57:14.856611 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.856618 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.856657 70718 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.856667 70718 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:57:14.856673 70718 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:57:14.856674 70718 net.cpp:159] Memory required for data: 454558208
I0122 19:57:14.856678 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:57:14.856688 70718 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:57:14.856690 70718 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.856695 70718 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:57:14.856942 70718 net.cpp:144] Setting up inception_3a/1x1
I0122 19:57:14.856951 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.856954 70718 net.cpp:159] Memory required for data: 471335424
I0122 19:57:14.856959 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:57:14.856976 70718 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:57:14.856982 70718 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:57:14.857007 70718 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.857722 70718 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:57:14.857729 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.857733 70718 net.cpp:159] Memory required for data: 488112640
I0122 19:57:14.857741 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:57:14.857746 70718 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:57:14.857749 70718 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:57:14.857754 70718 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.857762 70718 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:57:14.857769 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.857772 70718 net.cpp:159] Memory required for data: 504889856
I0122 19:57:14.857776 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:57:14.857795 70718 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:57:14.857801 70718 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.857810 70718 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:57:14.858260 70718 net.cpp:144] Setting up inception_3a/3x3
I0122 19:57:14.858269 70718 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:57:14.858273 70718 net.cpp:159] Memory required for data: 530055680
I0122 19:57:14.858297 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:57:14.858306 70718 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:57:14.858311 70718 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:57:14.858320 70718 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.859016 70718 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:57:14.859025 70718 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:57:14.859027 70718 net.cpp:159] Memory required for data: 555221504
I0122 19:57:14.859040 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:57:14.859047 70718 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:57:14.859051 70718 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:57:14.859058 70718 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.859067 70718 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:57:14.859074 70718 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:57:14.859079 70718 net.cpp:159] Memory required for data: 580387328
I0122 19:57:14.859082 70718 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:57:14.859092 70718 net.cpp:94] Creating Layer inception_3a/output
I0122 19:57:14.859098 70718 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:57:14.859102 70718 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:57:14.859107 70718 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:57:14.859135 70718 net.cpp:144] Setting up inception_3a/output
I0122 19:57:14.859143 70718 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:57:14.859149 70718 net.cpp:159] Memory required for data: 622330368
I0122 19:57:14.859153 70718 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.859158 70718 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.859160 70718 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:57:14.859166 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.859175 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.859215 70718 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.859220 70718 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:57:14.859225 70718 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:57:14.859227 70718 net.cpp:159] Memory required for data: 706216448
I0122 19:57:14.859230 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:57:14.859239 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:57:14.859243 70718 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.859251 70718 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:57:14.859817 70718 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:57:14.859824 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.859827 70718 net.cpp:159] Memory required for data: 716702208
I0122 19:57:14.859833 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:57:14.859840 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:57:14.859846 70718 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:57:14.859853 70718 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.860625 70718 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:57:14.860633 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.860635 70718 net.cpp:159] Memory required for data: 727187968
I0122 19:57:14.860644 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:57:14.860651 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:57:14.860653 70718 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:57:14.860671 70718 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.860682 70718 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:57:14.860690 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.860694 70718 net.cpp:159] Memory required for data: 737673728
I0122 19:57:14.860698 70718 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:57:14.860707 70718 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:57:14.860714 70718 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.860723 70718 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:57:14.860813 70718 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:57:14.860821 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.860823 70718 net.cpp:159] Memory required for data: 748159488
I0122 19:57:14.860826 70718 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:57:14.860831 70718 net.cpp:94] Creating Layer downsample_4/output
I0122 19:57:14.860836 70718 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:57:14.860838 70718 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:57:14.860846 70718 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:57:14.860867 70718 net.cpp:144] Setting up downsample_4/output
I0122 19:57:14.860874 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.860886 70718 net.cpp:159] Memory required for data: 769131008
I0122 19:57:14.860890 70718 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.860898 70718 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.860903 70718 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:57:14.860910 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.860918 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.860961 70718 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.860967 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.860971 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.860975 70718 net.cpp:159] Memory required for data: 811074048
I0122 19:57:14.860976 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:57:14.860986 70718 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:57:14.860990 70718 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.860996 70718 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:57:14.861351 70718 net.cpp:144] Setting up inception_5a/1x1
I0122 19:57:14.861361 70718 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:57:14.861362 70718 net.cpp:159] Memory required for data: 825754112
I0122 19:57:14.861367 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:57:14.861376 70718 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:57:14.861382 70718 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:57:14.861388 70718 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.862061 70718 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:57:14.862071 70718 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:57:14.862073 70718 net.cpp:159] Memory required for data: 840434176
I0122 19:57:14.862082 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:57:14.862087 70718 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:57:14.862090 70718 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:57:14.862095 70718 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.862104 70718 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:57:14.862110 70718 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:57:14.862124 70718 net.cpp:159] Memory required for data: 855114240
I0122 19:57:14.862129 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:57:14.862141 70718 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:57:14.862149 70718 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.862157 70718 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:57:14.862895 70718 net.cpp:144] Setting up inception_5a/3x3
I0122 19:57:14.862905 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.862908 70718 net.cpp:159] Memory required for data: 861405696
I0122 19:57:14.862913 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:57:14.862922 70718 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:57:14.862926 70718 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:57:14.862932 70718 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.863602 70718 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:57:14.863611 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.863615 70718 net.cpp:159] Memory required for data: 867697152
I0122 19:57:14.863622 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:57:14.863631 70718 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:57:14.863634 70718 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:57:14.863639 70718 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.863649 70718 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:57:14.863654 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.863659 70718 net.cpp:159] Memory required for data: 873988608
I0122 19:57:14.863662 70718 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:57:14.863672 70718 net.cpp:94] Creating Layer inception_5a/output
I0122 19:57:14.863678 70718 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:57:14.863685 70718 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:57:14.863692 70718 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:57:14.863718 70718 net.cpp:144] Setting up inception_5a/output
I0122 19:57:14.863725 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.863730 70718 net.cpp:159] Memory required for data: 894960128
I0122 19:57:14.863734 70718 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.863740 70718 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.863744 70718 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:57:14.863750 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.863759 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.863801 70718 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.863811 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.863816 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.863818 70718 net.cpp:159] Memory required for data: 936903168
I0122 19:57:14.863821 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:57:14.863828 70718 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:57:14.863832 70718 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.863840 70718 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:57:14.864886 70718 net.cpp:144] Setting up inception_6a/1x1
I0122 19:57:14.864897 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.864899 70718 net.cpp:159] Memory required for data: 949486080
I0122 19:57:14.864905 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:57:14.864915 70718 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:57:14.864939 70718 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:57:14.864949 70718 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.865965 70718 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:57:14.865978 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.865983 70718 net.cpp:159] Memory required for data: 962068992
I0122 19:57:14.865996 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:57:14.866006 70718 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:57:14.866011 70718 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:57:14.866020 70718 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.866034 70718 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:57:14.866041 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.866044 70718 net.cpp:159] Memory required for data: 974651904
I0122 19:57:14.866050 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:57:14.866063 70718 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:57:14.866070 70718 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.866080 70718 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:57:14.867453 70718 net.cpp:144] Setting up inception_6a/3x3
I0122 19:57:14.867468 70718 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:57:14.867473 70718 net.cpp:159] Memory required for data: 983040512
I0122 19:57:14.867492 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:57:14.867508 70718 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:57:14.867516 70718 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:57:14.867527 70718 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.868402 70718 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:57:14.868417 70718 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:57:14.868422 70718 net.cpp:159] Memory required for data: 991429120
I0122 19:57:14.868435 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:57:14.868446 70718 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:57:14.868451 70718 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:57:14.868459 70718 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.868472 70718 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:57:14.868479 70718 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:57:14.868482 70718 net.cpp:159] Memory required for data: 999817728
I0122 19:57:14.868487 70718 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:57:14.868496 70718 net.cpp:94] Creating Layer inception_6a/output
I0122 19:57:14.868505 70718 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:57:14.868510 70718 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:57:14.868518 70718 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:57:14.868546 70718 net.cpp:144] Setting up inception_6a/output
I0122 19:57:14.868554 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.868558 70718 net.cpp:159] Memory required for data: 1020789248
I0122 19:57:14.868563 70718 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.868569 70718 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.868574 70718 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:57:14.868583 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.868597 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.868639 70718 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.868647 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.868669 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.868674 70718 net.cpp:159] Memory required for data: 1062732288
I0122 19:57:14.868677 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:57:14.868690 70718 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:57:14.868696 70718 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.868705 70718 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:57:14.869055 70718 net.cpp:144] Setting up inception_7a/1x1
I0122 19:57:14.869062 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.869065 70718 net.cpp:159] Memory required for data: 1073218048
I0122 19:57:14.869071 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:57:14.869079 70718 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:57:14.869082 70718 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:57:14.869089 70718 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.869942 70718 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:57:14.869951 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.869954 70718 net.cpp:159] Memory required for data: 1083703808
I0122 19:57:14.869962 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:57:14.869971 70718 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:57:14.869973 70718 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:57:14.869978 70718 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.869990 70718 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:57:14.869998 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.870002 70718 net.cpp:159] Memory required for data: 1094189568
I0122 19:57:14.870005 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:57:14.870018 70718 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:57:14.870025 70718 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.870034 70718 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:57:14.870947 70718 net.cpp:144] Setting up inception_7a/3x3
I0122 19:57:14.870956 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.870960 70718 net.cpp:159] Memory required for data: 1104675328
I0122 19:57:14.870965 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:57:14.870975 70718 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:57:14.870977 70718 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:57:14.870985 70718 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.871769 70718 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:57:14.871778 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.871779 70718 net.cpp:159] Memory required for data: 1115161088
I0122 19:57:14.871788 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:57:14.871793 70718 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:57:14.871796 70718 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:57:14.871803 70718 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.871815 70718 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:57:14.871820 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.871824 70718 net.cpp:159] Memory required for data: 1125646848
I0122 19:57:14.871829 70718 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:57:14.871834 70718 net.cpp:94] Creating Layer inception_7a/output
I0122 19:57:14.871839 70718 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:57:14.871843 70718 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:57:14.871850 70718 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:57:14.871932 70718 net.cpp:144] Setting up inception_7a/output
I0122 19:57:14.871938 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.871953 70718 net.cpp:159] Memory required for data: 1146618368
I0122 19:57:14.871956 70718 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.871963 70718 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.871968 70718 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:57:14.871974 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.871989 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.872028 70718 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.872038 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.872042 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.872045 70718 net.cpp:159] Memory required for data: 1188561408
I0122 19:57:14.872048 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:57:14.872056 70718 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:57:14.872061 70718 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.872067 70718 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:57:14.872367 70718 net.cpp:144] Setting up inception_8a/1x1
I0122 19:57:14.872375 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.872376 70718 net.cpp:159] Memory required for data: 1194852864
I0122 19:57:14.872381 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:57:14.872390 70718 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:57:14.872392 70718 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:57:14.872400 70718 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.873090 70718 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:57:14.873097 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.873100 70718 net.cpp:159] Memory required for data: 1201144320
I0122 19:57:14.873108 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:57:14.873113 70718 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:57:14.873117 70718 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:57:14.873123 70718 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.873133 70718 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:57:14.873139 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.873143 70718 net.cpp:159] Memory required for data: 1207435776
I0122 19:57:14.873148 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:57:14.873160 70718 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:57:14.873167 70718 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.873178 70718 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:57:14.874861 70718 net.cpp:144] Setting up inception_8a/3x3
I0122 19:57:14.874871 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.874874 70718 net.cpp:159] Memory required for data: 1220018688
I0122 19:57:14.874879 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:57:14.874887 70718 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:57:14.874891 70718 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:57:14.874897 70718 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.875560 70718 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:57:14.875568 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.875571 70718 net.cpp:159] Memory required for data: 1232601600
I0122 19:57:14.875579 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:57:14.875587 70718 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:57:14.875591 70718 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:57:14.875612 70718 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.875624 70718 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:57:14.875632 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.875634 70718 net.cpp:159] Memory required for data: 1245184512
I0122 19:57:14.875638 70718 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:57:14.875644 70718 net.cpp:94] Creating Layer inception_8a/output
I0122 19:57:14.875655 70718 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:57:14.875660 70718 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:57:14.875668 70718 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:57:14.875697 70718 net.cpp:144] Setting up inception_8a/output
I0122 19:57:14.875706 70718 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:57:14.875710 70718 net.cpp:159] Memory required for data: 1264058880
I0122 19:57:14.875715 70718 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.875720 70718 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.875726 70718 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:57:14.875733 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.875742 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.875784 70718 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.875792 70718 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:57:14.875797 70718 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:57:14.875798 70718 net.cpp:159] Memory required for data: 1301807616
I0122 19:57:14.875802 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:57:14.875810 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:57:14.875815 70718 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.875824 70718 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:57:14.876761 70718 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:57:14.876773 70718 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:57:14.876776 70718 net.cpp:159] Memory required for data: 1304953344
I0122 19:57:14.876781 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:57:14.876791 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:57:14.876796 70718 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:57:14.876806 70718 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.877494 70718 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:57:14.877501 70718 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:57:14.877504 70718 net.cpp:159] Memory required for data: 1308099072
I0122 19:57:14.877512 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:57:14.877519 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:57:14.877522 70718 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:57:14.877530 70718 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.877542 70718 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:57:14.877550 70718 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:57:14.877554 70718 net.cpp:159] Memory required for data: 1311244800
I0122 19:57:14.877558 70718 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:57:14.877565 70718 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:57:14.877571 70718 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.877581 70718 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:57:14.877624 70718 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:57:14.877638 70718 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 19:57:14.877641 70718 net.cpp:159] Memory required for data: 1315963392
I0122 19:57:14.877645 70718 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:57:14.877650 70718 net.cpp:94] Creating Layer downsample_9/output
I0122 19:57:14.877652 70718 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:57:14.877656 70718 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:57:14.877662 70718 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:57:14.877689 70718 net.cpp:144] Setting up downsample_9/output
I0122 19:57:14.877697 70718 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:57:14.877701 70718 net.cpp:159] Memory required for data: 1323827712
I0122 19:57:14.877704 70718 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.877713 70718 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.877717 70718 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:57:14.877724 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.877733 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.877774 70718 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.877779 70718 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:57:14.877784 70718 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:57:14.877785 70718 net.cpp:159] Memory required for data: 1339556352
I0122 19:57:14.877789 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:57:14.877799 70718 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:57:14.877804 70718 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.877811 70718 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:57:14.878301 70718 net.cpp:144] Setting up inception_10a/1x1
I0122 19:57:14.878309 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.878312 70718 net.cpp:159] Memory required for data: 1345323520
I0122 19:57:14.878317 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:57:14.878325 70718 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:57:14.878330 70718 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:57:14.878340 70718 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.879026 70718 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:57:14.879035 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.879037 70718 net.cpp:159] Memory required for data: 1351090688
I0122 19:57:14.879045 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:57:14.879053 70718 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:57:14.879057 70718 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:57:14.879063 70718 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.879074 70718 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:57:14.879081 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.879086 70718 net.cpp:159] Memory required for data: 1356857856
I0122 19:57:14.879089 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:57:14.879101 70718 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:57:14.879107 70718 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.879117 70718 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:57:14.882319 70718 net.cpp:144] Setting up inception_10a/3x3
I0122 19:57:14.882333 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.882334 70718 net.cpp:159] Memory required for data: 1362100736
I0122 19:57:14.882340 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:57:14.882375 70718 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:57:14.882381 70718 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:57:14.882392 70718 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.883085 70718 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:57:14.883093 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.883096 70718 net.cpp:159] Memory required for data: 1367343616
I0122 19:57:14.883105 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:57:14.883111 70718 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:57:14.883116 70718 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:57:14.883122 70718 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.883133 70718 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:57:14.883139 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.883143 70718 net.cpp:159] Memory required for data: 1372586496
I0122 19:57:14.883147 70718 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:57:14.883155 70718 net.cpp:94] Creating Layer inception_10a/output
I0122 19:57:14.883162 70718 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:57:14.883168 70718 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:57:14.883175 70718 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:57:14.883204 70718 net.cpp:144] Setting up inception_10a/output
I0122 19:57:14.883213 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.883217 70718 net.cpp:159] Memory required for data: 1383596544
I0122 19:57:14.883221 70718 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.883226 70718 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.883232 70718 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:57:14.883240 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.883250 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.883291 70718 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.883298 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.883302 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.883306 70718 net.cpp:159] Memory required for data: 1405616640
I0122 19:57:14.883308 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:57:14.883321 70718 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:57:14.883325 70718 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.883333 70718 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:57:14.883913 70718 net.cpp:144] Setting up inception_11a/1x1
I0122 19:57:14.883921 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.883924 70718 net.cpp:159] Memory required for data: 1411383808
I0122 19:57:14.883929 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:57:14.883937 70718 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:57:14.883944 70718 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:57:14.883952 70718 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.884652 70718 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:57:14.884660 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.884663 70718 net.cpp:159] Memory required for data: 1417150976
I0122 19:57:14.884671 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:57:14.884680 70718 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:57:14.884686 70718 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:57:14.884706 70718 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.884716 70718 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:57:14.884721 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.884724 70718 net.cpp:159] Memory required for data: 1422918144
I0122 19:57:14.884728 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:57:14.884740 70718 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:57:14.884747 70718 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.884755 70718 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:57:14.888675 70718 net.cpp:144] Setting up inception_11a/3x3
I0122 19:57:14.888687 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.888690 70718 net.cpp:159] Memory required for data: 1428161024
I0122 19:57:14.888695 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:57:14.888703 70718 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:57:14.888708 70718 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:57:14.888715 70718 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.889382 70718 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:57:14.889390 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.889394 70718 net.cpp:159] Memory required for data: 1433403904
I0122 19:57:14.889415 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:57:14.889423 70718 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:57:14.889430 70718 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:57:14.889436 70718 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.889446 70718 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:57:14.889452 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.889456 70718 net.cpp:159] Memory required for data: 1438646784
I0122 19:57:14.889461 70718 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:57:14.889467 70718 net.cpp:94] Creating Layer inception_11a/output
I0122 19:57:14.889473 70718 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:57:14.889478 70718 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:57:14.889487 70718 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:57:14.889515 70718 net.cpp:144] Setting up inception_11a/output
I0122 19:57:14.889523 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.889528 70718 net.cpp:159] Memory required for data: 1449656832
I0122 19:57:14.889531 70718 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:57:14.889541 70718 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:57:14.889545 70718 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:57:14.889554 70718 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:57:14.889587 70718 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:57:14.889595 70718 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:57:14.889597 70718 net.cpp:159] Memory required for data: 1449828864
I0122 19:57:14.889600 70718 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:57:14.889606 70718 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:57:14.889611 70718 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:57:14.889616 70718 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:57:14.889642 70718 net.cpp:144] Setting up drop_8x8_s1
I0122 19:57:14.889648 70718 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:57:14.889652 70718 net.cpp:159] Memory required for data: 1450000896
I0122 19:57:14.889657 70718 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:57:14.889665 70718 net.cpp:94] Creating Layer loss/classifier
I0122 19:57:14.889668 70718 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:57:14.889675 70718 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:57:14.889827 70718 net.cpp:144] Setting up loss/classifier
I0122 19:57:14.889842 70718 net.cpp:151] Top shape: 128 10 (1280)
I0122 19:57:14.889845 70718 net.cpp:159] Memory required for data: 1450006016
I0122 19:57:14.889850 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.889855 70718 net.cpp:94] Creating Layer loss
I0122 19:57:14.889859 70718 net.cpp:435] loss <- loss/classifier
I0122 19:57:14.889863 70718 net.cpp:435] loss <- label
I0122 19:57:14.889868 70718 net.cpp:409] loss -> loss
I0122 19:57:14.889879 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.889981 70718 net.cpp:144] Setting up loss
I0122 19:57:14.889986 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.889988 70718 net.cpp:154]     with loss weight 1
I0122 19:57:14.889997 70718 net.cpp:159] Memory required for data: 1450006020
I0122 19:57:14.890000 70718 net.cpp:220] loss needs backward computation.
I0122 19:57:14.890008 70718 net.cpp:220] loss/classifier needs backward computation.
I0122 19:57:14.890013 70718 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:57:14.890017 70718 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:57:14.890022 70718 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:57:14.890027 70718 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:57:14.890031 70718 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:57:14.890035 70718 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:57:14.890040 70718 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:57:14.890044 70718 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:57:14.890048 70718 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:57:14.890053 70718 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:57:14.890058 70718 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:57:14.890063 70718 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:57:14.890065 70718 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:57:14.890069 70718 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:57:14.890074 70718 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:57:14.890079 70718 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:57:14.890081 70718 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:57:14.890089 70718 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:57:14.890094 70718 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:57:14.890097 70718 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:57:14.890102 70718 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.890106 70718 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.890110 70718 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:57:14.890115 70718 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:57:14.890120 70718 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:57:14.890125 70718 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:57:14.890130 70718 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:57:14.890132 70718 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:57:14.890137 70718 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:57:14.890141 70718 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:57:14.890146 70718 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:57:14.890149 70718 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:57:14.890154 70718 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:57:14.890161 70718 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:57:14.890177 70718 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:57:14.890180 70718 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:57:14.890184 70718 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:57:14.890192 70718 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:57:14.890197 70718 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:57:14.890200 70718 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:57:14.890205 70718 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:57:14.890210 70718 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:57:14.890215 70718 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:57:14.890218 70718 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:57:14.890223 70718 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:57:14.890228 70718 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:57:14.890233 70718 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:57:14.890236 70718 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:57:14.890242 70718 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:57:14.890247 70718 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:57:14.890252 70718 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:57:14.890256 70718 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:57:14.890260 70718 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:57:14.890264 70718 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:57:14.890269 70718 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:57:14.890274 70718 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:57:14.890278 70718 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:57:14.890283 70718 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:57:14.890288 70718 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.890292 70718 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.890296 70718 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:57:14.890300 70718 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:57:14.890305 70718 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:57:14.890312 70718 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:57:14.890316 70718 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:57:14.890321 70718 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:57:14.890326 70718 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:57:14.890329 70718 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:57:14.890333 70718 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:57:14.890337 70718 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:57:14.890343 70718 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:57:14.890348 70718 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:57:14.890352 70718 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:57:14.890357 70718 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:57:14.890360 70718 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:57:14.890364 70718 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:57:14.890368 70718 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:57:14.890372 70718 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:57:14.890384 70718 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:57:14.890388 70718 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:57:14.890393 70718 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:57:14.890398 70718 net.cpp:222] data does not need backward computation.
I0122 19:57:14.890405 70718 net.cpp:264] This network produces output loss
I0122 19:57:14.890482 70718 net.cpp:284] Network initialization done.
I0122 19:57:14.891386 70718 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt
I0122 19:57:14.891481 70718 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 19:57:14.892133 70718 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 19:57:14.892567 70718 layer_factory.hpp:77] Creating layer data
I0122 19:57:14.892623 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.893570 70718 net.cpp:94] Creating Layer data
I0122 19:57:14.893584 70718 net.cpp:409] data -> data
I0122 19:57:14.893594 70718 net.cpp:409] data -> label
I0122 19:57:14.894477 70787 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 19:57:14.894510 70787 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 19:57:14.894609 70718 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 19:57:14.894711 70718 data_layer.cpp:83] output data size: 50,3,32,32
I0122 19:57:14.897821 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.897859 70718 net.cpp:144] Setting up data
I0122 19:57:14.897892 70718 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 19:57:14.897898 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.897900 70718 net.cpp:159] Memory required for data: 614600
I0122 19:57:14.897909 70718 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 19:57:14.897919 70718 net.cpp:94] Creating Layer label_data_1_split
I0122 19:57:14.897923 70718 net.cpp:435] label_data_1_split <- label
I0122 19:57:14.897933 70718 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 19:57:14.897946 70718 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 19:57:14.897958 70718 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 19:57:14.897972 70718 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 19:57:14.898118 70718 net.cpp:144] Setting up label_data_1_split
I0122 19:57:14.898124 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898128 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898131 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898134 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898136 70718 net.cpp:159] Memory required for data: 615400
I0122 19:57:14.898139 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:57:14.898151 70718 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:57:14.898157 70718 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:57:14.898165 70718 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:57:14.898499 70718 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:57:14.898506 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.898509 70718 net.cpp:159] Memory required for data: 20276200
I0122 19:57:14.898517 70718 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:57:14.898525 70718 net.cpp:94] Creating Layer conv1/bn1
I0122 19:57:14.898528 70718 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:57:14.898547 70718 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.899274 70718 net.cpp:144] Setting up conv1/bn1
I0122 19:57:14.899283 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899286 70718 net.cpp:159] Memory required for data: 39937000
I0122 19:57:14.899298 70718 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:57:14.899304 70718 net.cpp:94] Creating Layer conv1/relu1
I0122 19:57:14.899308 70718 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:57:14.899314 70718 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.899322 70718 net.cpp:144] Setting up conv1/relu1
I0122 19:57:14.899328 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899333 70718 net.cpp:159] Memory required for data: 59597800
I0122 19:57:14.899338 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.899344 70718 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.899351 70718 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:57:14.899359 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.899370 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.899667 70718 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.899672 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899677 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899680 70718 net.cpp:159] Memory required for data: 98919400
I0122 19:57:14.899682 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:57:14.899691 70718 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:57:14.899696 70718 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.899713 70718 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:57:14.900265 70718 net.cpp:144] Setting up inception_2a/1x1
I0122 19:57:14.900275 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.900280 70718 net.cpp:159] Memory required for data: 105473000
I0122 19:57:14.900292 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:57:14.900305 70718 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:57:14.900310 70718 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:57:14.900319 70718 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.901423 70718 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:57:14.901434 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.901438 70718 net.cpp:159] Memory required for data: 112026600
I0122 19:57:14.901453 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:57:14.901461 70718 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:57:14.901465 70718 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:57:14.901476 70718 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.901489 70718 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:57:14.901494 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.901499 70718 net.cpp:159] Memory required for data: 118580200
I0122 19:57:14.901502 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:57:14.901517 70718 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:57:14.901525 70718 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.901535 70718 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:57:14.902186 70718 net.cpp:144] Setting up inception_2a/3x3
I0122 19:57:14.902197 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.902201 70718 net.cpp:159] Memory required for data: 125133800
I0122 19:57:14.902209 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:57:14.902225 70718 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:57:14.902232 70718 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:57:14.902253 70718 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.903350 70718 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:57:14.903362 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.903367 70718 net.cpp:159] Memory required for data: 131687400
I0122 19:57:14.903388 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:57:14.903396 70718 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:57:14.903401 70718 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:57:14.903409 70718 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.903420 70718 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:57:14.903429 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.903432 70718 net.cpp:159] Memory required for data: 138241000
I0122 19:57:14.903437 70718 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:57:14.903445 70718 net.cpp:94] Creating Layer inception_2a/output
I0122 19:57:14.903452 70718 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:57:14.903457 70718 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:57:14.903465 70718 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:57:14.903506 70718 net.cpp:144] Setting up inception_2a/output
I0122 19:57:14.903514 70718 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:14.903520 70718 net.cpp:159] Memory required for data: 151348200
I0122 19:57:14.903524 70718 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.903533 70718 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.903539 70718 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:57:14.903547 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.903568 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.903618 70718 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.903625 70718 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:14.903630 70718 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:14.903635 70718 net.cpp:159] Memory required for data: 177562600
I0122 19:57:14.903638 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:57:14.903652 70718 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:57:14.903656 70718 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.903671 70718 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:57:14.904026 70718 net.cpp:144] Setting up inception_3a/1x1
I0122 19:57:14.904034 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.904038 70718 net.cpp:159] Memory required for data: 184116200
I0122 19:57:14.904047 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:57:14.904069 70718 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:57:14.904078 70718 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:57:14.904088 70718 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.905180 70718 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:57:14.905190 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.905194 70718 net.cpp:159] Memory required for data: 190669800
I0122 19:57:14.905207 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:57:14.905221 70718 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:57:14.905227 70718 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:57:14.905236 70718 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.905246 70718 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:57:14.905254 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.905258 70718 net.cpp:159] Memory required for data: 197223400
I0122 19:57:14.905273 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:57:14.905285 70718 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:57:14.905292 70718 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.905303 70718 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:57:14.906867 70718 net.cpp:144] Setting up inception_3a/3x3
I0122 19:57:14.906883 70718 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:14.906888 70718 net.cpp:159] Memory required for data: 207053800
I0122 19:57:14.906896 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:57:14.906910 70718 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:57:14.906918 70718 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:57:14.906929 70718 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.908049 70718 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:57:14.908062 70718 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:14.908066 70718 net.cpp:159] Memory required for data: 216884200
I0122 19:57:14.908085 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:57:14.908097 70718 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:57:14.908103 70718 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:57:14.908112 70718 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.908121 70718 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:57:14.908129 70718 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:14.908133 70718 net.cpp:159] Memory required for data: 226714600
I0122 19:57:14.908138 70718 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:57:14.908146 70718 net.cpp:94] Creating Layer inception_3a/output
I0122 19:57:14.908150 70718 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:57:14.908156 70718 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:57:14.908164 70718 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:57:14.908197 70718 net.cpp:144] Setting up inception_3a/output
I0122 19:57:14.908207 70718 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:14.908215 70718 net.cpp:159] Memory required for data: 243098600
I0122 19:57:14.908218 70718 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.908226 70718 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.908231 70718 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:57:14.908239 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.908249 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.908296 70718 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.908308 70718 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:14.908313 70718 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:14.908318 70718 net.cpp:159] Memory required for data: 275866600
I0122 19:57:14.908324 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:57:14.908337 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:57:14.908344 70718 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.908356 70718 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:57:14.909276 70718 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:57:14.909288 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.909292 70718 net.cpp:159] Memory required for data: 279962600
I0122 19:57:14.909301 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:57:14.909312 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:57:14.909317 70718 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:57:14.909346 70718 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.910346 70718 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:57:14.910358 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.910362 70718 net.cpp:159] Memory required for data: 284058600
I0122 19:57:14.910370 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:57:14.910377 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:57:14.910383 70718 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:57:14.910388 70718 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.910395 70718 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:57:14.910399 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.910403 70718 net.cpp:159] Memory required for data: 288154600
I0122 19:57:14.910405 70718 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:57:14.910413 70718 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:57:14.910416 70718 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.910421 70718 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:57:14.910523 70718 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:57:14.910529 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.910531 70718 net.cpp:159] Memory required for data: 292250600
I0122 19:57:14.910535 70718 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:57:14.910539 70718 net.cpp:94] Creating Layer downsample_4/output
I0122 19:57:14.910542 70718 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:57:14.910547 70718 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:57:14.910553 70718 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:57:14.910576 70718 net.cpp:144] Setting up downsample_4/output
I0122 19:57:14.910581 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.910583 70718 net.cpp:159] Memory required for data: 300442600
I0122 19:57:14.910588 70718 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.910591 70718 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.910594 70718 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:57:14.910599 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.910606 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.910636 70718 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.910642 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.910645 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.910648 70718 net.cpp:159] Memory required for data: 316826600
I0122 19:57:14.910651 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:57:14.910660 70718 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:57:14.910663 70718 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.910671 70718 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:57:14.911026 70718 net.cpp:144] Setting up inception_5a/1x1
I0122 19:57:14.911031 70718 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:14.911034 70718 net.cpp:159] Memory required for data: 322561000
I0122 19:57:14.911041 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:57:14.911049 70718 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:57:14.911054 70718 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:57:14.911061 70718 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.911885 70718 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:57:14.911912 70718 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:14.911916 70718 net.cpp:159] Memory required for data: 328295400
I0122 19:57:14.911923 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:57:14.911931 70718 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:57:14.911934 70718 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:57:14.911940 70718 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.911947 70718 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:57:14.911952 70718 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:14.911954 70718 net.cpp:159] Memory required for data: 334029800
I0122 19:57:14.911957 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:57:14.911968 70718 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:57:14.911976 70718 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.911985 70718 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:57:14.912632 70718 net.cpp:144] Setting up inception_5a/3x3
I0122 19:57:14.912642 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.912645 70718 net.cpp:159] Memory required for data: 336487400
I0122 19:57:14.912650 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:57:14.912662 70718 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:57:14.912668 70718 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:57:14.912676 70718 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.913383 70718 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:57:14.913390 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.913393 70718 net.cpp:159] Memory required for data: 338945000
I0122 19:57:14.913401 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:57:14.913408 70718 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:57:14.913413 70718 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:57:14.913420 70718 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.913432 70718 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:57:14.913439 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.913442 70718 net.cpp:159] Memory required for data: 341402600
I0122 19:57:14.913446 70718 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:57:14.913452 70718 net.cpp:94] Creating Layer inception_5a/output
I0122 19:57:14.913457 70718 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:57:14.913462 70718 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:57:14.913470 70718 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:57:14.913498 70718 net.cpp:144] Setting up inception_5a/output
I0122 19:57:14.913506 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.913509 70718 net.cpp:159] Memory required for data: 349594600
I0122 19:57:14.913513 70718 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.913522 70718 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.913528 70718 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:57:14.913537 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.913549 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.913591 70718 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.913599 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.913604 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.913605 70718 net.cpp:159] Memory required for data: 365978600
I0122 19:57:14.913609 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:57:14.913630 70718 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:57:14.913635 70718 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.913645 70718 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:57:14.914003 70718 net.cpp:144] Setting up inception_6a/1x1
I0122 19:57:14.914011 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.914014 70718 net.cpp:159] Memory required for data: 370893800
I0122 19:57:14.914019 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:57:14.914027 70718 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:57:14.914031 70718 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:57:14.914037 70718 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.914749 70718 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:57:14.914759 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.914762 70718 net.cpp:159] Memory required for data: 375809000
I0122 19:57:14.914769 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:57:14.914777 70718 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:57:14.914780 70718 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:57:14.914788 70718 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.914796 70718 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:57:14.914803 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.914808 70718 net.cpp:159] Memory required for data: 380724200
I0122 19:57:14.914811 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:57:14.914824 70718 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:57:14.914830 70718 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.914839 70718 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:57:14.916250 70718 net.cpp:144] Setting up inception_6a/3x3
I0122 19:57:14.916262 70718 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:14.916265 70718 net.cpp:159] Memory required for data: 384001000
I0122 19:57:14.916280 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:57:14.916293 70718 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:57:14.916301 70718 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:57:14.916311 70718 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.917029 70718 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:57:14.917037 70718 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:14.917040 70718 net.cpp:159] Memory required for data: 387277800
I0122 19:57:14.917048 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:57:14.917057 70718 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:57:14.917059 70718 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:57:14.917065 70718 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.917074 70718 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:57:14.917083 70718 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:14.917086 70718 net.cpp:159] Memory required for data: 390554600
I0122 19:57:14.917090 70718 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:57:14.917098 70718 net.cpp:94] Creating Layer inception_6a/output
I0122 19:57:14.917104 70718 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:57:14.917110 70718 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:57:14.917119 70718 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:57:14.917145 70718 net.cpp:144] Setting up inception_6a/output
I0122 19:57:14.917155 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.917158 70718 net.cpp:159] Memory required for data: 398746600
I0122 19:57:14.917162 70718 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.917171 70718 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.917186 70718 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:57:14.917194 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.917207 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.917249 70718 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.917258 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.917261 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.917264 70718 net.cpp:159] Memory required for data: 415130600
I0122 19:57:14.917266 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:57:14.917277 70718 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:57:14.917282 70718 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.917290 70718 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:57:14.917618 70718 net.cpp:144] Setting up inception_7a/1x1
I0122 19:57:14.917626 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.917629 70718 net.cpp:159] Memory required for data: 419226600
I0122 19:57:14.917634 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:57:14.917641 70718 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:57:14.917646 70718 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:57:14.917654 70718 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.918383 70718 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:57:14.918393 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.918396 70718 net.cpp:159] Memory required for data: 423322600
I0122 19:57:14.918404 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:57:14.918411 70718 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:57:14.918414 70718 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:57:14.918422 70718 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.918434 70718 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:57:14.918440 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.918447 70718 net.cpp:159] Memory required for data: 427418600
I0122 19:57:14.918452 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:57:14.918462 70718 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:57:14.918469 70718 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.918478 70718 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:57:14.919374 70718 net.cpp:144] Setting up inception_7a/3x3
I0122 19:57:14.919383 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.919385 70718 net.cpp:159] Memory required for data: 431514600
I0122 19:57:14.919390 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:57:14.919399 70718 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:57:14.919404 70718 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:57:14.919414 70718 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.920126 70718 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:57:14.920135 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.920137 70718 net.cpp:159] Memory required for data: 435610600
I0122 19:57:14.920145 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:57:14.920156 70718 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:57:14.920159 70718 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:57:14.920166 70718 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.920174 70718 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:57:14.920181 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.920186 70718 net.cpp:159] Memory required for data: 439706600
I0122 19:57:14.920202 70718 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:57:14.920210 70718 net.cpp:94] Creating Layer inception_7a/output
I0122 19:57:14.920213 70718 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:57:14.920219 70718 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:57:14.920226 70718 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:57:14.920258 70718 net.cpp:144] Setting up inception_7a/output
I0122 19:57:14.920264 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.920269 70718 net.cpp:159] Memory required for data: 447898600
I0122 19:57:14.920272 70718 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.920281 70718 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.920284 70718 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:57:14.920291 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.920303 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.920344 70718 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.920349 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.920354 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.920356 70718 net.cpp:159] Memory required for data: 464282600
I0122 19:57:14.920359 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:57:14.920368 70718 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:57:14.920374 70718 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.920382 70718 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:57:14.920680 70718 net.cpp:144] Setting up inception_8a/1x1
I0122 19:57:14.920686 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.920691 70718 net.cpp:159] Memory required for data: 466740200
I0122 19:57:14.920696 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:57:14.920703 70718 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:57:14.920707 70718 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:57:14.920717 70718 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.921419 70718 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:57:14.921427 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.921429 70718 net.cpp:159] Memory required for data: 469197800
I0122 19:57:14.921437 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:57:14.921443 70718 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:57:14.921447 70718 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:57:14.921454 70718 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.921465 70718 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:57:14.921471 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.921475 70718 net.cpp:159] Memory required for data: 471655400
I0122 19:57:14.921478 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:57:14.921491 70718 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:57:14.921497 70718 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.921509 70718 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:57:14.923172 70718 net.cpp:144] Setting up inception_8a/3x3
I0122 19:57:14.923184 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.923187 70718 net.cpp:159] Memory required for data: 476570600
I0122 19:57:14.923193 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:57:14.923203 70718 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:57:14.923207 70718 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:57:14.923226 70718 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.923947 70718 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:57:14.923954 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.923957 70718 net.cpp:159] Memory required for data: 481485800
I0122 19:57:14.923965 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:57:14.923974 70718 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:57:14.923976 70718 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:57:14.923982 70718 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.923990 70718 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:57:14.923997 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.924001 70718 net.cpp:159] Memory required for data: 486401000
I0122 19:57:14.924005 70718 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:57:14.924013 70718 net.cpp:94] Creating Layer inception_8a/output
I0122 19:57:14.924021 70718 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:57:14.924026 70718 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:57:14.924033 70718 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:57:14.924063 70718 net.cpp:144] Setting up inception_8a/output
I0122 19:57:14.924070 70718 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:14.924074 70718 net.cpp:159] Memory required for data: 493773800
I0122 19:57:14.924079 70718 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.924085 70718 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.924088 70718 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:57:14.924093 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.924105 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.924144 70718 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.924151 70718 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:14.924155 70718 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:14.924158 70718 net.cpp:159] Memory required for data: 508519400
I0122 19:57:14.924160 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:57:14.924170 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:57:14.924175 70718 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.924185 70718 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:57:14.925724 70718 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:57:14.925735 70718 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:14.925738 70718 net.cpp:159] Memory required for data: 509748200
I0122 19:57:14.925745 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:57:14.925753 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:57:14.925760 70718 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:57:14.925765 70718 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.926522 70718 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:57:14.926529 70718 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:14.926532 70718 net.cpp:159] Memory required for data: 510977000
I0122 19:57:14.926540 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:57:14.926549 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:57:14.926553 70718 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:57:14.926559 70718 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.926570 70718 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:57:14.926590 70718 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:14.926594 70718 net.cpp:159] Memory required for data: 512205800
I0122 19:57:14.926599 70718 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:57:14.926606 70718 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:57:14.926610 70718 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.926618 70718 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:57:14.926666 70718 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:57:14.926672 70718 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 19:57:14.926676 70718 net.cpp:159] Memory required for data: 514049000
I0122 19:57:14.926677 70718 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:57:14.926687 70718 net.cpp:94] Creating Layer downsample_9/output
I0122 19:57:14.926692 70718 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:57:14.926697 70718 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:57:14.926704 70718 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:57:14.926730 70718 net.cpp:144] Setting up downsample_9/output
I0122 19:57:14.926738 70718 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:14.926741 70718 net.cpp:159] Memory required for data: 517121000
I0122 19:57:14.926744 70718 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.926751 70718 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.926753 70718 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:57:14.926759 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.926769 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.926810 70718 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.926817 70718 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:14.926821 70718 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:14.926825 70718 net.cpp:159] Memory required for data: 523265000
I0122 19:57:14.926826 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:57:14.926836 70718 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:57:14.926841 70718 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.926849 70718 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:57:14.927356 70718 net.cpp:144] Setting up inception_10a/1x1
I0122 19:57:14.927363 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.927366 70718 net.cpp:159] Memory required for data: 525517800
I0122 19:57:14.927371 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:57:14.927379 70718 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:57:14.927383 70718 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:57:14.927392 70718 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.928090 70718 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:57:14.928098 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.928102 70718 net.cpp:159] Memory required for data: 527770600
I0122 19:57:14.928109 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:57:14.928117 70718 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:57:14.928119 70718 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:57:14.928126 70718 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.928138 70718 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:57:14.928143 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.928146 70718 net.cpp:159] Memory required for data: 530023400
I0122 19:57:14.928150 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:57:14.928175 70718 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:57:14.928181 70718 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.928187 70718 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:57:14.930739 70718 net.cpp:144] Setting up inception_10a/3x3
I0122 19:57:14.930752 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.930753 70718 net.cpp:159] Memory required for data: 532071400
I0122 19:57:14.930758 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:57:14.930766 70718 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:57:14.930771 70718 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:57:14.930779 70718 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.931411 70718 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:57:14.931417 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.931421 70718 net.cpp:159] Memory required for data: 534119400
I0122 19:57:14.931427 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:57:14.931432 70718 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:57:14.931434 70718 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:57:14.931440 70718 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.931448 70718 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:57:14.931454 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.931457 70718 net.cpp:159] Memory required for data: 536167400
I0122 19:57:14.931461 70718 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:57:14.931466 70718 net.cpp:94] Creating Layer inception_10a/output
I0122 19:57:14.931469 70718 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:57:14.931484 70718 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:57:14.931495 70718 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:57:14.931521 70718 net.cpp:144] Setting up inception_10a/output
I0122 19:57:14.931529 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.931532 70718 net.cpp:159] Memory required for data: 540468200
I0122 19:57:14.931537 70718 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.931545 70718 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.931550 70718 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:57:14.931556 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.931566 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.931609 70718 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.931617 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.931620 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.931624 70718 net.cpp:159] Memory required for data: 549069800
I0122 19:57:14.931627 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:57:14.931635 70718 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:57:14.931640 70718 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.931650 70718 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:57:14.932226 70718 net.cpp:144] Setting up inception_11a/1x1
I0122 19:57:14.932235 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.932236 70718 net.cpp:159] Memory required for data: 551322600
I0122 19:57:14.932242 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:57:14.932250 70718 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:57:14.932255 70718 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:57:14.932262 70718 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.932984 70718 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:57:14.932992 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.932994 70718 net.cpp:159] Memory required for data: 553575400
I0122 19:57:14.933002 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:57:14.933009 70718 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:57:14.933012 70718 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:57:14.933019 70718 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.933028 70718 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:57:14.933037 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.933039 70718 net.cpp:159] Memory required for data: 555828200
I0122 19:57:14.933043 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:57:14.933054 70718 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:57:14.933061 70718 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.933071 70718 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:57:14.936873 70718 net.cpp:144] Setting up inception_11a/3x3
I0122 19:57:14.936884 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.936887 70718 net.cpp:159] Memory required for data: 557876200
I0122 19:57:14.936893 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:57:14.936902 70718 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:57:14.936906 70718 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:57:14.936914 70718 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.937593 70718 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:57:14.937602 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.937604 70718 net.cpp:159] Memory required for data: 559924200
I0122 19:57:14.937624 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:57:14.937633 70718 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:57:14.937638 70718 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:57:14.937645 70718 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.937654 70718 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:57:14.937661 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.937665 70718 net.cpp:159] Memory required for data: 561972200
I0122 19:57:14.937669 70718 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:57:14.937676 70718 net.cpp:94] Creating Layer inception_11a/output
I0122 19:57:14.937682 70718 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:57:14.937686 70718 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:57:14.937695 70718 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:57:14.937723 70718 net.cpp:144] Setting up inception_11a/output
I0122 19:57:14.937731 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.937734 70718 net.cpp:159] Memory required for data: 566273000
I0122 19:57:14.937737 70718 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:57:14.937744 70718 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:57:14.937749 70718 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:57:14.937753 70718 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:57:14.937781 70718 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:57:14.937790 70718 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:57:14.937794 70718 net.cpp:159] Memory required for data: 566340200
I0122 19:57:14.937798 70718 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:57:14.937803 70718 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:57:14.937805 70718 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:57:14.937811 70718 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:57:14.937834 70718 net.cpp:144] Setting up drop_8x8_s1
I0122 19:57:14.937841 70718 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:57:14.937857 70718 net.cpp:159] Memory required for data: 566407400
I0122 19:57:14.937860 70718 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:57:14.937870 70718 net.cpp:94] Creating Layer loss/classifier
I0122 19:57:14.937875 70718 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:57:14.937885 70718 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:57:14.938068 70718 net.cpp:144] Setting up loss/classifier
I0122 19:57:14.938076 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938077 70718 net.cpp:159] Memory required for data: 566409400
I0122 19:57:14.938083 70718 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 19:57:14.938091 70718 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 19:57:14.938093 70718 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 19:57:14.938098 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 19:57:14.938108 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 19:57:14.938118 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 19:57:14.938127 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 19:57:14.938192 70718 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 19:57:14.938199 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938202 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938205 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938208 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938211 70718 net.cpp:159] Memory required for data: 566417400
I0122 19:57:14.938215 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.938220 70718 net.cpp:94] Creating Layer loss
I0122 19:57:14.938222 70718 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 19:57:14.938228 70718 net.cpp:435] loss <- label_data_1_split_0
I0122 19:57:14.938236 70718 net.cpp:409] loss -> loss
I0122 19:57:14.938247 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.938345 70718 net.cpp:144] Setting up loss
I0122 19:57:14.938351 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938354 70718 net.cpp:154]     with loss weight 1
I0122 19:57:14.938362 70718 net.cpp:159] Memory required for data: 566417404
I0122 19:57:14.938364 70718 layer_factory.hpp:77] Creating layer accuracy
I0122 19:57:14.938370 70718 net.cpp:94] Creating Layer accuracy
I0122 19:57:14.938374 70718 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 19:57:14.938380 70718 net.cpp:435] accuracy <- label_data_1_split_1
I0122 19:57:14.938385 70718 net.cpp:409] accuracy -> accuracy
I0122 19:57:14.938403 70718 net.cpp:144] Setting up accuracy
I0122 19:57:14.938410 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938414 70718 net.cpp:159] Memory required for data: 566417408
I0122 19:57:14.938418 70718 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 19:57:14.938426 70718 net.cpp:94] Creating Layer accuracy-top1
I0122 19:57:14.938431 70718 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 19:57:14.938436 70718 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 19:57:14.938441 70718 net.cpp:409] accuracy-top1 -> top-1
I0122 19:57:14.938453 70718 net.cpp:144] Setting up accuracy-top1
I0122 19:57:14.938458 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938462 70718 net.cpp:159] Memory required for data: 566417412
I0122 19:57:14.938465 70718 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 19:57:14.938474 70718 net.cpp:94] Creating Layer accuracy-top5
I0122 19:57:14.938480 70718 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 19:57:14.938485 70718 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 19:57:14.938491 70718 net.cpp:409] accuracy-top5 -> top-5
I0122 19:57:14.938511 70718 net.cpp:144] Setting up accuracy-top5
I0122 19:57:14.938518 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938524 70718 net.cpp:159] Memory required for data: 566417416
I0122 19:57:14.938526 70718 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 19:57:14.938531 70718 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 19:57:14.938536 70718 net.cpp:222] accuracy does not need backward computation.
I0122 19:57:14.938541 70718 net.cpp:220] loss needs backward computation.
I0122 19:57:14.938546 70718 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 19:57:14.938555 70718 net.cpp:220] loss/classifier needs backward computation.
I0122 19:57:14.938558 70718 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:57:14.938562 70718 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:57:14.938566 70718 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:57:14.938573 70718 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:57:14.938577 70718 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:57:14.938580 70718 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:57:14.938585 70718 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:57:14.938591 70718 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:57:14.938593 70718 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:57:14.938598 70718 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:57:14.938602 70718 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:57:14.938608 70718 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:57:14.938612 70718 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:57:14.938616 70718 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:57:14.938622 70718 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:57:14.938627 70718 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:57:14.938630 70718 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:57:14.938635 70718 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:57:14.938639 70718 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:57:14.938645 70718 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:57:14.938649 70718 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.938653 70718 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.938657 70718 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:57:14.938663 70718 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:57:14.938668 70718 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:57:14.938673 70718 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:57:14.938676 70718 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:57:14.938681 70718 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:57:14.938686 70718 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:57:14.938690 70718 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:57:14.938694 70718 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:57:14.938699 70718 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:57:14.938704 70718 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:57:14.938709 70718 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:57:14.938712 70718 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:57:14.938717 70718 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:57:14.938722 70718 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:57:14.938737 70718 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:57:14.938741 70718 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:57:14.938747 70718 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:57:14.938755 70718 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:57:14.938757 70718 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:57:14.938761 70718 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:57:14.938766 70718 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:57:14.938771 70718 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:57:14.938776 70718 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:57:14.938779 70718 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:57:14.938784 70718 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:57:14.938789 70718 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:57:14.938794 70718 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:57:14.938798 70718 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:57:14.938803 70718 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:57:14.938807 70718 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:57:14.938812 70718 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:57:14.938815 70718 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:57:14.938822 70718 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:57:14.938827 70718 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:57:14.938832 70718 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:57:14.938835 70718 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.938841 70718 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.938845 70718 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:57:14.938849 70718 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:57:14.938856 70718 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:57:14.938863 70718 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:57:14.938868 70718 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:57:14.938874 70718 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:57:14.938877 70718 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:57:14.938882 70718 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:57:14.938885 70718 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:57:14.938890 70718 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:57:14.938895 70718 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:57:14.938901 70718 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:57:14.938905 70718 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:57:14.938908 70718 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:57:14.938913 70718 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:57:14.938917 70718 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:57:14.938921 70718 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:57:14.938926 70718 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:57:14.938930 70718 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:57:14.938935 70718 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:57:14.938941 70718 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:57:14.938952 70718 net.cpp:222] label_data_1_split does not need backward computation.
I0122 19:57:14.938957 70718 net.cpp:222] data does not need backward computation.
I0122 19:57:14.938962 70718 net.cpp:264] This network produces output accuracy
I0122 19:57:14.938966 70718 net.cpp:264] This network produces output loss
I0122 19:57:14.938971 70718 net.cpp:264] This network produces output top-1
I0122 19:57:14.938975 70718 net.cpp:264] This network produces output top-5
I0122 19:57:14.939070 70718 net.cpp:284] Network initialization done.
I0122 19:57:14.939397 70718 solver.cpp:63] Solver scaffolding done.
I0122 19:57:14.944720 70718 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/sparse.caffemodel
I0122 19:57:14.985493 70718 caffe_interface.cpp:527] Starting Optimization
I0122 19:57:14.985522 70718 solver.cpp:335] Solving 
I0122 19:57:14.985524 70718 solver.cpp:336] Learning Rate Policy: step
I0122 19:57:14.988097 70718 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 19:57:16.441881 70718 solver.cpp:517]     Test net output #0: accuracy = 0.884888
I0122 19:57:16.441912 70718 solver.cpp:517]     Test net output #1: loss = 0.407635 (* 1 = 0.407635 loss)
I0122 19:57:16.441917 70718 solver.cpp:517]     Test net output #2: top-1 = 0.884888
I0122 19:57:16.441920 70718 solver.cpp:517]     Test net output #3: top-5 = 0.994445
I0122 19:57:16.523113 70718 solver.cpp:266] Iteration 0 (0 iter/s, 1.5375s/100 iter), loss = 0.0288452
I0122 19:57:16.523149 70718 solver.cpp:285]     Train net output #0: loss = 0.0288452 (* 1 = 0.0288452 loss)
I0122 19:57:16.523166 70718 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 19:57:22.631466 70718 solver.cpp:266] Iteration 100 (16.3717 iter/s, 6.10809s/100 iter), loss = 0.955029
I0122 19:57:22.631495 70718 solver.cpp:285]     Train net output #0: loss = 0.955029 (* 1 = 0.955029 loss)
I0122 19:57:22.631501 70718 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 19:57:28.740334 70718 solver.cpp:266] Iteration 200 (16.3703 iter/s, 6.10861s/100 iter), loss = 0.93137
I0122 19:57:28.740362 70718 solver.cpp:285]     Train net output #0: loss = 0.93137 (* 1 = 0.93137 loss)
I0122 19:57:28.740368 70718 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 19:57:34.846798 70718 solver.cpp:266] Iteration 300 (16.3768 iter/s, 6.1062s/100 iter), loss = 0.75935
I0122 19:57:34.846827 70718 solver.cpp:285]     Train net output #0: loss = 0.75935 (* 1 = 0.75935 loss)
I0122 19:57:34.846833 70718 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 19:57:40.970335 70718 solver.cpp:266] Iteration 400 (16.3311 iter/s, 6.12327s/100 iter), loss = 0.63203
I0122 19:57:40.970363 70718 solver.cpp:285]     Train net output #0: loss = 0.63203 (* 1 = 0.63203 loss)
I0122 19:57:40.970369 70718 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 19:57:47.140592 70718 solver.cpp:266] Iteration 500 (16.2075 iter/s, 6.16999s/100 iter), loss = 0.549617
I0122 19:57:47.140803 70718 solver.cpp:285]     Train net output #0: loss = 0.549617 (* 1 = 0.549617 loss)
I0122 19:57:47.140813 70718 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 19:57:53.329478 70718 solver.cpp:266] Iteration 600 (16.1592 iter/s, 6.18844s/100 iter), loss = 0.546069
I0122 19:57:53.329507 70718 solver.cpp:285]     Train net output #0: loss = 0.546069 (* 1 = 0.546069 loss)
I0122 19:57:53.329512 70718 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 19:57:59.531250 70718 solver.cpp:266] Iteration 700 (16.1251 iter/s, 6.20151s/100 iter), loss = 0.820554
I0122 19:57:59.531278 70718 solver.cpp:285]     Train net output #0: loss = 0.820554 (* 1 = 0.820554 loss)
I0122 19:57:59.531285 70718 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 19:58:05.724577 70718 solver.cpp:266] Iteration 800 (16.1471 iter/s, 6.19306s/100 iter), loss = 0.727752
I0122 19:58:05.724619 70718 solver.cpp:285]     Train net output #0: loss = 0.727752 (* 1 = 0.727752 loss)
I0122 19:58:05.724625 70718 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 19:58:11.931339 70718 solver.cpp:266] Iteration 900 (16.1122 iter/s, 6.20648s/100 iter), loss = 0.498048
I0122 19:58:11.931368 70718 solver.cpp:285]     Train net output #0: loss = 0.498048 (* 1 = 0.498048 loss)
I0122 19:58:11.931375 70718 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 19:58:18.063923 70718 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 19:58:19.510509 70718 solver.cpp:517]     Test net output #0: accuracy = 0.416667
I0122 19:58:19.510535 70718 solver.cpp:517]     Test net output #1: loss = 3.37431 (* 1 = 3.37431 loss)
I0122 19:58:19.510540 70718 solver.cpp:517]     Test net output #2: top-1 = 0.416667
I0122 19:58:19.510542 70718 solver.cpp:517]     Test net output #3: top-5 = 0.797334
I0122 19:58:19.572508 70718 solver.cpp:266] Iteration 1000 (13.0875 iter/s, 7.64085s/100 iter), loss = 0.668271
I0122 19:58:19.572530 70718 solver.cpp:285]     Train net output #0: loss = 0.668271 (* 1 = 0.668271 loss)
I0122 19:58:19.572537 70718 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 19:58:25.779922 70718 solver.cpp:266] Iteration 1100 (16.1104 iter/s, 6.20715s/100 iter), loss = 0.592751
I0122 19:58:25.779948 70718 solver.cpp:285]     Train net output #0: loss = 0.592751 (* 1 = 0.592751 loss)
I0122 19:58:25.779954 70718 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 19:58:31.985296 70718 solver.cpp:266] Iteration 1200 (16.1158 iter/s, 6.20511s/100 iter), loss = 0.67195
I0122 19:58:31.985337 70718 solver.cpp:285]     Train net output #0: loss = 0.67195 (* 1 = 0.67195 loss)
I0122 19:58:31.985344 70718 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 19:58:38.173473 70718 solver.cpp:266] Iteration 1300 (16.1606 iter/s, 6.1879s/100 iter), loss = 0.488602
I0122 19:58:38.173502 70718 solver.cpp:285]     Train net output #0: loss = 0.488602 (* 1 = 0.488602 loss)
I0122 19:58:38.173507 70718 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 19:58:44.377544 70718 solver.cpp:266] Iteration 1400 (16.1191 iter/s, 6.2038s/100 iter), loss = 0.643387
I0122 19:58:44.377573 70718 solver.cpp:285]     Train net output #0: loss = 0.643387 (* 1 = 0.643387 loss)
I0122 19:58:44.377578 70718 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 19:58:50.587370 70718 solver.cpp:266] Iteration 1500 (16.1042 iter/s, 6.20956s/100 iter), loss = 0.516658
I0122 19:58:50.587471 70718 solver.cpp:285]     Train net output #0: loss = 0.516658 (* 1 = 0.516658 loss)
I0122 19:58:50.587478 70718 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 19:58:56.779511 70718 solver.cpp:266] Iteration 1600 (16.1504 iter/s, 6.1918s/100 iter), loss = 0.666034
I0122 19:58:56.779541 70718 solver.cpp:285]     Train net output #0: loss = 0.666034 (* 1 = 0.666034 loss)
I0122 19:58:56.779546 70718 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 19:59:02.983443 70718 solver.cpp:266] Iteration 1700 (16.1195 iter/s, 6.20367s/100 iter), loss = 0.503105
I0122 19:59:02.983471 70718 solver.cpp:285]     Train net output #0: loss = 0.503105 (* 1 = 0.503105 loss)
I0122 19:59:02.983477 70718 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 19:59:09.191874 70718 solver.cpp:266] Iteration 1800 (16.1078 iter/s, 6.20817s/100 iter), loss = 0.43784
I0122 19:59:09.191900 70718 solver.cpp:285]     Train net output #0: loss = 0.43784 (* 1 = 0.43784 loss)
I0122 19:59:09.191905 70718 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 19:59:15.396297 70718 solver.cpp:266] Iteration 1900 (16.1182 iter/s, 6.20416s/100 iter), loss = 0.491468
I0122 19:59:15.396325 70718 solver.cpp:285]     Train net output #0: loss = 0.491468 (* 1 = 0.491468 loss)
I0122 19:59:15.396332 70718 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 19:59:21.530323 70718 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 19:59:22.986248 70718 solver.cpp:517]     Test net output #0: accuracy = 0.582889
I0122 19:59:22.986274 70718 solver.cpp:517]     Test net output #1: loss = 1.60058 (* 1 = 1.60058 loss)
I0122 19:59:22.986279 70718 solver.cpp:517]     Test net output #2: top-1 = 0.582889
I0122 19:59:22.986282 70718 solver.cpp:517]     Test net output #3: top-5 = 0.939778
I0122 19:59:23.048117 70718 solver.cpp:266] Iteration 2000 (13.0693 iter/s, 7.6515s/100 iter), loss = 0.396029
I0122 19:59:23.048138 70718 solver.cpp:285]     Train net output #0: loss = 0.396029 (* 1 = 0.396029 loss)
I0122 19:59:23.048146 70718 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 19:59:29.251765 70718 solver.cpp:266] Iteration 2100 (16.1202 iter/s, 6.20339s/100 iter), loss = 0.607879
I0122 19:59:29.251791 70718 solver.cpp:285]     Train net output #0: loss = 0.607879 (* 1 = 0.607879 loss)
I0122 19:59:29.251797 70718 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 19:59:35.464603 70718 solver.cpp:266] Iteration 2200 (16.0964 iter/s, 6.21257s/100 iter), loss = 0.376225
I0122 19:59:35.464643 70718 solver.cpp:285]     Train net output #0: loss = 0.376225 (* 1 = 0.376225 loss)
I0122 19:59:35.464651 70718 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 19:59:41.670804 70718 solver.cpp:266] Iteration 2300 (16.1136 iter/s, 6.20593s/100 iter), loss = 0.473856
I0122 19:59:41.670831 70718 solver.cpp:285]     Train net output #0: loss = 0.473856 (* 1 = 0.473856 loss)
I0122 19:59:41.670848 70718 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 19:59:47.865725 70718 solver.cpp:266] Iteration 2400 (16.1429 iter/s, 6.19466s/100 iter), loss = 0.428299
I0122 19:59:47.865761 70718 solver.cpp:285]     Train net output #0: loss = 0.428299 (* 1 = 0.428299 loss)
I0122 19:59:47.865767 70718 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 19:59:54.056520 70718 solver.cpp:266] Iteration 2500 (16.1537 iter/s, 6.19052s/100 iter), loss = 0.423682
I0122 19:59:54.056601 70718 solver.cpp:285]     Train net output #0: loss = 0.423682 (* 1 = 0.423682 loss)
I0122 19:59:54.056607 70718 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 20:00:00.264242 70718 solver.cpp:266] Iteration 2600 (16.1098 iter/s, 6.20741s/100 iter), loss = 0.464466
I0122 20:00:00.264269 70718 solver.cpp:285]     Train net output #0: loss = 0.464466 (* 1 = 0.464466 loss)
I0122 20:00:00.264276 70718 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 20:00:06.467967 70718 solver.cpp:266] Iteration 2700 (16.12 iter/s, 6.20346s/100 iter), loss = 0.730639
I0122 20:00:06.467993 70718 solver.cpp:285]     Train net output #0: loss = 0.730639 (* 1 = 0.730639 loss)
I0122 20:00:06.468000 70718 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 20:00:12.660615 70718 solver.cpp:266] Iteration 2800 (16.1489 iter/s, 6.19238s/100 iter), loss = 0.576423
I0122 20:00:12.660645 70718 solver.cpp:285]     Train net output #0: loss = 0.576423 (* 1 = 0.576423 loss)
I0122 20:00:12.660650 70718 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 20:00:18.869730 70718 solver.cpp:266] Iteration 2900 (16.106 iter/s, 6.20885s/100 iter), loss = 0.49941
I0122 20:00:18.869768 70718 solver.cpp:285]     Train net output #0: loss = 0.49941 (* 1 = 0.49941 loss)
I0122 20:00:18.869776 70718 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 20:00:25.014103 70718 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 20:00:26.463665 70718 solver.cpp:517]     Test net output #0: accuracy = 0.546333
I0122 20:00:26.463690 70718 solver.cpp:517]     Test net output #1: loss = 1.52578 (* 1 = 1.52578 loss)
I0122 20:00:26.463694 70718 solver.cpp:517]     Test net output #2: top-1 = 0.546333
I0122 20:00:26.463697 70718 solver.cpp:517]     Test net output #3: top-5 = 0.945889
I0122 20:00:26.525640 70718 solver.cpp:266] Iteration 3000 (13.0623 iter/s, 7.65559s/100 iter), loss = 0.394277
I0122 20:00:26.525660 70718 solver.cpp:285]     Train net output #0: loss = 0.394277 (* 1 = 0.394277 loss)
I0122 20:00:26.525666 70718 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 20:00:32.731998 70718 solver.cpp:266] Iteration 3100 (16.1132 iter/s, 6.2061s/100 iter), loss = 0.475582
I0122 20:00:32.732026 70718 solver.cpp:285]     Train net output #0: loss = 0.475582 (* 1 = 0.475582 loss)
I0122 20:00:32.732033 70718 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 20:00:38.936556 70718 solver.cpp:266] Iteration 3200 (16.1179 iter/s, 6.20429s/100 iter), loss = 0.523642
I0122 20:00:38.936585 70718 solver.cpp:285]     Train net output #0: loss = 0.523642 (* 1 = 0.523642 loss)
I0122 20:00:38.936591 70718 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 20:00:45.153081 70718 solver.cpp:266] Iteration 3300 (16.0868 iter/s, 6.21626s/100 iter), loss = 0.357407
I0122 20:00:45.153120 70718 solver.cpp:285]     Train net output #0: loss = 0.357407 (* 1 = 0.357407 loss)
I0122 20:00:45.153126 70718 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 20:00:51.358381 70718 solver.cpp:266] Iteration 3400 (16.116 iter/s, 6.20502s/100 iter), loss = 0.640476
I0122 20:00:51.358409 70718 solver.cpp:285]     Train net output #0: loss = 0.640476 (* 1 = 0.640476 loss)
I0122 20:00:51.358415 70718 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 20:00:57.545017 70718 solver.cpp:266] Iteration 3500 (16.1646 iter/s, 6.18637s/100 iter), loss = 0.51945
I0122 20:00:57.545111 70718 solver.cpp:285]     Train net output #0: loss = 0.51945 (* 1 = 0.51945 loss)
I0122 20:00:57.545119 70718 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 20:01:03.762450 70718 solver.cpp:266] Iteration 3600 (16.0847 iter/s, 6.2171s/100 iter), loss = 0.532824
I0122 20:01:03.762491 70718 solver.cpp:285]     Train net output #0: loss = 0.532824 (* 1 = 0.532824 loss)
I0122 20:01:03.762498 70718 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 20:01:09.961258 70718 solver.cpp:266] Iteration 3700 (16.1329 iter/s, 6.19853s/100 iter), loss = 0.436289
I0122 20:01:09.961285 70718 solver.cpp:285]     Train net output #0: loss = 0.436289 (* 1 = 0.436289 loss)
I0122 20:01:09.961292 70718 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 20:01:16.174474 70718 solver.cpp:266] Iteration 3800 (16.0954 iter/s, 6.21295s/100 iter), loss = 0.509245
I0122 20:01:16.174501 70718 solver.cpp:285]     Train net output #0: loss = 0.509245 (* 1 = 0.509245 loss)
I0122 20:01:16.174507 70718 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 20:01:22.378450 70718 solver.cpp:266] Iteration 3900 (16.1194 iter/s, 6.20371s/100 iter), loss = 0.442305
I0122 20:01:22.378480 70718 solver.cpp:285]     Train net output #0: loss = 0.442305 (* 1 = 0.442305 loss)
I0122 20:01:22.378486 70718 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 20:01:28.523691 70718 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 20:01:29.971530 70718 solver.cpp:517]     Test net output #0: accuracy = 0.344111
I0122 20:01:29.971555 70718 solver.cpp:517]     Test net output #1: loss = 1.88703 (* 1 = 1.88703 loss)
I0122 20:01:29.971560 70718 solver.cpp:517]     Test net output #2: top-1 = 0.344111
I0122 20:01:29.971563 70718 solver.cpp:517]     Test net output #3: top-5 = 0.829555
I0122 20:01:30.032670 70718 solver.cpp:266] Iteration 4000 (13.0652 iter/s, 7.6539s/100 iter), loss = 0.467795
I0122 20:01:30.032691 70718 solver.cpp:285]     Train net output #0: loss = 0.467795 (* 1 = 0.467795 loss)
I0122 20:01:30.032697 70718 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 20:01:36.231251 70718 solver.cpp:266] Iteration 4100 (16.1334 iter/s, 6.19832s/100 iter), loss = 0.377432
I0122 20:01:36.231288 70718 solver.cpp:285]     Train net output #0: loss = 0.377432 (* 1 = 0.377432 loss)
I0122 20:01:36.231295 70718 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 20:01:42.453809 70718 solver.cpp:266] Iteration 4200 (16.0713 iter/s, 6.22228s/100 iter), loss = 0.399696
I0122 20:01:42.453848 70718 solver.cpp:285]     Train net output #0: loss = 0.399696 (* 1 = 0.399696 loss)
I0122 20:01:42.453855 70718 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 20:01:48.664057 70718 solver.cpp:266] Iteration 4300 (16.1031 iter/s, 6.20997s/100 iter), loss = 0.562433
I0122 20:01:48.664095 70718 solver.cpp:285]     Train net output #0: loss = 0.562433 (* 1 = 0.562433 loss)
I0122 20:01:48.664103 70718 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 20:01:54.879918 70718 solver.cpp:266] Iteration 4400 (16.0886 iter/s, 6.2156s/100 iter), loss = 0.639381
I0122 20:01:54.879957 70718 solver.cpp:285]     Train net output #0: loss = 0.639381 (* 1 = 0.639381 loss)
I0122 20:01:54.879963 70718 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 20:02:01.094172 70718 solver.cpp:266] Iteration 4500 (16.0927 iter/s, 6.21399s/100 iter), loss = 0.427303
I0122 20:02:01.094249 70718 solver.cpp:285]     Train net output #0: loss = 0.427303 (* 1 = 0.427303 loss)
I0122 20:02:01.094256 70718 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 20:02:07.297348 70718 solver.cpp:266] Iteration 4600 (16.1216 iter/s, 6.20286s/100 iter), loss = 0.604064
I0122 20:02:07.297387 70718 solver.cpp:285]     Train net output #0: loss = 0.604064 (* 1 = 0.604064 loss)
I0122 20:02:07.297394 70718 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 20:02:13.498052 70718 solver.cpp:266] Iteration 4700 (16.1279 iter/s, 6.20043s/100 iter), loss = 0.595444
I0122 20:02:13.498080 70718 solver.cpp:285]     Train net output #0: loss = 0.595444 (* 1 = 0.595444 loss)
I0122 20:02:13.498086 70718 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 20:02:19.715428 70718 solver.cpp:266] Iteration 4800 (16.0846 iter/s, 6.21711s/100 iter), loss = 0.492715
I0122 20:02:19.715457 70718 solver.cpp:285]     Train net output #0: loss = 0.492715 (* 1 = 0.492715 loss)
I0122 20:02:19.715462 70718 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 20:02:25.919868 70718 solver.cpp:266] Iteration 4900 (16.1182 iter/s, 6.20418s/100 iter), loss = 0.629915
I0122 20:02:25.919905 70718 solver.cpp:285]     Train net output #0: loss = 0.629915 (* 1 = 0.629915 loss)
I0122 20:02:25.919912 70718 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 20:02:32.054193 70718 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 20:02:33.509234 70718 solver.cpp:517]     Test net output #0: accuracy = 0.587223
I0122 20:02:33.509260 70718 solver.cpp:517]     Test net output #1: loss = 1.1665 (* 1 = 1.1665 loss)
I0122 20:02:33.509266 70718 solver.cpp:517]     Test net output #2: top-1 = 0.587223
I0122 20:02:33.509269 70718 solver.cpp:517]     Test net output #3: top-5 = 0.945
I0122 20:02:33.570116 70718 solver.cpp:266] Iteration 5000 (13.072 iter/s, 7.64993s/100 iter), loss = 0.539379
I0122 20:02:33.570137 70718 solver.cpp:285]     Train net output #0: loss = 0.539379 (* 1 = 0.539379 loss)
I0122 20:02:33.570144 70718 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 20:02:39.758805 70718 solver.cpp:266] Iteration 5100 (16.1592 iter/s, 6.18843s/100 iter), loss = 0.370682
I0122 20:02:39.758834 70718 solver.cpp:285]     Train net output #0: loss = 0.370682 (* 1 = 0.370682 loss)
I0122 20:02:39.758841 70718 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 20:02:45.964638 70718 solver.cpp:266] Iteration 5200 (16.1146 iter/s, 6.20557s/100 iter), loss = 0.58287
I0122 20:02:45.964668 70718 solver.cpp:285]     Train net output #0: loss = 0.58287 (* 1 = 0.58287 loss)
I0122 20:02:45.964674 70718 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 20:02:52.172088 70718 solver.cpp:266] Iteration 5300 (16.1104 iter/s, 6.20718s/100 iter), loss = 0.506658
I0122 20:02:52.172117 70718 solver.cpp:285]     Train net output #0: loss = 0.506658 (* 1 = 0.506658 loss)
I0122 20:02:52.172122 70718 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 20:02:58.395488 70718 solver.cpp:266] Iteration 5400 (16.0691 iter/s, 6.22313s/100 iter), loss = 0.423528
I0122 20:02:58.395517 70718 solver.cpp:285]     Train net output #0: loss = 0.423528 (* 1 = 0.423528 loss)
I0122 20:02:58.395524 70718 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 20:03:04.598695 70718 solver.cpp:266] Iteration 5500 (16.1214 iter/s, 6.20294s/100 iter), loss = 0.540767
I0122 20:03:04.598822 70718 solver.cpp:285]     Train net output #0: loss = 0.540767 (* 1 = 0.540767 loss)
I0122 20:03:04.598829 70718 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 20:03:10.795501 70718 solver.cpp:266] Iteration 5600 (16.1383 iter/s, 6.19644s/100 iter), loss = 0.536797
I0122 20:03:10.795528 70718 solver.cpp:285]     Train net output #0: loss = 0.536797 (* 1 = 0.536797 loss)
I0122 20:03:10.795534 70718 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 20:03:16.989522 70718 solver.cpp:266] Iteration 5700 (16.1453 iter/s, 6.19376s/100 iter), loss = 0.387972
I0122 20:03:16.989549 70718 solver.cpp:285]     Train net output #0: loss = 0.387972 (* 1 = 0.387972 loss)
I0122 20:03:16.989554 70718 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 20:03:23.184337 70718 solver.cpp:266] Iteration 5800 (16.1432 iter/s, 6.19455s/100 iter), loss = 0.480485
I0122 20:03:23.184366 70718 solver.cpp:285]     Train net output #0: loss = 0.480485 (* 1 = 0.480485 loss)
I0122 20:03:23.184372 70718 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 20:03:29.380476 70718 solver.cpp:266] Iteration 5900 (16.1398 iter/s, 6.19587s/100 iter), loss = 0.541794
I0122 20:03:29.380503 70718 solver.cpp:285]     Train net output #0: loss = 0.541794 (* 1 = 0.541794 loss)
I0122 20:03:29.380509 70718 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 20:03:35.508208 70718 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 20:03:36.953573 70718 solver.cpp:517]     Test net output #0: accuracy = 0.608889
I0122 20:03:36.953598 70718 solver.cpp:517]     Test net output #1: loss = 1.14369 (* 1 = 1.14369 loss)
I0122 20:03:36.953601 70718 solver.cpp:517]     Test net output #2: top-1 = 0.608889
I0122 20:03:36.953604 70718 solver.cpp:517]     Test net output #3: top-5 = 0.933556
I0122 20:03:37.015830 70718 solver.cpp:266] Iteration 6000 (13.0975 iter/s, 7.63504s/100 iter), loss = 0.599417
I0122 20:03:37.015851 70718 solver.cpp:285]     Train net output #0: loss = 0.599417 (* 1 = 0.599417 loss)
I0122 20:03:37.015857 70718 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 20:03:43.229921 70718 solver.cpp:266] Iteration 6100 (16.0931 iter/s, 6.21383s/100 iter), loss = 0.423725
I0122 20:03:43.229948 70718 solver.cpp:285]     Train net output #0: loss = 0.423725 (* 1 = 0.423725 loss)
I0122 20:03:43.229954 70718 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 20:03:49.431541 70718 solver.cpp:266] Iteration 6200 (16.1255 iter/s, 6.20135s/100 iter), loss = 0.456409
I0122 20:03:49.431569 70718 solver.cpp:285]     Train net output #0: loss = 0.456409 (* 1 = 0.456409 loss)
I0122 20:03:49.431576 70718 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 20:03:55.629691 70718 solver.cpp:266] Iteration 6300 (16.1345 iter/s, 6.19788s/100 iter), loss = 0.473987
I0122 20:03:55.629719 70718 solver.cpp:285]     Train net output #0: loss = 0.473987 (* 1 = 0.473987 loss)
I0122 20:03:55.629724 70718 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 20:04:01.826365 70718 solver.cpp:266] Iteration 6400 (16.1384 iter/s, 6.19641s/100 iter), loss = 0.458477
I0122 20:04:01.826392 70718 solver.cpp:285]     Train net output #0: loss = 0.458477 (* 1 = 0.458477 loss)
I0122 20:04:01.826397 70718 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 20:04:08.026897 70718 solver.cpp:266] Iteration 6500 (16.1283 iter/s, 6.20027s/100 iter), loss = 0.689133
I0122 20:04:08.027000 70718 solver.cpp:285]     Train net output #0: loss = 0.689133 (* 1 = 0.689133 loss)
I0122 20:04:08.027006 70718 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 20:04:14.226850 70718 solver.cpp:266] Iteration 6600 (16.13 iter/s, 6.19961s/100 iter), loss = 0.572168
I0122 20:04:14.226891 70718 solver.cpp:285]     Train net output #0: loss = 0.572168 (* 1 = 0.572168 loss)
I0122 20:04:14.226897 70718 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 20:04:20.435529 70718 solver.cpp:266] Iteration 6700 (16.1072 iter/s, 6.20841s/100 iter), loss = 0.380594
I0122 20:04:20.435567 70718 solver.cpp:285]     Train net output #0: loss = 0.380594 (* 1 = 0.380594 loss)
I0122 20:04:20.435575 70718 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 20:04:26.651610 70718 solver.cpp:266] Iteration 6800 (16.088 iter/s, 6.21581s/100 iter), loss = 0.413607
I0122 20:04:26.651638 70718 solver.cpp:285]     Train net output #0: loss = 0.413607 (* 1 = 0.413607 loss)
I0122 20:04:26.651643 70718 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 20:04:32.859081 70718 solver.cpp:266] Iteration 6900 (16.1103 iter/s, 6.2072s/100 iter), loss = 0.37108
I0122 20:04:32.859120 70718 solver.cpp:285]     Train net output #0: loss = 0.37108 (* 1 = 0.37108 loss)
I0122 20:04:32.859127 70718 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 20:04:39.009910 70718 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 20:04:40.454742 70718 solver.cpp:517]     Test net output #0: accuracy = 0.455778
I0122 20:04:40.454767 70718 solver.cpp:517]     Test net output #1: loss = 1.51304 (* 1 = 1.51304 loss)
I0122 20:04:40.454771 70718 solver.cpp:517]     Test net output #2: top-1 = 0.455778
I0122 20:04:40.454776 70718 solver.cpp:517]     Test net output #3: top-5 = 0.900667
I0122 20:04:40.515669 70718 solver.cpp:266] Iteration 7000 (13.0612 iter/s, 7.65626s/100 iter), loss = 0.386719
I0122 20:04:40.515689 70718 solver.cpp:285]     Train net output #0: loss = 0.386719 (* 1 = 0.386719 loss)
I0122 20:04:40.515696 70718 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 20:04:46.717226 70718 solver.cpp:266] Iteration 7100 (16.1257 iter/s, 6.2013s/100 iter), loss = 0.58528
I0122 20:04:46.717254 70718 solver.cpp:285]     Train net output #0: loss = 0.58528 (* 1 = 0.58528 loss)
I0122 20:04:46.717260 70718 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 20:04:52.927958 70718 solver.cpp:266] Iteration 7200 (16.1019 iter/s, 6.21047s/100 iter), loss = 0.548132
I0122 20:04:52.927995 70718 solver.cpp:285]     Train net output #0: loss = 0.548132 (* 1 = 0.548132 loss)
I0122 20:04:52.928002 70718 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 20:04:59.130491 70718 solver.cpp:266] Iteration 7300 (16.1231 iter/s, 6.20227s/100 iter), loss = 0.558016
I0122 20:04:59.130518 70718 solver.cpp:285]     Train net output #0: loss = 0.558016 (* 1 = 0.558016 loss)
I0122 20:04:59.130524 70718 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 20:05:05.348954 70718 solver.cpp:266] Iteration 7400 (16.0818 iter/s, 6.2182s/100 iter), loss = 0.393111
I0122 20:05:05.348982 70718 solver.cpp:285]     Train net output #0: loss = 0.393111 (* 1 = 0.393111 loss)
I0122 20:05:05.348989 70718 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 20:05:11.553928 70718 solver.cpp:266] Iteration 7500 (16.1168 iter/s, 6.20471s/100 iter), loss = 0.490846
I0122 20:05:11.554044 70718 solver.cpp:285]     Train net output #0: loss = 0.490846 (* 1 = 0.490846 loss)
I0122 20:05:11.554051 70718 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 20:05:17.767599 70718 solver.cpp:266] Iteration 7600 (16.0945 iter/s, 6.21331s/100 iter), loss = 0.421701
I0122 20:05:17.767629 70718 solver.cpp:285]     Train net output #0: loss = 0.421701 (* 1 = 0.421701 loss)
I0122 20:05:17.767637 70718 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 20:05:23.981238 70718 solver.cpp:266] Iteration 7700 (16.0943 iter/s, 6.21337s/100 iter), loss = 0.474478
I0122 20:05:23.981266 70718 solver.cpp:285]     Train net output #0: loss = 0.474478 (* 1 = 0.474478 loss)
I0122 20:05:23.981271 70718 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 20:05:30.185649 70718 solver.cpp:266] Iteration 7800 (16.1183 iter/s, 6.20415s/100 iter), loss = 0.339519
I0122 20:05:30.185678 70718 solver.cpp:285]     Train net output #0: loss = 0.339519 (* 1 = 0.339519 loss)
I0122 20:05:30.185683 70718 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 20:05:36.381450 70718 solver.cpp:266] Iteration 7900 (16.1407 iter/s, 6.19553s/100 iter), loss = 0.424793
I0122 20:05:36.381479 70718 solver.cpp:285]     Train net output #0: loss = 0.424793 (* 1 = 0.424793 loss)
I0122 20:05:36.381484 70718 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 20:05:42.543411 70718 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 20:05:44.004163 70718 solver.cpp:517]     Test net output #0: accuracy = 0.679667
I0122 20:05:44.004189 70718 solver.cpp:517]     Test net output #1: loss = 0.941858 (* 1 = 0.941858 loss)
I0122 20:05:44.004192 70718 solver.cpp:517]     Test net output #2: top-1 = 0.679667
I0122 20:05:44.004196 70718 solver.cpp:517]     Test net output #3: top-5 = 0.962667
I0122 20:05:44.065462 70718 solver.cpp:266] Iteration 8000 (13.0146 iter/s, 7.6837s/100 iter), loss = 0.419778
I0122 20:05:44.065484 70718 solver.cpp:285]     Train net output #0: loss = 0.419778 (* 1 = 0.419778 loss)
I0122 20:05:44.065490 70718 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 20:05:50.248616 70718 solver.cpp:266] Iteration 8100 (16.1737 iter/s, 6.1829s/100 iter), loss = 0.548536
I0122 20:05:50.248644 70718 solver.cpp:285]     Train net output #0: loss = 0.548536 (* 1 = 0.548536 loss)
I0122 20:05:50.248651 70718 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 20:05:56.446229 70718 solver.cpp:266] Iteration 8200 (16.1359 iter/s, 6.19735s/100 iter), loss = 0.513904
I0122 20:05:56.446255 70718 solver.cpp:285]     Train net output #0: loss = 0.513904 (* 1 = 0.513904 loss)
I0122 20:05:56.446260 70718 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 20:06:02.637682 70718 solver.cpp:266] Iteration 8300 (16.152 iter/s, 6.19119s/100 iter), loss = 0.406621
I0122 20:06:02.637711 70718 solver.cpp:285]     Train net output #0: loss = 0.406621 (* 1 = 0.406621 loss)
I0122 20:06:02.637717 70718 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 20:06:08.844125 70718 solver.cpp:266] Iteration 8400 (16.113 iter/s, 6.20618s/100 iter), loss = 0.355183
I0122 20:06:08.844151 70718 solver.cpp:285]     Train net output #0: loss = 0.355183 (* 1 = 0.355183 loss)
I0122 20:06:08.844157 70718 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 20:06:15.065215 70718 solver.cpp:266] Iteration 8500 (16.075 iter/s, 6.22083s/100 iter), loss = 0.553047
I0122 20:06:15.065338 70718 solver.cpp:285]     Train net output #0: loss = 0.553047 (* 1 = 0.553047 loss)
I0122 20:06:15.065358 70718 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 20:06:21.253993 70718 solver.cpp:266] Iteration 8600 (16.1592 iter/s, 6.18842s/100 iter), loss = 0.364745
I0122 20:06:21.254020 70718 solver.cpp:285]     Train net output #0: loss = 0.364745 (* 1 = 0.364745 loss)
I0122 20:06:21.254026 70718 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 20:06:27.461663 70718 solver.cpp:266] Iteration 8700 (16.1098 iter/s, 6.2074s/100 iter), loss = 0.441849
I0122 20:06:27.461701 70718 solver.cpp:285]     Train net output #0: loss = 0.441849 (* 1 = 0.441849 loss)
I0122 20:06:27.461707 70718 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 20:06:33.663388 70718 solver.cpp:266] Iteration 8800 (16.1252 iter/s, 6.20146s/100 iter), loss = 0.559849
I0122 20:06:33.663416 70718 solver.cpp:285]     Train net output #0: loss = 0.559849 (* 1 = 0.559849 loss)
I0122 20:06:33.663422 70718 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 20:06:39.856395 70718 solver.cpp:266] Iteration 8900 (16.1479 iter/s, 6.19274s/100 iter), loss = 0.485911
I0122 20:06:39.856432 70718 solver.cpp:285]     Train net output #0: loss = 0.485911 (* 1 = 0.485911 loss)
I0122 20:06:39.856439 70718 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 20:06:46.003636 70718 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 20:06:47.454390 70718 solver.cpp:517]     Test net output #0: accuracy = 0.482444
I0122 20:06:47.454414 70718 solver.cpp:517]     Test net output #1: loss = 1.6503 (* 1 = 1.6503 loss)
I0122 20:06:47.454419 70718 solver.cpp:517]     Test net output #2: top-1 = 0.482444
I0122 20:06:47.454422 70718 solver.cpp:517]     Test net output #3: top-5 = 0.843555
I0122 20:06:47.515722 70718 solver.cpp:266] Iteration 9000 (13.0565 iter/s, 7.65901s/100 iter), loss = 0.353304
I0122 20:06:47.515743 70718 solver.cpp:285]     Train net output #0: loss = 0.353304 (* 1 = 0.353304 loss)
I0122 20:06:47.515748 70718 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 20:06:53.703563 70718 solver.cpp:266] Iteration 9100 (16.1614 iter/s, 6.18758s/100 iter), loss = 0.308731
I0122 20:06:53.703590 70718 solver.cpp:285]     Train net output #0: loss = 0.308731 (* 1 = 0.308731 loss)
I0122 20:06:53.703596 70718 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 20:06:59.909857 70718 solver.cpp:266] Iteration 9200 (16.1134 iter/s, 6.20603s/100 iter), loss = 0.602015
I0122 20:06:59.909885 70718 solver.cpp:285]     Train net output #0: loss = 0.602015 (* 1 = 0.602015 loss)
I0122 20:06:59.909901 70718 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 20:07:06.105412 70718 solver.cpp:266] Iteration 9300 (16.1413 iter/s, 6.19529s/100 iter), loss = 0.291449
I0122 20:07:06.105439 70718 solver.cpp:285]     Train net output #0: loss = 0.291449 (* 1 = 0.291449 loss)
I0122 20:07:06.105445 70718 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 20:07:12.312242 70718 solver.cpp:266] Iteration 9400 (16.112 iter/s, 6.20657s/100 iter), loss = 0.591797
I0122 20:07:12.312269 70718 solver.cpp:285]     Train net output #0: loss = 0.591797 (* 1 = 0.591797 loss)
I0122 20:07:12.312275 70718 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 20:07:18.517442 70718 solver.cpp:266] Iteration 9500 (16.1162 iter/s, 6.20493s/100 iter), loss = 0.418521
I0122 20:07:18.517570 70718 solver.cpp:285]     Train net output #0: loss = 0.418521 (* 1 = 0.418521 loss)
I0122 20:07:18.517577 70718 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 20:07:24.725688 70718 solver.cpp:266] Iteration 9600 (16.1086 iter/s, 6.20788s/100 iter), loss = 0.523939
I0122 20:07:24.725716 70718 solver.cpp:285]     Train net output #0: loss = 0.523939 (* 1 = 0.523939 loss)
I0122 20:07:24.725723 70718 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 20:07:30.920775 70718 solver.cpp:266] Iteration 9700 (16.1425 iter/s, 6.19482s/100 iter), loss = 0.345824
I0122 20:07:30.920812 70718 solver.cpp:285]     Train net output #0: loss = 0.345824 (* 1 = 0.345824 loss)
I0122 20:07:30.920819 70718 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 20:07:37.130374 70718 solver.cpp:266] Iteration 9800 (16.1048 iter/s, 6.20933s/100 iter), loss = 0.422069
I0122 20:07:37.130401 70718 solver.cpp:285]     Train net output #0: loss = 0.422069 (* 1 = 0.422069 loss)
I0122 20:07:37.130409 70718 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 20:07:43.325747 70718 solver.cpp:266] Iteration 9900 (16.1418 iter/s, 6.19511s/100 iter), loss = 0.736626
I0122 20:07:43.325775 70718 solver.cpp:285]     Train net output #0: loss = 0.736626 (* 1 = 0.736626 loss)
I0122 20:07:43.325798 70718 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 20:07:49.474355 70718 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 20:07:50.929266 70718 solver.cpp:517]     Test net output #0: accuracy = 0.649111
I0122 20:07:50.929291 70718 solver.cpp:517]     Test net output #1: loss = 1.06116 (* 1 = 1.06116 loss)
I0122 20:07:50.929296 70718 solver.cpp:517]     Test net output #2: top-1 = 0.649111
I0122 20:07:50.929299 70718 solver.cpp:517]     Test net output #3: top-5 = 0.954667
I0122 20:07:50.991235 70718 solver.cpp:266] Iteration 10000 (13.046 iter/s, 7.66517s/100 iter), loss = 0.630893
I0122 20:07:50.991256 70718 solver.cpp:285]     Train net output #0: loss = 0.630893 (* 1 = 0.630893 loss)
I0122 20:07:50.991262 70718 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 20:07:57.170753 70718 solver.cpp:266] Iteration 10100 (16.1832 iter/s, 6.17926s/100 iter), loss = 0.39685
I0122 20:07:57.170779 70718 solver.cpp:285]     Train net output #0: loss = 0.39685 (* 1 = 0.39685 loss)
I0122 20:07:57.170785 70718 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 20:08:03.378108 70718 solver.cpp:266] Iteration 10200 (16.1106 iter/s, 6.20709s/100 iter), loss = 0.350924
I0122 20:08:03.378134 70718 solver.cpp:285]     Train net output #0: loss = 0.350924 (* 1 = 0.350924 loss)
I0122 20:08:03.378140 70718 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 20:08:09.578375 70718 solver.cpp:266] Iteration 10300 (16.129 iter/s, 6.2s/100 iter), loss = 0.256052
I0122 20:08:09.578404 70718 solver.cpp:285]     Train net output #0: loss = 0.256052 (* 1 = 0.256052 loss)
I0122 20:08:09.578410 70718 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 20:08:15.777864 70718 solver.cpp:266] Iteration 10400 (16.1311 iter/s, 6.19922s/100 iter), loss = 0.391942
I0122 20:08:15.777891 70718 solver.cpp:285]     Train net output #0: loss = 0.391942 (* 1 = 0.391942 loss)
I0122 20:08:15.777897 70718 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 20:08:21.973567 70718 solver.cpp:266] Iteration 10500 (16.1409 iter/s, 6.19544s/100 iter), loss = 0.261851
I0122 20:08:21.973628 70718 solver.cpp:285]     Train net output #0: loss = 0.261851 (* 1 = 0.261851 loss)
I0122 20:08:21.973634 70718 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 20:08:28.170006 70718 solver.cpp:266] Iteration 10600 (16.1391 iter/s, 6.19614s/100 iter), loss = 0.262397
I0122 20:08:28.170035 70718 solver.cpp:285]     Train net output #0: loss = 0.262397 (* 1 = 0.262397 loss)
I0122 20:08:28.170042 70718 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 20:08:34.376863 70718 solver.cpp:266] Iteration 10700 (16.1119 iter/s, 6.20659s/100 iter), loss = 0.278904
I0122 20:08:34.376889 70718 solver.cpp:285]     Train net output #0: loss = 0.278904 (* 1 = 0.278904 loss)
I0122 20:08:34.376895 70718 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 20:08:40.564771 70718 solver.cpp:266] Iteration 10800 (16.1612 iter/s, 6.18765s/100 iter), loss = 0.178317
I0122 20:08:40.564810 70718 solver.cpp:285]     Train net output #0: loss = 0.178317 (* 1 = 0.178317 loss)
I0122 20:08:40.564816 70718 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 20:08:46.776870 70718 solver.cpp:266] Iteration 10900 (16.0983 iter/s, 6.21183s/100 iter), loss = 0.200183
I0122 20:08:46.776897 70718 solver.cpp:285]     Train net output #0: loss = 0.200183 (* 1 = 0.200183 loss)
I0122 20:08:46.776914 70718 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 20:08:52.920339 70718 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 20:08:54.363567 70718 solver.cpp:517]     Test net output #0: accuracy = 0.811222
I0122 20:08:54.363593 70718 solver.cpp:517]     Test net output #1: loss = 0.593092 (* 1 = 0.593092 loss)
I0122 20:08:54.363597 70718 solver.cpp:517]     Test net output #2: top-1 = 0.811222
I0122 20:08:54.363600 70718 solver.cpp:517]     Test net output #3: top-5 = 0.985001
I0122 20:08:54.425014 70718 solver.cpp:266] Iteration 11000 (13.0756 iter/s, 7.64783s/100 iter), loss = 0.252836
I0122 20:08:54.425034 70718 solver.cpp:285]     Train net output #0: loss = 0.252836 (* 1 = 0.252836 loss)
I0122 20:08:54.425038 70718 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 20:09:00.647500 70718 solver.cpp:266] Iteration 11100 (16.0714 iter/s, 6.22223s/100 iter), loss = 0.159726
I0122 20:09:00.647539 70718 solver.cpp:285]     Train net output #0: loss = 0.159726 (* 1 = 0.159726 loss)
I0122 20:09:00.647545 70718 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 20:09:06.850775 70718 solver.cpp:266] Iteration 11200 (16.1212 iter/s, 6.20301s/100 iter), loss = 0.163452
I0122 20:09:06.850803 70718 solver.cpp:285]     Train net output #0: loss = 0.163452 (* 1 = 0.163452 loss)
I0122 20:09:06.850809 70718 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 20:09:13.054767 70718 solver.cpp:266] Iteration 11300 (16.1193 iter/s, 6.20373s/100 iter), loss = 0.132919
I0122 20:09:13.054795 70718 solver.cpp:285]     Train net output #0: loss = 0.132919 (* 1 = 0.132919 loss)
I0122 20:09:13.054800 70718 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 20:09:19.257699 70718 solver.cpp:266] Iteration 11400 (16.1221 iter/s, 6.20267s/100 iter), loss = 0.13728
I0122 20:09:19.257738 70718 solver.cpp:285]     Train net output #0: loss = 0.13728 (* 1 = 0.13728 loss)
I0122 20:09:19.257745 70718 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 20:09:25.479434 70718 solver.cpp:266] Iteration 11500 (16.0734 iter/s, 6.22147s/100 iter), loss = 0.198154
I0122 20:09:25.479521 70718 solver.cpp:285]     Train net output #0: loss = 0.198154 (* 1 = 0.198154 loss)
I0122 20:09:25.479528 70718 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 20:09:31.665117 70718 solver.cpp:266] Iteration 11600 (16.1672 iter/s, 6.18536s/100 iter), loss = 0.266266
I0122 20:09:31.665143 70718 solver.cpp:285]     Train net output #0: loss = 0.266266 (* 1 = 0.266266 loss)
I0122 20:09:31.665150 70718 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 20:09:37.862514 70718 solver.cpp:266] Iteration 11700 (16.1365 iter/s, 6.19713s/100 iter), loss = 0.171539
I0122 20:09:37.862552 70718 solver.cpp:285]     Train net output #0: loss = 0.171539 (* 1 = 0.171539 loss)
I0122 20:09:37.862573 70718 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 20:09:44.056182 70718 solver.cpp:266] Iteration 11800 (16.1462 iter/s, 6.19339s/100 iter), loss = 0.262956
I0122 20:09:44.056222 70718 solver.cpp:285]     Train net output #0: loss = 0.262956 (* 1 = 0.262956 loss)
I0122 20:09:44.056229 70718 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 20:09:50.259227 70718 solver.cpp:266] Iteration 11900 (16.1218 iter/s, 6.20277s/100 iter), loss = 0.1122
I0122 20:09:50.259255 70718 solver.cpp:285]     Train net output #0: loss = 0.1122 (* 1 = 0.1122 loss)
I0122 20:09:50.259261 70718 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 20:09:56.411448 70718 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 20:09:57.857591 70718 solver.cpp:517]     Test net output #0: accuracy = 0.681667
I0122 20:09:57.857623 70718 solver.cpp:517]     Test net output #1: loss = 0.97773 (* 1 = 0.97773 loss)
I0122 20:09:57.857627 70718 solver.cpp:517]     Test net output #2: top-1 = 0.681667
I0122 20:09:57.857631 70718 solver.cpp:517]     Test net output #3: top-5 = 0.958889
I0122 20:09:57.919075 70718 solver.cpp:266] Iteration 12000 (13.0556 iter/s, 7.65953s/100 iter), loss = 0.0938202
I0122 20:09:57.919096 70718 solver.cpp:285]     Train net output #0: loss = 0.0938202 (* 1 = 0.0938202 loss)
I0122 20:09:57.919102 70718 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 20:10:04.103595 70718 solver.cpp:266] Iteration 12100 (16.1701 iter/s, 6.18426s/100 iter), loss = 0.127468
I0122 20:10:04.103622 70718 solver.cpp:285]     Train net output #0: loss = 0.127468 (* 1 = 0.127468 loss)
I0122 20:10:04.103644 70718 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 20:10:10.317875 70718 solver.cpp:266] Iteration 12200 (16.0927 iter/s, 6.21402s/100 iter), loss = 0.115206
I0122 20:10:10.317906 70718 solver.cpp:285]     Train net output #0: loss = 0.115206 (* 1 = 0.115206 loss)
I0122 20:10:10.317912 70718 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 20:10:16.533383 70718 solver.cpp:266] Iteration 12300 (16.0895 iter/s, 6.21524s/100 iter), loss = 0.121613
I0122 20:10:16.533411 70718 solver.cpp:285]     Train net output #0: loss = 0.121613 (* 1 = 0.121613 loss)
I0122 20:10:16.533416 70718 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 20:10:22.724761 70718 solver.cpp:266] Iteration 12400 (16.1522 iter/s, 6.19111s/100 iter), loss = 0.166166
I0122 20:10:22.724800 70718 solver.cpp:285]     Train net output #0: loss = 0.166166 (* 1 = 0.166166 loss)
I0122 20:10:22.724807 70718 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 20:10:28.935400 70718 solver.cpp:266] Iteration 12500 (16.1021 iter/s, 6.21037s/100 iter), loss = 0.0720637
I0122 20:10:28.935459 70718 solver.cpp:285]     Train net output #0: loss = 0.0720637 (* 1 = 0.0720637 loss)
I0122 20:10:28.935467 70718 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 20:10:35.127230 70718 solver.cpp:266] Iteration 12600 (16.1511 iter/s, 6.19153s/100 iter), loss = 0.185179
I0122 20:10:35.127259 70718 solver.cpp:285]     Train net output #0: loss = 0.185179 (* 1 = 0.185179 loss)
I0122 20:10:35.127264 70718 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 20:10:41.340694 70718 solver.cpp:266] Iteration 12700 (16.0948 iter/s, 6.2132s/100 iter), loss = 0.199481
I0122 20:10:41.340723 70718 solver.cpp:285]     Train net output #0: loss = 0.199481 (* 1 = 0.199481 loss)
I0122 20:10:41.340728 70718 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 20:10:47.551126 70718 solver.cpp:266] Iteration 12800 (16.1026 iter/s, 6.21017s/100 iter), loss = 0.182429
I0122 20:10:47.551167 70718 solver.cpp:285]     Train net output #0: loss = 0.182429 (* 1 = 0.182429 loss)
I0122 20:10:47.551172 70718 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 20:10:53.760568 70718 solver.cpp:266] Iteration 12900 (16.1052 iter/s, 6.20917s/100 iter), loss = 0.127761
I0122 20:10:53.760607 70718 solver.cpp:285]     Train net output #0: loss = 0.127761 (* 1 = 0.127761 loss)
I0122 20:10:53.760614 70718 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 20:10:59.911172 70718 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 20:11:01.359946 70718 solver.cpp:517]     Test net output #0: accuracy = 0.657889
I0122 20:11:01.359971 70718 solver.cpp:517]     Test net output #1: loss = 1.05835 (* 1 = 1.05835 loss)
I0122 20:11:01.359975 70718 solver.cpp:517]     Test net output #2: top-1 = 0.657889
I0122 20:11:01.359979 70718 solver.cpp:517]     Test net output #3: top-5 = 0.941445
I0122 20:11:01.421205 70718 solver.cpp:266] Iteration 13000 (13.0543 iter/s, 7.66031s/100 iter), loss = 0.0740421
I0122 20:11:01.421226 70718 solver.cpp:285]     Train net output #0: loss = 0.0740421 (* 1 = 0.0740421 loss)
I0122 20:11:01.421232 70718 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 20:11:07.622895 70718 solver.cpp:266] Iteration 13100 (16.1253 iter/s, 6.20143s/100 iter), loss = 0.130862
I0122 20:11:07.622923 70718 solver.cpp:285]     Train net output #0: loss = 0.130862 (* 1 = 0.130862 loss)
I0122 20:11:07.622929 70718 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 20:11:13.828912 70718 solver.cpp:266] Iteration 13200 (16.1141 iter/s, 6.20575s/100 iter), loss = 0.175835
I0122 20:11:13.828951 70718 solver.cpp:285]     Train net output #0: loss = 0.175835 (* 1 = 0.175835 loss)
I0122 20:11:13.828958 70718 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 20:11:20.027099 70718 solver.cpp:266] Iteration 13300 (16.1344 iter/s, 6.19792s/100 iter), loss = 0.142658
I0122 20:11:20.027138 70718 solver.cpp:285]     Train net output #0: loss = 0.142658 (* 1 = 0.142658 loss)
I0122 20:11:20.027145 70718 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 20:11:26.237934 70718 solver.cpp:266] Iteration 13400 (16.1016 iter/s, 6.21057s/100 iter), loss = 0.106303
I0122 20:11:26.237962 70718 solver.cpp:285]     Train net output #0: loss = 0.106303 (* 1 = 0.106303 loss)
I0122 20:11:26.237969 70718 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 20:11:32.453891 70718 solver.cpp:266] Iteration 13500 (16.0883 iter/s, 6.21569s/100 iter), loss = 0.0956133
I0122 20:11:32.453985 70718 solver.cpp:285]     Train net output #0: loss = 0.0956133 (* 1 = 0.0956133 loss)
I0122 20:11:32.453994 70718 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 20:11:38.654394 70718 solver.cpp:266] Iteration 13600 (16.1286 iter/s, 6.20017s/100 iter), loss = 0.0776256
I0122 20:11:38.654431 70718 solver.cpp:285]     Train net output #0: loss = 0.0776256 (* 1 = 0.0776256 loss)
I0122 20:11:38.654438 70718 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 20:11:44.856567 70718 solver.cpp:266] Iteration 13700 (16.1241 iter/s, 6.20191s/100 iter), loss = 0.0814026
I0122 20:11:44.856606 70718 solver.cpp:285]     Train net output #0: loss = 0.0814026 (* 1 = 0.0814026 loss)
I0122 20:11:44.856613 70718 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 20:11:51.054651 70718 solver.cpp:266] Iteration 13800 (16.1347 iter/s, 6.19782s/100 iter), loss = 0.0694383
I0122 20:11:51.054690 70718 solver.cpp:285]     Train net output #0: loss = 0.0694383 (* 1 = 0.0694383 loss)
I0122 20:11:51.054697 70718 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 20:11:57.254189 70718 solver.cpp:266] Iteration 13900 (16.131 iter/s, 6.19926s/100 iter), loss = 0.0789684
I0122 20:11:57.254230 70718 solver.cpp:285]     Train net output #0: loss = 0.0789684 (* 1 = 0.0789684 loss)
I0122 20:11:57.254235 70718 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 20:12:03.415987 70718 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 20:12:04.859568 70718 solver.cpp:517]     Test net output #0: accuracy = 0.724444
I0122 20:12:04.859593 70718 solver.cpp:517]     Test net output #1: loss = 0.849222 (* 1 = 0.849222 loss)
I0122 20:12:04.859597 70718 solver.cpp:517]     Test net output #2: top-1 = 0.724444
I0122 20:12:04.859601 70718 solver.cpp:517]     Test net output #3: top-5 = 0.966445
I0122 20:12:04.921526 70718 solver.cpp:266] Iteration 14000 (13.0429 iter/s, 7.66701s/100 iter), loss = 0.0450811
I0122 20:12:04.921546 70718 solver.cpp:285]     Train net output #0: loss = 0.0450811 (* 1 = 0.0450811 loss)
I0122 20:12:04.921551 70718 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 20:12:11.114883 70718 solver.cpp:266] Iteration 14100 (16.147 iter/s, 6.1931s/100 iter), loss = 0.150055
I0122 20:12:11.114912 70718 solver.cpp:285]     Train net output #0: loss = 0.150055 (* 1 = 0.150055 loss)
I0122 20:12:11.114917 70718 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 20:12:17.317785 70718 solver.cpp:266] Iteration 14200 (16.1222 iter/s, 6.20264s/100 iter), loss = 0.113769
I0122 20:12:17.317813 70718 solver.cpp:285]     Train net output #0: loss = 0.113769 (* 1 = 0.113769 loss)
I0122 20:12:17.317819 70718 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 20:12:23.527369 70718 solver.cpp:266] Iteration 14300 (16.1048 iter/s, 6.20932s/100 iter), loss = 0.0940524
I0122 20:12:23.527398 70718 solver.cpp:285]     Train net output #0: loss = 0.0940524 (* 1 = 0.0940524 loss)
I0122 20:12:23.527405 70718 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 20:12:29.723393 70718 solver.cpp:266] Iteration 14400 (16.1401 iter/s, 6.19576s/100 iter), loss = 0.0769485
I0122 20:12:29.723423 70718 solver.cpp:285]     Train net output #0: loss = 0.0769485 (* 1 = 0.0769485 loss)
I0122 20:12:29.723428 70718 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 20:12:35.929334 70718 solver.cpp:266] Iteration 14500 (16.1143 iter/s, 6.20567s/100 iter), loss = 0.0707368
I0122 20:12:35.929414 70718 solver.cpp:285]     Train net output #0: loss = 0.0707368 (* 1 = 0.0707368 loss)
I0122 20:12:35.929421 70718 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 20:12:42.132915 70718 solver.cpp:266] Iteration 14600 (16.1205 iter/s, 6.20327s/100 iter), loss = 0.117741
I0122 20:12:42.132957 70718 solver.cpp:285]     Train net output #0: loss = 0.117741 (* 1 = 0.117741 loss)
I0122 20:12:42.132964 70718 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 20:12:48.344372 70718 solver.cpp:266] Iteration 14700 (16.1 iter/s, 6.21118s/100 iter), loss = 0.0428568
I0122 20:12:48.344401 70718 solver.cpp:285]     Train net output #0: loss = 0.0428568 (* 1 = 0.0428568 loss)
I0122 20:12:48.344408 70718 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 20:12:54.535229 70718 solver.cpp:266] Iteration 14800 (16.1535 iter/s, 6.19059s/100 iter), loss = 0.0801891
I0122 20:12:54.535269 70718 solver.cpp:285]     Train net output #0: loss = 0.0801891 (* 1 = 0.0801891 loss)
I0122 20:12:54.535275 70718 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 20:13:00.746349 70718 solver.cpp:266] Iteration 14900 (16.1009 iter/s, 6.21084s/100 iter), loss = 0.0910393
I0122 20:13:00.746394 70718 solver.cpp:285]     Train net output #0: loss = 0.0910392 (* 1 = 0.0910392 loss)
I0122 20:13:00.746400 70718 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 20:13:06.886782 70718 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 20:13:08.332245 70718 solver.cpp:517]     Test net output #0: accuracy = 0.753222
I0122 20:13:08.332269 70718 solver.cpp:517]     Test net output #1: loss = 0.776205 (* 1 = 0.776205 loss)
I0122 20:13:08.332273 70718 solver.cpp:517]     Test net output #2: top-1 = 0.753222
I0122 20:13:08.332278 70718 solver.cpp:517]     Test net output #3: top-5 = 0.972111
I0122 20:13:08.394227 70718 solver.cpp:266] Iteration 15000 (13.0761 iter/s, 7.64755s/100 iter), loss = 0.0693504
I0122 20:13:08.394248 70718 solver.cpp:285]     Train net output #0: loss = 0.0693504 (* 1 = 0.0693504 loss)
I0122 20:13:08.394253 70718 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 20:13:14.584893 70718 solver.cpp:266] Iteration 15100 (16.154 iter/s, 6.19041s/100 iter), loss = 0.0426243
I0122 20:13:14.584923 70718 solver.cpp:285]     Train net output #0: loss = 0.0426243 (* 1 = 0.0426243 loss)
I0122 20:13:14.584928 70718 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 20:13:20.768533 70718 solver.cpp:266] Iteration 15200 (16.1724 iter/s, 6.18337s/100 iter), loss = 0.0734822
I0122 20:13:20.768561 70718 solver.cpp:285]     Train net output #0: loss = 0.0734822 (* 1 = 0.0734822 loss)
I0122 20:13:20.768568 70718 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 20:13:26.994580 70718 solver.cpp:266] Iteration 15300 (16.0622 iter/s, 6.22578s/100 iter), loss = 0.0921456
I0122 20:13:26.994618 70718 solver.cpp:285]     Train net output #0: loss = 0.0921456 (* 1 = 0.0921456 loss)
I0122 20:13:26.994624 70718 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 20:13:33.204540 70718 solver.cpp:266] Iteration 15400 (16.1039 iter/s, 6.20969s/100 iter), loss = 0.0844483
I0122 20:13:33.204568 70718 solver.cpp:285]     Train net output #0: loss = 0.0844482 (* 1 = 0.0844482 loss)
I0122 20:13:33.204574 70718 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 20:13:39.408125 70718 solver.cpp:266] Iteration 15500 (16.1204 iter/s, 6.20332s/100 iter), loss = 0.0810893
I0122 20:13:39.408241 70718 solver.cpp:285]     Train net output #0: loss = 0.0810893 (* 1 = 0.0810893 loss)
I0122 20:13:39.408247 70718 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 20:13:45.604563 70718 solver.cpp:266] Iteration 15600 (16.1392 iter/s, 6.19609s/100 iter), loss = 0.0780126
I0122 20:13:45.604589 70718 solver.cpp:285]     Train net output #0: loss = 0.0780125 (* 1 = 0.0780125 loss)
I0122 20:13:45.604595 70718 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 20:13:51.829144 70718 solver.cpp:266] Iteration 15700 (16.066 iter/s, 6.22432s/100 iter), loss = 0.0993893
I0122 20:13:51.829172 70718 solver.cpp:285]     Train net output #0: loss = 0.0993893 (* 1 = 0.0993893 loss)
I0122 20:13:51.829179 70718 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 20:13:58.032552 70718 solver.cpp:266] Iteration 15800 (16.1209 iter/s, 6.20314s/100 iter), loss = 0.0664111
I0122 20:13:58.032590 70718 solver.cpp:285]     Train net output #0: loss = 0.066411 (* 1 = 0.066411 loss)
I0122 20:13:58.032598 70718 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 20:14:04.237918 70718 solver.cpp:266] Iteration 15900 (16.1158 iter/s, 6.2051s/100 iter), loss = 0.0656008
I0122 20:14:04.237948 70718 solver.cpp:285]     Train net output #0: loss = 0.0656008 (* 1 = 0.0656008 loss)
I0122 20:14:04.237954 70718 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 20:14:10.379120 70718 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 20:14:11.828549 70718 solver.cpp:517]     Test net output #0: accuracy = 0.799
I0122 20:14:11.828574 70718 solver.cpp:517]     Test net output #1: loss = 0.619807 (* 1 = 0.619807 loss)
I0122 20:14:11.828579 70718 solver.cpp:517]     Test net output #2: top-1 = 0.799
I0122 20:14:11.828583 70718 solver.cpp:517]     Test net output #3: top-5 = 0.985334
I0122 20:14:11.890174 70718 solver.cpp:266] Iteration 16000 (13.0686 iter/s, 7.65194s/100 iter), loss = 0.0443127
I0122 20:14:11.890194 70718 solver.cpp:285]     Train net output #0: loss = 0.0443127 (* 1 = 0.0443127 loss)
I0122 20:14:11.890200 70718 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 20:14:18.091868 70718 solver.cpp:266] Iteration 16100 (16.1253 iter/s, 6.20144s/100 iter), loss = 0.193857
I0122 20:14:18.091897 70718 solver.cpp:285]     Train net output #0: loss = 0.193857 (* 1 = 0.193857 loss)
I0122 20:14:18.091903 70718 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 20:14:24.292721 70718 solver.cpp:266] Iteration 16200 (16.1275 iter/s, 6.20059s/100 iter), loss = 0.0644307
I0122 20:14:24.292748 70718 solver.cpp:285]     Train net output #0: loss = 0.0644306 (* 1 = 0.0644306 loss)
I0122 20:14:24.292753 70718 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 20:14:30.498344 70718 solver.cpp:266] Iteration 16300 (16.1151 iter/s, 6.20536s/100 iter), loss = 0.082988
I0122 20:14:30.498383 70718 solver.cpp:285]     Train net output #0: loss = 0.082988 (* 1 = 0.082988 loss)
I0122 20:14:30.498389 70718 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 20:14:36.707455 70718 solver.cpp:266] Iteration 16400 (16.1061 iter/s, 6.20885s/100 iter), loss = 0.0620904
I0122 20:14:36.707496 70718 solver.cpp:285]     Train net output #0: loss = 0.0620904 (* 1 = 0.0620904 loss)
I0122 20:14:36.707504 70718 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 20:14:42.914018 70718 solver.cpp:266] Iteration 16500 (16.1127 iter/s, 6.20628s/100 iter), loss = 0.0534329
I0122 20:14:42.914090 70718 solver.cpp:285]     Train net output #0: loss = 0.0534329 (* 1 = 0.0534329 loss)
I0122 20:14:42.914098 70718 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 20:14:49.108438 70718 solver.cpp:266] Iteration 16600 (16.1444 iter/s, 6.19411s/100 iter), loss = 0.0370192
I0122 20:14:49.108465 70718 solver.cpp:285]     Train net output #0: loss = 0.0370192 (* 1 = 0.0370192 loss)
I0122 20:14:49.108487 70718 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 20:14:55.317934 70718 solver.cpp:266] Iteration 16700 (16.1051 iter/s, 6.20923s/100 iter), loss = 0.047355
I0122 20:14:55.317961 70718 solver.cpp:285]     Train net output #0: loss = 0.047355 (* 1 = 0.047355 loss)
I0122 20:14:55.317967 70718 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 20:15:01.521723 70718 solver.cpp:266] Iteration 16800 (16.1199 iter/s, 6.20352s/100 iter), loss = 0.0688652
I0122 20:15:01.521759 70718 solver.cpp:285]     Train net output #0: loss = 0.0688651 (* 1 = 0.0688651 loss)
I0122 20:15:01.521766 70718 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 20:15:07.725560 70718 solver.cpp:266] Iteration 16900 (16.1197 iter/s, 6.20357s/100 iter), loss = 0.137951
I0122 20:15:07.725597 70718 solver.cpp:285]     Train net output #0: loss = 0.137951 (* 1 = 0.137951 loss)
I0122 20:15:07.725605 70718 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 20:15:13.870177 70718 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 20:15:15.315157 70718 solver.cpp:517]     Test net output #0: accuracy = 0.781778
I0122 20:15:15.315181 70718 solver.cpp:517]     Test net output #1: loss = 0.666969 (* 1 = 0.666969 loss)
I0122 20:15:15.315184 70718 solver.cpp:517]     Test net output #2: top-1 = 0.781778
I0122 20:15:15.315187 70718 solver.cpp:517]     Test net output #3: top-5 = 0.977223
I0122 20:15:15.377307 70718 solver.cpp:266] Iteration 17000 (13.0695 iter/s, 7.65143s/100 iter), loss = 0.0419673
I0122 20:15:15.377328 70718 solver.cpp:285]     Train net output #0: loss = 0.0419672 (* 1 = 0.0419672 loss)
I0122 20:15:15.377336 70718 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 20:15:21.584848 70718 solver.cpp:266] Iteration 17100 (16.1101 iter/s, 6.20728s/100 iter), loss = 0.148361
I0122 20:15:21.584877 70718 solver.cpp:285]     Train net output #0: loss = 0.148361 (* 1 = 0.148361 loss)
I0122 20:15:21.584883 70718 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 20:15:27.789620 70718 solver.cpp:266] Iteration 17200 (16.1173 iter/s, 6.20451s/100 iter), loss = 0.0920349
I0122 20:15:27.789649 70718 solver.cpp:285]     Train net output #0: loss = 0.0920348 (* 1 = 0.0920348 loss)
I0122 20:15:27.789654 70718 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 20:15:33.989686 70718 solver.cpp:266] Iteration 17300 (16.1296 iter/s, 6.1998s/100 iter), loss = 0.080277
I0122 20:15:33.989727 70718 solver.cpp:285]     Train net output #0: loss = 0.080277 (* 1 = 0.080277 loss)
I0122 20:15:33.989732 70718 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 20:15:40.199496 70718 solver.cpp:266] Iteration 17400 (16.1042 iter/s, 6.20954s/100 iter), loss = 0.158945
I0122 20:15:40.199532 70718 solver.cpp:285]     Train net output #0: loss = 0.158945 (* 1 = 0.158945 loss)
I0122 20:15:40.199539 70718 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 20:15:46.394492 70718 solver.cpp:266] Iteration 17500 (16.1427 iter/s, 6.19473s/100 iter), loss = 0.137852
I0122 20:15:46.394554 70718 solver.cpp:285]     Train net output #0: loss = 0.137852 (* 1 = 0.137852 loss)
I0122 20:15:46.394560 70718 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 20:15:52.600054 70718 solver.cpp:266] Iteration 17600 (16.1154 iter/s, 6.20526s/100 iter), loss = 0.0545917
I0122 20:15:52.600091 70718 solver.cpp:285]     Train net output #0: loss = 0.0545916 (* 1 = 0.0545916 loss)
I0122 20:15:52.600097 70718 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 20:15:58.828835 70718 solver.cpp:266] Iteration 17700 (16.0552 iter/s, 6.22852s/100 iter), loss = 0.137945
I0122 20:15:58.828862 70718 solver.cpp:285]     Train net output #0: loss = 0.137945 (* 1 = 0.137945 loss)
I0122 20:15:58.828868 70718 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 20:16:05.054673 70718 solver.cpp:266] Iteration 17800 (16.0628 iter/s, 6.22557s/100 iter), loss = 0.106974
I0122 20:16:05.054713 70718 solver.cpp:285]     Train net output #0: loss = 0.106974 (* 1 = 0.106974 loss)
I0122 20:16:05.054720 70718 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 20:16:11.248587 70718 solver.cpp:266] Iteration 17900 (16.1456 iter/s, 6.19365s/100 iter), loss = 0.0965851
I0122 20:16:11.248625 70718 solver.cpp:285]     Train net output #0: loss = 0.0965851 (* 1 = 0.0965851 loss)
I0122 20:16:11.248632 70718 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 20:16:17.395083 70718 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 20:16:18.840544 70718 solver.cpp:517]     Test net output #0: accuracy = 0.806667
I0122 20:16:18.840569 70718 solver.cpp:517]     Test net output #1: loss = 0.613429 (* 1 = 0.613429 loss)
I0122 20:16:18.840574 70718 solver.cpp:517]     Test net output #2: top-1 = 0.806667
I0122 20:16:18.840577 70718 solver.cpp:517]     Test net output #3: top-5 = 0.986778
I0122 20:16:18.902223 70718 solver.cpp:266] Iteration 18000 (13.0662 iter/s, 7.65332s/100 iter), loss = 0.107945
I0122 20:16:18.902242 70718 solver.cpp:285]     Train net output #0: loss = 0.107945 (* 1 = 0.107945 loss)
I0122 20:16:18.902248 70718 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 20:16:25.100718 70718 solver.cpp:266] Iteration 18100 (16.1336 iter/s, 6.19824s/100 iter), loss = 0.0887526
I0122 20:16:25.100744 70718 solver.cpp:285]     Train net output #0: loss = 0.0887526 (* 1 = 0.0887526 loss)
I0122 20:16:25.100749 70718 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 20:16:31.306490 70718 solver.cpp:266] Iteration 18200 (16.1147 iter/s, 6.20551s/100 iter), loss = 0.0962536
I0122 20:16:31.306517 70718 solver.cpp:285]     Train net output #0: loss = 0.0962535 (* 1 = 0.0962535 loss)
I0122 20:16:31.306524 70718 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 20:16:37.494400 70718 solver.cpp:266] Iteration 18300 (16.1612 iter/s, 6.18764s/100 iter), loss = 0.0941099
I0122 20:16:37.494427 70718 solver.cpp:285]     Train net output #0: loss = 0.0941098 (* 1 = 0.0941098 loss)
I0122 20:16:37.494433 70718 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 20:16:43.711138 70718 solver.cpp:266] Iteration 18400 (16.0863 iter/s, 6.21647s/100 iter), loss = 0.0831456
I0122 20:16:43.711164 70718 solver.cpp:285]     Train net output #0: loss = 0.0831456 (* 1 = 0.0831456 loss)
I0122 20:16:43.711170 70718 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 20:16:49.916252 70718 solver.cpp:266] Iteration 18500 (16.1164 iter/s, 6.20485s/100 iter), loss = 0.103909
I0122 20:16:49.916301 70718 solver.cpp:285]     Train net output #0: loss = 0.103909 (* 1 = 0.103909 loss)
I0122 20:16:49.916307 70718 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 20:16:56.116654 70718 solver.cpp:266] Iteration 18600 (16.1287 iter/s, 6.20012s/100 iter), loss = 0.0556992
I0122 20:16:56.116694 70718 solver.cpp:285]     Train net output #0: loss = 0.0556991 (* 1 = 0.0556991 loss)
I0122 20:16:56.116701 70718 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 20:17:02.317914 70718 solver.cpp:266] Iteration 18700 (16.1264 iter/s, 6.20099s/100 iter), loss = 0.0588313
I0122 20:17:02.317941 70718 solver.cpp:285]     Train net output #0: loss = 0.0588313 (* 1 = 0.0588313 loss)
I0122 20:17:02.317947 70718 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 20:17:08.510263 70718 solver.cpp:266] Iteration 18800 (16.1497 iter/s, 6.19208s/100 iter), loss = 0.0670613
I0122 20:17:08.510293 70718 solver.cpp:285]     Train net output #0: loss = 0.0670612 (* 1 = 0.0670612 loss)
I0122 20:17:08.510298 70718 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 20:17:14.715518 70718 solver.cpp:266] Iteration 18900 (16.1161 iter/s, 6.20499s/100 iter), loss = 0.123926
I0122 20:17:14.715548 70718 solver.cpp:285]     Train net output #0: loss = 0.123926 (* 1 = 0.123926 loss)
I0122 20:17:14.715553 70718 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 20:17:20.852237 70718 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 20:17:22.299631 70718 solver.cpp:517]     Test net output #0: accuracy = 0.805778
I0122 20:17:22.299657 70718 solver.cpp:517]     Test net output #1: loss = 0.681567 (* 1 = 0.681567 loss)
I0122 20:17:22.299661 70718 solver.cpp:517]     Test net output #2: top-1 = 0.805778
I0122 20:17:22.299664 70718 solver.cpp:517]     Test net output #3: top-5 = 0.987444
I0122 20:17:22.361131 70718 solver.cpp:266] Iteration 19000 (13.0799 iter/s, 7.6453s/100 iter), loss = 0.151295
I0122 20:17:22.361151 70718 solver.cpp:285]     Train net output #0: loss = 0.151295 (* 1 = 0.151295 loss)
I0122 20:17:22.361157 70718 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 20:17:28.554616 70718 solver.cpp:266] Iteration 19100 (16.1467 iter/s, 6.19323s/100 iter), loss = 0.0319603
I0122 20:17:28.554643 70718 solver.cpp:285]     Train net output #0: loss = 0.0319602 (* 1 = 0.0319602 loss)
I0122 20:17:28.554649 70718 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 20:17:34.755566 70718 solver.cpp:266] Iteration 19200 (16.1272 iter/s, 6.20069s/100 iter), loss = 0.0523434
I0122 20:17:34.755594 70718 solver.cpp:285]     Train net output #0: loss = 0.0523434 (* 1 = 0.0523434 loss)
I0122 20:17:34.755600 70718 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 20:17:40.947449 70718 solver.cpp:266] Iteration 19300 (16.1509 iter/s, 6.19162s/100 iter), loss = 0.0852471
I0122 20:17:40.947476 70718 solver.cpp:285]     Train net output #0: loss = 0.085247 (* 1 = 0.085247 loss)
I0122 20:17:40.947482 70718 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 20:17:47.159497 70718 solver.cpp:266] Iteration 19400 (16.0984 iter/s, 6.21178s/100 iter), loss = 0.11108
I0122 20:17:47.159525 70718 solver.cpp:285]     Train net output #0: loss = 0.11108 (* 1 = 0.11108 loss)
I0122 20:17:47.159530 70718 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 20:17:53.357780 70718 solver.cpp:266] Iteration 19500 (16.1342 iter/s, 6.19802s/100 iter), loss = 0.0783336
I0122 20:17:53.357859 70718 solver.cpp:285]     Train net output #0: loss = 0.0783336 (* 1 = 0.0783336 loss)
I0122 20:17:53.357867 70718 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 20:17:59.544704 70718 solver.cpp:266] Iteration 19600 (16.1639 iter/s, 6.18661s/100 iter), loss = 0.0704193
I0122 20:17:59.544744 70718 solver.cpp:285]     Train net output #0: loss = 0.0704193 (* 1 = 0.0704193 loss)
I0122 20:17:59.544751 70718 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 20:18:05.765976 70718 solver.cpp:266] Iteration 19700 (16.0746 iter/s, 6.221s/100 iter), loss = 0.0638372
I0122 20:18:05.766005 70718 solver.cpp:285]     Train net output #0: loss = 0.0638372 (* 1 = 0.0638372 loss)
I0122 20:18:05.766011 70718 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 20:18:11.976516 70718 solver.cpp:266] Iteration 19800 (16.1024 iter/s, 6.21027s/100 iter), loss = 0.0856983
I0122 20:18:11.976546 70718 solver.cpp:285]     Train net output #0: loss = 0.0856983 (* 1 = 0.0856983 loss)
I0122 20:18:11.976552 70718 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 20:18:18.174692 70718 solver.cpp:266] Iteration 19900 (16.1345 iter/s, 6.19791s/100 iter), loss = 0.0602519
I0122 20:18:18.174721 70718 solver.cpp:285]     Train net output #0: loss = 0.0602519 (* 1 = 0.0602519 loss)
I0122 20:18:18.174726 70718 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 20:18:24.335024 70718 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_20000.caffemodel
I0122 20:18:24.385376 70718 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_20000.solverstate
I0122 20:18:24.392966 70718 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 20:18:25.838289 70718 solver.cpp:517]     Test net output #0: accuracy = 0.823555
I0122 20:18:25.838313 70718 solver.cpp:517]     Test net output #1: loss = 0.544263 (* 1 = 0.544263 loss)
I0122 20:18:25.838318 70718 solver.cpp:517]     Test net output #2: top-1 = 0.823555
I0122 20:18:25.838322 70718 solver.cpp:517]     Test net output #3: top-5 = 0.990333
I0122 20:18:25.899863 70718 solver.cpp:266] Iteration 20000 (12.9452 iter/s, 7.72485s/100 iter), loss = 0.0978462
I0122 20:18:25.899881 70718 solver.cpp:285]     Train net output #0: loss = 0.0978461 (* 1 = 0.0978461 loss)
I0122 20:18:25.899888 70718 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 20:18:32.097497 70718 solver.cpp:266] Iteration 20100 (16.1359 iter/s, 6.19738s/100 iter), loss = 0.0647567
I0122 20:18:32.097527 70718 solver.cpp:285]     Train net output #0: loss = 0.0647566 (* 1 = 0.0647566 loss)
I0122 20:18:32.097532 70718 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 20:18:38.305946 70718 solver.cpp:266] Iteration 20200 (16.1078 iter/s, 6.20818s/100 iter), loss = 0.0732051
I0122 20:18:38.305976 70718 solver.cpp:285]     Train net output #0: loss = 0.073205 (* 1 = 0.073205 loss)
I0122 20:18:38.305981 70718 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 20:18:44.493160 70718 solver.cpp:266] Iteration 20300 (16.1631 iter/s, 6.18695s/100 iter), loss = 0.0240059
I0122 20:18:44.493189 70718 solver.cpp:285]     Train net output #0: loss = 0.0240059 (* 1 = 0.0240059 loss)
I0122 20:18:44.493196 70718 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 20:18:50.698110 70718 solver.cpp:266] Iteration 20400 (16.1169 iter/s, 6.20468s/100 iter), loss = 0.0634191
I0122 20:18:50.698140 70718 solver.cpp:285]     Train net output #0: loss = 0.0634191 (* 1 = 0.0634191 loss)
I0122 20:18:50.698146 70718 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 20:18:56.884109 70718 solver.cpp:266] Iteration 20500 (16.1662 iter/s, 6.18573s/100 iter), loss = 0.047717
I0122 20:18:56.884203 70718 solver.cpp:285]     Train net output #0: loss = 0.0477169 (* 1 = 0.0477169 loss)
I0122 20:18:56.884212 70718 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 20:19:03.082566 70718 solver.cpp:266] Iteration 20600 (16.1339 iter/s, 6.19813s/100 iter), loss = 0.0383876
I0122 20:19:03.082594 70718 solver.cpp:285]     Train net output #0: loss = 0.0383875 (* 1 = 0.0383875 loss)
I0122 20:19:03.082617 70718 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 20:19:09.291399 70718 solver.cpp:266] Iteration 20700 (16.1068 iter/s, 6.20857s/100 iter), loss = 0.0283104
I0122 20:19:09.291427 70718 solver.cpp:285]     Train net output #0: loss = 0.0283103 (* 1 = 0.0283103 loss)
I0122 20:19:09.291433 70718 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 20:19:15.492718 70718 solver.cpp:266] Iteration 20800 (16.1263 iter/s, 6.20105s/100 iter), loss = 0.0182067
I0122 20:19:15.492748 70718 solver.cpp:285]     Train net output #0: loss = 0.0182066 (* 1 = 0.0182066 loss)
I0122 20:19:15.492769 70718 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 20:19:21.708766 70718 solver.cpp:266] Iteration 20900 (16.0881 iter/s, 6.21578s/100 iter), loss = 0.0105558
I0122 20:19:21.708796 70718 solver.cpp:285]     Train net output #0: loss = 0.0105557 (* 1 = 0.0105557 loss)
I0122 20:19:21.708802 70718 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 20:19:27.856003 70718 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 20:19:29.303911 70718 solver.cpp:517]     Test net output #0: accuracy = 0.895111
I0122 20:19:29.303936 70718 solver.cpp:517]     Test net output #1: loss = 0.348441 (* 1 = 0.348441 loss)
I0122 20:19:29.303941 70718 solver.cpp:517]     Test net output #2: top-1 = 0.895111
I0122 20:19:29.303944 70718 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 20:19:29.365517 70718 solver.cpp:266] Iteration 21000 (13.0609 iter/s, 7.65643s/100 iter), loss = 0.0414593
I0122 20:19:29.365537 70718 solver.cpp:285]     Train net output #0: loss = 0.0414592 (* 1 = 0.0414592 loss)
I0122 20:19:29.365543 70718 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 20:19:35.564282 70718 solver.cpp:266] Iteration 21100 (16.1329 iter/s, 6.19851s/100 iter), loss = 0.0120907
I0122 20:19:35.564311 70718 solver.cpp:285]     Train net output #0: loss = 0.0120906 (* 1 = 0.0120906 loss)
I0122 20:19:35.564317 70718 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 20:19:41.765588 70718 solver.cpp:266] Iteration 21200 (16.1263 iter/s, 6.20104s/100 iter), loss = 0.0477159
I0122 20:19:41.765628 70718 solver.cpp:285]     Train net output #0: loss = 0.0477158 (* 1 = 0.0477158 loss)
I0122 20:19:41.765635 70718 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 20:19:47.966717 70718 solver.cpp:266] Iteration 21300 (16.1268 iter/s, 6.20085s/100 iter), loss = 0.0174922
I0122 20:19:47.966744 70718 solver.cpp:285]     Train net output #0: loss = 0.0174921 (* 1 = 0.0174921 loss)
I0122 20:19:47.966749 70718 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 20:19:54.162137 70718 solver.cpp:266] Iteration 21400 (16.1416 iter/s, 6.19516s/100 iter), loss = 0.0219383
I0122 20:19:54.162168 70718 solver.cpp:285]     Train net output #0: loss = 0.0219382 (* 1 = 0.0219382 loss)
I0122 20:19:54.162173 70718 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 20:20:00.372910 70718 solver.cpp:266] Iteration 21500 (16.1017 iter/s, 6.21051s/100 iter), loss = 0.0207228
I0122 20:20:00.373039 70718 solver.cpp:285]     Train net output #0: loss = 0.0207227 (* 1 = 0.0207227 loss)
I0122 20:20:00.373045 70718 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 20:20:06.567795 70718 solver.cpp:266] Iteration 21600 (16.1433 iter/s, 6.19452s/100 iter), loss = 0.0288106
I0122 20:20:06.567823 70718 solver.cpp:285]     Train net output #0: loss = 0.0288105 (* 1 = 0.0288105 loss)
I0122 20:20:06.567829 70718 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 20:20:12.786218 70718 solver.cpp:266] Iteration 21700 (16.0819 iter/s, 6.21816s/100 iter), loss = 0.0245898
I0122 20:20:12.786247 70718 solver.cpp:285]     Train net output #0: loss = 0.0245897 (* 1 = 0.0245897 loss)
I0122 20:20:12.786253 70718 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 20:20:19.000622 70718 solver.cpp:266] Iteration 21800 (16.0923 iter/s, 6.21414s/100 iter), loss = 0.00656261
I0122 20:20:19.000649 70718 solver.cpp:285]     Train net output #0: loss = 0.00656252 (* 1 = 0.00656252 loss)
I0122 20:20:19.000655 70718 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 20:20:25.204378 70718 solver.cpp:266] Iteration 21900 (16.12 iter/s, 6.20349s/100 iter), loss = 0.0260553
I0122 20:20:25.204407 70718 solver.cpp:285]     Train net output #0: loss = 0.0260552 (* 1 = 0.0260552 loss)
I0122 20:20:25.204412 70718 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 20:20:31.321990 70718 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 20:20:32.767171 70718 solver.cpp:517]     Test net output #0: accuracy = 0.897555
I0122 20:20:32.767196 70718 solver.cpp:517]     Test net output #1: loss = 0.349665 (* 1 = 0.349665 loss)
I0122 20:20:32.767201 70718 solver.cpp:517]     Test net output #2: top-1 = 0.897555
I0122 20:20:32.767204 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996667
I0122 20:20:32.828428 70718 solver.cpp:266] Iteration 22000 (13.1169 iter/s, 7.62373s/100 iter), loss = 0.0100802
I0122 20:20:32.828449 70718 solver.cpp:285]     Train net output #0: loss = 0.0100801 (* 1 = 0.0100801 loss)
I0122 20:20:32.828454 70718 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 20:20:39.045101 70718 solver.cpp:266] Iteration 22100 (16.0864 iter/s, 6.21641s/100 iter), loss = 0.0292658
I0122 20:20:39.045130 70718 solver.cpp:285]     Train net output #0: loss = 0.0292657 (* 1 = 0.0292657 loss)
I0122 20:20:39.045136 70718 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 20:20:45.240491 70718 solver.cpp:266] Iteration 22200 (16.1417 iter/s, 6.19512s/100 iter), loss = 0.0127999
I0122 20:20:45.240520 70718 solver.cpp:285]     Train net output #0: loss = 0.0127998 (* 1 = 0.0127998 loss)
I0122 20:20:45.240526 70718 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 20:20:51.436843 70718 solver.cpp:266] Iteration 22300 (16.1392 iter/s, 6.19609s/100 iter), loss = 0.00666936
I0122 20:20:51.436872 70718 solver.cpp:285]     Train net output #0: loss = 0.00666927 (* 1 = 0.00666927 loss)
I0122 20:20:51.436877 70718 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 20:20:57.642958 70718 solver.cpp:266] Iteration 22400 (16.1138 iter/s, 6.20585s/100 iter), loss = 0.0187491
I0122 20:20:57.643000 70718 solver.cpp:285]     Train net output #0: loss = 0.018749 (* 1 = 0.018749 loss)
I0122 20:20:57.643007 70718 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 20:21:03.851944 70718 solver.cpp:266] Iteration 22500 (16.1064 iter/s, 6.20871s/100 iter), loss = 0.0138719
I0122 20:21:03.852100 70718 solver.cpp:285]     Train net output #0: loss = 0.0138718 (* 1 = 0.0138718 loss)
I0122 20:21:03.852123 70718 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 20:21:10.052994 70718 solver.cpp:266] Iteration 22600 (16.1273 iter/s, 6.20067s/100 iter), loss = 0.0132217
I0122 20:21:10.053025 70718 solver.cpp:285]     Train net output #0: loss = 0.0132216 (* 1 = 0.0132216 loss)
I0122 20:21:10.053031 70718 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 20:21:16.278553 70718 solver.cpp:266] Iteration 22700 (16.0635 iter/s, 6.22529s/100 iter), loss = 0.010282
I0122 20:21:16.278584 70718 solver.cpp:285]     Train net output #0: loss = 0.0102819 (* 1 = 0.0102819 loss)
I0122 20:21:16.278589 70718 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 20:21:22.477470 70718 solver.cpp:266] Iteration 22800 (16.1325 iter/s, 6.19865s/100 iter), loss = 0.014787
I0122 20:21:22.477509 70718 solver.cpp:285]     Train net output #0: loss = 0.0147869 (* 1 = 0.0147869 loss)
I0122 20:21:22.477516 70718 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 20:21:28.676484 70718 solver.cpp:266] Iteration 22900 (16.1323 iter/s, 6.19875s/100 iter), loss = 0.0183866
I0122 20:21:28.676512 70718 solver.cpp:285]     Train net output #0: loss = 0.0183865 (* 1 = 0.0183865 loss)
I0122 20:21:28.676519 70718 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 20:21:34.818292 70718 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 20:21:36.280228 70718 solver.cpp:517]     Test net output #0: accuracy = 0.898555
I0122 20:21:36.280253 70718 solver.cpp:517]     Test net output #1: loss = 0.347008 (* 1 = 0.347008 loss)
I0122 20:21:36.280258 70718 solver.cpp:517]     Test net output #2: top-1 = 0.898555
I0122 20:21:36.280261 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996667
I0122 20:21:36.343817 70718 solver.cpp:266] Iteration 23000 (13.0429 iter/s, 7.66702s/100 iter), loss = 0.013857
I0122 20:21:36.343837 70718 solver.cpp:285]     Train net output #0: loss = 0.0138569 (* 1 = 0.0138569 loss)
I0122 20:21:36.343844 70718 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 20:21:42.544041 70718 solver.cpp:266] Iteration 23100 (16.1291 iter/s, 6.19997s/100 iter), loss = 0.00920291
I0122 20:21:42.544070 70718 solver.cpp:285]     Train net output #0: loss = 0.00920282 (* 1 = 0.00920282 loss)
I0122 20:21:42.544076 70718 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 20:21:48.728729 70718 solver.cpp:266] Iteration 23200 (16.1697 iter/s, 6.18442s/100 iter), loss = 0.0252366
I0122 20:21:48.728757 70718 solver.cpp:285]     Train net output #0: loss = 0.0252365 (* 1 = 0.0252365 loss)
I0122 20:21:48.728762 70718 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 20:21:54.944994 70718 solver.cpp:266] Iteration 23300 (16.0875 iter/s, 6.216s/100 iter), loss = 0.019173
I0122 20:21:54.945024 70718 solver.cpp:285]     Train net output #0: loss = 0.019173 (* 1 = 0.019173 loss)
I0122 20:21:54.945029 70718 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 20:22:01.139719 70718 solver.cpp:266] Iteration 23400 (16.1435 iter/s, 6.19446s/100 iter), loss = 0.0137355
I0122 20:22:01.139748 70718 solver.cpp:285]     Train net output #0: loss = 0.0137354 (* 1 = 0.0137354 loss)
I0122 20:22:01.139755 70718 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 20:22:07.338595 70718 solver.cpp:266] Iteration 23500 (16.1327 iter/s, 6.19861s/100 iter), loss = 0.0139024
I0122 20:22:07.338724 70718 solver.cpp:285]     Train net output #0: loss = 0.0139023 (* 1 = 0.0139023 loss)
I0122 20:22:07.338732 70718 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 20:22:13.546540 70718 solver.cpp:266] Iteration 23600 (16.1093 iter/s, 6.20758s/100 iter), loss = 0.0106322
I0122 20:22:13.546569 70718 solver.cpp:285]     Train net output #0: loss = 0.0106321 (* 1 = 0.0106321 loss)
I0122 20:22:13.546576 70718 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 20:22:19.734153 70718 solver.cpp:266] Iteration 23700 (16.162 iter/s, 6.18735s/100 iter), loss = 0.0205203
I0122 20:22:19.734182 70718 solver.cpp:285]     Train net output #0: loss = 0.0205202 (* 1 = 0.0205202 loss)
I0122 20:22:19.734187 70718 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 20:22:25.933367 70718 solver.cpp:266] Iteration 23800 (16.1318 iter/s, 6.19895s/100 iter), loss = 0.0174627
I0122 20:22:25.933395 70718 solver.cpp:285]     Train net output #0: loss = 0.0174626 (* 1 = 0.0174626 loss)
I0122 20:22:25.933401 70718 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 20:22:32.145059 70718 solver.cpp:266] Iteration 23900 (16.0994 iter/s, 6.21143s/100 iter), loss = 0.00601303
I0122 20:22:32.145088 70718 solver.cpp:285]     Train net output #0: loss = 0.00601295 (* 1 = 0.00601295 loss)
I0122 20:22:32.145093 70718 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 20:22:38.300473 70718 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 20:22:39.751407 70718 solver.cpp:517]     Test net output #0: accuracy = 0.897444
I0122 20:22:39.751432 70718 solver.cpp:517]     Test net output #1: loss = 0.35527 (* 1 = 0.35527 loss)
I0122 20:22:39.751436 70718 solver.cpp:517]     Test net output #2: top-1 = 0.897444
I0122 20:22:39.751441 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 20:22:39.814177 70718 solver.cpp:266] Iteration 24000 (13.0398 iter/s, 7.6688s/100 iter), loss = 0.0111231
I0122 20:22:39.814198 70718 solver.cpp:285]     Train net output #0: loss = 0.011123 (* 1 = 0.011123 loss)
I0122 20:22:39.814204 70718 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 20:22:46.002313 70718 solver.cpp:266] Iteration 24100 (16.1606 iter/s, 6.18788s/100 iter), loss = 0.00880879
I0122 20:22:46.002342 70718 solver.cpp:285]     Train net output #0: loss = 0.00880872 (* 1 = 0.00880872 loss)
I0122 20:22:46.002348 70718 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 20:22:52.190340 70718 solver.cpp:266] Iteration 24200 (16.1609 iter/s, 6.18776s/100 iter), loss = 0.00561981
I0122 20:22:52.190368 70718 solver.cpp:285]     Train net output #0: loss = 0.00561973 (* 1 = 0.00561973 loss)
I0122 20:22:52.190374 70718 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 20:22:58.396522 70718 solver.cpp:266] Iteration 24300 (16.1137 iter/s, 6.20591s/100 iter), loss = 0.0192083
I0122 20:22:58.396550 70718 solver.cpp:285]     Train net output #0: loss = 0.0192082 (* 1 = 0.0192082 loss)
I0122 20:22:58.396556 70718 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 20:23:04.597750 70718 solver.cpp:266] Iteration 24400 (16.1265 iter/s, 6.20096s/100 iter), loss = 0.00976159
I0122 20:23:04.597779 70718 solver.cpp:285]     Train net output #0: loss = 0.00976151 (* 1 = 0.00976151 loss)
I0122 20:23:04.597785 70718 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 20:23:10.800704 70718 solver.cpp:266] Iteration 24500 (16.122 iter/s, 6.20269s/100 iter), loss = 0.015664
I0122 20:23:10.800782 70718 solver.cpp:285]     Train net output #0: loss = 0.0156639 (* 1 = 0.0156639 loss)
I0122 20:23:10.800791 70718 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 20:23:17.006361 70718 solver.cpp:266] Iteration 24600 (16.1151 iter/s, 6.20534s/100 iter), loss = 0.00844654
I0122 20:23:17.006388 70718 solver.cpp:285]     Train net output #0: loss = 0.00844647 (* 1 = 0.00844647 loss)
I0122 20:23:17.006393 70718 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 20:23:23.209816 70718 solver.cpp:266] Iteration 24700 (16.1207 iter/s, 6.20319s/100 iter), loss = 0.0130988
I0122 20:23:23.209844 70718 solver.cpp:285]     Train net output #0: loss = 0.0130987 (* 1 = 0.0130987 loss)
I0122 20:23:23.209851 70718 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 20:23:29.415608 70718 solver.cpp:266] Iteration 24800 (16.1147 iter/s, 6.20553s/100 iter), loss = 0.0110313
I0122 20:23:29.415637 70718 solver.cpp:285]     Train net output #0: loss = 0.0110312 (* 1 = 0.0110312 loss)
I0122 20:23:29.415643 70718 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 20:23:35.616375 70718 solver.cpp:266] Iteration 24900 (16.1277 iter/s, 6.2005s/100 iter), loss = 0.00900748
I0122 20:23:35.616415 70718 solver.cpp:285]     Train net output #0: loss = 0.0090074 (* 1 = 0.0090074 loss)
I0122 20:23:35.616421 70718 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 20:23:41.755497 70718 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 20:23:43.205276 70718 solver.cpp:517]     Test net output #0: accuracy = 0.9
I0122 20:23:43.205301 70718 solver.cpp:517]     Test net output #1: loss = 0.352507 (* 1 = 0.352507 loss)
I0122 20:23:43.205305 70718 solver.cpp:517]     Test net output #2: top-1 = 0.9
I0122 20:23:43.205308 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996667
I0122 20:23:43.266924 70718 solver.cpp:266] Iteration 25000 (13.0715 iter/s, 7.65022s/100 iter), loss = 0.00758248
I0122 20:23:43.266945 70718 solver.cpp:285]     Train net output #0: loss = 0.0075824 (* 1 = 0.0075824 loss)
I0122 20:23:43.266952 70718 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 20:23:49.455862 70718 solver.cpp:266] Iteration 25100 (16.1585 iter/s, 6.18868s/100 iter), loss = 0.00711895
I0122 20:23:49.455890 70718 solver.cpp:285]     Train net output #0: loss = 0.00711887 (* 1 = 0.00711887 loss)
I0122 20:23:49.455896 70718 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 20:23:55.659425 70718 solver.cpp:266] Iteration 25200 (16.1205 iter/s, 6.20329s/100 iter), loss = 0.0143573
I0122 20:23:55.659453 70718 solver.cpp:285]     Train net output #0: loss = 0.0143572 (* 1 = 0.0143572 loss)
I0122 20:23:55.659459 70718 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 20:24:01.868959 70718 solver.cpp:266] Iteration 25300 (16.105 iter/s, 6.20927s/100 iter), loss = 0.00880235
I0122 20:24:01.868988 70718 solver.cpp:285]     Train net output #0: loss = 0.00880228 (* 1 = 0.00880228 loss)
I0122 20:24:01.868994 70718 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 20:24:08.059651 70718 solver.cpp:266] Iteration 25400 (16.154 iter/s, 6.19043s/100 iter), loss = 0.00936099
I0122 20:24:08.059680 70718 solver.cpp:285]     Train net output #0: loss = 0.00936091 (* 1 = 0.00936091 loss)
I0122 20:24:08.059685 70718 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 20:24:14.280766 70718 solver.cpp:266] Iteration 25500 (16.075 iter/s, 6.22085s/100 iter), loss = 0.0123087
I0122 20:24:14.280867 70718 solver.cpp:285]     Train net output #0: loss = 0.0123086 (* 1 = 0.0123086 loss)
I0122 20:24:14.280874 70718 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 20:24:20.463898 70718 solver.cpp:266] Iteration 25600 (16.1739 iter/s, 6.18279s/100 iter), loss = 0.00873857
I0122 20:24:20.463927 70718 solver.cpp:285]     Train net output #0: loss = 0.00873849 (* 1 = 0.00873849 loss)
I0122 20:24:20.463932 70718 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 20:24:26.658819 70718 solver.cpp:266] Iteration 25700 (16.1429 iter/s, 6.19466s/100 iter), loss = 0.0100264
I0122 20:24:26.658845 70718 solver.cpp:285]     Train net output #0: loss = 0.0100263 (* 1 = 0.0100263 loss)
I0122 20:24:26.658850 70718 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 20:24:32.864439 70718 solver.cpp:266] Iteration 25800 (16.1151 iter/s, 6.20536s/100 iter), loss = 0.00945067
I0122 20:24:32.864468 70718 solver.cpp:285]     Train net output #0: loss = 0.0094506 (* 1 = 0.0094506 loss)
I0122 20:24:32.864475 70718 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 20:24:39.061453 70718 solver.cpp:266] Iteration 25900 (16.1375 iter/s, 6.19675s/100 iter), loss = 0.0119605
I0122 20:24:39.061483 70718 solver.cpp:285]     Train net output #0: loss = 0.0119604 (* 1 = 0.0119604 loss)
I0122 20:24:39.061489 70718 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 20:24:45.203155 70718 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 20:24:46.650770 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899666
I0122 20:24:46.650796 70718 solver.cpp:517]     Test net output #1: loss = 0.357994 (* 1 = 0.357994 loss)
I0122 20:24:46.650801 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899666
I0122 20:24:46.650804 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996778
I0122 20:24:46.712870 70718 solver.cpp:266] Iteration 26000 (13.07 iter/s, 7.6511s/100 iter), loss = 0.0101272
I0122 20:24:46.712890 70718 solver.cpp:285]     Train net output #0: loss = 0.0101271 (* 1 = 0.0101271 loss)
I0122 20:24:46.712898 70718 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 20:24:52.913715 70718 solver.cpp:266] Iteration 26100 (16.1275 iter/s, 6.20059s/100 iter), loss = 0.00681618
I0122 20:24:52.913756 70718 solver.cpp:285]     Train net output #0: loss = 0.0068161 (* 1 = 0.0068161 loss)
I0122 20:24:52.913764 70718 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 20:24:59.112232 70718 solver.cpp:266] Iteration 26200 (16.1336 iter/s, 6.19824s/100 iter), loss = 0.0023983
I0122 20:24:59.112272 70718 solver.cpp:285]     Train net output #0: loss = 0.00239822 (* 1 = 0.00239822 loss)
I0122 20:24:59.112293 70718 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 20:25:05.316318 70718 solver.cpp:266] Iteration 26300 (16.1191 iter/s, 6.20381s/100 iter), loss = 0.00913252
I0122 20:25:05.316347 70718 solver.cpp:285]     Train net output #0: loss = 0.00913244 (* 1 = 0.00913244 loss)
I0122 20:25:05.316352 70718 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 20:25:11.513371 70718 solver.cpp:266] Iteration 26400 (16.1374 iter/s, 6.19679s/100 iter), loss = 0.0137025
I0122 20:25:11.513401 70718 solver.cpp:285]     Train net output #0: loss = 0.0137025 (* 1 = 0.0137025 loss)
I0122 20:25:11.513407 70718 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 20:25:17.712505 70718 solver.cpp:266] Iteration 26500 (16.132 iter/s, 6.19887s/100 iter), loss = 0.0038352
I0122 20:25:17.712625 70718 solver.cpp:285]     Train net output #0: loss = 0.00383512 (* 1 = 0.00383512 loss)
I0122 20:25:17.712632 70718 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 20:25:23.903621 70718 solver.cpp:266] Iteration 26600 (16.1531 iter/s, 6.19076s/100 iter), loss = 0.0140946
I0122 20:25:23.903650 70718 solver.cpp:285]     Train net output #0: loss = 0.0140945 (* 1 = 0.0140945 loss)
I0122 20:25:23.903656 70718 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 20:25:30.113137 70718 solver.cpp:266] Iteration 26700 (16.105 iter/s, 6.20925s/100 iter), loss = 0.00752431
I0122 20:25:30.113164 70718 solver.cpp:285]     Train net output #0: loss = 0.00752422 (* 1 = 0.00752422 loss)
I0122 20:25:30.113170 70718 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 20:25:36.304330 70718 solver.cpp:266] Iteration 26800 (16.1527 iter/s, 6.19093s/100 iter), loss = 0.00832125
I0122 20:25:36.304359 70718 solver.cpp:285]     Train net output #0: loss = 0.00832117 (* 1 = 0.00832117 loss)
I0122 20:25:36.304364 70718 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 20:25:42.503196 70718 solver.cpp:266] Iteration 26900 (16.1327 iter/s, 6.1986s/100 iter), loss = 0.00949964
I0122 20:25:42.503224 70718 solver.cpp:285]     Train net output #0: loss = 0.00949956 (* 1 = 0.00949956 loss)
I0122 20:25:42.503231 70718 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 20:25:48.630139 70718 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 20:25:50.077003 70718 solver.cpp:517]     Test net output #0: accuracy = 0.898667
I0122 20:25:50.077028 70718 solver.cpp:517]     Test net output #1: loss = 0.361246 (* 1 = 0.361246 loss)
I0122 20:25:50.077033 70718 solver.cpp:517]     Test net output #2: top-1 = 0.898667
I0122 20:25:50.077035 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:25:50.138839 70718 solver.cpp:266] Iteration 27000 (13.097 iter/s, 7.63533s/100 iter), loss = 0.00374075
I0122 20:25:50.138860 70718 solver.cpp:285]     Train net output #0: loss = 0.00374067 (* 1 = 0.00374067 loss)
I0122 20:25:50.138867 70718 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 20:25:56.345070 70718 solver.cpp:266] Iteration 27100 (16.1135 iter/s, 6.20597s/100 iter), loss = 0.011796
I0122 20:25:56.345100 70718 solver.cpp:285]     Train net output #0: loss = 0.0117959 (* 1 = 0.0117959 loss)
I0122 20:25:56.345105 70718 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 20:26:02.542425 70718 solver.cpp:266] Iteration 27200 (16.1366 iter/s, 6.19709s/100 iter), loss = 0.00469637
I0122 20:26:02.542454 70718 solver.cpp:285]     Train net output #0: loss = 0.0046963 (* 1 = 0.0046963 loss)
I0122 20:26:02.542459 70718 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 20:26:08.721525 70718 solver.cpp:266] Iteration 27300 (16.1843 iter/s, 6.17884s/100 iter), loss = 0.00460201
I0122 20:26:08.721554 70718 solver.cpp:285]     Train net output #0: loss = 0.00460194 (* 1 = 0.00460194 loss)
I0122 20:26:08.721560 70718 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 20:26:14.917357 70718 solver.cpp:266] Iteration 27400 (16.1406 iter/s, 6.19557s/100 iter), loss = 0.00514257
I0122 20:26:14.917387 70718 solver.cpp:285]     Train net output #0: loss = 0.00514249 (* 1 = 0.00514249 loss)
I0122 20:26:14.917392 70718 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 20:26:21.120872 70718 solver.cpp:266] Iteration 27500 (16.1206 iter/s, 6.20325s/100 iter), loss = 0.00566148
I0122 20:26:21.120950 70718 solver.cpp:285]     Train net output #0: loss = 0.0056614 (* 1 = 0.0056614 loss)
I0122 20:26:21.120957 70718 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 20:26:27.316151 70718 solver.cpp:266] Iteration 27600 (16.1421 iter/s, 6.19497s/100 iter), loss = 0.00593666
I0122 20:26:27.316179 70718 solver.cpp:285]     Train net output #0: loss = 0.00593658 (* 1 = 0.00593658 loss)
I0122 20:26:27.316185 70718 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 20:26:33.530978 70718 solver.cpp:266] Iteration 27700 (16.0912 iter/s, 6.21456s/100 iter), loss = 0.00332879
I0122 20:26:33.531008 70718 solver.cpp:285]     Train net output #0: loss = 0.00332871 (* 1 = 0.00332871 loss)
I0122 20:26:33.531013 70718 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 20:26:39.732965 70718 solver.cpp:266] Iteration 27800 (16.1246 iter/s, 6.20172s/100 iter), loss = 0.0124262
I0122 20:26:39.732995 70718 solver.cpp:285]     Train net output #0: loss = 0.0124261 (* 1 = 0.0124261 loss)
I0122 20:26:39.733000 70718 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 20:26:45.924360 70718 solver.cpp:266] Iteration 27900 (16.1521 iter/s, 6.19113s/100 iter), loss = 0.00406756
I0122 20:26:45.924388 70718 solver.cpp:285]     Train net output #0: loss = 0.00406748 (* 1 = 0.00406748 loss)
I0122 20:26:45.924394 70718 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 20:26:52.078770 70718 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 20:26:53.533629 70718 solver.cpp:517]     Test net output #0: accuracy = 0.900889
I0122 20:26:53.533655 70718 solver.cpp:517]     Test net output #1: loss = 0.360952 (* 1 = 0.360952 loss)
I0122 20:26:53.533659 70718 solver.cpp:517]     Test net output #2: top-1 = 0.900889
I0122 20:26:53.533663 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 20:26:53.595118 70718 solver.cpp:266] Iteration 28000 (13.0371 iter/s, 7.67044s/100 iter), loss = 0.00584294
I0122 20:26:53.595139 70718 solver.cpp:285]     Train net output #0: loss = 0.00584286 (* 1 = 0.00584286 loss)
I0122 20:26:53.595144 70718 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 20:26:59.802543 70718 solver.cpp:266] Iteration 28100 (16.1104 iter/s, 6.20717s/100 iter), loss = 0.00397279
I0122 20:26:59.802572 70718 solver.cpp:285]     Train net output #0: loss = 0.00397272 (* 1 = 0.00397272 loss)
I0122 20:26:59.802578 70718 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 20:27:06.003203 70718 solver.cpp:266] Iteration 28200 (16.128 iter/s, 6.20039s/100 iter), loss = 0.00622059
I0122 20:27:06.003232 70718 solver.cpp:285]     Train net output #0: loss = 0.00622051 (* 1 = 0.00622051 loss)
I0122 20:27:06.003238 70718 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 20:27:12.196523 70718 solver.cpp:266] Iteration 28300 (16.1471 iter/s, 6.19305s/100 iter), loss = 0.00555125
I0122 20:27:12.196552 70718 solver.cpp:285]     Train net output #0: loss = 0.00555117 (* 1 = 0.00555117 loss)
I0122 20:27:12.196558 70718 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 20:27:18.402312 70718 solver.cpp:266] Iteration 28400 (16.1147 iter/s, 6.20552s/100 iter), loss = 0.00682436
I0122 20:27:18.402340 70718 solver.cpp:285]     Train net output #0: loss = 0.00682428 (* 1 = 0.00682428 loss)
I0122 20:27:18.402346 70718 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 20:27:24.619565 70718 solver.cpp:266] Iteration 28500 (16.085 iter/s, 6.21699s/100 iter), loss = 0.0035756
I0122 20:27:24.619647 70718 solver.cpp:285]     Train net output #0: loss = 0.00357552 (* 1 = 0.00357552 loss)
I0122 20:27:24.619653 70718 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 20:27:30.828804 70718 solver.cpp:266] Iteration 28600 (16.1059 iter/s, 6.20892s/100 iter), loss = 0.0232265
I0122 20:27:30.828845 70718 solver.cpp:285]     Train net output #0: loss = 0.0232264 (* 1 = 0.0232264 loss)
I0122 20:27:30.828851 70718 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 20:27:37.044334 70718 solver.cpp:266] Iteration 28700 (16.0895 iter/s, 6.21525s/100 iter), loss = 0.00687387
I0122 20:27:37.044375 70718 solver.cpp:285]     Train net output #0: loss = 0.00687379 (* 1 = 0.00687379 loss)
I0122 20:27:37.044384 70718 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 20:27:43.259141 70718 solver.cpp:266] Iteration 28800 (16.0913 iter/s, 6.21453s/100 iter), loss = 0.00812762
I0122 20:27:43.259169 70718 solver.cpp:285]     Train net output #0: loss = 0.00812754 (* 1 = 0.00812754 loss)
I0122 20:27:43.259174 70718 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 20:27:49.467222 70718 solver.cpp:266] Iteration 28900 (16.1087 iter/s, 6.20781s/100 iter), loss = 0.0142634
I0122 20:27:49.467264 70718 solver.cpp:285]     Train net output #0: loss = 0.0142634 (* 1 = 0.0142634 loss)
I0122 20:27:49.467272 70718 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 20:27:55.622332 70718 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 20:27:57.069805 70718 solver.cpp:517]     Test net output #0: accuracy = 0.901889
I0122 20:27:57.069829 70718 solver.cpp:517]     Test net output #1: loss = 0.363654 (* 1 = 0.363654 loss)
I0122 20:27:57.069833 70718 solver.cpp:517]     Test net output #2: top-1 = 0.901889
I0122 20:27:57.069836 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 20:27:57.131084 70718 solver.cpp:266] Iteration 29000 (13.0488 iter/s, 7.66353s/100 iter), loss = 0.00567331
I0122 20:27:57.131104 70718 solver.cpp:285]     Train net output #0: loss = 0.00567323 (* 1 = 0.00567323 loss)
I0122 20:27:57.131110 70718 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 20:28:03.326337 70718 solver.cpp:266] Iteration 29100 (16.1421 iter/s, 6.19499s/100 iter), loss = 0.0041811
I0122 20:28:03.326377 70718 solver.cpp:285]     Train net output #0: loss = 0.00418102 (* 1 = 0.00418102 loss)
I0122 20:28:03.326383 70718 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 20:28:09.530923 70718 solver.cpp:266] Iteration 29200 (16.1178 iter/s, 6.20431s/100 iter), loss = 0.00975759
I0122 20:28:09.530952 70718 solver.cpp:285]     Train net output #0: loss = 0.00975751 (* 1 = 0.00975751 loss)
I0122 20:28:09.530958 70718 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 20:28:15.732195 70718 solver.cpp:266] Iteration 29300 (16.1264 iter/s, 6.20101s/100 iter), loss = 0.0138762
I0122 20:28:15.732223 70718 solver.cpp:285]     Train net output #0: loss = 0.0138761 (* 1 = 0.0138761 loss)
I0122 20:28:15.732228 70718 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 20:28:21.936951 70718 solver.cpp:266] Iteration 29400 (16.1174 iter/s, 6.20449s/100 iter), loss = 0.00695865
I0122 20:28:21.936980 70718 solver.cpp:285]     Train net output #0: loss = 0.00695857 (* 1 = 0.00695857 loss)
I0122 20:28:21.936986 70718 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 20:28:28.147964 70718 solver.cpp:266] Iteration 29500 (16.1011 iter/s, 6.21075s/100 iter), loss = 0.00339745
I0122 20:28:28.148026 70718 solver.cpp:285]     Train net output #0: loss = 0.00339736 (* 1 = 0.00339736 loss)
I0122 20:28:28.148032 70718 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 20:28:34.357475 70718 solver.cpp:266] Iteration 29600 (16.1051 iter/s, 6.20921s/100 iter), loss = 0.00881534
I0122 20:28:34.357503 70718 solver.cpp:285]     Train net output #0: loss = 0.00881526 (* 1 = 0.00881526 loss)
I0122 20:28:34.357511 70718 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 20:28:40.564875 70718 solver.cpp:266] Iteration 29700 (16.1105 iter/s, 6.20714s/100 iter), loss = 0.00716699
I0122 20:28:40.564916 70718 solver.cpp:285]     Train net output #0: loss = 0.0071669 (* 1 = 0.0071669 loss)
I0122 20:28:40.564923 70718 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 20:28:46.767171 70718 solver.cpp:266] Iteration 29800 (16.1238 iter/s, 6.20202s/100 iter), loss = 0.00469171
I0122 20:28:46.767211 70718 solver.cpp:285]     Train net output #0: loss = 0.00469163 (* 1 = 0.00469163 loss)
I0122 20:28:46.767218 70718 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 20:28:52.972595 70718 solver.cpp:266] Iteration 29900 (16.1157 iter/s, 6.20515s/100 iter), loss = 0.00532881
I0122 20:28:52.972625 70718 solver.cpp:285]     Train net output #0: loss = 0.00532872 (* 1 = 0.00532872 loss)
I0122 20:28:52.972631 70718 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 20:28:59.108914 70718 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 20:29:00.567732 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899778
I0122 20:29:00.567755 70718 solver.cpp:517]     Test net output #1: loss = 0.365968 (* 1 = 0.365968 loss)
I0122 20:29:00.567759 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899778
I0122 20:29:00.567762 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 20:29:00.630275 70718 solver.cpp:266] Iteration 30000 (13.0593 iter/s, 7.65736s/100 iter), loss = 0.00552254
I0122 20:29:00.630295 70718 solver.cpp:285]     Train net output #0: loss = 0.00552246 (* 1 = 0.00552246 loss)
I0122 20:29:00.630302 70718 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 20:29:06.829299 70718 solver.cpp:266] Iteration 30100 (16.1322 iter/s, 6.19877s/100 iter), loss = 0.00611626
I0122 20:29:06.829329 70718 solver.cpp:285]     Train net output #0: loss = 0.00611618 (* 1 = 0.00611618 loss)
I0122 20:29:06.829334 70718 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 20:29:13.037106 70718 solver.cpp:266] Iteration 30200 (16.1094 iter/s, 6.20754s/100 iter), loss = 0.0123182
I0122 20:29:13.037134 70718 solver.cpp:285]     Train net output #0: loss = 0.0123181 (* 1 = 0.0123181 loss)
I0122 20:29:13.037140 70718 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 20:29:19.234654 70718 solver.cpp:266] Iteration 30300 (16.1361 iter/s, 6.19728s/100 iter), loss = 0.00561252
I0122 20:29:19.234695 70718 solver.cpp:285]     Train net output #0: loss = 0.00561244 (* 1 = 0.00561244 loss)
I0122 20:29:19.234702 70718 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 20:29:25.445528 70718 solver.cpp:266] Iteration 30400 (16.1015 iter/s, 6.21059s/100 iter), loss = 0.00333682
I0122 20:29:25.445555 70718 solver.cpp:285]     Train net output #0: loss = 0.00333674 (* 1 = 0.00333674 loss)
I0122 20:29:25.445561 70718 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 20:29:31.650308 70718 solver.cpp:266] Iteration 30500 (16.1173 iter/s, 6.20451s/100 iter), loss = 0.00641494
I0122 20:29:31.650384 70718 solver.cpp:285]     Train net output #0: loss = 0.00641485 (* 1 = 0.00641485 loss)
I0122 20:29:31.650393 70718 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 20:29:37.840692 70718 solver.cpp:266] Iteration 30600 (16.1549 iter/s, 6.19007s/100 iter), loss = 0.00667516
I0122 20:29:37.840719 70718 solver.cpp:285]     Train net output #0: loss = 0.00667507 (* 1 = 0.00667507 loss)
I0122 20:29:37.840725 70718 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 20:29:44.038494 70718 solver.cpp:266] Iteration 30700 (16.1354 iter/s, 6.19754s/100 iter), loss = 0.00302001
I0122 20:29:44.038524 70718 solver.cpp:285]     Train net output #0: loss = 0.00301992 (* 1 = 0.00301992 loss)
I0122 20:29:44.038530 70718 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 20:29:50.244926 70718 solver.cpp:266] Iteration 30800 (16.113 iter/s, 6.20616s/100 iter), loss = 0.00745495
I0122 20:29:50.244953 70718 solver.cpp:285]     Train net output #0: loss = 0.00745486 (* 1 = 0.00745486 loss)
I0122 20:29:50.244961 70718 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 20:29:56.443433 70718 solver.cpp:266] Iteration 30900 (16.1336 iter/s, 6.19824s/100 iter), loss = 0.00525521
I0122 20:29:56.443461 70718 solver.cpp:285]     Train net output #0: loss = 0.00525513 (* 1 = 0.00525513 loss)
I0122 20:29:56.443480 70718 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 20:30:02.579411 70718 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 20:30:04.030552 70718 solver.cpp:517]     Test net output #0: accuracy = 0.9
I0122 20:30:04.030575 70718 solver.cpp:517]     Test net output #1: loss = 0.370193 (* 1 = 0.370193 loss)
I0122 20:30:04.030580 70718 solver.cpp:517]     Test net output #2: top-1 = 0.9
I0122 20:30:04.030583 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996444
I0122 20:30:04.092964 70718 solver.cpp:266] Iteration 31000 (13.0732 iter/s, 7.64921s/100 iter), loss = 0.00794866
I0122 20:30:04.092985 70718 solver.cpp:285]     Train net output #0: loss = 0.00794857 (* 1 = 0.00794857 loss)
I0122 20:30:04.092993 70718 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 20:30:10.292094 70718 solver.cpp:266] Iteration 31100 (16.132 iter/s, 6.19887s/100 iter), loss = 0.0066325
I0122 20:30:10.292124 70718 solver.cpp:285]     Train net output #0: loss = 0.00663241 (* 1 = 0.00663241 loss)
I0122 20:30:10.292129 70718 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 20:30:16.485491 70718 solver.cpp:266] Iteration 31200 (16.1469 iter/s, 6.19313s/100 iter), loss = 0.00355822
I0122 20:30:16.485530 70718 solver.cpp:285]     Train net output #0: loss = 0.00355814 (* 1 = 0.00355814 loss)
I0122 20:30:16.485538 70718 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 20:30:22.691915 70718 solver.cpp:266] Iteration 31300 (16.1131 iter/s, 6.20615s/100 iter), loss = 0.00330803
I0122 20:30:22.691946 70718 solver.cpp:285]     Train net output #0: loss = 0.00330795 (* 1 = 0.00330795 loss)
I0122 20:30:22.691951 70718 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 20:30:28.902386 70718 solver.cpp:266] Iteration 31400 (16.1025 iter/s, 6.2102s/100 iter), loss = 0.00743019
I0122 20:30:28.902426 70718 solver.cpp:285]     Train net output #0: loss = 0.00743011 (* 1 = 0.00743011 loss)
I0122 20:30:28.902434 70718 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 20:30:35.109926 70718 solver.cpp:266] Iteration 31500 (16.1102 iter/s, 6.20726s/100 iter), loss = 0.00481854
I0122 20:30:35.109987 70718 solver.cpp:285]     Train net output #0: loss = 0.00481846 (* 1 = 0.00481846 loss)
I0122 20:30:35.109993 70718 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 20:30:41.317920 70718 solver.cpp:266] Iteration 31600 (16.109 iter/s, 6.2077s/100 iter), loss = 0.00606318
I0122 20:30:41.317948 70718 solver.cpp:285]     Train net output #0: loss = 0.0060631 (* 1 = 0.0060631 loss)
I0122 20:30:41.317955 70718 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 20:30:47.522336 70718 solver.cpp:266] Iteration 31700 (16.1182 iter/s, 6.20415s/100 iter), loss = 0.00496643
I0122 20:30:47.522366 70718 solver.cpp:285]     Train net output #0: loss = 0.00496635 (* 1 = 0.00496635 loss)
I0122 20:30:47.522387 70718 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 20:30:53.727798 70718 solver.cpp:266] Iteration 31800 (16.1155 iter/s, 6.2052s/100 iter), loss = 0.00943733
I0122 20:30:53.727826 70718 solver.cpp:285]     Train net output #0: loss = 0.00943725 (* 1 = 0.00943725 loss)
I0122 20:30:53.727833 70718 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 20:30:59.923460 70718 solver.cpp:266] Iteration 31900 (16.141 iter/s, 6.1954s/100 iter), loss = 0.00501113
I0122 20:30:59.923488 70718 solver.cpp:285]     Train net output #0: loss = 0.00501105 (* 1 = 0.00501105 loss)
I0122 20:30:59.923496 70718 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 20:31:06.059522 70718 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 20:31:07.511231 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899444
I0122 20:31:07.511255 70718 solver.cpp:517]     Test net output #1: loss = 0.372118 (* 1 = 0.372118 loss)
I0122 20:31:07.511260 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899444
I0122 20:31:07.511265 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 20:31:07.572461 70718 solver.cpp:266] Iteration 32000 (13.0741 iter/s, 7.64868s/100 iter), loss = 0.00361351
I0122 20:31:07.572482 70718 solver.cpp:285]     Train net output #0: loss = 0.00361343 (* 1 = 0.00361343 loss)
I0122 20:31:07.572489 70718 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 20:31:13.765342 70718 solver.cpp:266] Iteration 32100 (16.1482 iter/s, 6.19262s/100 iter), loss = 0.00753389
I0122 20:31:13.765369 70718 solver.cpp:285]     Train net output #0: loss = 0.0075338 (* 1 = 0.0075338 loss)
I0122 20:31:13.765375 70718 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 20:31:19.968930 70718 solver.cpp:266] Iteration 32200 (16.1204 iter/s, 6.20332s/100 iter), loss = 0.00415799
I0122 20:31:19.968957 70718 solver.cpp:285]     Train net output #0: loss = 0.00415791 (* 1 = 0.00415791 loss)
I0122 20:31:19.968963 70718 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 20:31:26.171748 70718 solver.cpp:266] Iteration 32300 (16.1224 iter/s, 6.20255s/100 iter), loss = 0.018667
I0122 20:31:26.171777 70718 solver.cpp:285]     Train net output #0: loss = 0.0186669 (* 1 = 0.0186669 loss)
I0122 20:31:26.171783 70718 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 20:31:32.377636 70718 solver.cpp:266] Iteration 32400 (16.1144 iter/s, 6.20562s/100 iter), loss = 0.00612738
I0122 20:31:32.377665 70718 solver.cpp:285]     Train net output #0: loss = 0.0061273 (* 1 = 0.0061273 loss)
I0122 20:31:32.377671 70718 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 20:31:38.588007 70718 solver.cpp:266] Iteration 32500 (16.1028 iter/s, 6.2101s/100 iter), loss = 0.00531083
I0122 20:31:38.588104 70718 solver.cpp:285]     Train net output #0: loss = 0.00531075 (* 1 = 0.00531075 loss)
I0122 20:31:38.588112 70718 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 20:31:44.793982 70718 solver.cpp:266] Iteration 32600 (16.1144 iter/s, 6.20564s/100 iter), loss = 0.0066058
I0122 20:31:44.794011 70718 solver.cpp:285]     Train net output #0: loss = 0.00660572 (* 1 = 0.00660572 loss)
I0122 20:31:44.794018 70718 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 20:31:50.993175 70718 solver.cpp:266] Iteration 32700 (16.1318 iter/s, 6.19893s/100 iter), loss = 0.00472253
I0122 20:31:50.993202 70718 solver.cpp:285]     Train net output #0: loss = 0.00472245 (* 1 = 0.00472245 loss)
I0122 20:31:50.993208 70718 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 20:31:57.176762 70718 solver.cpp:266] Iteration 32800 (16.1725 iter/s, 6.18332s/100 iter), loss = 0.00654015
I0122 20:31:57.176801 70718 solver.cpp:285]     Train net output #0: loss = 0.00654006 (* 1 = 0.00654006 loss)
I0122 20:31:57.176808 70718 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 20:32:03.382206 70718 solver.cpp:266] Iteration 32900 (16.1156 iter/s, 6.20517s/100 iter), loss = 0.00735087
I0122 20:32:03.382233 70718 solver.cpp:285]     Train net output #0: loss = 0.00735079 (* 1 = 0.00735079 loss)
I0122 20:32:03.382239 70718 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 20:32:09.546061 70718 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 20:32:10.994668 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 20:32:10.994694 70718 solver.cpp:517]     Test net output #1: loss = 0.372893 (* 1 = 0.372893 loss)
I0122 20:32:10.994699 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 20:32:10.994702 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 20:32:11.055877 70718 solver.cpp:266] Iteration 33000 (13.0321 iter/s, 7.67336s/100 iter), loss = 0.00590706
I0122 20:32:11.055908 70718 solver.cpp:285]     Train net output #0: loss = 0.00590698 (* 1 = 0.00590698 loss)
I0122 20:32:11.055917 70718 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 20:32:17.264212 70718 solver.cpp:266] Iteration 33100 (16.1081 iter/s, 6.20807s/100 iter), loss = 0.00435368
I0122 20:32:17.264252 70718 solver.cpp:285]     Train net output #0: loss = 0.0043536 (* 1 = 0.0043536 loss)
I0122 20:32:17.264259 70718 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 20:32:23.472419 70718 solver.cpp:266] Iteration 33200 (16.1084 iter/s, 6.20794s/100 iter), loss = 0.00287423
I0122 20:32:23.472460 70718 solver.cpp:285]     Train net output #0: loss = 0.00287415 (* 1 = 0.00287415 loss)
I0122 20:32:23.472466 70718 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 20:32:29.676168 70718 solver.cpp:266] Iteration 33300 (16.12 iter/s, 6.20347s/100 iter), loss = 0.00423889
I0122 20:32:29.676196 70718 solver.cpp:285]     Train net output #0: loss = 0.00423881 (* 1 = 0.00423881 loss)
I0122 20:32:29.676203 70718 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 20:32:35.874743 70718 solver.cpp:266] Iteration 33400 (16.1334 iter/s, 6.19831s/100 iter), loss = 0.00327488
I0122 20:32:35.874783 70718 solver.cpp:285]     Train net output #0: loss = 0.00327479 (* 1 = 0.00327479 loss)
I0122 20:32:35.874790 70718 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 20:32:42.091066 70718 solver.cpp:266] Iteration 33500 (16.0874 iter/s, 6.21605s/100 iter), loss = 0.00835461
I0122 20:32:42.091181 70718 solver.cpp:285]     Train net output #0: loss = 0.00835453 (* 1 = 0.00835453 loss)
I0122 20:32:42.091188 70718 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 20:32:48.284765 70718 solver.cpp:266] Iteration 33600 (16.1464 iter/s, 6.19335s/100 iter), loss = 0.00557956
I0122 20:32:48.284792 70718 solver.cpp:285]     Train net output #0: loss = 0.00557948 (* 1 = 0.00557948 loss)
I0122 20:32:48.284799 70718 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 20:32:54.498208 70718 solver.cpp:266] Iteration 33700 (16.0948 iter/s, 6.21318s/100 iter), loss = 0.00878324
I0122 20:32:54.498235 70718 solver.cpp:285]     Train net output #0: loss = 0.00878316 (* 1 = 0.00878316 loss)
I0122 20:32:54.498241 70718 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 20:33:00.685140 70718 solver.cpp:266] Iteration 33800 (16.1638 iter/s, 6.18667s/100 iter), loss = 0.00693649
I0122 20:33:00.685168 70718 solver.cpp:285]     Train net output #0: loss = 0.00693641 (* 1 = 0.00693641 loss)
I0122 20:33:00.685174 70718 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 20:33:06.893698 70718 solver.cpp:266] Iteration 33900 (16.1075 iter/s, 6.20829s/100 iter), loss = 0.00516509
I0122 20:33:06.893739 70718 solver.cpp:285]     Train net output #0: loss = 0.00516501 (* 1 = 0.00516501 loss)
I0122 20:33:06.893762 70718 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 20:33:13.041708 70718 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 20:33:14.494040 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 20:33:14.494065 70718 solver.cpp:517]     Test net output #1: loss = 0.373453 (* 1 = 0.373453 loss)
I0122 20:33:14.494068 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 20:33:14.494071 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:33:14.556102 70718 solver.cpp:266] Iteration 34000 (13.0513 iter/s, 7.66207s/100 iter), loss = 0.00311512
I0122 20:33:14.556133 70718 solver.cpp:285]     Train net output #0: loss = 0.00311504 (* 1 = 0.00311504 loss)
I0122 20:33:14.556140 70718 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 20:33:20.763397 70718 solver.cpp:266] Iteration 34100 (16.1108 iter/s, 6.20703s/100 iter), loss = 0.00635277
I0122 20:33:20.763425 70718 solver.cpp:285]     Train net output #0: loss = 0.00635269 (* 1 = 0.00635269 loss)
I0122 20:33:20.763432 70718 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 20:33:26.974340 70718 solver.cpp:266] Iteration 34200 (16.1013 iter/s, 6.21068s/100 iter), loss = 0.0076815
I0122 20:33:26.974380 70718 solver.cpp:285]     Train net output #0: loss = 0.00768141 (* 1 = 0.00768141 loss)
I0122 20:33:26.974385 70718 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 20:33:33.179988 70718 solver.cpp:266] Iteration 34300 (16.1151 iter/s, 6.20537s/100 iter), loss = 0.00447896
I0122 20:33:33.180016 70718 solver.cpp:285]     Train net output #0: loss = 0.00447888 (* 1 = 0.00447888 loss)
I0122 20:33:33.180022 70718 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 20:33:39.372658 70718 solver.cpp:266] Iteration 34400 (16.1488 iter/s, 6.1924s/100 iter), loss = 0.0172971
I0122 20:33:39.372685 70718 solver.cpp:285]     Train net output #0: loss = 0.017297 (* 1 = 0.017297 loss)
I0122 20:33:39.372691 70718 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 20:33:45.575791 70718 solver.cpp:266] Iteration 34500 (16.1216 iter/s, 6.20287s/100 iter), loss = 0.00612893
I0122 20:33:45.575913 70718 solver.cpp:285]     Train net output #0: loss = 0.00612884 (* 1 = 0.00612884 loss)
I0122 20:33:45.575922 70718 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 20:33:51.775367 70718 solver.cpp:266] Iteration 34600 (16.1311 iter/s, 6.19922s/100 iter), loss = 0.0105193
I0122 20:33:51.775394 70718 solver.cpp:285]     Train net output #0: loss = 0.0105192 (* 1 = 0.0105192 loss)
I0122 20:33:51.775400 70718 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 20:33:57.966023 70718 solver.cpp:266] Iteration 34700 (16.1541 iter/s, 6.19039s/100 iter), loss = 0.00370432
I0122 20:33:57.966063 70718 solver.cpp:285]     Train net output #0: loss = 0.00370424 (* 1 = 0.00370424 loss)
I0122 20:33:57.966069 70718 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 20:34:04.174996 70718 solver.cpp:266] Iteration 34800 (16.1064 iter/s, 6.2087s/100 iter), loss = 0.00295221
I0122 20:34:04.175024 70718 solver.cpp:285]     Train net output #0: loss = 0.00295212 (* 1 = 0.00295212 loss)
I0122 20:34:04.175029 70718 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 20:34:10.372938 70718 solver.cpp:266] Iteration 34900 (16.1351 iter/s, 6.19768s/100 iter), loss = 0.0156529
I0122 20:34:10.372967 70718 solver.cpp:285]     Train net output #0: loss = 0.0156528 (* 1 = 0.0156528 loss)
I0122 20:34:10.372973 70718 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 20:34:16.526171 70718 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 20:34:17.971680 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 20:34:17.971705 70718 solver.cpp:517]     Test net output #1: loss = 0.373393 (* 1 = 0.373393 loss)
I0122 20:34:17.971710 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 20:34:17.971714 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:34:18.033236 70718 solver.cpp:266] Iteration 35000 (13.0549 iter/s, 7.65998s/100 iter), loss = 0.00689614
I0122 20:34:18.033267 70718 solver.cpp:285]     Train net output #0: loss = 0.00689605 (* 1 = 0.00689605 loss)
I0122 20:34:18.033274 70718 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 20:34:24.237941 70718 solver.cpp:266] Iteration 35100 (16.1175 iter/s, 6.20444s/100 iter), loss = 0.00329959
I0122 20:34:24.237968 70718 solver.cpp:285]     Train net output #0: loss = 0.0032995 (* 1 = 0.0032995 loss)
I0122 20:34:24.237975 70718 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 20:34:30.448900 70718 solver.cpp:266] Iteration 35200 (16.1013 iter/s, 6.21069s/100 iter), loss = 0.00359551
I0122 20:34:30.448930 70718 solver.cpp:285]     Train net output #0: loss = 0.00359543 (* 1 = 0.00359543 loss)
I0122 20:34:30.448935 70718 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 20:34:36.649828 70718 solver.cpp:266] Iteration 35300 (16.1273 iter/s, 6.20066s/100 iter), loss = 0.00708786
I0122 20:34:36.649855 70718 solver.cpp:285]     Train net output #0: loss = 0.00708778 (* 1 = 0.00708778 loss)
I0122 20:34:36.649861 70718 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 20:34:42.836593 70718 solver.cpp:266] Iteration 35400 (16.1642 iter/s, 6.1865s/100 iter), loss = 0.00645593
I0122 20:34:42.836633 70718 solver.cpp:285]     Train net output #0: loss = 0.00645585 (* 1 = 0.00645585 loss)
I0122 20:34:42.836640 70718 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 20:34:49.043642 70718 solver.cpp:266] Iteration 35500 (16.1114 iter/s, 6.20677s/100 iter), loss = 0.00355811
I0122 20:34:49.043735 70718 solver.cpp:285]     Train net output #0: loss = 0.00355803 (* 1 = 0.00355803 loss)
I0122 20:34:49.043743 70718 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 20:34:55.234828 70718 solver.cpp:266] Iteration 35600 (16.1529 iter/s, 6.19086s/100 iter), loss = 0.00365341
I0122 20:34:55.234856 70718 solver.cpp:285]     Train net output #0: loss = 0.00365333 (* 1 = 0.00365333 loss)
I0122 20:34:55.234863 70718 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 20:35:01.434854 70718 solver.cpp:266] Iteration 35700 (16.1297 iter/s, 6.19976s/100 iter), loss = 0.00697216
I0122 20:35:01.434883 70718 solver.cpp:285]     Train net output #0: loss = 0.00697208 (* 1 = 0.00697208 loss)
I0122 20:35:01.434890 70718 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 20:35:07.637023 70718 solver.cpp:266] Iteration 35800 (16.1241 iter/s, 6.2019s/100 iter), loss = 0.0077624
I0122 20:35:07.637050 70718 solver.cpp:285]     Train net output #0: loss = 0.00776232 (* 1 = 0.00776232 loss)
I0122 20:35:07.637058 70718 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 20:35:13.827513 70718 solver.cpp:266] Iteration 35900 (16.1545 iter/s, 6.19023s/100 iter), loss = 0.0125554
I0122 20:35:13.827543 70718 solver.cpp:285]     Train net output #0: loss = 0.0125553 (* 1 = 0.0125553 loss)
I0122 20:35:13.827548 70718 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 20:35:19.979404 70718 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 20:35:21.426430 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 20:35:21.426455 70718 solver.cpp:517]     Test net output #1: loss = 0.37363 (* 1 = 0.37363 loss)
I0122 20:35:21.426460 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 20:35:21.426463 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 20:35:21.489015 70718 solver.cpp:266] Iteration 36000 (13.0528 iter/s, 7.66119s/100 iter), loss = 0.00802551
I0122 20:35:21.489037 70718 solver.cpp:285]     Train net output #0: loss = 0.00802543 (* 1 = 0.00802543 loss)
I0122 20:35:21.489043 70718 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 20:35:27.711336 70718 solver.cpp:266] Iteration 36100 (16.0718 iter/s, 6.22206s/100 iter), loss = 0.00395506
I0122 20:35:27.711364 70718 solver.cpp:285]     Train net output #0: loss = 0.00395498 (* 1 = 0.00395498 loss)
I0122 20:35:27.711369 70718 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 20:35:33.902087 70718 solver.cpp:266] Iteration 36200 (16.1538 iter/s, 6.19049s/100 iter), loss = 0.0034668
I0122 20:35:33.902117 70718 solver.cpp:285]     Train net output #0: loss = 0.00346672 (* 1 = 0.00346672 loss)
I0122 20:35:33.902122 70718 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 20:35:40.110222 70718 solver.cpp:266] Iteration 36300 (16.1086 iter/s, 6.20787s/100 iter), loss = 0.00740461
I0122 20:35:40.110250 70718 solver.cpp:285]     Train net output #0: loss = 0.00740452 (* 1 = 0.00740452 loss)
I0122 20:35:40.110256 70718 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 20:35:46.326431 70718 solver.cpp:266] Iteration 36400 (16.0877 iter/s, 6.21594s/100 iter), loss = 0.00399333
I0122 20:35:46.326458 70718 solver.cpp:285]     Train net output #0: loss = 0.00399325 (* 1 = 0.00399325 loss)
I0122 20:35:46.326463 70718 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 20:35:52.525502 70718 solver.cpp:266] Iteration 36500 (16.1321 iter/s, 6.19881s/100 iter), loss = 0.0047178
I0122 20:35:52.525562 70718 solver.cpp:285]     Train net output #0: loss = 0.00471772 (* 1 = 0.00471772 loss)
I0122 20:35:52.525568 70718 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 20:35:58.735944 70718 solver.cpp:266] Iteration 36600 (16.1027 iter/s, 6.21015s/100 iter), loss = 0.00435263
I0122 20:35:58.735982 70718 solver.cpp:285]     Train net output #0: loss = 0.00435254 (* 1 = 0.00435254 loss)
I0122 20:35:58.735990 70718 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 20:36:04.941591 70718 solver.cpp:266] Iteration 36700 (16.115 iter/s, 6.20538s/100 iter), loss = 0.00391698
I0122 20:36:04.941617 70718 solver.cpp:285]     Train net output #0: loss = 0.0039169 (* 1 = 0.0039169 loss)
I0122 20:36:04.941639 70718 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 20:36:11.143576 70718 solver.cpp:266] Iteration 36800 (16.1246 iter/s, 6.20172s/100 iter), loss = 0.00509807
I0122 20:36:11.143604 70718 solver.cpp:285]     Train net output #0: loss = 0.00509799 (* 1 = 0.00509799 loss)
I0122 20:36:11.143610 70718 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 20:36:17.350001 70718 solver.cpp:266] Iteration 36900 (16.113 iter/s, 6.20616s/100 iter), loss = 0.00422166
I0122 20:36:17.350029 70718 solver.cpp:285]     Train net output #0: loss = 0.00422158 (* 1 = 0.00422158 loss)
I0122 20:36:17.350035 70718 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 20:36:23.495049 70718 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 20:36:24.940136 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899444
I0122 20:36:24.940160 70718 solver.cpp:517]     Test net output #1: loss = 0.373825 (* 1 = 0.373825 loss)
I0122 20:36:24.940165 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899444
I0122 20:36:24.940168 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:36:25.001646 70718 solver.cpp:266] Iteration 37000 (13.0696 iter/s, 7.65133s/100 iter), loss = 0.00622223
I0122 20:36:25.001664 70718 solver.cpp:285]     Train net output #0: loss = 0.00622215 (* 1 = 0.00622215 loss)
I0122 20:36:25.001672 70718 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 20:36:31.179252 70718 solver.cpp:266] Iteration 37100 (16.1882 iter/s, 6.17735s/100 iter), loss = 0.0094263
I0122 20:36:31.179280 70718 solver.cpp:285]     Train net output #0: loss = 0.00942622 (* 1 = 0.00942622 loss)
I0122 20:36:31.179286 70718 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 20:36:37.392138 70718 solver.cpp:266] Iteration 37200 (16.0963 iter/s, 6.21262s/100 iter), loss = 0.00948734
I0122 20:36:37.392179 70718 solver.cpp:285]     Train net output #0: loss = 0.00948726 (* 1 = 0.00948726 loss)
I0122 20:36:37.392185 70718 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 20:36:43.596427 70718 solver.cpp:266] Iteration 37300 (16.1186 iter/s, 6.20401s/100 iter), loss = 0.00576864
I0122 20:36:43.596455 70718 solver.cpp:285]     Train net output #0: loss = 0.00576857 (* 1 = 0.00576857 loss)
I0122 20:36:43.596462 70718 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 20:36:49.798296 70718 solver.cpp:266] Iteration 37400 (16.1249 iter/s, 6.2016s/100 iter), loss = 0.0089949
I0122 20:36:49.798322 70718 solver.cpp:285]     Train net output #0: loss = 0.00899483 (* 1 = 0.00899483 loss)
I0122 20:36:49.798328 70718 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 20:36:56.003279 70718 solver.cpp:266] Iteration 37500 (16.1168 iter/s, 6.20472s/100 iter), loss = 0.00821695
I0122 20:36:56.003341 70718 solver.cpp:285]     Train net output #0: loss = 0.00821687 (* 1 = 0.00821687 loss)
I0122 20:36:56.003348 70718 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 20:37:02.207056 70718 solver.cpp:266] Iteration 37600 (16.12 iter/s, 6.20348s/100 iter), loss = 0.0053546
I0122 20:37:02.207083 70718 solver.cpp:285]     Train net output #0: loss = 0.00535452 (* 1 = 0.00535452 loss)
I0122 20:37:02.207090 70718 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 20:37:08.409735 70718 solver.cpp:266] Iteration 37700 (16.1228 iter/s, 6.20241s/100 iter), loss = 0.00529876
I0122 20:37:08.409765 70718 solver.cpp:285]     Train net output #0: loss = 0.00529868 (* 1 = 0.00529868 loss)
I0122 20:37:08.409771 70718 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 20:37:14.615902 70718 solver.cpp:266] Iteration 37800 (16.1137 iter/s, 6.2059s/100 iter), loss = 0.00997215
I0122 20:37:14.615929 70718 solver.cpp:285]     Train net output #0: loss = 0.00997207 (* 1 = 0.00997207 loss)
I0122 20:37:14.615936 70718 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 20:37:20.794764 70718 solver.cpp:266] Iteration 37900 (16.1849 iter/s, 6.1786s/100 iter), loss = 0.00348177
I0122 20:37:20.794791 70718 solver.cpp:285]     Train net output #0: loss = 0.0034817 (* 1 = 0.0034817 loss)
I0122 20:37:20.794797 70718 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 20:37:26.931969 70718 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 20:37:28.381232 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 20:37:28.381258 70718 solver.cpp:517]     Test net output #1: loss = 0.373755 (* 1 = 0.373755 loss)
I0122 20:37:28.381263 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 20:37:28.381266 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:37:28.442404 70718 solver.cpp:266] Iteration 38000 (13.0765 iter/s, 7.64732s/100 iter), loss = 0.00481743
I0122 20:37:28.442425 70718 solver.cpp:285]     Train net output #0: loss = 0.00481735 (* 1 = 0.00481735 loss)
I0122 20:37:28.442431 70718 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 20:37:34.637769 70718 solver.cpp:266] Iteration 38100 (16.1418 iter/s, 6.19511s/100 iter), loss = 0.00355702
I0122 20:37:34.637809 70718 solver.cpp:285]     Train net output #0: loss = 0.00355695 (* 1 = 0.00355695 loss)
I0122 20:37:34.637817 70718 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 20:37:40.854301 70718 solver.cpp:266] Iteration 38200 (16.0869 iter/s, 6.21626s/100 iter), loss = 0.00668491
I0122 20:37:40.854328 70718 solver.cpp:285]     Train net output #0: loss = 0.00668484 (* 1 = 0.00668484 loss)
I0122 20:37:40.854334 70718 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 20:37:47.058743 70718 solver.cpp:266] Iteration 38300 (16.1182 iter/s, 6.20418s/100 iter), loss = 0.00939392
I0122 20:37:47.058782 70718 solver.cpp:285]     Train net output #0: loss = 0.00939385 (* 1 = 0.00939385 loss)
I0122 20:37:47.058789 70718 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 20:37:53.256264 70718 solver.cpp:266] Iteration 38400 (16.1362 iter/s, 6.19725s/100 iter), loss = 0.00667439
I0122 20:37:53.256294 70718 solver.cpp:285]     Train net output #0: loss = 0.00667431 (* 1 = 0.00667431 loss)
I0122 20:37:53.256299 70718 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 20:37:59.456917 70718 solver.cpp:266] Iteration 38500 (16.128 iter/s, 6.20039s/100 iter), loss = 0.00437214
I0122 20:37:59.456980 70718 solver.cpp:285]     Train net output #0: loss = 0.00437207 (* 1 = 0.00437207 loss)
I0122 20:37:59.456997 70718 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 20:38:05.646288 70718 solver.cpp:266] Iteration 38600 (16.1575 iter/s, 6.18907s/100 iter), loss = 0.00452465
I0122 20:38:05.646328 70718 solver.cpp:285]     Train net output #0: loss = 0.00452458 (* 1 = 0.00452458 loss)
I0122 20:38:05.646335 70718 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 20:38:11.871708 70718 solver.cpp:266] Iteration 38700 (16.0639 iter/s, 6.22514s/100 iter), loss = 0.00521805
I0122 20:38:11.871737 70718 solver.cpp:285]     Train net output #0: loss = 0.00521798 (* 1 = 0.00521798 loss)
I0122 20:38:11.871743 70718 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 20:38:18.070106 70718 solver.cpp:266] Iteration 38800 (16.1339 iter/s, 6.19813s/100 iter), loss = 0.00629103
I0122 20:38:18.070144 70718 solver.cpp:285]     Train net output #0: loss = 0.00629096 (* 1 = 0.00629096 loss)
I0122 20:38:18.070152 70718 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 20:38:24.265154 70718 solver.cpp:266] Iteration 38900 (16.1426 iter/s, 6.19477s/100 iter), loss = 0.00887805
I0122 20:38:24.265184 70718 solver.cpp:285]     Train net output #0: loss = 0.00887798 (* 1 = 0.00887798 loss)
I0122 20:38:24.265206 70718 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 20:38:30.411933 70718 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 20:38:31.854773 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899444
I0122 20:38:31.854797 70718 solver.cpp:517]     Test net output #1: loss = 0.373764 (* 1 = 0.373764 loss)
I0122 20:38:31.854802 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899444
I0122 20:38:31.854806 70718 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 20:38:31.917341 70718 solver.cpp:266] Iteration 39000 (13.0687 iter/s, 7.65187s/100 iter), loss = 0.00509599
I0122 20:38:31.917361 70718 solver.cpp:285]     Train net output #0: loss = 0.00509591 (* 1 = 0.00509591 loss)
I0122 20:38:31.917366 70718 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 20:38:38.126869 70718 solver.cpp:266] Iteration 39100 (16.1049 iter/s, 6.20927s/100 iter), loss = 0.00530876
I0122 20:38:38.126907 70718 solver.cpp:285]     Train net output #0: loss = 0.00530869 (* 1 = 0.00530869 loss)
I0122 20:38:38.126914 70718 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 20:38:44.337792 70718 solver.cpp:266] Iteration 39200 (16.1014 iter/s, 6.21066s/100 iter), loss = 0.00299923
I0122 20:38:44.337832 70718 solver.cpp:285]     Train net output #0: loss = 0.00299915 (* 1 = 0.00299915 loss)
I0122 20:38:44.337839 70718 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 20:38:50.535099 70718 solver.cpp:266] Iteration 39300 (16.1368 iter/s, 6.19703s/100 iter), loss = 0.00696637
I0122 20:38:50.535128 70718 solver.cpp:285]     Train net output #0: loss = 0.00696629 (* 1 = 0.00696629 loss)
I0122 20:38:50.535135 70718 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 20:38:56.751660 70718 solver.cpp:266] Iteration 39400 (16.0868 iter/s, 6.2163s/100 iter), loss = 0.00465221
I0122 20:38:56.751688 70718 solver.cpp:285]     Train net output #0: loss = 0.00465213 (* 1 = 0.00465213 loss)
I0122 20:38:56.751710 70718 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 20:39:02.955868 70718 solver.cpp:266] Iteration 39500 (16.1188 iter/s, 6.20394s/100 iter), loss = 0.00470407
I0122 20:39:02.956013 70718 solver.cpp:285]     Train net output #0: loss = 0.00470399 (* 1 = 0.00470399 loss)
I0122 20:39:02.956020 70718 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 20:39:09.160516 70718 solver.cpp:266] Iteration 39600 (16.1179 iter/s, 6.20427s/100 iter), loss = 0.016735
I0122 20:39:09.160557 70718 solver.cpp:285]     Train net output #0: loss = 0.016735 (* 1 = 0.016735 loss)
I0122 20:39:09.160564 70718 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 20:39:15.353826 70718 solver.cpp:266] Iteration 39700 (16.1472 iter/s, 6.19303s/100 iter), loss = 0.00300382
I0122 20:39:15.353854 70718 solver.cpp:285]     Train net output #0: loss = 0.00300374 (* 1 = 0.00300374 loss)
I0122 20:39:15.353860 70718 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 20:39:21.539139 70718 solver.cpp:266] Iteration 39800 (16.168 iter/s, 6.18505s/100 iter), loss = 0.00606758
I0122 20:39:21.539178 70718 solver.cpp:285]     Train net output #0: loss = 0.0060675 (* 1 = 0.0060675 loss)
I0122 20:39:21.539186 70718 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 20:39:27.745748 70718 solver.cpp:266] Iteration 39900 (16.1125 iter/s, 6.20634s/100 iter), loss = 0.00274859
I0122 20:39:27.745776 70718 solver.cpp:285]     Train net output #0: loss = 0.00274851 (* 1 = 0.00274851 loss)
I0122 20:39:27.745782 70718 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 20:39:33.879789 70718 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_40000.caffemodel
I0122 20:39:33.924834 70718 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_40000.solverstate
I0122 20:39:33.954723 70718 solver.cpp:378] Iteration 40000, loss = 0.00169878
I0122 20:39:33.954744 70718 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 20:39:35.412382 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899667
I0122 20:39:35.412406 70718 solver.cpp:517]     Test net output #1: loss = 0.374285 (* 1 = 0.374285 loss)
I0122 20:39:35.412411 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899667
I0122 20:39:35.412415 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 20:39:35.412420 70718 solver.cpp:386] Optimization Done (15.7937 iter/s).
I0122 20:39:35.412425 70718 caffe_interface.cpp:530] Optimization Done.




## last step: get the final output model
## note that it does not work if you used the "final.prototxt" as wrongly described by transform help
#
$PRUNE_ROOT/deephi_compress transform -model ${WORK_DIR}/train_val.prototxt -weights ${WORK_DIR}/regular_rate_0.4/snapshots/_iter_40000.caffemodel 2>&1 | tee ${WORK_DIR}/rpt/logfile_transform_miniGoogleNet.txt
I0122 20:39:36.225066 70976 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 20:39:36.225729 70976 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24778440704, dev_info[0]: total=25620447232 free=24778440704
I0122 20:39:36.225735 70976 caffe_interface.cpp:66] Use GPU with device ID 0
I0122 20:39:36.225991 70976 caffe_interface.cpp:70] GPU device name: Quadro P6000
I0122 20:39:36.816146 70976 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 20:39:36.816730 70976 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 20:39:36.817016 70976 layer_factory.hpp:77] Creating layer data
I0122 20:39:36.817066 70976 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 20:39:36.818472 70976 net.cpp:94] Creating Layer data
I0122 20:39:36.818486 70976 net.cpp:409] data -> data
I0122 20:39:36.818495 70976 net.cpp:409] data -> label
I0122 20:39:36.819631 71011 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 20:39:36.819671 71011 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 20:39:36.819763 70976 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 20:39:36.819847 70976 data_layer.cpp:83] output data size: 50,3,32,32
I0122 20:39:36.823434 70976 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 20:39:36.823488 70976 net.cpp:144] Setting up data
I0122 20:39:36.823496 70976 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 20:39:36.823500 70976 net.cpp:151] Top shape: 50 (50)
I0122 20:39:36.823503 70976 net.cpp:159] Memory required for data: 614600
I0122 20:39:36.823508 70976 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 20:39:36.823529 70976 net.cpp:94] Creating Layer label_data_1_split
I0122 20:39:36.823544 70976 net.cpp:435] label_data_1_split <- label
I0122 20:39:36.823556 70976 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 20:39:36.823566 70976 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 20:39:36.823572 70976 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 20:39:36.823578 70976 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 20:39:36.823657 70976 net.cpp:144] Setting up label_data_1_split
I0122 20:39:36.823663 70976 net.cpp:151] Top shape: 50 (50)
I0122 20:39:36.823668 70976 net.cpp:151] Top shape: 50 (50)
I0122 20:39:36.823670 70976 net.cpp:151] Top shape: 50 (50)
I0122 20:39:36.823673 70976 net.cpp:151] Top shape: 50 (50)
I0122 20:39:36.823675 70976 net.cpp:159] Memory required for data: 615400
I0122 20:39:36.823679 70976 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 20:39:36.823689 70976 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 20:39:36.823698 70976 net.cpp:435] conv1/3x3_s1 <- data
I0122 20:39:36.823704 70976 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 20:39:36.825181 70976 net.cpp:144] Setting up conv1/3x3_s1
I0122 20:39:36.825191 70976 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:36.825194 70976 net.cpp:159] Memory required for data: 20276200
I0122 20:39:36.825209 70976 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 20:39:36.825217 70976 net.cpp:94] Creating Layer conv1/bn1
I0122 20:39:36.825220 70976 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 20:39:36.825225 70976 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 20:39:36.825918 70976 net.cpp:144] Setting up conv1/bn1
I0122 20:39:36.825927 70976 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:36.825930 70976 net.cpp:159] Memory required for data: 39937000
I0122 20:39:36.825942 70976 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 20:39:36.825951 70976 net.cpp:94] Creating Layer conv1/relu1
I0122 20:39:36.825954 70976 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 20:39:36.825960 70976 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 20:39:36.825969 70976 net.cpp:144] Setting up conv1/relu1
I0122 20:39:36.825975 70976 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:36.825978 70976 net.cpp:159] Memory required for data: 59597800
I0122 20:39:36.825980 70976 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:36.825985 70976 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:36.825989 70976 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 20:39:36.825994 70976 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 20:39:36.826002 70976 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 20:39:36.826572 70976 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:36.826578 70976 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:36.826582 70976 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:36.826586 70976 net.cpp:159] Memory required for data: 98919400
I0122 20:39:36.826587 70976 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 20:39:36.826597 70976 net.cpp:94] Creating Layer inception_2a/1x1
I0122 20:39:36.826602 70976 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 20:39:36.826608 70976 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 20:39:36.826938 70976 net.cpp:144] Setting up inception_2a/1x1
I0122 20:39:36.826956 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.826959 70976 net.cpp:159] Memory required for data: 105473000
I0122 20:39:36.826966 70976 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 20:39:36.826974 70976 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 20:39:36.826980 70976 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 20:39:36.826987 70976 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 20:39:36.827728 70976 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 20:39:36.827736 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.827739 70976 net.cpp:159] Memory required for data: 112026600
I0122 20:39:36.827746 70976 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 20:39:36.827754 70976 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 20:39:36.827757 70976 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 20:39:36.827775 70976 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 20:39:36.827781 70976 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 20:39:36.827785 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.827787 70976 net.cpp:159] Memory required for data: 118580200
I0122 20:39:36.827790 70976 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 20:39:36.827800 70976 net.cpp:94] Creating Layer inception_2a/3x3
I0122 20:39:36.827805 70976 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 20:39:36.827811 70976 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 20:39:36.828871 70976 net.cpp:144] Setting up inception_2a/3x3
I0122 20:39:36.828883 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.828886 70976 net.cpp:159] Memory required for data: 125133800
I0122 20:39:36.828892 70976 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 20:39:36.828907 70976 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 20:39:36.828913 70976 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 20:39:36.828920 70976 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 20:39:36.829603 70976 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 20:39:36.829610 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.829614 70976 net.cpp:159] Memory required for data: 131687400
I0122 20:39:36.829625 70976 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 20:39:36.829632 70976 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 20:39:36.829635 70976 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 20:39:36.829644 70976 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 20:39:36.829650 70976 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 20:39:36.829658 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.829661 70976 net.cpp:159] Memory required for data: 138241000
I0122 20:39:36.829664 70976 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 20:39:36.829668 70976 net.cpp:94] Creating Layer inception_2a/output
I0122 20:39:36.829671 70976 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 20:39:36.829675 70976 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 20:39:36.829684 70976 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 20:39:36.829704 70976 net.cpp:144] Setting up inception_2a/output
I0122 20:39:36.829710 70976 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 20:39:36.829712 70976 net.cpp:159] Memory required for data: 151348200
I0122 20:39:36.829715 70976 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 20:39:36.829720 70976 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 20:39:36.829722 70976 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 20:39:36.829728 70976 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 20:39:36.829736 70976 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 20:39:36.829793 70976 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 20:39:36.829799 70976 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 20:39:36.829802 70976 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 20:39:36.829807 70976 net.cpp:159] Memory required for data: 177562600
I0122 20:39:36.829808 70976 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 20:39:36.829818 70976 net.cpp:94] Creating Layer inception_3a/1x1
I0122 20:39:36.829821 70976 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 20:39:36.829828 70976 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 20:39:36.830067 70976 net.cpp:144] Setting up inception_3a/1x1
I0122 20:39:36.830076 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.830080 70976 net.cpp:159] Memory required for data: 184116200
I0122 20:39:36.830094 70976 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 20:39:36.830101 70976 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 20:39:36.830106 70976 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 20:39:36.830112 70976 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 20:39:36.830806 70976 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 20:39:36.830811 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.830814 70976 net.cpp:159] Memory required for data: 190669800
I0122 20:39:36.830821 70976 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 20:39:36.830829 70976 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 20:39:36.830835 70976 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 20:39:36.830840 70976 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 20:39:36.830847 70976 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 20:39:36.830850 70976 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:36.830854 70976 net.cpp:159] Memory required for data: 197223400
I0122 20:39:36.830857 70976 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 20:39:36.830868 70976 net.cpp:94] Creating Layer inception_3a/3x3
I0122 20:39:36.830873 70976 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 20:39:36.830881 70976 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 20:39:36.831351 70976 net.cpp:144] Setting up inception_3a/3x3
I0122 20:39:36.831358 70976 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:36.831362 70976 net.cpp:159] Memory required for data: 207053800
I0122 20:39:36.831367 70976 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 20:39:36.831375 70976 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 20:39:36.831378 70976 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 20:39:36.831385 70976 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 20:39:36.832073 70976 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 20:39:36.832080 70976 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:36.832083 70976 net.cpp:159] Memory required for data: 216884200
I0122 20:39:36.832096 70976 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 20:39:36.832103 70976 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 20:39:36.832106 70976 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 20:39:36.832113 70976 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 20:39:36.832119 70976 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 20:39:36.832123 70976 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:36.832125 70976 net.cpp:159] Memory required for data: 226714600
I0122 20:39:36.832129 70976 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 20:39:36.832134 70976 net.cpp:94] Creating Layer inception_3a/output
I0122 20:39:36.832136 70976 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 20:39:36.832139 70976 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 20:39:36.832146 70976 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 20:39:36.832170 70976 net.cpp:144] Setting up inception_3a/output
I0122 20:39:36.832175 70976 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 20:39:36.832177 70976 net.cpp:159] Memory required for data: 243098600
I0122 20:39:36.832180 70976 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 20:39:36.832186 70976 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 20:39:36.832190 70976 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 20:39:36.832195 70976 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 20:39:36.832201 70976 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 20:39:36.832275 70976 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 20:39:36.832281 70976 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 20:39:36.832285 70976 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 20:39:36.832288 70976 net.cpp:159] Memory required for data: 275866600
I0122 20:39:36.832291 70976 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 20:39:36.832301 70976 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 20:39:36.832306 70976 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 20:39:36.832312 70976 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 20:39:36.832866 70976 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 20:39:36.832875 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.832877 70976 net.cpp:159] Memory required for data: 279962600
I0122 20:39:36.832882 70976 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 20:39:36.832890 70976 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 20:39:36.832893 70976 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 20:39:36.832900 70976 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 20:39:36.833654 70976 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 20:39:36.833662 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.833665 70976 net.cpp:159] Memory required for data: 284058600
I0122 20:39:36.833673 70976 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 20:39:36.833678 70976 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 20:39:36.833683 70976 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 20:39:36.833689 70976 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 20:39:36.833695 70976 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 20:39:36.833701 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.833704 70976 net.cpp:159] Memory required for data: 288154600
I0122 20:39:36.833708 70976 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 20:39:36.833712 70976 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 20:39:36.833719 70976 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 20:39:36.833726 70976 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 20:39:36.833765 70976 net.cpp:144] Setting up downsample_4/pool_s2
I0122 20:39:36.833770 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.833773 70976 net.cpp:159] Memory required for data: 292250600
I0122 20:39:36.833776 70976 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 20:39:36.833781 70976 net.cpp:94] Creating Layer downsample_4/output
I0122 20:39:36.833783 70976 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 20:39:36.833787 70976 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 20:39:36.833793 70976 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 20:39:36.833859 70976 net.cpp:144] Setting up downsample_4/output
I0122 20:39:36.833864 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.833868 70976 net.cpp:159] Memory required for data: 300442600
I0122 20:39:36.833870 70976 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 20:39:36.833875 70976 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 20:39:36.833878 70976 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 20:39:36.833884 70976 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 20:39:36.833890 70976 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 20:39:36.833927 70976 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 20:39:36.833941 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.833954 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.833957 70976 net.cpp:159] Memory required for data: 316826600
I0122 20:39:36.833961 70976 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 20:39:36.833968 70976 net.cpp:94] Creating Layer inception_5a/1x1
I0122 20:39:36.833971 70976 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 20:39:36.833981 70976 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 20:39:36.834306 70976 net.cpp:144] Setting up inception_5a/1x1
I0122 20:39:36.834312 70976 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:36.834316 70976 net.cpp:159] Memory required for data: 322561000
I0122 20:39:36.834321 70976 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 20:39:36.834329 70976 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 20:39:36.834334 70976 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 20:39:36.834340 70976 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 20:39:36.835047 70976 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 20:39:36.835054 70976 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:36.835057 70976 net.cpp:159] Memory required for data: 328295400
I0122 20:39:36.835064 70976 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 20:39:36.835070 70976 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 20:39:36.835077 70976 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 20:39:36.835081 70976 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 20:39:36.835088 70976 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 20:39:36.835091 70976 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:36.835094 70976 net.cpp:159] Memory required for data: 334029800
I0122 20:39:36.835096 70976 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 20:39:36.835105 70976 net.cpp:94] Creating Layer inception_5a/3x3
I0122 20:39:36.835109 70976 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 20:39:36.835115 70976 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 20:39:36.835754 70976 net.cpp:144] Setting up inception_5a/3x3
I0122 20:39:36.835763 70976 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:36.835767 70976 net.cpp:159] Memory required for data: 336487400
I0122 20:39:36.835772 70976 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 20:39:36.835783 70976 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 20:39:36.835788 70976 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 20:39:36.835794 70976 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 20:39:36.836514 70976 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 20:39:36.836520 70976 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:36.836524 70976 net.cpp:159] Memory required for data: 338945000
I0122 20:39:36.836532 70976 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 20:39:36.836537 70976 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 20:39:36.836540 70976 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 20:39:36.836544 70976 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 20:39:36.836551 70976 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 20:39:36.836560 70976 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:36.836562 70976 net.cpp:159] Memory required for data: 341402600
I0122 20:39:36.836565 70976 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 20:39:36.836572 70976 net.cpp:94] Creating Layer inception_5a/output
I0122 20:39:36.836576 70976 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 20:39:36.836580 70976 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 20:39:36.836585 70976 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 20:39:36.836607 70976 net.cpp:144] Setting up inception_5a/output
I0122 20:39:36.836612 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.836624 70976 net.cpp:159] Memory required for data: 349594600
I0122 20:39:36.836627 70976 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 20:39:36.836634 70976 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 20:39:36.836637 70976 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 20:39:36.836642 70976 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 20:39:36.836649 70976 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 20:39:36.836719 70976 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 20:39:36.836724 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.836728 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.836731 70976 net.cpp:159] Memory required for data: 365978600
I0122 20:39:36.836735 70976 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 20:39:36.836743 70976 net.cpp:94] Creating Layer inception_6a/1x1
I0122 20:39:36.836748 70976 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 20:39:36.836755 70976 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 20:39:36.837826 70976 net.cpp:144] Setting up inception_6a/1x1
I0122 20:39:36.837836 70976 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:36.837839 70976 net.cpp:159] Memory required for data: 370893800
I0122 20:39:36.837846 70976 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 20:39:36.837858 70976 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 20:39:36.837863 70976 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 20:39:36.837870 70976 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 20:39:36.838577 70976 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 20:39:36.838584 70976 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:36.838587 70976 net.cpp:159] Memory required for data: 375809000
I0122 20:39:36.838594 70976 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 20:39:36.838603 70976 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 20:39:36.838608 70976 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 20:39:36.838613 70976 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 20:39:36.838618 70976 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 20:39:36.838623 70976 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:36.838625 70976 net.cpp:159] Memory required for data: 380724200
I0122 20:39:36.838629 70976 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 20:39:36.838639 70976 net.cpp:94] Creating Layer inception_6a/3x3
I0122 20:39:36.838642 70976 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 20:39:36.838650 70976 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 20:39:36.840035 70976 net.cpp:144] Setting up inception_6a/3x3
I0122 20:39:36.840047 70976 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:36.840050 70976 net.cpp:159] Memory required for data: 384001000
I0122 20:39:36.840064 70976 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 20:39:36.840073 70976 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 20:39:36.840077 70976 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 20:39:36.840082 70976 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 20:39:36.840731 70976 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 20:39:36.840737 70976 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:36.840740 70976 net.cpp:159] Memory required for data: 387277800
I0122 20:39:36.840749 70976 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 20:39:36.840755 70976 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 20:39:36.840760 70976 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 20:39:36.840775 70976 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 20:39:36.840781 70976 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 20:39:36.840790 70976 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:36.840793 70976 net.cpp:159] Memory required for data: 390554600
I0122 20:39:36.840795 70976 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 20:39:36.840801 70976 net.cpp:94] Creating Layer inception_6a/output
I0122 20:39:36.840804 70976 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 20:39:36.840807 70976 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 20:39:36.840812 70976 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 20:39:36.840831 70976 net.cpp:144] Setting up inception_6a/output
I0122 20:39:36.840837 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.840840 70976 net.cpp:159] Memory required for data: 398746600
I0122 20:39:36.840842 70976 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 20:39:36.840848 70976 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 20:39:36.840852 70976 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 20:39:36.840857 70976 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 20:39:36.840867 70976 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 20:39:36.840896 70976 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 20:39:36.840903 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.840906 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.840909 70976 net.cpp:159] Memory required for data: 415130600
I0122 20:39:36.840911 70976 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 20:39:36.840921 70976 net.cpp:94] Creating Layer inception_7a/1x1
I0122 20:39:36.840926 70976 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 20:39:36.840931 70976 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 20:39:36.841228 70976 net.cpp:144] Setting up inception_7a/1x1
I0122 20:39:36.841234 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.841236 70976 net.cpp:159] Memory required for data: 419226600
I0122 20:39:36.841241 70976 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 20:39:36.841248 70976 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 20:39:36.841254 70976 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 20:39:36.841260 70976 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 20:39:36.841910 70976 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 20:39:36.841917 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.841922 70976 net.cpp:159] Memory required for data: 423322600
I0122 20:39:36.841928 70976 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 20:39:36.841934 70976 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 20:39:36.841939 70976 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 20:39:36.841945 70976 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 20:39:36.841951 70976 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 20:39:36.841955 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.841958 70976 net.cpp:159] Memory required for data: 427418600
I0122 20:39:36.841961 70976 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 20:39:36.841969 70976 net.cpp:94] Creating Layer inception_7a/3x3
I0122 20:39:36.841974 70976 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 20:39:36.841981 70976 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 20:39:36.842842 70976 net.cpp:144] Setting up inception_7a/3x3
I0122 20:39:36.842851 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.842854 70976 net.cpp:159] Memory required for data: 431514600
I0122 20:39:36.842869 70976 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 20:39:36.842880 70976 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 20:39:36.842882 70976 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 20:39:36.842890 70976 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 20:39:36.843541 70976 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 20:39:36.843549 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.843552 70976 net.cpp:159] Memory required for data: 435610600
I0122 20:39:36.843560 70976 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 20:39:36.843565 70976 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 20:39:36.843571 70976 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 20:39:36.843575 70976 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 20:39:36.843581 70976 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 20:39:36.843585 70976 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:36.843588 70976 net.cpp:159] Memory required for data: 439706600
I0122 20:39:36.843591 70976 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 20:39:36.843597 70976 net.cpp:94] Creating Layer inception_7a/output
I0122 20:39:36.843602 70976 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 20:39:36.843605 70976 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 20:39:36.843611 70976 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 20:39:36.843629 70976 net.cpp:144] Setting up inception_7a/output
I0122 20:39:36.843634 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.843637 70976 net.cpp:159] Memory required for data: 447898600
I0122 20:39:36.843641 70976 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 20:39:36.843644 70976 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 20:39:36.843647 70976 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 20:39:36.843653 70976 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 20:39:36.843659 70976 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 20:39:36.843690 70976 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 20:39:36.843695 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.843699 70976 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:36.843703 70976 net.cpp:159] Memory required for data: 464282600
I0122 20:39:36.843704 70976 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 20:39:36.843713 70976 net.cpp:94] Creating Layer inception_8a/1x1
I0122 20:39:36.843717 70976 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 20:39:36.843724 70976 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 20:39:36.843991 70976 net.cpp:144] Setting up inception_8a/1x1
I0122 20:39:36.843998 70976 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:36.844002 70976 net.cpp:159] Memory required for data: 466740200
I0122 20:39:36.844005 70976 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 20:39:36.844013 70976 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 20:39:36.844017 70976 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 20:39:36.844024 70976 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 20:39:36.844666 70976 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 20:39:36.844671 70976 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:36.844674 70976 net.cpp:159] Memory required for data: 469197800
I0122 20:39:36.844682 70976 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 20:39:36.844686 70976 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 20:39:36.844689 70976 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 20:39:36.844707 70976 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 20:39:36.844713 70976 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 20:39:36.844717 70976 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:36.844719 70976 net.cpp:159] Memory required for data: 471655400
I0122 20:39:36.844722 70976 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 20:39:36.844730 70976 net.cpp:94] Creating Layer inception_8a/3x3
I0122 20:39:36.844735 70976 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 20:39:36.844741 70976 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 20:39:36.846377 70976 net.cpp:144] Setting up inception_8a/3x3
I0122 20:39:36.846390 70976 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:36.846392 70976 net.cpp:159] Memory required for data: 476570600
I0122 20:39:36.846398 70976 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 20:39:36.846408 70976 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 20:39:36.846415 70976 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 20:39:36.846421 70976 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 20:39:36.847084 70976 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 20:39:36.847090 70976 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:36.847093 70976 net.cpp:159] Memory required for data: 481485800
I0122 20:39:36.847101 70976 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 20:39:36.847107 70976 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 20:39:36.847112 70976 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 20:39:36.847117 70976 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 20:39:36.847124 70976 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 20:39:36.847128 70976 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:36.847131 70976 net.cpp:159] Memory required for data: 486401000
I0122 20:39:36.847134 70976 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 20:39:36.847141 70976 net.cpp:94] Creating Layer inception_8a/output
I0122 20:39:36.847144 70976 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 20:39:36.847147 70976 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 20:39:36.847153 70976 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 20:39:36.847172 70976 net.cpp:144] Setting up inception_8a/output
I0122 20:39:36.847177 70976 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 20:39:36.847180 70976 net.cpp:159] Memory required for data: 493773800
I0122 20:39:36.847183 70976 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 20:39:36.847188 70976 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 20:39:36.847193 70976 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 20:39:36.847198 70976 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 20:39:36.847203 70976 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 20:39:36.847235 70976 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 20:39:36.847240 70976 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 20:39:36.847244 70976 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 20:39:36.847247 70976 net.cpp:159] Memory required for data: 508519400
I0122 20:39:36.847249 70976 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 20:39:36.847259 70976 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 20:39:36.847263 70976 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 20:39:36.847270 70976 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 20:39:36.848809 70976 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 20:39:36.848819 70976 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:36.848829 70976 net.cpp:159] Memory required for data: 509748200
I0122 20:39:36.848852 70976 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 20:39:36.848860 70976 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 20:39:36.848865 70976 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 20:39:36.848871 70976 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 20:39:36.849534 70976 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 20:39:36.849542 70976 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:36.849545 70976 net.cpp:159] Memory required for data: 510977000
I0122 20:39:36.849552 70976 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 20:39:36.849557 70976 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 20:39:36.849560 70976 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 20:39:36.849566 70976 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 20:39:36.849572 70976 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 20:39:36.849578 70976 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:36.849581 70976 net.cpp:159] Memory required for data: 512205800
I0122 20:39:36.849583 70976 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 20:39:36.849588 70976 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 20:39:36.849596 70976 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 20:39:36.849601 70976 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 20:39:36.849630 70976 net.cpp:144] Setting up downsample_9/pool_s2
I0122 20:39:36.849637 70976 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 20:39:36.849639 70976 net.cpp:159] Memory required for data: 514049000
I0122 20:39:36.849642 70976 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 20:39:36.849649 70976 net.cpp:94] Creating Layer downsample_9/output
I0122 20:39:36.849654 70976 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 20:39:36.849658 70976 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 20:39:36.849663 70976 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 20:39:36.849679 70976 net.cpp:144] Setting up downsample_9/output
I0122 20:39:36.849684 70976 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 20:39:36.849687 70976 net.cpp:159] Memory required for data: 517121000
I0122 20:39:36.849690 70976 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 20:39:36.849695 70976 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 20:39:36.849699 70976 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 20:39:36.849704 70976 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 20:39:36.849709 70976 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 20:39:36.849737 70976 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 20:39:36.849741 70976 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 20:39:36.849746 70976 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 20:39:36.849748 70976 net.cpp:159] Memory required for data: 523265000
I0122 20:39:36.849751 70976 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 20:39:36.849761 70976 net.cpp:94] Creating Layer inception_10a/1x1
I0122 20:39:36.849766 70976 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 20:39:36.849772 70976 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 20:39:36.850227 70976 net.cpp:144] Setting up inception_10a/1x1
I0122 20:39:36.850234 70976 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:36.850237 70976 net.cpp:159] Memory required for data: 525517800
I0122 20:39:36.850242 70976 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 20:39:36.850250 70976 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 20:39:36.850263 70976 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 20:39:36.850270 70976 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 20:39:36.850914 70976 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 20:39:36.850920 70976 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:36.850924 70976 net.cpp:159] Memory required for data: 527770600
I0122 20:39:36.850930 70976 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 20:39:36.850939 70976 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 20:39:36.850941 70976 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 20:39:36.850945 70976 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 20:39:36.850951 70976 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 20:39:36.850955 70976 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:36.850957 70976 net.cpp:159] Memory required for data: 530023400
I0122 20:39:36.850961 70976 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 20:39:36.850970 70976 net.cpp:94] Creating Layer inception_10a/3x3
I0122 20:39:36.850975 70976 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 20:39:36.850981 70976 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 20:39:36.853319 70976 net.cpp:144] Setting up inception_10a/3x3
I0122 20:39:36.853330 70976 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:36.853332 70976 net.cpp:159] Memory required for data: 532071400
I0122 20:39:36.853336 70976 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 20:39:36.853343 70976 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 20:39:36.853346 70976 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 20:39:36.853361 70976 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 20:39:36.854045 70976 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 20:39:36.854053 70976 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:36.854056 70976 net.cpp:159] Memory required for data: 534119400
I0122 20:39:36.854063 70976 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 20:39:36.854070 70976 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 20:39:36.854074 70976 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 20:39:36.854079 70976 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 20:39:36.854085 70976 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 20:39:36.854089 70976 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:36.854092 70976 net.cpp:159] Memory required for data: 536167400
I0122 20:39:36.854095 70976 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 20:39:36.854099 70976 net.cpp:94] Creating Layer inception_10a/output
I0122 20:39:36.854102 70976 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 20:39:36.854105 70976 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 20:39:36.854111 70976 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 20:39:36.854130 70976 net.cpp:144] Setting up inception_10a/output
I0122 20:39:36.854135 70976 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:36.854137 70976 net.cpp:159] Memory required for data: 540468200
I0122 20:39:36.854140 70976 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 20:39:36.854146 70976 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 20:39:36.854149 70976 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 20:39:36.854154 70976 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 20:39:36.854161 70976 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 20:39:36.854192 70976 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 20:39:36.854205 70976 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:36.854209 70976 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:36.854212 70976 net.cpp:159] Memory required for data: 549069800
I0122 20:39:36.854215 70976 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 20:39:36.854224 70976 net.cpp:94] Creating Layer inception_11a/1x1
I0122 20:39:36.854229 70976 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 20:39:36.854235 70976 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 20:39:36.854776 70976 net.cpp:144] Setting up inception_11a/1x1
I0122 20:39:36.854784 70976 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:36.854785 70976 net.cpp:159] Memory required for data: 551322600
I0122 20:39:36.854791 70976 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 20:39:36.854799 70976 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 20:39:36.854801 70976 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 20:39:36.854807 70976 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 20:39:36.855463 70976 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 20:39:36.855468 70976 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:36.855471 70976 net.cpp:159] Memory required for data: 553575400
I0122 20:39:36.855479 70976 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 20:39:36.855484 70976 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 20:39:36.855486 70976 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 20:39:36.855494 70976 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 20:39:36.855500 70976 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 20:39:36.855505 70976 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:36.855509 70976 net.cpp:159] Memory required for data: 555828200
I0122 20:39:36.855510 70976 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 20:39:36.855518 70976 net.cpp:94] Creating Layer inception_11a/3x3
I0122 20:39:36.855523 70976 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 20:39:36.855530 70976 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 20:39:36.858947 70976 net.cpp:144] Setting up inception_11a/3x3
I0122 20:39:36.858958 70976 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:36.858960 70976 net.cpp:159] Memory required for data: 557876200
I0122 20:39:36.858964 70976 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 20:39:36.858973 70976 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 20:39:36.858974 70976 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 20:39:36.858981 70976 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 20:39:36.859647 70976 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 20:39:36.859653 70976 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:36.859658 70976 net.cpp:159] Memory required for data: 559924200
I0122 20:39:36.859676 70976 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 20:39:36.859683 70976 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 20:39:36.859686 70976 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 20:39:36.859690 70976 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 20:39:36.859697 70976 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 20:39:36.859701 70976 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:36.859704 70976 net.cpp:159] Memory required for data: 561972200
I0122 20:39:36.859706 70976 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 20:39:36.859711 70976 net.cpp:94] Creating Layer inception_11a/output
I0122 20:39:36.859714 70976 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 20:39:36.859717 70976 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 20:39:36.859722 70976 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 20:39:36.859740 70976 net.cpp:144] Setting up inception_11a/output
I0122 20:39:36.859755 70976 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:36.859758 70976 net.cpp:159] Memory required for data: 566273000
I0122 20:39:36.859760 70976 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 20:39:36.859767 70976 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 20:39:36.859771 70976 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 20:39:36.859776 70976 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 20:39:36.859800 70976 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 20:39:36.859807 70976 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 20:39:36.859808 70976 net.cpp:159] Memory required for data: 566340200
I0122 20:39:36.859812 70976 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 20:39:36.859817 70976 net.cpp:94] Creating Layer drop_8x8_s1
I0122 20:39:36.859820 70976 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 20:39:36.859824 70976 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 20:39:36.859843 70976 net.cpp:144] Setting up drop_8x8_s1
I0122 20:39:36.859848 70976 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 20:39:36.859850 70976 net.cpp:159] Memory required for data: 566407400
I0122 20:39:36.859853 70976 layer_factory.hpp:77] Creating layer loss/classifier
I0122 20:39:36.859860 70976 net.cpp:94] Creating Layer loss/classifier
I0122 20:39:36.859863 70976 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 20:39:36.859869 70976 net.cpp:409] loss/classifier -> loss/classifier
I0122 20:39:36.860007 70976 net.cpp:144] Setting up loss/classifier
I0122 20:39:36.860013 70976 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:36.860014 70976 net.cpp:159] Memory required for data: 566409400
I0122 20:39:36.860019 70976 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 20:39:36.860024 70976 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 20:39:36.860028 70976 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 20:39:36.860033 70976 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 20:39:36.860038 70976 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 20:39:36.860045 70976 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 20:39:36.860052 70976 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 20:39:36.860100 70976 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 20:39:36.860105 70976 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:36.860108 70976 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:36.860111 70976 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:36.860114 70976 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:36.860117 70976 net.cpp:159] Memory required for data: 566417400
I0122 20:39:36.860119 70976 layer_factory.hpp:77] Creating layer loss
I0122 20:39:36.860126 70976 net.cpp:94] Creating Layer loss
I0122 20:39:36.860128 70976 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 20:39:36.860132 70976 net.cpp:435] loss <- label_data_1_split_0
I0122 20:39:36.860137 70976 net.cpp:409] loss -> loss
I0122 20:39:36.860144 70976 layer_factory.hpp:77] Creating layer loss
I0122 20:39:36.860222 70976 net.cpp:144] Setting up loss
I0122 20:39:36.860229 70976 net.cpp:151] Top shape: (1)
I0122 20:39:36.860230 70976 net.cpp:154]     with loss weight 1
I0122 20:39:36.860255 70976 net.cpp:159] Memory required for data: 566417404
I0122 20:39:36.860258 70976 layer_factory.hpp:77] Creating layer accuracy
I0122 20:39:36.860265 70976 net.cpp:94] Creating Layer accuracy
I0122 20:39:36.860267 70976 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 20:39:36.860270 70976 net.cpp:435] accuracy <- label_data_1_split_1
I0122 20:39:36.860278 70976 net.cpp:409] accuracy -> accuracy
I0122 20:39:36.860291 70976 net.cpp:144] Setting up accuracy
I0122 20:39:36.860303 70976 net.cpp:151] Top shape: (1)
I0122 20:39:36.860306 70976 net.cpp:159] Memory required for data: 566417408
I0122 20:39:36.860308 70976 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 20:39:36.860313 70976 net.cpp:94] Creating Layer accuracy-top1
I0122 20:39:36.860316 70976 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 20:39:36.860319 70976 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 20:39:36.860323 70976 net.cpp:409] accuracy-top1 -> top-1
I0122 20:39:36.860330 70976 net.cpp:144] Setting up accuracy-top1
I0122 20:39:36.860333 70976 net.cpp:151] Top shape: (1)
I0122 20:39:36.860335 70976 net.cpp:159] Memory required for data: 566417412
I0122 20:39:36.860337 70976 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 20:39:36.860342 70976 net.cpp:94] Creating Layer accuracy-top5
I0122 20:39:36.860345 70976 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 20:39:36.860348 70976 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 20:39:36.860353 70976 net.cpp:409] accuracy-top5 -> top-5
I0122 20:39:36.860360 70976 net.cpp:144] Setting up accuracy-top5
I0122 20:39:36.860365 70976 net.cpp:151] Top shape: (1)
I0122 20:39:36.860368 70976 net.cpp:159] Memory required for data: 566417416
I0122 20:39:36.860370 70976 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 20:39:36.860378 70976 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 20:39:36.860380 70976 net.cpp:222] accuracy does not need backward computation.
I0122 20:39:36.860383 70976 net.cpp:220] loss needs backward computation.
I0122 20:39:36.860388 70976 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 20:39:36.860390 70976 net.cpp:220] loss/classifier needs backward computation.
I0122 20:39:36.860394 70976 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 20:39:36.860396 70976 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 20:39:36.860399 70976 net.cpp:220] inception_11a/output needs backward computation.
I0122 20:39:36.860402 70976 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 20:39:36.860405 70976 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 20:39:36.860407 70976 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 20:39:36.860410 70976 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 20:39:36.860414 70976 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 20:39:36.860416 70976 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 20:39:36.860420 70976 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 20:39:36.860424 70976 net.cpp:220] inception_10a/output needs backward computation.
I0122 20:39:36.860427 70976 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 20:39:36.860430 70976 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 20:39:36.860432 70976 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 20:39:36.860435 70976 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 20:39:36.860438 70976 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 20:39:36.860441 70976 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 20:39:36.860445 70976 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 20:39:36.860447 70976 net.cpp:220] downsample_9/output needs backward computation.
I0122 20:39:36.860451 70976 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 20:39:36.860455 70976 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 20:39:36.860457 70976 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 20:39:36.860460 70976 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 20:39:36.860463 70976 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 20:39:36.860474 70976 net.cpp:220] inception_8a/output needs backward computation.
I0122 20:39:36.860478 70976 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 20:39:36.860481 70976 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 20:39:36.860484 70976 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 20:39:36.860487 70976 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 20:39:36.860491 70976 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 20:39:36.860493 70976 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 20:39:36.860497 70976 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 20:39:36.860500 70976 net.cpp:220] inception_7a/output needs backward computation.
I0122 20:39:36.860503 70976 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 20:39:36.860507 70976 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 20:39:36.860510 70976 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 20:39:36.860512 70976 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 20:39:36.860515 70976 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 20:39:36.860518 70976 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 20:39:36.860522 70976 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 20:39:36.860524 70976 net.cpp:220] inception_6a/output needs backward computation.
I0122 20:39:36.860529 70976 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 20:39:36.860532 70976 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 20:39:36.860535 70976 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 20:39:36.860538 70976 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 20:39:36.860541 70976 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 20:39:36.860544 70976 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 20:39:36.860548 70976 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 20:39:36.860551 70976 net.cpp:220] inception_5a/output needs backward computation.
I0122 20:39:36.860554 70976 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 20:39:36.860556 70976 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 20:39:36.860560 70976 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 20:39:36.860563 70976 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 20:39:36.860566 70976 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 20:39:36.860569 70976 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 20:39:36.860572 70976 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 20:39:36.860575 70976 net.cpp:220] downsample_4/output needs backward computation.
I0122 20:39:36.860579 70976 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 20:39:36.860582 70976 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 20:39:36.860585 70976 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 20:39:36.860589 70976 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 20:39:36.860591 70976 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 20:39:36.860594 70976 net.cpp:220] inception_3a/output needs backward computation.
I0122 20:39:36.860599 70976 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 20:39:36.860601 70976 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 20:39:36.860604 70976 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 20:39:36.860606 70976 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 20:39:36.860610 70976 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 20:39:36.860613 70976 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 20:39:36.860621 70976 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 20:39:36.860625 70976 net.cpp:220] inception_2a/output needs backward computation.
I0122 20:39:36.860628 70976 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 20:39:36.860631 70976 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 20:39:36.860635 70976 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 20:39:36.860638 70976 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 20:39:36.860641 70976 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 20:39:36.860643 70976 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 20:39:36.860647 70976 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 20:39:36.860651 70976 net.cpp:220] conv1/relu1 needs backward computation.
I0122 20:39:36.860653 70976 net.cpp:220] conv1/bn1 needs backward computation.
I0122 20:39:36.860656 70976 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 20:39:36.860661 70976 net.cpp:222] label_data_1_split does not need backward computation.
I0122 20:39:36.860664 70976 net.cpp:222] data does not need backward computation.
I0122 20:39:36.860667 70976 net.cpp:264] This network produces output accuracy
I0122 20:39:36.860671 70976 net.cpp:264] This network produces output loss
I0122 20:39:36.860673 70976 net.cpp:264] This network produces output top-1
I0122 20:39:36.860677 70976 net.cpp:264] This network produces output top-5
I0122 20:39:36.860745 70976 net.cpp:284] Network initialization done.
I0122 20:39:36.863494 70976 model_transformer.cpp:80] layer: data
I0122 20:39:36.863509 70976 model_transformer.cpp:80] layer: conv1/3x3_s1
I0122 20:39:36.863553 70976 model_transformer.cpp:80] layer: conv1/bn1
I0122 20:39:36.863579 70976 model_transformer.cpp:80] layer: conv1/relu1
I0122 20:39:36.863584 70976 model_transformer.cpp:80] layer: conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:36.863590 70976 model_transformer.cpp:80] layer: inception_2a/1x1
I0122 20:39:36.863669 70976 model_transformer.cpp:80] layer: inception_2a/1x1/bn1
I0122 20:39:36.863692 70976 model_transformer.cpp:80] layer: inception_2a/1x1/relu1
I0122 20:39:36.863698 70976 model_transformer.cpp:80] layer: inception_2a/3x3
I0122 20:39:36.863885 70976 model_transformer.cpp:80] layer: inception_2a/3x3/bn1
I0122 20:39:36.863907 70976 model_transformer.cpp:80] layer: inception_2a/3x3/relu1
I0122 20:39:36.863914 70976 model_transformer.cpp:80] layer: inception_2a/output
I0122 20:39:36.863919 70976 model_transformer.cpp:80] layer: inception_2a/output_inception_2a/output_0_split
I0122 20:39:36.863925 70976 model_transformer.cpp:80] layer: inception_3a/1x1
I0122 20:39:36.863975 70976 model_transformer.cpp:80] layer: inception_3a/1x1/bn1
I0122 20:39:36.863996 70976 model_transformer.cpp:80] layer: inception_3a/1x1/relu1
I0122 20:39:36.864002 70976 model_transformer.cpp:80] layer: inception_3a/3x3
I0122 20:39:36.864221 70976 model_transformer.cpp:80] layer: inception_3a/3x3/bn1
I0122 20:39:36.864245 70976 model_transformer.cpp:80] layer: inception_3a/3x3/relu1
I0122 20:39:36.864251 70976 model_transformer.cpp:80] layer: inception_3a/output
I0122 20:39:36.864257 70976 model_transformer.cpp:80] layer: inception_3a/output_inception_3a/output_0_split
I0122 20:39:36.864264 70976 model_transformer.cpp:80] layer: downsample_4/3x3_s2
I0122 20:39:36.864475 70976 model_transformer.cpp:80] layer: downsample_4/3x3_s2/bn1
I0122 20:39:36.864502 70976 model_transformer.cpp:80] layer: downsample_4/3x3_s2/relu1
I0122 20:39:36.864508 70976 model_transformer.cpp:80] layer: downsample_4/pool_s2
I0122 20:39:36.864514 70976 model_transformer.cpp:80] layer: downsample_4/output
I0122 20:39:36.864519 70976 model_transformer.cpp:80] layer: downsample_4/output_downsample_4/output_0_split
I0122 20:39:36.864528 70976 model_transformer.cpp:80] layer: inception_5a/1x1
I0122 20:39:36.864954 70976 model_transformer.cpp:80] layer: inception_5a/1x1/bn1
I0122 20:39:36.864989 70976 model_transformer.cpp:80] layer: inception_5a/1x1/relu1
I0122 20:39:36.864996 70976 model_transformer.cpp:80] layer: inception_5a/3x3
I0122 20:39:36.865478 70976 model_transformer.cpp:80] layer: inception_5a/3x3/bn1
I0122 20:39:36.865504 70976 model_transformer.cpp:80] layer: inception_5a/3x3/relu1
I0122 20:39:36.865509 70976 model_transformer.cpp:80] layer: inception_5a/output
I0122 20:39:36.865515 70976 model_transformer.cpp:80] layer: inception_5a/output_inception_5a/output_0_split
I0122 20:39:36.865521 70976 model_transformer.cpp:80] layer: inception_6a/1x1
I0122 20:39:36.865854 70976 model_transformer.cpp:80] layer: inception_6a/1x1/bn1
I0122 20:39:36.865880 70976 model_transformer.cpp:80] layer: inception_6a/1x1/relu1
I0122 20:39:36.865885 70976 model_transformer.cpp:80] layer: inception_6a/3x3
I0122 20:39:36.866570 70976 model_transformer.cpp:80] layer: inception_6a/3x3/bn1
I0122 20:39:36.866600 70976 model_transformer.cpp:80] layer: inception_6a/3x3/relu1
I0122 20:39:36.866605 70976 model_transformer.cpp:80] layer: inception_6a/output
I0122 20:39:36.866611 70976 model_transformer.cpp:80] layer: inception_6a/output_inception_6a/output_0_split
I0122 20:39:36.866617 70976 model_transformer.cpp:80] layer: inception_7a/1x1
I0122 20:39:36.866814 70976 model_transformer.cpp:80] layer: inception_7a/1x1/bn1
I0122 20:39:36.866838 70976 model_transformer.cpp:80] layer: inception_7a/1x1/relu1
I0122 20:39:36.866843 70976 model_transformer.cpp:80] layer: inception_7a/3x3
I0122 20:39:36.867794 70976 model_transformer.cpp:80] layer: inception_7a/3x3/bn1
I0122 20:39:36.867821 70976 model_transformer.cpp:80] layer: inception_7a/3x3/relu1
I0122 20:39:36.867828 70976 model_transformer.cpp:80] layer: inception_7a/output
I0122 20:39:36.867833 70976 model_transformer.cpp:80] layer: inception_7a/output_inception_7a/output_0_split
I0122 20:39:36.867841 70976 model_transformer.cpp:80] layer: inception_8a/1x1
I0122 20:39:36.868003 70976 model_transformer.cpp:80] layer: inception_8a/1x1/bn1
I0122 20:39:36.868026 70976 model_transformer.cpp:80] layer: inception_8a/1x1/relu1
I0122 20:39:36.868031 70976 model_transformer.cpp:80] layer: inception_8a/3x3
I0122 20:39:36.868873 70976 model_transformer.cpp:80] layer: inception_8a/3x3/bn1
I0122 20:39:36.868903 70976 model_transformer.cpp:80] layer: inception_8a/3x3/relu1
I0122 20:39:36.868909 70976 model_transformer.cpp:80] layer: inception_8a/output
I0122 20:39:36.868914 70976 model_transformer.cpp:80] layer: inception_8a/output_inception_8a/output_0_split
I0122 20:39:36.868921 70976 model_transformer.cpp:80] layer: downsample_9/3x3_s2
I0122 20:39:36.869619 70976 model_transformer.cpp:80] layer: downsample_9/3x3_s2/bn1
I0122 20:39:36.869647 70976 model_transformer.cpp:80] layer: downsample_9/3x3_s2/relu1
I0122 20:39:36.869653 70976 model_transformer.cpp:80] layer: downsample_9/pool_s2
I0122 20:39:36.869660 70976 model_transformer.cpp:80] layer: downsample_9/output
I0122 20:39:36.869665 70976 model_transformer.cpp:80] layer: downsample_9/output_downsample_9/output_0_split
I0122 20:39:36.869674 70976 model_transformer.cpp:80] layer: inception_10a/1x1
I0122 20:39:36.869854 70976 model_transformer.cpp:80] layer: inception_10a/1x1/bn1
I0122 20:39:36.869884 70976 model_transformer.cpp:80] layer: inception_10a/1x1/relu1
I0122 20:39:36.869890 70976 model_transformer.cpp:80] layer: inception_10a/3x3
I0122 20:39:36.873157 70976 model_transformer.cpp:80] layer: inception_10a/3x3/bn1
I0122 20:39:36.873188 70976 model_transformer.cpp:80] layer: inception_10a/3x3/relu1
I0122 20:39:36.873193 70976 model_transformer.cpp:80] layer: inception_10a/output
I0122 20:39:36.873198 70976 model_transformer.cpp:80] layer: inception_10a/output_inception_10a/output_0_split
I0122 20:39:36.873204 70976 model_transformer.cpp:80] layer: inception_11a/1x1
I0122 20:39:36.874810 70976 model_transformer.cpp:80] layer: inception_11a/1x1/bn1
I0122 20:39:36.874835 70976 model_transformer.cpp:80] layer: inception_11a/1x1/relu1
I0122 20:39:36.874838 70976 model_transformer.cpp:80] layer: inception_11a/3x3
I0122 20:39:36.877678 70976 model_transformer.cpp:80] layer: inception_11a/3x3/bn1
I0122 20:39:36.877707 70976 model_transformer.cpp:80] layer: inception_11a/3x3/relu1
I0122 20:39:36.877710 70976 model_transformer.cpp:80] layer: inception_11a/output
I0122 20:39:36.877715 70976 model_transformer.cpp:80] layer: avg_pool_12/8x8_s1
I0122 20:39:36.877722 70976 model_transformer.cpp:80] layer: drop_8x8_s1
I0122 20:39:36.877725 70976 model_transformer.cpp:80] layer: loss/classifier
I0122 20:39:36.877861 70976 model_transformer.cpp:80] layer: loss
Output transformed caffemodel: transformed.caffemodel
mv transformed.caffemodel ${WORK_DIR}

# get flops and the number of parameters of a model
$PRUNE_ROOT/deephi_compress stat -model ${WORK_DIR}/train_val.prototxt 2>&1 | tee ${WORK_DIR}/rpt/logfile_stat_miniGoogleNet.txt
I0122 20:39:38.109580 71044 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 20:39:38.110448 71044 net.cpp:52] Initializing net from parameters: 
name: "miniGoogleNet for CIFAR10, model 3"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale1"
  type: "Scale"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_2a/1x1/scale1"
  type: "Scale"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_2a/3x3/scale1"
  type: "Scale"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_3a/1x1/scale1"
  type: "Scale"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_3a/3x3/scale1"
  type: "Scale"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "downsample_4/3x3_s2/scale1"
  type: "Scale"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_5a/1x1/scale1"
  type: "Scale"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_5a/3x3/scale1"
  type: "Scale"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_6a/1x1/scale1"
  type: "Scale"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_6a/3x3/scale1"
  type: "Scale"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_7a/1x1/scale1"
  type: "Scale"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_7a/3x3/scale1"
  type: "Scale"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_8a/1x1/scale1"
  type: "Scale"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_8a/3x3/scale1"
  type: "Scale"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "downsample_9/3x3_s2/scale1"
  type: "Scale"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_10a/1x1/scale1"
  type: "Scale"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_10a/3x3/scale1"
  type: "Scale"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_11a/1x1/scale1"
  type: "Scale"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "inception_11a/3x3/scale1"
  type: "Scale"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 20:39:38.110800 71044 layer_factory.hpp:77] Creating layer data
I0122 20:39:38.111542 71044 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 20:39:38.111990 71044 net.cpp:94] Creating Layer data
I0122 20:39:38.112001 71044 net.cpp:409] data -> data
I0122 20:39:38.112015 71044 net.cpp:409] data -> label
I0122 20:39:38.113772 71079 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 20:39:38.113817 71079 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 20:39:38.113868 71044 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 20:39:38.113879 71044 data_layer.cpp:83] output data size: 50,3,32,32
I0122 20:39:38.115613 71044 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 20:39:38.115640 71044 net.cpp:144] Setting up data
I0122 20:39:38.115648 71044 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 20:39:38.115653 71044 net.cpp:151] Top shape: 50 (50)
I0122 20:39:38.115655 71044 net.cpp:159] Memory required for data: 614600
I0122 20:39:38.115661 71044 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 20:39:38.115669 71044 net.cpp:94] Creating Layer label_data_1_split
I0122 20:39:38.115679 71044 net.cpp:435] label_data_1_split <- label
I0122 20:39:38.115695 71044 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 20:39:38.115705 71044 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 20:39:38.115711 71044 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 20:39:38.115717 71044 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 20:39:38.115725 71044 net.cpp:144] Setting up label_data_1_split
I0122 20:39:38.115731 71044 net.cpp:151] Top shape: 50 (50)
I0122 20:39:38.115734 71044 net.cpp:151] Top shape: 50 (50)
I0122 20:39:38.115738 71044 net.cpp:151] Top shape: 50 (50)
I0122 20:39:38.115741 71044 net.cpp:151] Top shape: 50 (50)
I0122 20:39:38.115743 71044 net.cpp:159] Memory required for data: 615400
I0122 20:39:38.115747 71044 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 20:39:38.115756 71044 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 20:39:38.115761 71044 net.cpp:435] conv1/3x3_s1 <- data
I0122 20:39:38.115766 71044 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 20:39:38.115842 71044 net.cpp:144] Setting up conv1/3x3_s1
I0122 20:39:38.115849 71044 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:38.115851 71044 net.cpp:159] Memory required for data: 20276200
I0122 20:39:38.115865 71044 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 20:39:38.115873 71044 net.cpp:94] Creating Layer conv1/bn1
I0122 20:39:38.115876 71044 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 20:39:38.115880 71044 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 20:39:38.115913 71044 net.cpp:144] Setting up conv1/bn1
I0122 20:39:38.115919 71044 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:38.115921 71044 net.cpp:159] Memory required for data: 39937000
I0122 20:39:38.115932 71044 layer_factory.hpp:77] Creating layer conv1/scale1
I0122 20:39:38.115939 71044 net.cpp:94] Creating Layer conv1/scale1
I0122 20:39:38.115942 71044 net.cpp:435] conv1/scale1 <- conv1/3x3_s1
I0122 20:39:38.115947 71044 net.cpp:396] conv1/scale1 -> conv1/3x3_s1 (in-place)
I0122 20:39:38.115968 71044 layer_factory.hpp:77] Creating layer conv1/scale1
I0122 20:39:38.115983 71044 net.cpp:144] Setting up conv1/scale1
I0122 20:39:38.115988 71044 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:38.115991 71044 net.cpp:159] Memory required for data: 59597800
I0122 20:39:38.115998 71044 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 20:39:38.116001 71044 net.cpp:94] Creating Layer conv1/relu1
I0122 20:39:38.116004 71044 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 20:39:38.116008 71044 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 20:39:38.116017 71044 net.cpp:144] Setting up conv1/relu1
I0122 20:39:38.116022 71044 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:38.116026 71044 net.cpp:159] Memory required for data: 79258600
I0122 20:39:38.116029 71044 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:38.116034 71044 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:38.116036 71044 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 20:39:38.116041 71044 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 20:39:38.116046 71044 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 20:39:38.116053 71044 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 20:39:38.116057 71044 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:38.116061 71044 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 20:39:38.116065 71044 net.cpp:159] Memory required for data: 118580200
I0122 20:39:38.116066 71044 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 20:39:38.116073 71044 net.cpp:94] Creating Layer inception_2a/1x1
I0122 20:39:38.116080 71044 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 20:39:38.116084 71044 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 20:39:38.116124 71044 net.cpp:144] Setting up inception_2a/1x1
I0122 20:39:38.116129 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116132 71044 net.cpp:159] Memory required for data: 125133800
I0122 20:39:38.116137 71044 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 20:39:38.116142 71044 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 20:39:38.116145 71044 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 20:39:38.116150 71044 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 20:39:38.116178 71044 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 20:39:38.116183 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116186 71044 net.cpp:159] Memory required for data: 131687400
I0122 20:39:38.116194 71044 layer_factory.hpp:77] Creating layer inception_2a/1x1/scale1
I0122 20:39:38.116199 71044 net.cpp:94] Creating Layer inception_2a/1x1/scale1
I0122 20:39:38.116200 71044 net.cpp:435] inception_2a/1x1/scale1 <- inception_2a/1x1
I0122 20:39:38.116204 71044 net.cpp:396] inception_2a/1x1/scale1 -> inception_2a/1x1 (in-place)
I0122 20:39:38.116212 71044 layer_factory.hpp:77] Creating layer inception_2a/1x1/scale1
I0122 20:39:38.116225 71044 net.cpp:144] Setting up inception_2a/1x1/scale1
I0122 20:39:38.116230 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116231 71044 net.cpp:159] Memory required for data: 138241000
I0122 20:39:38.116240 71044 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 20:39:38.116242 71044 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 20:39:38.116245 71044 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 20:39:38.116250 71044 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 20:39:38.116255 71044 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 20:39:38.116258 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116261 71044 net.cpp:159] Memory required for data: 144794600
I0122 20:39:38.116263 71044 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 20:39:38.116271 71044 net.cpp:94] Creating Layer inception_2a/3x3
I0122 20:39:38.116284 71044 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 20:39:38.116289 71044 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 20:39:38.116498 71044 net.cpp:144] Setting up inception_2a/3x3
I0122 20:39:38.116505 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116508 71044 net.cpp:159] Memory required for data: 151348200
I0122 20:39:38.116513 71044 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 20:39:38.116518 71044 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 20:39:38.116521 71044 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 20:39:38.116525 71044 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 20:39:38.116552 71044 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 20:39:38.116557 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116560 71044 net.cpp:159] Memory required for data: 157901800
I0122 20:39:38.116567 71044 layer_factory.hpp:77] Creating layer inception_2a/3x3/scale1
I0122 20:39:38.116571 71044 net.cpp:94] Creating Layer inception_2a/3x3/scale1
I0122 20:39:38.116575 71044 net.cpp:435] inception_2a/3x3/scale1 <- inception_2a/3x3
I0122 20:39:38.116578 71044 net.cpp:396] inception_2a/3x3/scale1 -> inception_2a/3x3 (in-place)
I0122 20:39:38.116585 71044 layer_factory.hpp:77] Creating layer inception_2a/3x3/scale1
I0122 20:39:38.116597 71044 net.cpp:144] Setting up inception_2a/3x3/scale1
I0122 20:39:38.116602 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116605 71044 net.cpp:159] Memory required for data: 164455400
I0122 20:39:38.116609 71044 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 20:39:38.116613 71044 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 20:39:38.116616 71044 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 20:39:38.116621 71044 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 20:39:38.116626 71044 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 20:39:38.116629 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116631 71044 net.cpp:159] Memory required for data: 171009000
I0122 20:39:38.116634 71044 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 20:39:38.116638 71044 net.cpp:94] Creating Layer inception_2a/output
I0122 20:39:38.116641 71044 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 20:39:38.116644 71044 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 20:39:38.116649 71044 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 20:39:38.116657 71044 net.cpp:144] Setting up inception_2a/output
I0122 20:39:38.116662 71044 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 20:39:38.116664 71044 net.cpp:159] Memory required for data: 184116200
I0122 20:39:38.116667 71044 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 20:39:38.116672 71044 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 20:39:38.116675 71044 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 20:39:38.116680 71044 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 20:39:38.116686 71044 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 20:39:38.116694 71044 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 20:39:38.116698 71044 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 20:39:38.116701 71044 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 20:39:38.116704 71044 net.cpp:159] Memory required for data: 210330600
I0122 20:39:38.116708 71044 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 20:39:38.116714 71044 net.cpp:94] Creating Layer inception_3a/1x1
I0122 20:39:38.116717 71044 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 20:39:38.116724 71044 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 20:39:38.116765 71044 net.cpp:144] Setting up inception_3a/1x1
I0122 20:39:38.116771 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116775 71044 net.cpp:159] Memory required for data: 216884200
I0122 20:39:38.116780 71044 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 20:39:38.116784 71044 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 20:39:38.116787 71044 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 20:39:38.116792 71044 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 20:39:38.116824 71044 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 20:39:38.116829 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116832 71044 net.cpp:159] Memory required for data: 223437800
I0122 20:39:38.116842 71044 layer_factory.hpp:77] Creating layer inception_3a/1x1/scale1
I0122 20:39:38.116850 71044 net.cpp:94] Creating Layer inception_3a/1x1/scale1
I0122 20:39:38.116853 71044 net.cpp:435] inception_3a/1x1/scale1 <- inception_3a/1x1
I0122 20:39:38.116858 71044 net.cpp:396] inception_3a/1x1/scale1 -> inception_3a/1x1 (in-place)
I0122 20:39:38.116865 71044 layer_factory.hpp:77] Creating layer inception_3a/1x1/scale1
I0122 20:39:38.116884 71044 net.cpp:144] Setting up inception_3a/1x1/scale1
I0122 20:39:38.116889 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116892 71044 net.cpp:159] Memory required for data: 229991400
I0122 20:39:38.116896 71044 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 20:39:38.116901 71044 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 20:39:38.116904 71044 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 20:39:38.116909 71044 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 20:39:38.116914 71044 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 20:39:38.116919 71044 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 20:39:38.116922 71044 net.cpp:159] Memory required for data: 236545000
I0122 20:39:38.116925 71044 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 20:39:38.116930 71044 net.cpp:94] Creating Layer inception_3a/3x3
I0122 20:39:38.116935 71044 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 20:39:38.116941 71044 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 20:39:38.117211 71044 net.cpp:144] Setting up inception_3a/3x3
I0122 20:39:38.117218 71044 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:38.117221 71044 net.cpp:159] Memory required for data: 246375400
I0122 20:39:38.117225 71044 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 20:39:38.117233 71044 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 20:39:38.117238 71044 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 20:39:38.117244 71044 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 20:39:38.117277 71044 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 20:39:38.117282 71044 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:38.117285 71044 net.cpp:159] Memory required for data: 256205800
I0122 20:39:38.117292 71044 layer_factory.hpp:77] Creating layer inception_3a/3x3/scale1
I0122 20:39:38.117298 71044 net.cpp:94] Creating Layer inception_3a/3x3/scale1
I0122 20:39:38.117302 71044 net.cpp:435] inception_3a/3x3/scale1 <- inception_3a/3x3
I0122 20:39:38.117308 71044 net.cpp:396] inception_3a/3x3/scale1 -> inception_3a/3x3 (in-place)
I0122 20:39:38.117316 71044 layer_factory.hpp:77] Creating layer inception_3a/3x3/scale1
I0122 20:39:38.117336 71044 net.cpp:144] Setting up inception_3a/3x3/scale1
I0122 20:39:38.117341 71044 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:38.117343 71044 net.cpp:159] Memory required for data: 266036200
I0122 20:39:38.117348 71044 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 20:39:38.117352 71044 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 20:39:38.117355 71044 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 20:39:38.117358 71044 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 20:39:38.117372 71044 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 20:39:38.117377 71044 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 20:39:38.117378 71044 net.cpp:159] Memory required for data: 275866600
I0122 20:39:38.117381 71044 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 20:39:38.117388 71044 net.cpp:94] Creating Layer inception_3a/output
I0122 20:39:38.117390 71044 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 20:39:38.117393 71044 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 20:39:38.117399 71044 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 20:39:38.117410 71044 net.cpp:144] Setting up inception_3a/output
I0122 20:39:38.117414 71044 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 20:39:38.117416 71044 net.cpp:159] Memory required for data: 292250600
I0122 20:39:38.117419 71044 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 20:39:38.117424 71044 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 20:39:38.117427 71044 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 20:39:38.117434 71044 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 20:39:38.117439 71044 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 20:39:38.117446 71044 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 20:39:38.117451 71044 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 20:39:38.117455 71044 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 20:39:38.117457 71044 net.cpp:159] Memory required for data: 325018600
I0122 20:39:38.117460 71044 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 20:39:38.117468 71044 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 20:39:38.117473 71044 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 20:39:38.117480 71044 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 20:39:38.117987 71044 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 20:39:38.117996 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.117998 71044 net.cpp:159] Memory required for data: 329114600
I0122 20:39:38.118003 71044 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 20:39:38.118010 71044 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 20:39:38.118013 71044 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 20:39:38.118021 71044 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 20:39:38.118052 71044 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 20:39:38.118059 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.118062 71044 net.cpp:159] Memory required for data: 333210600
I0122 20:39:38.118069 71044 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/scale1
I0122 20:39:38.118073 71044 net.cpp:94] Creating Layer downsample_4/3x3_s2/scale1
I0122 20:39:38.118078 71044 net.cpp:435] downsample_4/3x3_s2/scale1 <- downsample_4/3x3_s2
I0122 20:39:38.118084 71044 net.cpp:396] downsample_4/3x3_s2/scale1 -> downsample_4/3x3_s2 (in-place)
I0122 20:39:38.118093 71044 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/scale1
I0122 20:39:38.118108 71044 net.cpp:144] Setting up downsample_4/3x3_s2/scale1
I0122 20:39:38.118114 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.118116 71044 net.cpp:159] Memory required for data: 337306600
I0122 20:39:38.118120 71044 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 20:39:38.118126 71044 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 20:39:38.118129 71044 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 20:39:38.118134 71044 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 20:39:38.118147 71044 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 20:39:38.118150 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.118155 71044 net.cpp:159] Memory required for data: 341402600
I0122 20:39:38.118156 71044 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 20:39:38.118161 71044 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 20:39:38.118165 71044 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 20:39:38.118170 71044 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 20:39:38.118183 71044 net.cpp:144] Setting up downsample_4/pool_s2
I0122 20:39:38.118188 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.118191 71044 net.cpp:159] Memory required for data: 345498600
I0122 20:39:38.118193 71044 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 20:39:38.118201 71044 net.cpp:94] Creating Layer downsample_4/output
I0122 20:39:38.118204 71044 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 20:39:38.118208 71044 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 20:39:38.118213 71044 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 20:39:38.118219 71044 net.cpp:144] Setting up downsample_4/output
I0122 20:39:38.118222 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.118225 71044 net.cpp:159] Memory required for data: 353690600
I0122 20:39:38.118228 71044 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 20:39:38.118232 71044 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 20:39:38.118235 71044 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 20:39:38.118240 71044 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 20:39:38.118249 71044 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 20:39:38.118255 71044 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 20:39:38.118258 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.118263 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.118265 71044 net.cpp:159] Memory required for data: 370074600
I0122 20:39:38.118268 71044 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 20:39:38.118278 71044 net.cpp:94] Creating Layer inception_5a/1x1
I0122 20:39:38.118283 71044 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 20:39:38.118288 71044 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 20:39:38.118453 71044 net.cpp:144] Setting up inception_5a/1x1
I0122 20:39:38.118458 71044 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:38.118460 71044 net.cpp:159] Memory required for data: 375809000
I0122 20:39:38.118465 71044 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 20:39:38.118471 71044 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 20:39:38.118474 71044 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 20:39:38.118481 71044 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 20:39:38.118515 71044 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 20:39:38.118520 71044 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:38.118522 71044 net.cpp:159] Memory required for data: 381543400
I0122 20:39:38.118528 71044 layer_factory.hpp:77] Creating layer inception_5a/1x1/scale1
I0122 20:39:38.118535 71044 net.cpp:94] Creating Layer inception_5a/1x1/scale1
I0122 20:39:38.118540 71044 net.cpp:435] inception_5a/1x1/scale1 <- inception_5a/1x1
I0122 20:39:38.118546 71044 net.cpp:396] inception_5a/1x1/scale1 -> inception_5a/1x1 (in-place)
I0122 20:39:38.118552 71044 layer_factory.hpp:77] Creating layer inception_5a/1x1/scale1
I0122 20:39:38.118568 71044 net.cpp:144] Setting up inception_5a/1x1/scale1
I0122 20:39:38.118573 71044 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:38.118582 71044 net.cpp:159] Memory required for data: 387277800
I0122 20:39:38.118587 71044 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 20:39:38.118590 71044 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 20:39:38.118593 71044 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 20:39:38.118599 71044 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 20:39:38.118604 71044 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 20:39:38.118608 71044 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 20:39:38.118611 71044 net.cpp:159] Memory required for data: 393012200
I0122 20:39:38.118614 71044 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 20:39:38.118621 71044 net.cpp:94] Creating Layer inception_5a/3x3
I0122 20:39:38.118628 71044 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 20:39:38.118633 71044 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 20:39:38.119217 71044 net.cpp:144] Setting up inception_5a/3x3
I0122 20:39:38.119225 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.119227 71044 net.cpp:159] Memory required for data: 395469800
I0122 20:39:38.119240 71044 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 20:39:38.119248 71044 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 20:39:38.119251 71044 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 20:39:38.119256 71044 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 20:39:38.119289 71044 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 20:39:38.119294 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.119297 71044 net.cpp:159] Memory required for data: 397927400
I0122 20:39:38.119304 71044 layer_factory.hpp:77] Creating layer inception_5a/3x3/scale1
I0122 20:39:38.119309 71044 net.cpp:94] Creating Layer inception_5a/3x3/scale1
I0122 20:39:38.119314 71044 net.cpp:435] inception_5a/3x3/scale1 <- inception_5a/3x3
I0122 20:39:38.119320 71044 net.cpp:396] inception_5a/3x3/scale1 -> inception_5a/3x3 (in-place)
I0122 20:39:38.119328 71044 layer_factory.hpp:77] Creating layer inception_5a/3x3/scale1
I0122 20:39:38.119343 71044 net.cpp:144] Setting up inception_5a/3x3/scale1
I0122 20:39:38.119347 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.119350 71044 net.cpp:159] Memory required for data: 400385000
I0122 20:39:38.119354 71044 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 20:39:38.119359 71044 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 20:39:38.119362 71044 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 20:39:38.119366 71044 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 20:39:38.119372 71044 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 20:39:38.119375 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.119379 71044 net.cpp:159] Memory required for data: 402842600
I0122 20:39:38.119380 71044 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 20:39:38.119386 71044 net.cpp:94] Creating Layer inception_5a/output
I0122 20:39:38.119390 71044 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 20:39:38.119392 71044 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 20:39:38.119397 71044 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 20:39:38.119405 71044 net.cpp:144] Setting up inception_5a/output
I0122 20:39:38.119407 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.119410 71044 net.cpp:159] Memory required for data: 411034600
I0122 20:39:38.119412 71044 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 20:39:38.119417 71044 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 20:39:38.119421 71044 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 20:39:38.119426 71044 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 20:39:38.119439 71044 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 20:39:38.119447 71044 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 20:39:38.119452 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.119457 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.119458 71044 net.cpp:159] Memory required for data: 427418600
I0122 20:39:38.119462 71044 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 20:39:38.119468 71044 net.cpp:94] Creating Layer inception_6a/1x1
I0122 20:39:38.119472 71044 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 20:39:38.119477 71044 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 20:39:38.119627 71044 net.cpp:144] Setting up inception_6a/1x1
I0122 20:39:38.119633 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.119637 71044 net.cpp:159] Memory required for data: 432333800
I0122 20:39:38.119640 71044 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 20:39:38.119647 71044 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 20:39:38.119650 71044 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 20:39:38.119657 71044 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 20:39:38.119691 71044 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 20:39:38.119698 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.119700 71044 net.cpp:159] Memory required for data: 437249000
I0122 20:39:38.119709 71044 layer_factory.hpp:77] Creating layer inception_6a/1x1/scale1
I0122 20:39:38.119716 71044 net.cpp:94] Creating Layer inception_6a/1x1/scale1
I0122 20:39:38.119720 71044 net.cpp:435] inception_6a/1x1/scale1 <- inception_6a/1x1
I0122 20:39:38.119725 71044 net.cpp:396] inception_6a/1x1/scale1 -> inception_6a/1x1 (in-place)
I0122 20:39:38.119732 71044 layer_factory.hpp:77] Creating layer inception_6a/1x1/scale1
I0122 20:39:38.119747 71044 net.cpp:144] Setting up inception_6a/1x1/scale1
I0122 20:39:38.119752 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.119755 71044 net.cpp:159] Memory required for data: 442164200
I0122 20:39:38.119760 71044 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 20:39:38.119763 71044 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 20:39:38.119766 71044 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 20:39:38.119771 71044 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 20:39:38.119776 71044 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 20:39:38.119778 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.119782 71044 net.cpp:159] Memory required for data: 447079400
I0122 20:39:38.119784 71044 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 20:39:38.119792 71044 net.cpp:94] Creating Layer inception_6a/3x3
I0122 20:39:38.119796 71044 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 20:39:38.119801 71044 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 20:39:38.120568 71044 net.cpp:144] Setting up inception_6a/3x3
I0122 20:39:38.120575 71044 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:38.120579 71044 net.cpp:159] Memory required for data: 450356200
I0122 20:39:38.120584 71044 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 20:39:38.120590 71044 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 20:39:38.120595 71044 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 20:39:38.120601 71044 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 20:39:38.120636 71044 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 20:39:38.120641 71044 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:38.120645 71044 net.cpp:159] Memory required for data: 453633000
I0122 20:39:38.120651 71044 layer_factory.hpp:77] Creating layer inception_6a/3x3/scale1
I0122 20:39:38.120658 71044 net.cpp:94] Creating Layer inception_6a/3x3/scale1
I0122 20:39:38.120669 71044 net.cpp:435] inception_6a/3x3/scale1 <- inception_6a/3x3
I0122 20:39:38.120674 71044 net.cpp:396] inception_6a/3x3/scale1 -> inception_6a/3x3 (in-place)
I0122 20:39:38.120683 71044 layer_factory.hpp:77] Creating layer inception_6a/3x3/scale1
I0122 20:39:38.120699 71044 net.cpp:144] Setting up inception_6a/3x3/scale1
I0122 20:39:38.120707 71044 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:38.120709 71044 net.cpp:159] Memory required for data: 456909800
I0122 20:39:38.120713 71044 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 20:39:38.120718 71044 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 20:39:38.120721 71044 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 20:39:38.120725 71044 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 20:39:38.120730 71044 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 20:39:38.120734 71044 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 20:39:38.120738 71044 net.cpp:159] Memory required for data: 460186600
I0122 20:39:38.120740 71044 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 20:39:38.120745 71044 net.cpp:94] Creating Layer inception_6a/output
I0122 20:39:38.120749 71044 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 20:39:38.120752 71044 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 20:39:38.120756 71044 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 20:39:38.120764 71044 net.cpp:144] Setting up inception_6a/output
I0122 20:39:38.120767 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.120769 71044 net.cpp:159] Memory required for data: 468378600
I0122 20:39:38.120772 71044 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 20:39:38.120776 71044 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 20:39:38.120779 71044 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 20:39:38.120785 71044 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 20:39:38.120793 71044 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 20:39:38.120800 71044 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 20:39:38.120806 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.120810 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.120812 71044 net.cpp:159] Memory required for data: 484762600
I0122 20:39:38.120815 71044 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 20:39:38.120823 71044 net.cpp:94] Creating Layer inception_7a/1x1
I0122 20:39:38.120826 71044 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 20:39:38.120832 71044 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 20:39:38.120954 71044 net.cpp:144] Setting up inception_7a/1x1
I0122 20:39:38.120960 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.120963 71044 net.cpp:159] Memory required for data: 488858600
I0122 20:39:38.120967 71044 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 20:39:38.120973 71044 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 20:39:38.120977 71044 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 20:39:38.120982 71044 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 20:39:38.121013 71044 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 20:39:38.121019 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.121022 71044 net.cpp:159] Memory required for data: 492954600
I0122 20:39:38.121028 71044 layer_factory.hpp:77] Creating layer inception_7a/1x1/scale1
I0122 20:39:38.121033 71044 net.cpp:94] Creating Layer inception_7a/1x1/scale1
I0122 20:39:38.121038 71044 net.cpp:435] inception_7a/1x1/scale1 <- inception_7a/1x1
I0122 20:39:38.121044 71044 net.cpp:396] inception_7a/1x1/scale1 -> inception_7a/1x1 (in-place)
I0122 20:39:38.121057 71044 layer_factory.hpp:77] Creating layer inception_7a/1x1/scale1
I0122 20:39:38.121071 71044 net.cpp:144] Setting up inception_7a/1x1/scale1
I0122 20:39:38.121078 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.121080 71044 net.cpp:159] Memory required for data: 497050600
I0122 20:39:38.121084 71044 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 20:39:38.121088 71044 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 20:39:38.121090 71044 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 20:39:38.121098 71044 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 20:39:38.121104 71044 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 20:39:38.121107 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.121109 71044 net.cpp:159] Memory required for data: 501146600
I0122 20:39:38.121112 71044 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 20:39:38.121119 71044 net.cpp:94] Creating Layer inception_7a/3x3
I0122 20:39:38.121124 71044 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 20:39:38.121130 71044 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 20:39:38.122095 71044 net.cpp:144] Setting up inception_7a/3x3
I0122 20:39:38.122105 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.122107 71044 net.cpp:159] Memory required for data: 505242600
I0122 20:39:38.122112 71044 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 20:39:38.122120 71044 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 20:39:38.122126 71044 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 20:39:38.122131 71044 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 20:39:38.122164 71044 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 20:39:38.122169 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.122172 71044 net.cpp:159] Memory required for data: 509338600
I0122 20:39:38.122179 71044 layer_factory.hpp:77] Creating layer inception_7a/3x3/scale1
I0122 20:39:38.122184 71044 net.cpp:94] Creating Layer inception_7a/3x3/scale1
I0122 20:39:38.122189 71044 net.cpp:435] inception_7a/3x3/scale1 <- inception_7a/3x3
I0122 20:39:38.122195 71044 net.cpp:396] inception_7a/3x3/scale1 -> inception_7a/3x3 (in-place)
I0122 20:39:38.122203 71044 layer_factory.hpp:77] Creating layer inception_7a/3x3/scale1
I0122 20:39:38.122218 71044 net.cpp:144] Setting up inception_7a/3x3/scale1
I0122 20:39:38.122225 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.122227 71044 net.cpp:159] Memory required for data: 513434600
I0122 20:39:38.122231 71044 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 20:39:38.122236 71044 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 20:39:38.122241 71044 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 20:39:38.122243 71044 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 20:39:38.122249 71044 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 20:39:38.122252 71044 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 20:39:38.122256 71044 net.cpp:159] Memory required for data: 517530600
I0122 20:39:38.122258 71044 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 20:39:38.122262 71044 net.cpp:94] Creating Layer inception_7a/output
I0122 20:39:38.122264 71044 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 20:39:38.122269 71044 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 20:39:38.122275 71044 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 20:39:38.122282 71044 net.cpp:144] Setting up inception_7a/output
I0122 20:39:38.122287 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.122289 71044 net.cpp:159] Memory required for data: 525722600
I0122 20:39:38.122292 71044 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 20:39:38.122297 71044 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 20:39:38.122310 71044 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 20:39:38.122316 71044 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 20:39:38.122321 71044 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 20:39:38.122328 71044 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 20:39:38.122334 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.122337 71044 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 20:39:38.122339 71044 net.cpp:159] Memory required for data: 542106600
I0122 20:39:38.122342 71044 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 20:39:38.122354 71044 net.cpp:94] Creating Layer inception_8a/1x1
I0122 20:39:38.122359 71044 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 20:39:38.122364 71044 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 20:39:38.122445 71044 net.cpp:144] Setting up inception_8a/1x1
I0122 20:39:38.122450 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.122453 71044 net.cpp:159] Memory required for data: 544564200
I0122 20:39:38.122458 71044 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 20:39:38.122464 71044 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 20:39:38.122467 71044 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 20:39:38.122474 71044 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 20:39:38.122509 71044 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 20:39:38.122514 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.122516 71044 net.cpp:159] Memory required for data: 547021800
I0122 20:39:38.122524 71044 layer_factory.hpp:77] Creating layer inception_8a/1x1/scale1
I0122 20:39:38.122529 71044 net.cpp:94] Creating Layer inception_8a/1x1/scale1
I0122 20:39:38.122531 71044 net.cpp:435] inception_8a/1x1/scale1 <- inception_8a/1x1
I0122 20:39:38.122536 71044 net.cpp:396] inception_8a/1x1/scale1 -> inception_8a/1x1 (in-place)
I0122 20:39:38.122545 71044 layer_factory.hpp:77] Creating layer inception_8a/1x1/scale1
I0122 20:39:38.122558 71044 net.cpp:144] Setting up inception_8a/1x1/scale1
I0122 20:39:38.122565 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.122566 71044 net.cpp:159] Memory required for data: 549479400
I0122 20:39:38.122571 71044 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 20:39:38.122576 71044 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 20:39:38.122578 71044 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 20:39:38.122582 71044 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 20:39:38.122588 71044 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 20:39:38.122591 71044 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 20:39:38.122594 71044 net.cpp:159] Memory required for data: 551937000
I0122 20:39:38.122596 71044 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 20:39:38.122611 71044 net.cpp:94] Creating Layer inception_8a/3x3
I0122 20:39:38.122615 71044 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 20:39:38.122620 71044 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 20:39:38.123759 71044 net.cpp:144] Setting up inception_8a/3x3
I0122 20:39:38.123770 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.123772 71044 net.cpp:159] Memory required for data: 556852200
I0122 20:39:38.123777 71044 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 20:39:38.123785 71044 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 20:39:38.123790 71044 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 20:39:38.123795 71044 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 20:39:38.123828 71044 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 20:39:38.123842 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.123847 71044 net.cpp:159] Memory required for data: 561767400
I0122 20:39:38.123852 71044 layer_factory.hpp:77] Creating layer inception_8a/3x3/scale1
I0122 20:39:38.123858 71044 net.cpp:94] Creating Layer inception_8a/3x3/scale1
I0122 20:39:38.123862 71044 net.cpp:435] inception_8a/3x3/scale1 <- inception_8a/3x3
I0122 20:39:38.123867 71044 net.cpp:396] inception_8a/3x3/scale1 -> inception_8a/3x3 (in-place)
I0122 20:39:38.123874 71044 layer_factory.hpp:77] Creating layer inception_8a/3x3/scale1
I0122 20:39:38.123891 71044 net.cpp:144] Setting up inception_8a/3x3/scale1
I0122 20:39:38.123896 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.123899 71044 net.cpp:159] Memory required for data: 566682600
I0122 20:39:38.123903 71044 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 20:39:38.123908 71044 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 20:39:38.123911 71044 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 20:39:38.123915 71044 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 20:39:38.123920 71044 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 20:39:38.123924 71044 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 20:39:38.123926 71044 net.cpp:159] Memory required for data: 571597800
I0122 20:39:38.123929 71044 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 20:39:38.123934 71044 net.cpp:94] Creating Layer inception_8a/output
I0122 20:39:38.123936 71044 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 20:39:38.123939 71044 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 20:39:38.123945 71044 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 20:39:38.123951 71044 net.cpp:144] Setting up inception_8a/output
I0122 20:39:38.123955 71044 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 20:39:38.123957 71044 net.cpp:159] Memory required for data: 578970600
I0122 20:39:38.123960 71044 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 20:39:38.123966 71044 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 20:39:38.123968 71044 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 20:39:38.123973 71044 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 20:39:38.123980 71044 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 20:39:38.123986 71044 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 20:39:38.123989 71044 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 20:39:38.123992 71044 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 20:39:38.123996 71044 net.cpp:159] Memory required for data: 593716200
I0122 20:39:38.123998 71044 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 20:39:38.124007 71044 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 20:39:38.124011 71044 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 20:39:38.124018 71044 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 20:39:38.125047 71044 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 20:39:38.125056 71044 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:38.125058 71044 net.cpp:159] Memory required for data: 594945000
I0122 20:39:38.125063 71044 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 20:39:38.125069 71044 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 20:39:38.125075 71044 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 20:39:38.125080 71044 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 20:39:38.125114 71044 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 20:39:38.125119 71044 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:38.125123 71044 net.cpp:159] Memory required for data: 596173800
I0122 20:39:38.125147 71044 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/scale1
I0122 20:39:38.125154 71044 net.cpp:94] Creating Layer downsample_9/3x3_s2/scale1
I0122 20:39:38.125157 71044 net.cpp:435] downsample_9/3x3_s2/scale1 <- downsample_9/3x3_s2
I0122 20:39:38.125162 71044 net.cpp:396] downsample_9/3x3_s2/scale1 -> downsample_9/3x3_s2 (in-place)
I0122 20:39:38.125171 71044 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/scale1
I0122 20:39:38.125185 71044 net.cpp:144] Setting up downsample_9/3x3_s2/scale1
I0122 20:39:38.125190 71044 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:38.125193 71044 net.cpp:159] Memory required for data: 597402600
I0122 20:39:38.125197 71044 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 20:39:38.125203 71044 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 20:39:38.125206 71044 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 20:39:38.125211 71044 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 20:39:38.125216 71044 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 20:39:38.125219 71044 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 20:39:38.125222 71044 net.cpp:159] Memory required for data: 598631400
I0122 20:39:38.125224 71044 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 20:39:38.125231 71044 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 20:39:38.125234 71044 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 20:39:38.125239 71044 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 20:39:38.125247 71044 net.cpp:144] Setting up downsample_9/pool_s2
I0122 20:39:38.125252 71044 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 20:39:38.125255 71044 net.cpp:159] Memory required for data: 600474600
I0122 20:39:38.125258 71044 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 20:39:38.125264 71044 net.cpp:94] Creating Layer downsample_9/output
I0122 20:39:38.125267 71044 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 20:39:38.125272 71044 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 20:39:38.125277 71044 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 20:39:38.125285 71044 net.cpp:144] Setting up downsample_9/output
I0122 20:39:38.125288 71044 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 20:39:38.125293 71044 net.cpp:159] Memory required for data: 603546600
I0122 20:39:38.125294 71044 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 20:39:38.125298 71044 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 20:39:38.125301 71044 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 20:39:38.125308 71044 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 20:39:38.125315 71044 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 20:39:38.125321 71044 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 20:39:38.125325 71044 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 20:39:38.125329 71044 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 20:39:38.125331 71044 net.cpp:159] Memory required for data: 609690600
I0122 20:39:38.125334 71044 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 20:39:38.125342 71044 net.cpp:94] Creating Layer inception_10a/1x1
I0122 20:39:38.125346 71044 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 20:39:38.125352 71044 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 20:39:38.125713 71044 net.cpp:144] Setting up inception_10a/1x1
I0122 20:39:38.125720 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.125722 71044 net.cpp:159] Memory required for data: 611943400
I0122 20:39:38.125727 71044 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 20:39:38.125739 71044 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 20:39:38.125742 71044 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 20:39:38.125748 71044 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 20:39:38.125782 71044 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 20:39:38.125787 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.125789 71044 net.cpp:159] Memory required for data: 614196200
I0122 20:39:38.125797 71044 layer_factory.hpp:77] Creating layer inception_10a/1x1/scale1
I0122 20:39:38.125803 71044 net.cpp:94] Creating Layer inception_10a/1x1/scale1
I0122 20:39:38.125808 71044 net.cpp:435] inception_10a/1x1/scale1 <- inception_10a/1x1
I0122 20:39:38.125811 71044 net.cpp:396] inception_10a/1x1/scale1 -> inception_10a/1x1 (in-place)
I0122 20:39:38.125821 71044 layer_factory.hpp:77] Creating layer inception_10a/1x1/scale1
I0122 20:39:38.125834 71044 net.cpp:144] Setting up inception_10a/1x1/scale1
I0122 20:39:38.125839 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.125843 71044 net.cpp:159] Memory required for data: 616449000
I0122 20:39:38.125847 71044 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 20:39:38.125851 71044 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 20:39:38.125854 71044 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 20:39:38.125857 71044 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 20:39:38.125864 71044 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 20:39:38.125866 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.125869 71044 net.cpp:159] Memory required for data: 618701800
I0122 20:39:38.125871 71044 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 20:39:38.125880 71044 net.cpp:94] Creating Layer inception_10a/3x3
I0122 20:39:38.125885 71044 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 20:39:38.125890 71044 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 20:39:38.128512 71044 net.cpp:144] Setting up inception_10a/3x3
I0122 20:39:38.128533 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.128536 71044 net.cpp:159] Memory required for data: 620749800
I0122 20:39:38.128541 71044 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 20:39:38.128549 71044 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 20:39:38.128554 71044 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 20:39:38.128559 71044 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 20:39:38.128595 71044 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 20:39:38.128600 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.128603 71044 net.cpp:159] Memory required for data: 622797800
I0122 20:39:38.128610 71044 layer_factory.hpp:77] Creating layer inception_10a/3x3/scale1
I0122 20:39:38.128615 71044 net.cpp:94] Creating Layer inception_10a/3x3/scale1
I0122 20:39:38.128620 71044 net.cpp:435] inception_10a/3x3/scale1 <- inception_10a/3x3
I0122 20:39:38.128626 71044 net.cpp:396] inception_10a/3x3/scale1 -> inception_10a/3x3 (in-place)
I0122 20:39:38.128634 71044 layer_factory.hpp:77] Creating layer inception_10a/3x3/scale1
I0122 20:39:38.128648 71044 net.cpp:144] Setting up inception_10a/3x3/scale1
I0122 20:39:38.128652 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.128655 71044 net.cpp:159] Memory required for data: 624845800
I0122 20:39:38.128659 71044 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 20:39:38.128664 71044 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 20:39:38.128667 71044 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 20:39:38.128672 71044 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 20:39:38.128677 71044 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 20:39:38.128680 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.128684 71044 net.cpp:159] Memory required for data: 626893800
I0122 20:39:38.128695 71044 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 20:39:38.128698 71044 net.cpp:94] Creating Layer inception_10a/output
I0122 20:39:38.128701 71044 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 20:39:38.128705 71044 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 20:39:38.128711 71044 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 20:39:38.128720 71044 net.cpp:144] Setting up inception_10a/output
I0122 20:39:38.128724 71044 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:38.128727 71044 net.cpp:159] Memory required for data: 631194600
I0122 20:39:38.128731 71044 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 20:39:38.128734 71044 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 20:39:38.128737 71044 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 20:39:38.128742 71044 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 20:39:38.128748 71044 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 20:39:38.128754 71044 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 20:39:38.128759 71044 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:38.128763 71044 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:38.128767 71044 net.cpp:159] Memory required for data: 639796200
I0122 20:39:38.128769 71044 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 20:39:38.128778 71044 net.cpp:94] Creating Layer inception_11a/1x1
I0122 20:39:38.128783 71044 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 20:39:38.128789 71044 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 20:39:38.129314 71044 net.cpp:144] Setting up inception_11a/1x1
I0122 20:39:38.129321 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.129324 71044 net.cpp:159] Memory required for data: 642049000
I0122 20:39:38.129330 71044 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 20:39:38.129338 71044 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 20:39:38.129343 71044 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 20:39:38.129349 71044 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 20:39:38.129384 71044 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 20:39:38.129390 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.129392 71044 net.cpp:159] Memory required for data: 644301800
I0122 20:39:38.129398 71044 layer_factory.hpp:77] Creating layer inception_11a/1x1/scale1
I0122 20:39:38.129403 71044 net.cpp:94] Creating Layer inception_11a/1x1/scale1
I0122 20:39:38.129406 71044 net.cpp:435] inception_11a/1x1/scale1 <- inception_11a/1x1
I0122 20:39:38.129411 71044 net.cpp:396] inception_11a/1x1/scale1 -> inception_11a/1x1 (in-place)
I0122 20:39:38.129420 71044 layer_factory.hpp:77] Creating layer inception_11a/1x1/scale1
I0122 20:39:38.129434 71044 net.cpp:144] Setting up inception_11a/1x1/scale1
I0122 20:39:38.129439 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.129442 71044 net.cpp:159] Memory required for data: 646554600
I0122 20:39:38.129446 71044 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 20:39:38.129451 71044 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 20:39:38.129453 71044 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 20:39:38.129458 71044 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 20:39:38.129463 71044 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 20:39:38.129469 71044 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 20:39:38.129472 71044 net.cpp:159] Memory required for data: 648807400
I0122 20:39:38.129474 71044 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 20:39:38.129482 71044 net.cpp:94] Creating Layer inception_11a/3x3
I0122 20:39:38.129495 71044 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 20:39:38.129503 71044 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 20:39:38.133122 71044 net.cpp:144] Setting up inception_11a/3x3
I0122 20:39:38.133131 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.133134 71044 net.cpp:159] Memory required for data: 650855400
I0122 20:39:38.133139 71044 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 20:39:38.133148 71044 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 20:39:38.133153 71044 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 20:39:38.133158 71044 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 20:39:38.133200 71044 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 20:39:38.133206 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.133209 71044 net.cpp:159] Memory required for data: 652903400
I0122 20:39:38.133216 71044 layer_factory.hpp:77] Creating layer inception_11a/3x3/scale1
I0122 20:39:38.133222 71044 net.cpp:94] Creating Layer inception_11a/3x3/scale1
I0122 20:39:38.133225 71044 net.cpp:435] inception_11a/3x3/scale1 <- inception_11a/3x3
I0122 20:39:38.133230 71044 net.cpp:396] inception_11a/3x3/scale1 -> inception_11a/3x3 (in-place)
I0122 20:39:38.133239 71044 layer_factory.hpp:77] Creating layer inception_11a/3x3/scale1
I0122 20:39:38.133255 71044 net.cpp:144] Setting up inception_11a/3x3/scale1
I0122 20:39:38.133260 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.133261 71044 net.cpp:159] Memory required for data: 654951400
I0122 20:39:38.133266 71044 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 20:39:38.133270 71044 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 20:39:38.133273 71044 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 20:39:38.133276 71044 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 20:39:38.133282 71044 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 20:39:38.133286 71044 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 20:39:38.133288 71044 net.cpp:159] Memory required for data: 656999400
I0122 20:39:38.133291 71044 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 20:39:38.133297 71044 net.cpp:94] Creating Layer inception_11a/output
I0122 20:39:38.133301 71044 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 20:39:38.133303 71044 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 20:39:38.133308 71044 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 20:39:38.133316 71044 net.cpp:144] Setting up inception_11a/output
I0122 20:39:38.133319 71044 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 20:39:38.133322 71044 net.cpp:159] Memory required for data: 661300200
I0122 20:39:38.133323 71044 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 20:39:38.133328 71044 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 20:39:38.133332 71044 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 20:39:38.133337 71044 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 20:39:38.133353 71044 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 20:39:38.133358 71044 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 20:39:38.133361 71044 net.cpp:159] Memory required for data: 661367400
I0122 20:39:38.133363 71044 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 20:39:38.133368 71044 net.cpp:94] Creating Layer drop_8x8_s1
I0122 20:39:38.133374 71044 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 20:39:38.133378 71044 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 20:39:38.133385 71044 net.cpp:144] Setting up drop_8x8_s1
I0122 20:39:38.133388 71044 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 20:39:38.133391 71044 net.cpp:159] Memory required for data: 661434600
I0122 20:39:38.133394 71044 layer_factory.hpp:77] Creating layer loss/classifier
I0122 20:39:38.133401 71044 net.cpp:94] Creating Layer loss/classifier
I0122 20:39:38.133414 71044 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 20:39:38.133420 71044 net.cpp:409] loss/classifier -> loss/classifier
I0122 20:39:38.133455 71044 net.cpp:144] Setting up loss/classifier
I0122 20:39:38.133460 71044 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:38.133462 71044 net.cpp:159] Memory required for data: 661436600
I0122 20:39:38.133467 71044 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 20:39:38.133472 71044 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 20:39:38.133476 71044 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 20:39:38.133481 71044 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 20:39:38.133488 71044 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 20:39:38.133493 71044 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 20:39:38.133500 71044 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 20:39:38.133508 71044 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 20:39:38.133512 71044 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:38.133515 71044 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:38.133518 71044 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:38.133522 71044 net.cpp:151] Top shape: 50 10 (500)
I0122 20:39:38.133524 71044 net.cpp:159] Memory required for data: 661444600
I0122 20:39:38.133527 71044 layer_factory.hpp:77] Creating layer loss
I0122 20:39:38.133532 71044 net.cpp:94] Creating Layer loss
I0122 20:39:38.133534 71044 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 20:39:38.133540 71044 net.cpp:435] loss <- label_data_1_split_0
I0122 20:39:38.133544 71044 net.cpp:409] loss -> loss
I0122 20:39:38.133551 71044 layer_factory.hpp:77] Creating layer loss
I0122 20:39:38.133566 71044 net.cpp:144] Setting up loss
I0122 20:39:38.133572 71044 net.cpp:151] Top shape: (1)
I0122 20:39:38.133575 71044 net.cpp:154]     with loss weight 1
I0122 20:39:38.133599 71044 net.cpp:159] Memory required for data: 661444604
I0122 20:39:38.133601 71044 layer_factory.hpp:77] Creating layer accuracy
I0122 20:39:38.133608 71044 net.cpp:94] Creating Layer accuracy
I0122 20:39:38.133611 71044 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 20:39:38.133615 71044 net.cpp:435] accuracy <- label_data_1_split_1
I0122 20:39:38.133621 71044 net.cpp:409] accuracy -> accuracy
I0122 20:39:38.133635 71044 net.cpp:144] Setting up accuracy
I0122 20:39:38.133641 71044 net.cpp:151] Top shape: (1)
I0122 20:39:38.133643 71044 net.cpp:159] Memory required for data: 661444608
I0122 20:39:38.133646 71044 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 20:39:38.133651 71044 net.cpp:94] Creating Layer accuracy-top1
I0122 20:39:38.133653 71044 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 20:39:38.133656 71044 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 20:39:38.133661 71044 net.cpp:409] accuracy-top1 -> top-1
I0122 20:39:38.133667 71044 net.cpp:144] Setting up accuracy-top1
I0122 20:39:38.133671 71044 net.cpp:151] Top shape: (1)
I0122 20:39:38.133673 71044 net.cpp:159] Memory required for data: 661444612
I0122 20:39:38.133675 71044 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 20:39:38.133680 71044 net.cpp:94] Creating Layer accuracy-top5
I0122 20:39:38.133684 71044 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 20:39:38.133687 71044 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 20:39:38.133693 71044 net.cpp:409] accuracy-top5 -> top-5
I0122 20:39:38.133699 71044 net.cpp:144] Setting up accuracy-top5
I0122 20:39:38.133705 71044 net.cpp:151] Top shape: (1)
I0122 20:39:38.133708 71044 net.cpp:159] Memory required for data: 661444616
I0122 20:39:38.133710 71044 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 20:39:38.133725 71044 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 20:39:38.133729 71044 net.cpp:222] accuracy does not need backward computation.
I0122 20:39:38.133733 71044 net.cpp:220] loss needs backward computation.
I0122 20:39:38.133736 71044 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 20:39:38.133740 71044 net.cpp:220] loss/classifier needs backward computation.
I0122 20:39:38.133744 71044 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 20:39:38.133746 71044 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 20:39:38.133749 71044 net.cpp:220] inception_11a/output needs backward computation.
I0122 20:39:38.133754 71044 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 20:39:38.133755 71044 net.cpp:220] inception_11a/3x3/scale1 needs backward computation.
I0122 20:39:38.133759 71044 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 20:39:38.133760 71044 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 20:39:38.133765 71044 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 20:39:38.133767 71044 net.cpp:220] inception_11a/1x1/scale1 needs backward computation.
I0122 20:39:38.133770 71044 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 20:39:38.133772 71044 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 20:39:38.133776 71044 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 20:39:38.133780 71044 net.cpp:220] inception_10a/output needs backward computation.
I0122 20:39:38.133785 71044 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 20:39:38.133787 71044 net.cpp:220] inception_10a/3x3/scale1 needs backward computation.
I0122 20:39:38.133790 71044 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 20:39:38.133795 71044 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 20:39:38.133797 71044 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 20:39:38.133800 71044 net.cpp:220] inception_10a/1x1/scale1 needs backward computation.
I0122 20:39:38.133803 71044 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 20:39:38.133805 71044 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 20:39:38.133810 71044 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 20:39:38.133812 71044 net.cpp:220] downsample_9/output needs backward computation.
I0122 20:39:38.133816 71044 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 20:39:38.133821 71044 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 20:39:38.133823 71044 net.cpp:220] downsample_9/3x3_s2/scale1 needs backward computation.
I0122 20:39:38.133826 71044 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 20:39:38.133828 71044 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 20:39:38.133831 71044 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 20:39:38.133836 71044 net.cpp:220] inception_8a/output needs backward computation.
I0122 20:39:38.133838 71044 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 20:39:38.133842 71044 net.cpp:220] inception_8a/3x3/scale1 needs backward computation.
I0122 20:39:38.133846 71044 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 20:39:38.133847 71044 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 20:39:38.133850 71044 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 20:39:38.133854 71044 net.cpp:220] inception_8a/1x1/scale1 needs backward computation.
I0122 20:39:38.133857 71044 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 20:39:38.133860 71044 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 20:39:38.133863 71044 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 20:39:38.133872 71044 net.cpp:220] inception_7a/output needs backward computation.
I0122 20:39:38.133877 71044 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 20:39:38.133878 71044 net.cpp:220] inception_7a/3x3/scale1 needs backward computation.
I0122 20:39:38.133882 71044 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 20:39:38.133884 71044 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 20:39:38.133888 71044 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 20:39:38.133890 71044 net.cpp:220] inception_7a/1x1/scale1 needs backward computation.
I0122 20:39:38.133893 71044 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 20:39:38.133896 71044 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 20:39:38.133901 71044 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 20:39:38.133910 71044 net.cpp:220] inception_6a/output needs backward computation.
I0122 20:39:38.133914 71044 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 20:39:38.133918 71044 net.cpp:220] inception_6a/3x3/scale1 needs backward computation.
I0122 20:39:38.133920 71044 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 20:39:38.133924 71044 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 20:39:38.133926 71044 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 20:39:38.133930 71044 net.cpp:220] inception_6a/1x1/scale1 needs backward computation.
I0122 20:39:38.133932 71044 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 20:39:38.133935 71044 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 20:39:38.133939 71044 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 20:39:38.133942 71044 net.cpp:220] inception_5a/output needs backward computation.
I0122 20:39:38.133945 71044 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 20:39:38.133949 71044 net.cpp:220] inception_5a/3x3/scale1 needs backward computation.
I0122 20:39:38.133951 71044 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 20:39:38.133955 71044 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 20:39:38.133957 71044 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 20:39:38.133960 71044 net.cpp:220] inception_5a/1x1/scale1 needs backward computation.
I0122 20:39:38.133963 71044 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 20:39:38.133967 71044 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 20:39:38.133970 71044 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 20:39:38.133973 71044 net.cpp:220] downsample_4/output needs backward computation.
I0122 20:39:38.133976 71044 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 20:39:38.133980 71044 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 20:39:38.133983 71044 net.cpp:220] downsample_4/3x3_s2/scale1 needs backward computation.
I0122 20:39:38.133986 71044 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 20:39:38.133989 71044 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 20:39:38.133992 71044 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 20:39:38.133996 71044 net.cpp:220] inception_3a/output needs backward computation.
I0122 20:39:38.133999 71044 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 20:39:38.134001 71044 net.cpp:220] inception_3a/3x3/scale1 needs backward computation.
I0122 20:39:38.134006 71044 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 20:39:38.134007 71044 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 20:39:38.134011 71044 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 20:39:38.134013 71044 net.cpp:220] inception_3a/1x1/scale1 needs backward computation.
I0122 20:39:38.134022 71044 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 20:39:38.134025 71044 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 20:39:38.134028 71044 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 20:39:38.134032 71044 net.cpp:220] inception_2a/output needs backward computation.
I0122 20:39:38.134035 71044 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 20:39:38.134038 71044 net.cpp:220] inception_2a/3x3/scale1 needs backward computation.
I0122 20:39:38.134042 71044 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 20:39:38.134044 71044 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 20:39:38.134048 71044 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 20:39:38.134052 71044 net.cpp:220] inception_2a/1x1/scale1 needs backward computation.
I0122 20:39:38.134054 71044 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 20:39:38.134057 71044 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 20:39:38.134061 71044 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 20:39:38.134064 71044 net.cpp:220] conv1/relu1 needs backward computation.
I0122 20:39:38.134068 71044 net.cpp:220] conv1/scale1 needs backward computation.
I0122 20:39:38.134070 71044 net.cpp:220] conv1/bn1 needs backward computation.
I0122 20:39:38.134073 71044 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 20:39:38.134078 71044 net.cpp:222] label_data_1_split does not need backward computation.
I0122 20:39:38.134081 71044 net.cpp:222] data does not need backward computation.
I0122 20:39:38.134083 71044 net.cpp:264] This network produces output accuracy
I0122 20:39:38.134088 71044 net.cpp:264] This network produces output loss
I0122 20:39:38.134091 71044 net.cpp:264] This network produces output top-1
I0122 20:39:38.134094 71044 net.cpp:264] This network produces output top-5
I0122 20:39:38.134174 71044 net.cpp:284] Network initialization done.
I0122 20:39:38.134510 71044 net_counter.cpp:58] Convolution layer conv1/3x3_s1 ops: 5406720
I0122 20:39:38.134516 71044 net_counter.cpp:62] Convolution layer conv1/3x3_s1 params: 2688
I0122 20:39:38.134519 71044 net_counter.cpp:62] BatchNorm layer conv1/bn1 params: 385
I0122 20:39:38.134522 71044 net_counter.cpp:58] Convolution layer inception_2a/1x1 ops: 6324224
I0122 20:39:38.134526 71044 net_counter.cpp:62] Convolution layer inception_2a/1x1 params: 3104
I0122 20:39:38.134527 71044 net_counter.cpp:62] BatchNorm layer inception_2a/1x1/bn1 params: 129
I0122 20:39:38.134531 71044 net_counter.cpp:58] Convolution layer inception_2a/3x3 ops: 56655872
I0122 20:39:38.134533 71044 net_counter.cpp:62] Convolution layer inception_2a/3x3 params: 27680
I0122 20:39:38.134536 71044 net_counter.cpp:62] BatchNorm layer inception_2a/3x3/bn1 params: 129
I0122 20:39:38.134539 71044 net_counter.cpp:58] Convolution layer inception_3a/1x1 ops: 4227072
I0122 20:39:38.134542 71044 net_counter.cpp:62] Convolution layer inception_3a/1x1 params: 2080
I0122 20:39:38.134546 71044 net_counter.cpp:62] BatchNorm layer inception_3a/1x1/bn1 params: 129
I0122 20:39:38.134549 71044 net_counter.cpp:58] Convolution layer inception_3a/3x3 ops: 56672256
I0122 20:39:38.134552 71044 net_counter.cpp:62] Convolution layer inception_3a/3x3 params: 27696
I0122 20:39:38.134555 71044 net_counter.cpp:62] BatchNorm layer inception_3a/3x3/bn1 params: 193
I0122 20:39:38.134558 71044 net_counter.cpp:58] Convolution layer downsample_4/3x3_s2 ops: 29511680
I0122 20:39:38.134562 71044 net_counter.cpp:62] Convolution layer downsample_4/3x3_s2 params: 57680
I0122 20:39:38.134564 71044 net_counter.cpp:62] BatchNorm layer downsample_4/3x3_s2/bn1 params: 321
I0122 20:39:38.134567 71044 net_counter.cpp:58] Convolution layer inception_5a/1x1 ops: 9203712
I0122 20:39:38.134570 71044 net_counter.cpp:62] Convolution layer inception_5a/1x1 params: 18032
I0122 20:39:38.134573 71044 net_counter.cpp:62] BatchNorm layer inception_5a/1x1/bn1 params: 449
I0122 20:39:38.134582 71044 net_counter.cpp:58] Convolution layer inception_5a/3x3 ops: 35401728
I0122 20:39:38.134584 71044 net_counter.cpp:62] Convolution layer inception_5a/3x3 params: 69168
I0122 20:39:38.134586 71044 net_counter.cpp:62] BatchNorm layer inception_5a/3x3/bn1 params: 193
I0122 20:39:38.134590 71044 net_counter.cpp:58] Convolution layer inception_6a/1x1 ops: 7888896
I0122 20:39:38.134593 71044 net_counter.cpp:62] Convolution layer inception_6a/1x1 params: 15456
I0122 20:39:38.134595 71044 net_counter.cpp:62] BatchNorm layer inception_6a/1x1/bn1 params: 385
I0122 20:39:38.134598 71044 net_counter.cpp:58] Convolution layer inception_6a/3x3 ops: 47202304
I0122 20:39:38.134601 71044 net_counter.cpp:62] Convolution layer inception_6a/3x3 params: 92224
I0122 20:39:38.134604 71044 net_counter.cpp:62] BatchNorm layer inception_6a/3x3/bn1 params: 257
I0122 20:39:38.134608 71044 net_counter.cpp:58] Convolution layer inception_7a/1x1 ops: 6574080
I0122 20:39:38.134609 71044 net_counter.cpp:62] Convolution layer inception_7a/1x1 params: 12880
I0122 20:39:38.134613 71044 net_counter.cpp:62] BatchNorm layer inception_7a/1x1/bn1 params: 321
I0122 20:39:38.134616 71044 net_counter.cpp:58] Convolution layer inception_7a/3x3 ops: 59002880
I0122 20:39:38.134618 71044 net_counter.cpp:62] Convolution layer inception_7a/3x3 params: 115280
I0122 20:39:38.134621 71044 net_counter.cpp:62] BatchNorm layer inception_7a/3x3/bn1 params: 321
I0122 20:39:38.134624 71044 net_counter.cpp:58] Convolution layer inception_8a/1x1 ops: 3944448
I0122 20:39:38.134626 71044 net_counter.cpp:62] Convolution layer inception_8a/1x1 params: 7728
I0122 20:39:38.134629 71044 net_counter.cpp:62] BatchNorm layer inception_8a/1x1/bn1 params: 193
I0122 20:39:38.134632 71044 net_counter.cpp:58] Convolution layer inception_8a/3x3 ops: 70803456
I0122 20:39:38.134635 71044 net_counter.cpp:62] Convolution layer inception_8a/3x3 params: 138336
I0122 20:39:38.134639 71044 net_counter.cpp:62] BatchNorm layer inception_8a/3x3/bn1 params: 385
I0122 20:39:38.134641 71044 net_counter.cpp:58] Convolution layer downsample_9/3x3_s2 ops: 15931392
I0122 20:39:38.134644 71044 net_counter.cpp:62] Convolution layer downsample_9/3x3_s2 params: 124512
I0122 20:39:38.134647 71044 net_counter.cpp:62] BatchNorm layer downsample_9/3x3_s2/bn1 params: 385
I0122 20:39:38.134650 71044 net_counter.cpp:58] Convolution layer inception_10a/1x1 ops: 5417984
I0122 20:39:38.134652 71044 net_counter.cpp:62] Convolution layer inception_10a/1x1 params: 42416
I0122 20:39:38.134655 71044 net_counter.cpp:62] BatchNorm layer inception_10a/1x1/bn1 params: 705
I0122 20:39:38.134658 71044 net_counter.cpp:58] Convolution layer inception_10a/3x3 ops: 44247040
I0122 20:39:38.134660 71044 net_counter.cpp:62] Convolution layer inception_10a/3x3 params: 345760
I0122 20:39:38.134663 71044 net_counter.cpp:62] BatchNorm layer inception_10a/3x3/bn1 params: 641
I0122 20:39:38.134666 71044 net_counter.cpp:58] Convolution layer inception_11a/1x1 ops: 7580672
I0122 20:39:38.134670 71044 net_counter.cpp:62] Convolution layer inception_11a/1x1 params: 59312
I0122 20:39:38.134672 71044 net_counter.cpp:62] BatchNorm layer inception_11a/1x1/bn1 params: 705
I0122 20:39:38.134675 71044 net_counter.cpp:58] Convolution layer inception_11a/3x3 ops: 61941760
I0122 20:39:38.134677 71044 net_counter.cpp:62] Convolution layer inception_11a/3x3 params: 484000
I0122 20:39:38.134680 71044 net_counter.cpp:62] BatchNorm layer inception_11a/3x3/bn1 params: 641
I0122 20:39:38.134683 71044 net_counter.cpp:68] Total operations: 533938176
I0122 20:39:38.134686 71044 net_counter.cpp:69] Total params: 1652899



