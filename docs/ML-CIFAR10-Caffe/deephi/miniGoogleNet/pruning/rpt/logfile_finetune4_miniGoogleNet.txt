I0122 19:57:14.074530 70718 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt
I0122 19:57:14.255364 70718 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 19:57:14.255919 70718 gpu_memory.cpp:55] Total memory: 25620447232, Free: 24778440704, dev_info[0]: total=25620447232 free=24778440704
I0122 19:57:14.255933 70718 caffe_interface.cpp:493] Using GPUs 0
I0122 19:57:14.256209 70718 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 19:57:14.837584 70718 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt"
type: "SGD"
I0122 19:57:14.837694 70718 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt
I0122 19:57:14.838297 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 19:57:14.838327 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 19:57:14.838330 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 19:57:14.838333 70718 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 19:57:14.838850 70718 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 19:57:14.839166 70718 layer_factory.hpp:77] Creating layer data
I0122 19:57:14.839268 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.840065 70718 net.cpp:94] Creating Layer data
I0122 19:57:14.840076 70718 net.cpp:409] data -> data
I0122 19:57:14.840088 70718 net.cpp:409] data -> label
I0122 19:57:14.841506 70757 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 19:57:14.841554 70757 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 19:57:14.841626 70718 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 19:57:14.841704 70718 data_layer.cpp:83] output data size: 128,3,32,32
I0122 19:57:14.849411 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.849478 70718 net.cpp:144] Setting up data
I0122 19:57:14.849486 70718 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 19:57:14.849493 70718 net.cpp:151] Top shape: 128 (128)
I0122 19:57:14.849495 70718 net.cpp:159] Memory required for data: 1573376
I0122 19:57:14.849500 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:57:14.849516 70718 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:57:14.849524 70718 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:57:14.849544 70718 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:57:14.851593 70718 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:57:14.851608 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.851611 70718 net.cpp:159] Memory required for data: 51905024
I0122 19:57:14.851644 70718 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:57:14.851655 70718 net.cpp:94] Creating Layer conv1/bn1
I0122 19:57:14.851658 70718 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:57:14.851667 70718 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.852416 70718 net.cpp:144] Setting up conv1/bn1
I0122 19:57:14.852427 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852430 70718 net.cpp:159] Memory required for data: 102236672
I0122 19:57:14.852445 70718 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:57:14.852455 70718 net.cpp:94] Creating Layer conv1/relu1
I0122 19:57:14.852458 70718 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:57:14.852464 70718 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.852478 70718 net.cpp:144] Setting up conv1/relu1
I0122 19:57:14.852494 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852497 70718 net.cpp:159] Memory required for data: 152568320
I0122 19:57:14.852501 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.852510 70718 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.852516 70718 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:57:14.852522 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.852530 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.852571 70718 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.852579 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852584 70718 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 19:57:14.852587 70718 net.cpp:159] Memory required for data: 253231616
I0122 19:57:14.852592 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:57:14.852602 70718 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:57:14.852607 70718 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.852613 70718 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:57:14.853647 70718 net.cpp:144] Setting up inception_2a/1x1
I0122 19:57:14.853660 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.853663 70718 net.cpp:159] Memory required for data: 270008832
I0122 19:57:14.853672 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:57:14.853683 70718 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:57:14.853688 70718 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:57:14.853694 70718 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.854457 70718 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:57:14.854466 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.854468 70718 net.cpp:159] Memory required for data: 286786048
I0122 19:57:14.854477 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:57:14.854483 70718 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:57:14.854488 70718 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:57:14.854495 70718 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.854516 70718 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:57:14.854521 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.854524 70718 net.cpp:159] Memory required for data: 303563264
I0122 19:57:14.854527 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:57:14.854539 70718 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:57:14.854545 70718 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.854554 70718 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:57:14.855700 70718 net.cpp:144] Setting up inception_2a/3x3
I0122 19:57:14.855711 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.855715 70718 net.cpp:159] Memory required for data: 320340480
I0122 19:57:14.855721 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:57:14.855729 70718 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:57:14.855732 70718 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:57:14.855741 70718 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.856446 70718 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:57:14.856453 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.856457 70718 net.cpp:159] Memory required for data: 337117696
I0122 19:57:14.856472 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:57:14.856478 70718 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:57:14.856482 70718 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:57:14.856487 70718 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.856518 70718 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:57:14.856523 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.856525 70718 net.cpp:159] Memory required for data: 353894912
I0122 19:57:14.856528 70718 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:57:14.856534 70718 net.cpp:94] Creating Layer inception_2a/output
I0122 19:57:14.856540 70718 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:57:14.856545 70718 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:57:14.856552 70718 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:57:14.856580 70718 net.cpp:144] Setting up inception_2a/output
I0122 19:57:14.856590 70718 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:57:14.856593 70718 net.cpp:159] Memory required for data: 387449344
I0122 19:57:14.856597 70718 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.856602 70718 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.856606 70718 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:57:14.856611 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.856618 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.856657 70718 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.856667 70718 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:57:14.856673 70718 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 19:57:14.856674 70718 net.cpp:159] Memory required for data: 454558208
I0122 19:57:14.856678 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:57:14.856688 70718 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:57:14.856690 70718 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.856695 70718 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:57:14.856942 70718 net.cpp:144] Setting up inception_3a/1x1
I0122 19:57:14.856951 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.856954 70718 net.cpp:159] Memory required for data: 471335424
I0122 19:57:14.856959 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:57:14.856976 70718 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:57:14.856982 70718 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:57:14.857007 70718 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.857722 70718 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:57:14.857729 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.857733 70718 net.cpp:159] Memory required for data: 488112640
I0122 19:57:14.857741 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:57:14.857746 70718 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:57:14.857749 70718 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:57:14.857754 70718 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.857762 70718 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:57:14.857769 70718 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 19:57:14.857772 70718 net.cpp:159] Memory required for data: 504889856
I0122 19:57:14.857776 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:57:14.857795 70718 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:57:14.857801 70718 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.857810 70718 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:57:14.858260 70718 net.cpp:144] Setting up inception_3a/3x3
I0122 19:57:14.858269 70718 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:57:14.858273 70718 net.cpp:159] Memory required for data: 530055680
I0122 19:57:14.858297 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:57:14.858306 70718 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:57:14.858311 70718 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:57:14.858320 70718 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.859016 70718 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:57:14.859025 70718 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:57:14.859027 70718 net.cpp:159] Memory required for data: 555221504
I0122 19:57:14.859040 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:57:14.859047 70718 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:57:14.859051 70718 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:57:14.859058 70718 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.859067 70718 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:57:14.859074 70718 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 19:57:14.859079 70718 net.cpp:159] Memory required for data: 580387328
I0122 19:57:14.859082 70718 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:57:14.859092 70718 net.cpp:94] Creating Layer inception_3a/output
I0122 19:57:14.859098 70718 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:57:14.859102 70718 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:57:14.859107 70718 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:57:14.859135 70718 net.cpp:144] Setting up inception_3a/output
I0122 19:57:14.859143 70718 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:57:14.859149 70718 net.cpp:159] Memory required for data: 622330368
I0122 19:57:14.859153 70718 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.859158 70718 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.859160 70718 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:57:14.859166 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.859175 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.859215 70718 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.859220 70718 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:57:14.859225 70718 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 19:57:14.859227 70718 net.cpp:159] Memory required for data: 706216448
I0122 19:57:14.859230 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:57:14.859239 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:57:14.859243 70718 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.859251 70718 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:57:14.859817 70718 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:57:14.859824 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.859827 70718 net.cpp:159] Memory required for data: 716702208
I0122 19:57:14.859833 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:57:14.859840 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:57:14.859846 70718 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:57:14.859853 70718 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.860625 70718 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:57:14.860633 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.860635 70718 net.cpp:159] Memory required for data: 727187968
I0122 19:57:14.860644 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:57:14.860651 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:57:14.860653 70718 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:57:14.860671 70718 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.860682 70718 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:57:14.860690 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.860694 70718 net.cpp:159] Memory required for data: 737673728
I0122 19:57:14.860698 70718 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:57:14.860707 70718 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:57:14.860714 70718 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.860723 70718 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:57:14.860813 70718 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:57:14.860821 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.860823 70718 net.cpp:159] Memory required for data: 748159488
I0122 19:57:14.860826 70718 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:57:14.860831 70718 net.cpp:94] Creating Layer downsample_4/output
I0122 19:57:14.860836 70718 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:57:14.860838 70718 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:57:14.860846 70718 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:57:14.860867 70718 net.cpp:144] Setting up downsample_4/output
I0122 19:57:14.860874 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.860886 70718 net.cpp:159] Memory required for data: 769131008
I0122 19:57:14.860890 70718 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.860898 70718 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.860903 70718 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:57:14.860910 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.860918 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.860961 70718 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.860967 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.860971 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.860975 70718 net.cpp:159] Memory required for data: 811074048
I0122 19:57:14.860976 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:57:14.860986 70718 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:57:14.860990 70718 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.860996 70718 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:57:14.861351 70718 net.cpp:144] Setting up inception_5a/1x1
I0122 19:57:14.861361 70718 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:57:14.861362 70718 net.cpp:159] Memory required for data: 825754112
I0122 19:57:14.861367 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:57:14.861376 70718 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:57:14.861382 70718 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:57:14.861388 70718 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.862061 70718 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:57:14.862071 70718 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:57:14.862073 70718 net.cpp:159] Memory required for data: 840434176
I0122 19:57:14.862082 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:57:14.862087 70718 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:57:14.862090 70718 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:57:14.862095 70718 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.862104 70718 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:57:14.862110 70718 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 19:57:14.862124 70718 net.cpp:159] Memory required for data: 855114240
I0122 19:57:14.862129 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:57:14.862141 70718 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:57:14.862149 70718 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.862157 70718 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:57:14.862895 70718 net.cpp:144] Setting up inception_5a/3x3
I0122 19:57:14.862905 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.862908 70718 net.cpp:159] Memory required for data: 861405696
I0122 19:57:14.862913 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:57:14.862922 70718 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:57:14.862926 70718 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:57:14.862932 70718 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.863602 70718 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:57:14.863611 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.863615 70718 net.cpp:159] Memory required for data: 867697152
I0122 19:57:14.863622 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:57:14.863631 70718 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:57:14.863634 70718 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:57:14.863639 70718 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.863649 70718 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:57:14.863654 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.863659 70718 net.cpp:159] Memory required for data: 873988608
I0122 19:57:14.863662 70718 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:57:14.863672 70718 net.cpp:94] Creating Layer inception_5a/output
I0122 19:57:14.863678 70718 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:57:14.863685 70718 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:57:14.863692 70718 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:57:14.863718 70718 net.cpp:144] Setting up inception_5a/output
I0122 19:57:14.863725 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.863730 70718 net.cpp:159] Memory required for data: 894960128
I0122 19:57:14.863734 70718 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.863740 70718 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.863744 70718 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:57:14.863750 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.863759 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.863801 70718 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.863811 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.863816 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.863818 70718 net.cpp:159] Memory required for data: 936903168
I0122 19:57:14.863821 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:57:14.863828 70718 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:57:14.863832 70718 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.863840 70718 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:57:14.864886 70718 net.cpp:144] Setting up inception_6a/1x1
I0122 19:57:14.864897 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.864899 70718 net.cpp:159] Memory required for data: 949486080
I0122 19:57:14.864905 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:57:14.864915 70718 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:57:14.864939 70718 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:57:14.864949 70718 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.865965 70718 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:57:14.865978 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.865983 70718 net.cpp:159] Memory required for data: 962068992
I0122 19:57:14.865996 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:57:14.866006 70718 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:57:14.866011 70718 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:57:14.866020 70718 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.866034 70718 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:57:14.866041 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.866044 70718 net.cpp:159] Memory required for data: 974651904
I0122 19:57:14.866050 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:57:14.866063 70718 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:57:14.866070 70718 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.866080 70718 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:57:14.867453 70718 net.cpp:144] Setting up inception_6a/3x3
I0122 19:57:14.867468 70718 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:57:14.867473 70718 net.cpp:159] Memory required for data: 983040512
I0122 19:57:14.867492 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:57:14.867508 70718 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:57:14.867516 70718 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:57:14.867527 70718 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.868402 70718 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:57:14.868417 70718 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:57:14.868422 70718 net.cpp:159] Memory required for data: 991429120
I0122 19:57:14.868435 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:57:14.868446 70718 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:57:14.868451 70718 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:57:14.868459 70718 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.868472 70718 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:57:14.868479 70718 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 19:57:14.868482 70718 net.cpp:159] Memory required for data: 999817728
I0122 19:57:14.868487 70718 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:57:14.868496 70718 net.cpp:94] Creating Layer inception_6a/output
I0122 19:57:14.868505 70718 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:57:14.868510 70718 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:57:14.868518 70718 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:57:14.868546 70718 net.cpp:144] Setting up inception_6a/output
I0122 19:57:14.868554 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.868558 70718 net.cpp:159] Memory required for data: 1020789248
I0122 19:57:14.868563 70718 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.868569 70718 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.868574 70718 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:57:14.868583 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.868597 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.868639 70718 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.868647 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.868669 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.868674 70718 net.cpp:159] Memory required for data: 1062732288
I0122 19:57:14.868677 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:57:14.868690 70718 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:57:14.868696 70718 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.868705 70718 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:57:14.869055 70718 net.cpp:144] Setting up inception_7a/1x1
I0122 19:57:14.869062 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.869065 70718 net.cpp:159] Memory required for data: 1073218048
I0122 19:57:14.869071 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:57:14.869079 70718 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:57:14.869082 70718 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:57:14.869089 70718 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.869942 70718 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:57:14.869951 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.869954 70718 net.cpp:159] Memory required for data: 1083703808
I0122 19:57:14.869962 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:57:14.869971 70718 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:57:14.869973 70718 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:57:14.869978 70718 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.869990 70718 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:57:14.869998 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.870002 70718 net.cpp:159] Memory required for data: 1094189568
I0122 19:57:14.870005 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:57:14.870018 70718 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:57:14.870025 70718 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.870034 70718 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:57:14.870947 70718 net.cpp:144] Setting up inception_7a/3x3
I0122 19:57:14.870956 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.870960 70718 net.cpp:159] Memory required for data: 1104675328
I0122 19:57:14.870965 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:57:14.870975 70718 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:57:14.870977 70718 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:57:14.870985 70718 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.871769 70718 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:57:14.871778 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.871779 70718 net.cpp:159] Memory required for data: 1115161088
I0122 19:57:14.871788 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:57:14.871793 70718 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:57:14.871796 70718 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:57:14.871803 70718 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.871815 70718 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:57:14.871820 70718 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 19:57:14.871824 70718 net.cpp:159] Memory required for data: 1125646848
I0122 19:57:14.871829 70718 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:57:14.871834 70718 net.cpp:94] Creating Layer inception_7a/output
I0122 19:57:14.871839 70718 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:57:14.871843 70718 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:57:14.871850 70718 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:57:14.871932 70718 net.cpp:144] Setting up inception_7a/output
I0122 19:57:14.871938 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.871953 70718 net.cpp:159] Memory required for data: 1146618368
I0122 19:57:14.871956 70718 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.871963 70718 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.871968 70718 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:57:14.871974 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.871989 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.872028 70718 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.872038 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.872042 70718 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 19:57:14.872045 70718 net.cpp:159] Memory required for data: 1188561408
I0122 19:57:14.872048 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:57:14.872056 70718 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:57:14.872061 70718 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.872067 70718 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:57:14.872367 70718 net.cpp:144] Setting up inception_8a/1x1
I0122 19:57:14.872375 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.872376 70718 net.cpp:159] Memory required for data: 1194852864
I0122 19:57:14.872381 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:57:14.872390 70718 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:57:14.872392 70718 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:57:14.872400 70718 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.873090 70718 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:57:14.873097 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.873100 70718 net.cpp:159] Memory required for data: 1201144320
I0122 19:57:14.873108 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:57:14.873113 70718 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:57:14.873117 70718 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:57:14.873123 70718 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.873133 70718 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:57:14.873139 70718 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 19:57:14.873143 70718 net.cpp:159] Memory required for data: 1207435776
I0122 19:57:14.873148 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:57:14.873160 70718 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:57:14.873167 70718 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.873178 70718 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:57:14.874861 70718 net.cpp:144] Setting up inception_8a/3x3
I0122 19:57:14.874871 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.874874 70718 net.cpp:159] Memory required for data: 1220018688
I0122 19:57:14.874879 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:57:14.874887 70718 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:57:14.874891 70718 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:57:14.874897 70718 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.875560 70718 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:57:14.875568 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.875571 70718 net.cpp:159] Memory required for data: 1232601600
I0122 19:57:14.875579 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:57:14.875587 70718 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:57:14.875591 70718 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:57:14.875612 70718 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.875624 70718 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:57:14.875632 70718 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 19:57:14.875634 70718 net.cpp:159] Memory required for data: 1245184512
I0122 19:57:14.875638 70718 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:57:14.875644 70718 net.cpp:94] Creating Layer inception_8a/output
I0122 19:57:14.875655 70718 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:57:14.875660 70718 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:57:14.875668 70718 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:57:14.875697 70718 net.cpp:144] Setting up inception_8a/output
I0122 19:57:14.875706 70718 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:57:14.875710 70718 net.cpp:159] Memory required for data: 1264058880
I0122 19:57:14.875715 70718 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.875720 70718 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.875726 70718 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:57:14.875733 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.875742 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.875784 70718 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.875792 70718 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:57:14.875797 70718 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 19:57:14.875798 70718 net.cpp:159] Memory required for data: 1301807616
I0122 19:57:14.875802 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:57:14.875810 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:57:14.875815 70718 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.875824 70718 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:57:14.876761 70718 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:57:14.876773 70718 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:57:14.876776 70718 net.cpp:159] Memory required for data: 1304953344
I0122 19:57:14.876781 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:57:14.876791 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:57:14.876796 70718 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:57:14.876806 70718 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.877494 70718 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:57:14.877501 70718 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:57:14.877504 70718 net.cpp:159] Memory required for data: 1308099072
I0122 19:57:14.877512 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:57:14.877519 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:57:14.877522 70718 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:57:14.877530 70718 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.877542 70718 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:57:14.877550 70718 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 19:57:14.877554 70718 net.cpp:159] Memory required for data: 1311244800
I0122 19:57:14.877558 70718 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:57:14.877565 70718 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:57:14.877571 70718 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.877581 70718 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:57:14.877624 70718 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:57:14.877638 70718 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 19:57:14.877641 70718 net.cpp:159] Memory required for data: 1315963392
I0122 19:57:14.877645 70718 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:57:14.877650 70718 net.cpp:94] Creating Layer downsample_9/output
I0122 19:57:14.877652 70718 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:57:14.877656 70718 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:57:14.877662 70718 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:57:14.877689 70718 net.cpp:144] Setting up downsample_9/output
I0122 19:57:14.877697 70718 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:57:14.877701 70718 net.cpp:159] Memory required for data: 1323827712
I0122 19:57:14.877704 70718 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.877713 70718 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.877717 70718 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:57:14.877724 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.877733 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.877774 70718 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.877779 70718 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:57:14.877784 70718 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 19:57:14.877785 70718 net.cpp:159] Memory required for data: 1339556352
I0122 19:57:14.877789 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:57:14.877799 70718 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:57:14.877804 70718 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.877811 70718 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:57:14.878301 70718 net.cpp:144] Setting up inception_10a/1x1
I0122 19:57:14.878309 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.878312 70718 net.cpp:159] Memory required for data: 1345323520
I0122 19:57:14.878317 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:57:14.878325 70718 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:57:14.878330 70718 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:57:14.878340 70718 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.879026 70718 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:57:14.879035 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.879037 70718 net.cpp:159] Memory required for data: 1351090688
I0122 19:57:14.879045 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:57:14.879053 70718 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:57:14.879057 70718 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:57:14.879063 70718 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.879074 70718 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:57:14.879081 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.879086 70718 net.cpp:159] Memory required for data: 1356857856
I0122 19:57:14.879089 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:57:14.879101 70718 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:57:14.879107 70718 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.879117 70718 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:57:14.882319 70718 net.cpp:144] Setting up inception_10a/3x3
I0122 19:57:14.882333 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.882334 70718 net.cpp:159] Memory required for data: 1362100736
I0122 19:57:14.882340 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:57:14.882375 70718 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:57:14.882381 70718 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:57:14.882392 70718 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.883085 70718 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:57:14.883093 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.883096 70718 net.cpp:159] Memory required for data: 1367343616
I0122 19:57:14.883105 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:57:14.883111 70718 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:57:14.883116 70718 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:57:14.883122 70718 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.883133 70718 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:57:14.883139 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.883143 70718 net.cpp:159] Memory required for data: 1372586496
I0122 19:57:14.883147 70718 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:57:14.883155 70718 net.cpp:94] Creating Layer inception_10a/output
I0122 19:57:14.883162 70718 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:57:14.883168 70718 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:57:14.883175 70718 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:57:14.883204 70718 net.cpp:144] Setting up inception_10a/output
I0122 19:57:14.883213 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.883217 70718 net.cpp:159] Memory required for data: 1383596544
I0122 19:57:14.883221 70718 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.883226 70718 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.883232 70718 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:57:14.883240 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.883250 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.883291 70718 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.883298 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.883302 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.883306 70718 net.cpp:159] Memory required for data: 1405616640
I0122 19:57:14.883308 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:57:14.883321 70718 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:57:14.883325 70718 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.883333 70718 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:57:14.883913 70718 net.cpp:144] Setting up inception_11a/1x1
I0122 19:57:14.883921 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.883924 70718 net.cpp:159] Memory required for data: 1411383808
I0122 19:57:14.883929 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:57:14.883937 70718 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:57:14.883944 70718 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:57:14.883952 70718 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.884652 70718 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:57:14.884660 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.884663 70718 net.cpp:159] Memory required for data: 1417150976
I0122 19:57:14.884671 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:57:14.884680 70718 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:57:14.884686 70718 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:57:14.884706 70718 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.884716 70718 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:57:14.884721 70718 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 19:57:14.884724 70718 net.cpp:159] Memory required for data: 1422918144
I0122 19:57:14.884728 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:57:14.884740 70718 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:57:14.884747 70718 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.884755 70718 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:57:14.888675 70718 net.cpp:144] Setting up inception_11a/3x3
I0122 19:57:14.888687 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.888690 70718 net.cpp:159] Memory required for data: 1428161024
I0122 19:57:14.888695 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:57:14.888703 70718 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:57:14.888708 70718 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:57:14.888715 70718 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.889382 70718 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:57:14.889390 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.889394 70718 net.cpp:159] Memory required for data: 1433403904
I0122 19:57:14.889415 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:57:14.889423 70718 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:57:14.889430 70718 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:57:14.889436 70718 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.889446 70718 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:57:14.889452 70718 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 19:57:14.889456 70718 net.cpp:159] Memory required for data: 1438646784
I0122 19:57:14.889461 70718 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:57:14.889467 70718 net.cpp:94] Creating Layer inception_11a/output
I0122 19:57:14.889473 70718 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:57:14.889478 70718 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:57:14.889487 70718 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:57:14.889515 70718 net.cpp:144] Setting up inception_11a/output
I0122 19:57:14.889523 70718 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 19:57:14.889528 70718 net.cpp:159] Memory required for data: 1449656832
I0122 19:57:14.889531 70718 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:57:14.889541 70718 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:57:14.889545 70718 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:57:14.889554 70718 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:57:14.889587 70718 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:57:14.889595 70718 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:57:14.889597 70718 net.cpp:159] Memory required for data: 1449828864
I0122 19:57:14.889600 70718 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:57:14.889606 70718 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:57:14.889611 70718 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:57:14.889616 70718 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:57:14.889642 70718 net.cpp:144] Setting up drop_8x8_s1
I0122 19:57:14.889648 70718 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 19:57:14.889652 70718 net.cpp:159] Memory required for data: 1450000896
I0122 19:57:14.889657 70718 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:57:14.889665 70718 net.cpp:94] Creating Layer loss/classifier
I0122 19:57:14.889668 70718 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:57:14.889675 70718 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:57:14.889827 70718 net.cpp:144] Setting up loss/classifier
I0122 19:57:14.889842 70718 net.cpp:151] Top shape: 128 10 (1280)
I0122 19:57:14.889845 70718 net.cpp:159] Memory required for data: 1450006016
I0122 19:57:14.889850 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.889855 70718 net.cpp:94] Creating Layer loss
I0122 19:57:14.889859 70718 net.cpp:435] loss <- loss/classifier
I0122 19:57:14.889863 70718 net.cpp:435] loss <- label
I0122 19:57:14.889868 70718 net.cpp:409] loss -> loss
I0122 19:57:14.889879 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.889981 70718 net.cpp:144] Setting up loss
I0122 19:57:14.889986 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.889988 70718 net.cpp:154]     with loss weight 1
I0122 19:57:14.889997 70718 net.cpp:159] Memory required for data: 1450006020
I0122 19:57:14.890000 70718 net.cpp:220] loss needs backward computation.
I0122 19:57:14.890008 70718 net.cpp:220] loss/classifier needs backward computation.
I0122 19:57:14.890013 70718 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:57:14.890017 70718 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:57:14.890022 70718 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:57:14.890027 70718 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:57:14.890031 70718 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:57:14.890035 70718 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:57:14.890040 70718 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:57:14.890044 70718 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:57:14.890048 70718 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:57:14.890053 70718 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:57:14.890058 70718 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:57:14.890063 70718 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:57:14.890065 70718 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:57:14.890069 70718 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:57:14.890074 70718 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:57:14.890079 70718 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:57:14.890081 70718 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:57:14.890089 70718 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:57:14.890094 70718 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:57:14.890097 70718 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:57:14.890102 70718 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.890106 70718 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.890110 70718 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:57:14.890115 70718 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:57:14.890120 70718 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:57:14.890125 70718 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:57:14.890130 70718 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:57:14.890132 70718 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:57:14.890137 70718 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:57:14.890141 70718 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:57:14.890146 70718 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:57:14.890149 70718 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:57:14.890154 70718 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:57:14.890161 70718 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:57:14.890177 70718 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:57:14.890180 70718 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:57:14.890184 70718 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:57:14.890192 70718 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:57:14.890197 70718 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:57:14.890200 70718 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:57:14.890205 70718 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:57:14.890210 70718 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:57:14.890215 70718 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:57:14.890218 70718 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:57:14.890223 70718 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:57:14.890228 70718 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:57:14.890233 70718 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:57:14.890236 70718 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:57:14.890242 70718 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:57:14.890247 70718 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:57:14.890252 70718 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:57:14.890256 70718 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:57:14.890260 70718 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:57:14.890264 70718 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:57:14.890269 70718 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:57:14.890274 70718 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:57:14.890278 70718 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:57:14.890283 70718 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:57:14.890288 70718 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.890292 70718 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.890296 70718 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:57:14.890300 70718 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:57:14.890305 70718 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:57:14.890312 70718 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:57:14.890316 70718 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:57:14.890321 70718 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:57:14.890326 70718 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:57:14.890329 70718 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:57:14.890333 70718 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:57:14.890337 70718 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:57:14.890343 70718 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:57:14.890348 70718 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:57:14.890352 70718 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:57:14.890357 70718 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:57:14.890360 70718 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:57:14.890364 70718 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:57:14.890368 70718 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:57:14.890372 70718 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:57:14.890384 70718 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:57:14.890388 70718 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:57:14.890393 70718 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:57:14.890398 70718 net.cpp:222] data does not need backward computation.
I0122 19:57:14.890405 70718 net.cpp:264] This network produces output loss
I0122 19:57:14.890482 70718 net.cpp:284] Network initialization done.
I0122 19:57:14.891386 70718 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/net_finetune.prototxt
I0122 19:57:14.891481 70718 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 19:57:14.892133 70718 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 19:57:14.892567 70718 layer_factory.hpp:77] Creating layer data
I0122 19:57:14.892623 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.893570 70718 net.cpp:94] Creating Layer data
I0122 19:57:14.893584 70718 net.cpp:409] data -> data
I0122 19:57:14.893594 70718 net.cpp:409] data -> label
I0122 19:57:14.894477 70787 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 19:57:14.894510 70787 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 19:57:14.894609 70718 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 19:57:14.894711 70718 data_layer.cpp:83] output data size: 50,3,32,32
I0122 19:57:14.897821 70718 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 19:57:14.897859 70718 net.cpp:144] Setting up data
I0122 19:57:14.897892 70718 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 19:57:14.897898 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.897900 70718 net.cpp:159] Memory required for data: 614600
I0122 19:57:14.897909 70718 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 19:57:14.897919 70718 net.cpp:94] Creating Layer label_data_1_split
I0122 19:57:14.897923 70718 net.cpp:435] label_data_1_split <- label
I0122 19:57:14.897933 70718 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 19:57:14.897946 70718 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 19:57:14.897958 70718 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 19:57:14.897972 70718 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 19:57:14.898118 70718 net.cpp:144] Setting up label_data_1_split
I0122 19:57:14.898124 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898128 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898131 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898134 70718 net.cpp:151] Top shape: 50 (50)
I0122 19:57:14.898136 70718 net.cpp:159] Memory required for data: 615400
I0122 19:57:14.898139 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 19:57:14.898151 70718 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 19:57:14.898157 70718 net.cpp:435] conv1/3x3_s1 <- data
I0122 19:57:14.898165 70718 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 19:57:14.898499 70718 net.cpp:144] Setting up conv1/3x3_s1
I0122 19:57:14.898506 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.898509 70718 net.cpp:159] Memory required for data: 20276200
I0122 19:57:14.898517 70718 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 19:57:14.898525 70718 net.cpp:94] Creating Layer conv1/bn1
I0122 19:57:14.898528 70718 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 19:57:14.898547 70718 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.899274 70718 net.cpp:144] Setting up conv1/bn1
I0122 19:57:14.899283 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899286 70718 net.cpp:159] Memory required for data: 39937000
I0122 19:57:14.899298 70718 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 19:57:14.899304 70718 net.cpp:94] Creating Layer conv1/relu1
I0122 19:57:14.899308 70718 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 19:57:14.899314 70718 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 19:57:14.899322 70718 net.cpp:144] Setting up conv1/relu1
I0122 19:57:14.899328 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899333 70718 net.cpp:159] Memory required for data: 59597800
I0122 19:57:14.899338 70718 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.899344 70718 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.899351 70718 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 19:57:14.899359 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.899370 70718 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.899667 70718 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 19:57:14.899672 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899677 70718 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 19:57:14.899680 70718 net.cpp:159] Memory required for data: 98919400
I0122 19:57:14.899682 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 19:57:14.899691 70718 net.cpp:94] Creating Layer inception_2a/1x1
I0122 19:57:14.899696 70718 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 19:57:14.899713 70718 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 19:57:14.900265 70718 net.cpp:144] Setting up inception_2a/1x1
I0122 19:57:14.900275 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.900280 70718 net.cpp:159] Memory required for data: 105473000
I0122 19:57:14.900292 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 19:57:14.900305 70718 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 19:57:14.900310 70718 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 19:57:14.900319 70718 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.901423 70718 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 19:57:14.901434 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.901438 70718 net.cpp:159] Memory required for data: 112026600
I0122 19:57:14.901453 70718 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 19:57:14.901461 70718 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 19:57:14.901465 70718 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 19:57:14.901476 70718 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 19:57:14.901489 70718 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 19:57:14.901494 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.901499 70718 net.cpp:159] Memory required for data: 118580200
I0122 19:57:14.901502 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 19:57:14.901517 70718 net.cpp:94] Creating Layer inception_2a/3x3
I0122 19:57:14.901525 70718 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 19:57:14.901535 70718 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 19:57:14.902186 70718 net.cpp:144] Setting up inception_2a/3x3
I0122 19:57:14.902197 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.902201 70718 net.cpp:159] Memory required for data: 125133800
I0122 19:57:14.902209 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 19:57:14.902225 70718 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 19:57:14.902232 70718 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 19:57:14.902253 70718 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.903350 70718 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 19:57:14.903362 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.903367 70718 net.cpp:159] Memory required for data: 131687400
I0122 19:57:14.903388 70718 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 19:57:14.903396 70718 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 19:57:14.903401 70718 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 19:57:14.903409 70718 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 19:57:14.903420 70718 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 19:57:14.903429 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.903432 70718 net.cpp:159] Memory required for data: 138241000
I0122 19:57:14.903437 70718 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 19:57:14.903445 70718 net.cpp:94] Creating Layer inception_2a/output
I0122 19:57:14.903452 70718 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 19:57:14.903457 70718 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 19:57:14.903465 70718 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 19:57:14.903506 70718 net.cpp:144] Setting up inception_2a/output
I0122 19:57:14.903514 70718 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:14.903520 70718 net.cpp:159] Memory required for data: 151348200
I0122 19:57:14.903524 70718 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.903533 70718 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.903539 70718 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 19:57:14.903547 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.903568 70718 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.903618 70718 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 19:57:14.903625 70718 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:14.903630 70718 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 19:57:14.903635 70718 net.cpp:159] Memory required for data: 177562600
I0122 19:57:14.903638 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 19:57:14.903652 70718 net.cpp:94] Creating Layer inception_3a/1x1
I0122 19:57:14.903656 70718 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 19:57:14.903671 70718 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 19:57:14.904026 70718 net.cpp:144] Setting up inception_3a/1x1
I0122 19:57:14.904034 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.904038 70718 net.cpp:159] Memory required for data: 184116200
I0122 19:57:14.904047 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 19:57:14.904069 70718 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 19:57:14.904078 70718 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 19:57:14.904088 70718 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.905180 70718 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 19:57:14.905190 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.905194 70718 net.cpp:159] Memory required for data: 190669800
I0122 19:57:14.905207 70718 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 19:57:14.905221 70718 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 19:57:14.905227 70718 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 19:57:14.905236 70718 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 19:57:14.905246 70718 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 19:57:14.905254 70718 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 19:57:14.905258 70718 net.cpp:159] Memory required for data: 197223400
I0122 19:57:14.905273 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 19:57:14.905285 70718 net.cpp:94] Creating Layer inception_3a/3x3
I0122 19:57:14.905292 70718 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 19:57:14.905303 70718 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 19:57:14.906867 70718 net.cpp:144] Setting up inception_3a/3x3
I0122 19:57:14.906883 70718 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:14.906888 70718 net.cpp:159] Memory required for data: 207053800
I0122 19:57:14.906896 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 19:57:14.906910 70718 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 19:57:14.906918 70718 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 19:57:14.906929 70718 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.908049 70718 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 19:57:14.908062 70718 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:14.908066 70718 net.cpp:159] Memory required for data: 216884200
I0122 19:57:14.908085 70718 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 19:57:14.908097 70718 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 19:57:14.908103 70718 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 19:57:14.908112 70718 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 19:57:14.908121 70718 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 19:57:14.908129 70718 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 19:57:14.908133 70718 net.cpp:159] Memory required for data: 226714600
I0122 19:57:14.908138 70718 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 19:57:14.908146 70718 net.cpp:94] Creating Layer inception_3a/output
I0122 19:57:14.908150 70718 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 19:57:14.908156 70718 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 19:57:14.908164 70718 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 19:57:14.908197 70718 net.cpp:144] Setting up inception_3a/output
I0122 19:57:14.908207 70718 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:14.908215 70718 net.cpp:159] Memory required for data: 243098600
I0122 19:57:14.908218 70718 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.908226 70718 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.908231 70718 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 19:57:14.908239 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.908249 70718 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.908296 70718 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 19:57:14.908308 70718 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:14.908313 70718 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 19:57:14.908318 70718 net.cpp:159] Memory required for data: 275866600
I0122 19:57:14.908324 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 19:57:14.908337 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 19:57:14.908344 70718 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 19:57:14.908356 70718 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 19:57:14.909276 70718 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 19:57:14.909288 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.909292 70718 net.cpp:159] Memory required for data: 279962600
I0122 19:57:14.909301 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 19:57:14.909312 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 19:57:14.909317 70718 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 19:57:14.909346 70718 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.910346 70718 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 19:57:14.910358 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.910362 70718 net.cpp:159] Memory required for data: 284058600
I0122 19:57:14.910370 70718 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 19:57:14.910377 70718 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 19:57:14.910383 70718 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 19:57:14.910388 70718 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 19:57:14.910395 70718 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 19:57:14.910399 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.910403 70718 net.cpp:159] Memory required for data: 288154600
I0122 19:57:14.910405 70718 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 19:57:14.910413 70718 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 19:57:14.910416 70718 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 19:57:14.910421 70718 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 19:57:14.910523 70718 net.cpp:144] Setting up downsample_4/pool_s2
I0122 19:57:14.910529 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.910531 70718 net.cpp:159] Memory required for data: 292250600
I0122 19:57:14.910535 70718 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 19:57:14.910539 70718 net.cpp:94] Creating Layer downsample_4/output
I0122 19:57:14.910542 70718 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 19:57:14.910547 70718 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 19:57:14.910553 70718 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 19:57:14.910576 70718 net.cpp:144] Setting up downsample_4/output
I0122 19:57:14.910581 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.910583 70718 net.cpp:159] Memory required for data: 300442600
I0122 19:57:14.910588 70718 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.910591 70718 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.910594 70718 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 19:57:14.910599 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.910606 70718 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.910636 70718 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 19:57:14.910642 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.910645 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.910648 70718 net.cpp:159] Memory required for data: 316826600
I0122 19:57:14.910651 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 19:57:14.910660 70718 net.cpp:94] Creating Layer inception_5a/1x1
I0122 19:57:14.910663 70718 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 19:57:14.910671 70718 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 19:57:14.911026 70718 net.cpp:144] Setting up inception_5a/1x1
I0122 19:57:14.911031 70718 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:14.911034 70718 net.cpp:159] Memory required for data: 322561000
I0122 19:57:14.911041 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 19:57:14.911049 70718 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 19:57:14.911054 70718 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 19:57:14.911061 70718 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.911885 70718 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 19:57:14.911912 70718 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:14.911916 70718 net.cpp:159] Memory required for data: 328295400
I0122 19:57:14.911923 70718 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 19:57:14.911931 70718 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 19:57:14.911934 70718 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 19:57:14.911940 70718 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 19:57:14.911947 70718 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 19:57:14.911952 70718 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 19:57:14.911954 70718 net.cpp:159] Memory required for data: 334029800
I0122 19:57:14.911957 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 19:57:14.911968 70718 net.cpp:94] Creating Layer inception_5a/3x3
I0122 19:57:14.911976 70718 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 19:57:14.911985 70718 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 19:57:14.912632 70718 net.cpp:144] Setting up inception_5a/3x3
I0122 19:57:14.912642 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.912645 70718 net.cpp:159] Memory required for data: 336487400
I0122 19:57:14.912650 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 19:57:14.912662 70718 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 19:57:14.912668 70718 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 19:57:14.912676 70718 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.913383 70718 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 19:57:14.913390 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.913393 70718 net.cpp:159] Memory required for data: 338945000
I0122 19:57:14.913401 70718 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 19:57:14.913408 70718 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 19:57:14.913413 70718 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 19:57:14.913420 70718 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 19:57:14.913432 70718 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 19:57:14.913439 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.913442 70718 net.cpp:159] Memory required for data: 341402600
I0122 19:57:14.913446 70718 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 19:57:14.913452 70718 net.cpp:94] Creating Layer inception_5a/output
I0122 19:57:14.913457 70718 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 19:57:14.913462 70718 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 19:57:14.913470 70718 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 19:57:14.913498 70718 net.cpp:144] Setting up inception_5a/output
I0122 19:57:14.913506 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.913509 70718 net.cpp:159] Memory required for data: 349594600
I0122 19:57:14.913513 70718 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.913522 70718 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.913528 70718 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 19:57:14.913537 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.913549 70718 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.913591 70718 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 19:57:14.913599 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.913604 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.913605 70718 net.cpp:159] Memory required for data: 365978600
I0122 19:57:14.913609 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 19:57:14.913630 70718 net.cpp:94] Creating Layer inception_6a/1x1
I0122 19:57:14.913635 70718 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 19:57:14.913645 70718 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 19:57:14.914003 70718 net.cpp:144] Setting up inception_6a/1x1
I0122 19:57:14.914011 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.914014 70718 net.cpp:159] Memory required for data: 370893800
I0122 19:57:14.914019 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 19:57:14.914027 70718 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 19:57:14.914031 70718 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 19:57:14.914037 70718 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.914749 70718 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 19:57:14.914759 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.914762 70718 net.cpp:159] Memory required for data: 375809000
I0122 19:57:14.914769 70718 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 19:57:14.914777 70718 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 19:57:14.914780 70718 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 19:57:14.914788 70718 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 19:57:14.914796 70718 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 19:57:14.914803 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.914808 70718 net.cpp:159] Memory required for data: 380724200
I0122 19:57:14.914811 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 19:57:14.914824 70718 net.cpp:94] Creating Layer inception_6a/3x3
I0122 19:57:14.914830 70718 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 19:57:14.914839 70718 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 19:57:14.916250 70718 net.cpp:144] Setting up inception_6a/3x3
I0122 19:57:14.916262 70718 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:14.916265 70718 net.cpp:159] Memory required for data: 384001000
I0122 19:57:14.916280 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 19:57:14.916293 70718 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 19:57:14.916301 70718 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 19:57:14.916311 70718 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.917029 70718 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 19:57:14.917037 70718 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:14.917040 70718 net.cpp:159] Memory required for data: 387277800
I0122 19:57:14.917048 70718 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 19:57:14.917057 70718 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 19:57:14.917059 70718 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 19:57:14.917065 70718 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 19:57:14.917074 70718 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 19:57:14.917083 70718 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 19:57:14.917086 70718 net.cpp:159] Memory required for data: 390554600
I0122 19:57:14.917090 70718 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 19:57:14.917098 70718 net.cpp:94] Creating Layer inception_6a/output
I0122 19:57:14.917104 70718 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 19:57:14.917110 70718 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 19:57:14.917119 70718 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 19:57:14.917145 70718 net.cpp:144] Setting up inception_6a/output
I0122 19:57:14.917155 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.917158 70718 net.cpp:159] Memory required for data: 398746600
I0122 19:57:14.917162 70718 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.917171 70718 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.917186 70718 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 19:57:14.917194 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.917207 70718 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.917249 70718 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 19:57:14.917258 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.917261 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.917264 70718 net.cpp:159] Memory required for data: 415130600
I0122 19:57:14.917266 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 19:57:14.917277 70718 net.cpp:94] Creating Layer inception_7a/1x1
I0122 19:57:14.917282 70718 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 19:57:14.917290 70718 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 19:57:14.917618 70718 net.cpp:144] Setting up inception_7a/1x1
I0122 19:57:14.917626 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.917629 70718 net.cpp:159] Memory required for data: 419226600
I0122 19:57:14.917634 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 19:57:14.917641 70718 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 19:57:14.917646 70718 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 19:57:14.917654 70718 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.918383 70718 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 19:57:14.918393 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.918396 70718 net.cpp:159] Memory required for data: 423322600
I0122 19:57:14.918404 70718 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 19:57:14.918411 70718 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 19:57:14.918414 70718 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 19:57:14.918422 70718 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 19:57:14.918434 70718 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 19:57:14.918440 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.918447 70718 net.cpp:159] Memory required for data: 427418600
I0122 19:57:14.918452 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 19:57:14.918462 70718 net.cpp:94] Creating Layer inception_7a/3x3
I0122 19:57:14.918469 70718 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 19:57:14.918478 70718 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 19:57:14.919374 70718 net.cpp:144] Setting up inception_7a/3x3
I0122 19:57:14.919383 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.919385 70718 net.cpp:159] Memory required for data: 431514600
I0122 19:57:14.919390 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 19:57:14.919399 70718 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 19:57:14.919404 70718 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 19:57:14.919414 70718 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.920126 70718 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 19:57:14.920135 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.920137 70718 net.cpp:159] Memory required for data: 435610600
I0122 19:57:14.920145 70718 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 19:57:14.920156 70718 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 19:57:14.920159 70718 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 19:57:14.920166 70718 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 19:57:14.920174 70718 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 19:57:14.920181 70718 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 19:57:14.920186 70718 net.cpp:159] Memory required for data: 439706600
I0122 19:57:14.920202 70718 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 19:57:14.920210 70718 net.cpp:94] Creating Layer inception_7a/output
I0122 19:57:14.920213 70718 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 19:57:14.920219 70718 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 19:57:14.920226 70718 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 19:57:14.920258 70718 net.cpp:144] Setting up inception_7a/output
I0122 19:57:14.920264 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.920269 70718 net.cpp:159] Memory required for data: 447898600
I0122 19:57:14.920272 70718 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.920281 70718 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.920284 70718 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 19:57:14.920291 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.920303 70718 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.920344 70718 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 19:57:14.920349 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.920354 70718 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 19:57:14.920356 70718 net.cpp:159] Memory required for data: 464282600
I0122 19:57:14.920359 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 19:57:14.920368 70718 net.cpp:94] Creating Layer inception_8a/1x1
I0122 19:57:14.920374 70718 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 19:57:14.920382 70718 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 19:57:14.920680 70718 net.cpp:144] Setting up inception_8a/1x1
I0122 19:57:14.920686 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.920691 70718 net.cpp:159] Memory required for data: 466740200
I0122 19:57:14.920696 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 19:57:14.920703 70718 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 19:57:14.920707 70718 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 19:57:14.920717 70718 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.921419 70718 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 19:57:14.921427 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.921429 70718 net.cpp:159] Memory required for data: 469197800
I0122 19:57:14.921437 70718 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 19:57:14.921443 70718 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 19:57:14.921447 70718 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 19:57:14.921454 70718 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 19:57:14.921465 70718 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 19:57:14.921471 70718 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 19:57:14.921475 70718 net.cpp:159] Memory required for data: 471655400
I0122 19:57:14.921478 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 19:57:14.921491 70718 net.cpp:94] Creating Layer inception_8a/3x3
I0122 19:57:14.921497 70718 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 19:57:14.921509 70718 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 19:57:14.923172 70718 net.cpp:144] Setting up inception_8a/3x3
I0122 19:57:14.923184 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.923187 70718 net.cpp:159] Memory required for data: 476570600
I0122 19:57:14.923193 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 19:57:14.923203 70718 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 19:57:14.923207 70718 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 19:57:14.923226 70718 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.923947 70718 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 19:57:14.923954 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.923957 70718 net.cpp:159] Memory required for data: 481485800
I0122 19:57:14.923965 70718 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 19:57:14.923974 70718 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 19:57:14.923976 70718 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 19:57:14.923982 70718 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 19:57:14.923990 70718 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 19:57:14.923997 70718 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 19:57:14.924001 70718 net.cpp:159] Memory required for data: 486401000
I0122 19:57:14.924005 70718 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 19:57:14.924013 70718 net.cpp:94] Creating Layer inception_8a/output
I0122 19:57:14.924021 70718 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 19:57:14.924026 70718 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 19:57:14.924033 70718 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 19:57:14.924063 70718 net.cpp:144] Setting up inception_8a/output
I0122 19:57:14.924070 70718 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:14.924074 70718 net.cpp:159] Memory required for data: 493773800
I0122 19:57:14.924079 70718 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.924085 70718 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.924088 70718 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 19:57:14.924093 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.924105 70718 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.924144 70718 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 19:57:14.924151 70718 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:14.924155 70718 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 19:57:14.924158 70718 net.cpp:159] Memory required for data: 508519400
I0122 19:57:14.924160 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 19:57:14.924170 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 19:57:14.924175 70718 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 19:57:14.924185 70718 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 19:57:14.925724 70718 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 19:57:14.925735 70718 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:14.925738 70718 net.cpp:159] Memory required for data: 509748200
I0122 19:57:14.925745 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 19:57:14.925753 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 19:57:14.925760 70718 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 19:57:14.925765 70718 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.926522 70718 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 19:57:14.926529 70718 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:14.926532 70718 net.cpp:159] Memory required for data: 510977000
I0122 19:57:14.926540 70718 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 19:57:14.926549 70718 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 19:57:14.926553 70718 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 19:57:14.926559 70718 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 19:57:14.926570 70718 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 19:57:14.926590 70718 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 19:57:14.926594 70718 net.cpp:159] Memory required for data: 512205800
I0122 19:57:14.926599 70718 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 19:57:14.926606 70718 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 19:57:14.926610 70718 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 19:57:14.926618 70718 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 19:57:14.926666 70718 net.cpp:144] Setting up downsample_9/pool_s2
I0122 19:57:14.926672 70718 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 19:57:14.926676 70718 net.cpp:159] Memory required for data: 514049000
I0122 19:57:14.926677 70718 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 19:57:14.926687 70718 net.cpp:94] Creating Layer downsample_9/output
I0122 19:57:14.926692 70718 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 19:57:14.926697 70718 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 19:57:14.926704 70718 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 19:57:14.926730 70718 net.cpp:144] Setting up downsample_9/output
I0122 19:57:14.926738 70718 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:14.926741 70718 net.cpp:159] Memory required for data: 517121000
I0122 19:57:14.926744 70718 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.926751 70718 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.926753 70718 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 19:57:14.926759 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.926769 70718 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.926810 70718 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 19:57:14.926817 70718 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:14.926821 70718 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 19:57:14.926825 70718 net.cpp:159] Memory required for data: 523265000
I0122 19:57:14.926826 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 19:57:14.926836 70718 net.cpp:94] Creating Layer inception_10a/1x1
I0122 19:57:14.926841 70718 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 19:57:14.926849 70718 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 19:57:14.927356 70718 net.cpp:144] Setting up inception_10a/1x1
I0122 19:57:14.927363 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.927366 70718 net.cpp:159] Memory required for data: 525517800
I0122 19:57:14.927371 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 19:57:14.927379 70718 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 19:57:14.927383 70718 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 19:57:14.927392 70718 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.928090 70718 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 19:57:14.928098 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.928102 70718 net.cpp:159] Memory required for data: 527770600
I0122 19:57:14.928109 70718 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 19:57:14.928117 70718 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 19:57:14.928119 70718 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 19:57:14.928126 70718 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 19:57:14.928138 70718 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 19:57:14.928143 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.928146 70718 net.cpp:159] Memory required for data: 530023400
I0122 19:57:14.928150 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 19:57:14.928175 70718 net.cpp:94] Creating Layer inception_10a/3x3
I0122 19:57:14.928181 70718 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 19:57:14.928187 70718 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 19:57:14.930739 70718 net.cpp:144] Setting up inception_10a/3x3
I0122 19:57:14.930752 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.930753 70718 net.cpp:159] Memory required for data: 532071400
I0122 19:57:14.930758 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 19:57:14.930766 70718 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 19:57:14.930771 70718 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 19:57:14.930779 70718 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.931411 70718 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 19:57:14.931417 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.931421 70718 net.cpp:159] Memory required for data: 534119400
I0122 19:57:14.931427 70718 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 19:57:14.931432 70718 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 19:57:14.931434 70718 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 19:57:14.931440 70718 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 19:57:14.931448 70718 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 19:57:14.931454 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.931457 70718 net.cpp:159] Memory required for data: 536167400
I0122 19:57:14.931461 70718 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 19:57:14.931466 70718 net.cpp:94] Creating Layer inception_10a/output
I0122 19:57:14.931469 70718 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 19:57:14.931484 70718 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 19:57:14.931495 70718 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 19:57:14.931521 70718 net.cpp:144] Setting up inception_10a/output
I0122 19:57:14.931529 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.931532 70718 net.cpp:159] Memory required for data: 540468200
I0122 19:57:14.931537 70718 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.931545 70718 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.931550 70718 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 19:57:14.931556 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.931566 70718 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.931609 70718 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 19:57:14.931617 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.931620 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.931624 70718 net.cpp:159] Memory required for data: 549069800
I0122 19:57:14.931627 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 19:57:14.931635 70718 net.cpp:94] Creating Layer inception_11a/1x1
I0122 19:57:14.931640 70718 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 19:57:14.931650 70718 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 19:57:14.932226 70718 net.cpp:144] Setting up inception_11a/1x1
I0122 19:57:14.932235 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.932236 70718 net.cpp:159] Memory required for data: 551322600
I0122 19:57:14.932242 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 19:57:14.932250 70718 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 19:57:14.932255 70718 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 19:57:14.932262 70718 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.932984 70718 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 19:57:14.932992 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.932994 70718 net.cpp:159] Memory required for data: 553575400
I0122 19:57:14.933002 70718 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 19:57:14.933009 70718 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 19:57:14.933012 70718 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 19:57:14.933019 70718 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 19:57:14.933028 70718 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 19:57:14.933037 70718 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 19:57:14.933039 70718 net.cpp:159] Memory required for data: 555828200
I0122 19:57:14.933043 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 19:57:14.933054 70718 net.cpp:94] Creating Layer inception_11a/3x3
I0122 19:57:14.933061 70718 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 19:57:14.933071 70718 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 19:57:14.936873 70718 net.cpp:144] Setting up inception_11a/3x3
I0122 19:57:14.936884 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.936887 70718 net.cpp:159] Memory required for data: 557876200
I0122 19:57:14.936893 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 19:57:14.936902 70718 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 19:57:14.936906 70718 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 19:57:14.936914 70718 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.937593 70718 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 19:57:14.937602 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.937604 70718 net.cpp:159] Memory required for data: 559924200
I0122 19:57:14.937624 70718 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 19:57:14.937633 70718 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 19:57:14.937638 70718 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 19:57:14.937645 70718 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 19:57:14.937654 70718 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 19:57:14.937661 70718 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 19:57:14.937665 70718 net.cpp:159] Memory required for data: 561972200
I0122 19:57:14.937669 70718 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 19:57:14.937676 70718 net.cpp:94] Creating Layer inception_11a/output
I0122 19:57:14.937682 70718 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 19:57:14.937686 70718 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 19:57:14.937695 70718 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 19:57:14.937723 70718 net.cpp:144] Setting up inception_11a/output
I0122 19:57:14.937731 70718 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 19:57:14.937734 70718 net.cpp:159] Memory required for data: 566273000
I0122 19:57:14.937737 70718 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 19:57:14.937744 70718 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 19:57:14.937749 70718 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 19:57:14.937753 70718 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 19:57:14.937781 70718 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 19:57:14.937790 70718 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:57:14.937794 70718 net.cpp:159] Memory required for data: 566340200
I0122 19:57:14.937798 70718 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 19:57:14.937803 70718 net.cpp:94] Creating Layer drop_8x8_s1
I0122 19:57:14.937805 70718 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 19:57:14.937811 70718 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 19:57:14.937834 70718 net.cpp:144] Setting up drop_8x8_s1
I0122 19:57:14.937841 70718 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 19:57:14.937857 70718 net.cpp:159] Memory required for data: 566407400
I0122 19:57:14.937860 70718 layer_factory.hpp:77] Creating layer loss/classifier
I0122 19:57:14.937870 70718 net.cpp:94] Creating Layer loss/classifier
I0122 19:57:14.937875 70718 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 19:57:14.937885 70718 net.cpp:409] loss/classifier -> loss/classifier
I0122 19:57:14.938068 70718 net.cpp:144] Setting up loss/classifier
I0122 19:57:14.938076 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938077 70718 net.cpp:159] Memory required for data: 566409400
I0122 19:57:14.938083 70718 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 19:57:14.938091 70718 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 19:57:14.938093 70718 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 19:57:14.938098 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 19:57:14.938108 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 19:57:14.938118 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 19:57:14.938127 70718 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 19:57:14.938192 70718 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 19:57:14.938199 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938202 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938205 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938208 70718 net.cpp:151] Top shape: 50 10 (500)
I0122 19:57:14.938211 70718 net.cpp:159] Memory required for data: 566417400
I0122 19:57:14.938215 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.938220 70718 net.cpp:94] Creating Layer loss
I0122 19:57:14.938222 70718 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 19:57:14.938228 70718 net.cpp:435] loss <- label_data_1_split_0
I0122 19:57:14.938236 70718 net.cpp:409] loss -> loss
I0122 19:57:14.938247 70718 layer_factory.hpp:77] Creating layer loss
I0122 19:57:14.938345 70718 net.cpp:144] Setting up loss
I0122 19:57:14.938351 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938354 70718 net.cpp:154]     with loss weight 1
I0122 19:57:14.938362 70718 net.cpp:159] Memory required for data: 566417404
I0122 19:57:14.938364 70718 layer_factory.hpp:77] Creating layer accuracy
I0122 19:57:14.938370 70718 net.cpp:94] Creating Layer accuracy
I0122 19:57:14.938374 70718 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 19:57:14.938380 70718 net.cpp:435] accuracy <- label_data_1_split_1
I0122 19:57:14.938385 70718 net.cpp:409] accuracy -> accuracy
I0122 19:57:14.938403 70718 net.cpp:144] Setting up accuracy
I0122 19:57:14.938410 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938414 70718 net.cpp:159] Memory required for data: 566417408
I0122 19:57:14.938418 70718 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 19:57:14.938426 70718 net.cpp:94] Creating Layer accuracy-top1
I0122 19:57:14.938431 70718 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 19:57:14.938436 70718 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 19:57:14.938441 70718 net.cpp:409] accuracy-top1 -> top-1
I0122 19:57:14.938453 70718 net.cpp:144] Setting up accuracy-top1
I0122 19:57:14.938458 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938462 70718 net.cpp:159] Memory required for data: 566417412
I0122 19:57:14.938465 70718 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 19:57:14.938474 70718 net.cpp:94] Creating Layer accuracy-top5
I0122 19:57:14.938480 70718 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 19:57:14.938485 70718 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 19:57:14.938491 70718 net.cpp:409] accuracy-top5 -> top-5
I0122 19:57:14.938511 70718 net.cpp:144] Setting up accuracy-top5
I0122 19:57:14.938518 70718 net.cpp:151] Top shape: (1)
I0122 19:57:14.938524 70718 net.cpp:159] Memory required for data: 566417416
I0122 19:57:14.938526 70718 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 19:57:14.938531 70718 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 19:57:14.938536 70718 net.cpp:222] accuracy does not need backward computation.
I0122 19:57:14.938541 70718 net.cpp:220] loss needs backward computation.
I0122 19:57:14.938546 70718 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 19:57:14.938555 70718 net.cpp:220] loss/classifier needs backward computation.
I0122 19:57:14.938558 70718 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 19:57:14.938562 70718 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 19:57:14.938566 70718 net.cpp:220] inception_11a/output needs backward computation.
I0122 19:57:14.938573 70718 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 19:57:14.938577 70718 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 19:57:14.938580 70718 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 19:57:14.938585 70718 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 19:57:14.938591 70718 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 19:57:14.938593 70718 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 19:57:14.938598 70718 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 19:57:14.938602 70718 net.cpp:220] inception_10a/output needs backward computation.
I0122 19:57:14.938608 70718 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 19:57:14.938612 70718 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 19:57:14.938616 70718 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 19:57:14.938622 70718 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 19:57:14.938627 70718 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 19:57:14.938630 70718 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 19:57:14.938635 70718 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 19:57:14.938639 70718 net.cpp:220] downsample_9/output needs backward computation.
I0122 19:57:14.938645 70718 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 19:57:14.938649 70718 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.938653 70718 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.938657 70718 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 19:57:14.938663 70718 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 19:57:14.938668 70718 net.cpp:220] inception_8a/output needs backward computation.
I0122 19:57:14.938673 70718 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 19:57:14.938676 70718 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 19:57:14.938681 70718 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 19:57:14.938686 70718 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 19:57:14.938690 70718 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 19:57:14.938694 70718 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 19:57:14.938699 70718 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 19:57:14.938704 70718 net.cpp:220] inception_7a/output needs backward computation.
I0122 19:57:14.938709 70718 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 19:57:14.938712 70718 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 19:57:14.938717 70718 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 19:57:14.938722 70718 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 19:57:14.938737 70718 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 19:57:14.938741 70718 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 19:57:14.938747 70718 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 19:57:14.938755 70718 net.cpp:220] inception_6a/output needs backward computation.
I0122 19:57:14.938757 70718 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 19:57:14.938761 70718 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 19:57:14.938766 70718 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 19:57:14.938771 70718 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 19:57:14.938776 70718 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 19:57:14.938779 70718 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 19:57:14.938784 70718 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 19:57:14.938789 70718 net.cpp:220] inception_5a/output needs backward computation.
I0122 19:57:14.938794 70718 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 19:57:14.938798 70718 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 19:57:14.938803 70718 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 19:57:14.938807 70718 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 19:57:14.938812 70718 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 19:57:14.938815 70718 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 19:57:14.938822 70718 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 19:57:14.938827 70718 net.cpp:220] downsample_4/output needs backward computation.
I0122 19:57:14.938832 70718 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 19:57:14.938835 70718 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 19:57:14.938841 70718 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 19:57:14.938845 70718 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 19:57:14.938849 70718 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 19:57:14.938856 70718 net.cpp:220] inception_3a/output needs backward computation.
I0122 19:57:14.938863 70718 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 19:57:14.938868 70718 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 19:57:14.938874 70718 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 19:57:14.938877 70718 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 19:57:14.938882 70718 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 19:57:14.938885 70718 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 19:57:14.938890 70718 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 19:57:14.938895 70718 net.cpp:220] inception_2a/output needs backward computation.
I0122 19:57:14.938901 70718 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 19:57:14.938905 70718 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 19:57:14.938908 70718 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 19:57:14.938913 70718 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 19:57:14.938917 70718 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 19:57:14.938921 70718 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 19:57:14.938926 70718 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 19:57:14.938930 70718 net.cpp:220] conv1/relu1 needs backward computation.
I0122 19:57:14.938935 70718 net.cpp:220] conv1/bn1 needs backward computation.
I0122 19:57:14.938941 70718 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 19:57:14.938952 70718 net.cpp:222] label_data_1_split does not need backward computation.
I0122 19:57:14.938957 70718 net.cpp:222] data does not need backward computation.
I0122 19:57:14.938962 70718 net.cpp:264] This network produces output accuracy
I0122 19:57:14.938966 70718 net.cpp:264] This network produces output loss
I0122 19:57:14.938971 70718 net.cpp:264] This network produces output top-1
I0122 19:57:14.938975 70718 net.cpp:264] This network produces output top-5
I0122 19:57:14.939070 70718 net.cpp:284] Network initialization done.
I0122 19:57:14.939397 70718 solver.cpp:63] Solver scaffolding done.
I0122 19:57:14.944720 70718 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/sparse.caffemodel
I0122 19:57:14.985493 70718 caffe_interface.cpp:527] Starting Optimization
I0122 19:57:14.985522 70718 solver.cpp:335] Solving 
I0122 19:57:14.985524 70718 solver.cpp:336] Learning Rate Policy: step
I0122 19:57:14.988097 70718 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 19:57:16.441881 70718 solver.cpp:517]     Test net output #0: accuracy = 0.884888
I0122 19:57:16.441912 70718 solver.cpp:517]     Test net output #1: loss = 0.407635 (* 1 = 0.407635 loss)
I0122 19:57:16.441917 70718 solver.cpp:517]     Test net output #2: top-1 = 0.884888
I0122 19:57:16.441920 70718 solver.cpp:517]     Test net output #3: top-5 = 0.994445
I0122 19:57:16.523113 70718 solver.cpp:266] Iteration 0 (0 iter/s, 1.5375s/100 iter), loss = 0.0288452
I0122 19:57:16.523149 70718 solver.cpp:285]     Train net output #0: loss = 0.0288452 (* 1 = 0.0288452 loss)
I0122 19:57:16.523166 70718 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 19:57:22.631466 70718 solver.cpp:266] Iteration 100 (16.3717 iter/s, 6.10809s/100 iter), loss = 0.955029
I0122 19:57:22.631495 70718 solver.cpp:285]     Train net output #0: loss = 0.955029 (* 1 = 0.955029 loss)
I0122 19:57:22.631501 70718 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 19:57:28.740334 70718 solver.cpp:266] Iteration 200 (16.3703 iter/s, 6.10861s/100 iter), loss = 0.93137
I0122 19:57:28.740362 70718 solver.cpp:285]     Train net output #0: loss = 0.93137 (* 1 = 0.93137 loss)
I0122 19:57:28.740368 70718 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 19:57:34.846798 70718 solver.cpp:266] Iteration 300 (16.3768 iter/s, 6.1062s/100 iter), loss = 0.75935
I0122 19:57:34.846827 70718 solver.cpp:285]     Train net output #0: loss = 0.75935 (* 1 = 0.75935 loss)
I0122 19:57:34.846833 70718 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 19:57:40.970335 70718 solver.cpp:266] Iteration 400 (16.3311 iter/s, 6.12327s/100 iter), loss = 0.63203
I0122 19:57:40.970363 70718 solver.cpp:285]     Train net output #0: loss = 0.63203 (* 1 = 0.63203 loss)
I0122 19:57:40.970369 70718 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 19:57:47.140592 70718 solver.cpp:266] Iteration 500 (16.2075 iter/s, 6.16999s/100 iter), loss = 0.549617
I0122 19:57:47.140803 70718 solver.cpp:285]     Train net output #0: loss = 0.549617 (* 1 = 0.549617 loss)
I0122 19:57:47.140813 70718 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 19:57:53.329478 70718 solver.cpp:266] Iteration 600 (16.1592 iter/s, 6.18844s/100 iter), loss = 0.546069
I0122 19:57:53.329507 70718 solver.cpp:285]     Train net output #0: loss = 0.546069 (* 1 = 0.546069 loss)
I0122 19:57:53.329512 70718 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 19:57:59.531250 70718 solver.cpp:266] Iteration 700 (16.1251 iter/s, 6.20151s/100 iter), loss = 0.820554
I0122 19:57:59.531278 70718 solver.cpp:285]     Train net output #0: loss = 0.820554 (* 1 = 0.820554 loss)
I0122 19:57:59.531285 70718 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 19:58:05.724577 70718 solver.cpp:266] Iteration 800 (16.1471 iter/s, 6.19306s/100 iter), loss = 0.727752
I0122 19:58:05.724619 70718 solver.cpp:285]     Train net output #0: loss = 0.727752 (* 1 = 0.727752 loss)
I0122 19:58:05.724625 70718 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 19:58:11.931339 70718 solver.cpp:266] Iteration 900 (16.1122 iter/s, 6.20648s/100 iter), loss = 0.498048
I0122 19:58:11.931368 70718 solver.cpp:285]     Train net output #0: loss = 0.498048 (* 1 = 0.498048 loss)
I0122 19:58:11.931375 70718 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 19:58:18.063923 70718 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 19:58:19.510509 70718 solver.cpp:517]     Test net output #0: accuracy = 0.416667
I0122 19:58:19.510535 70718 solver.cpp:517]     Test net output #1: loss = 3.37431 (* 1 = 3.37431 loss)
I0122 19:58:19.510540 70718 solver.cpp:517]     Test net output #2: top-1 = 0.416667
I0122 19:58:19.510542 70718 solver.cpp:517]     Test net output #3: top-5 = 0.797334
I0122 19:58:19.572508 70718 solver.cpp:266] Iteration 1000 (13.0875 iter/s, 7.64085s/100 iter), loss = 0.668271
I0122 19:58:19.572530 70718 solver.cpp:285]     Train net output #0: loss = 0.668271 (* 1 = 0.668271 loss)
I0122 19:58:19.572537 70718 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 19:58:25.779922 70718 solver.cpp:266] Iteration 1100 (16.1104 iter/s, 6.20715s/100 iter), loss = 0.592751
I0122 19:58:25.779948 70718 solver.cpp:285]     Train net output #0: loss = 0.592751 (* 1 = 0.592751 loss)
I0122 19:58:25.779954 70718 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 19:58:31.985296 70718 solver.cpp:266] Iteration 1200 (16.1158 iter/s, 6.20511s/100 iter), loss = 0.67195
I0122 19:58:31.985337 70718 solver.cpp:285]     Train net output #0: loss = 0.67195 (* 1 = 0.67195 loss)
I0122 19:58:31.985344 70718 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 19:58:38.173473 70718 solver.cpp:266] Iteration 1300 (16.1606 iter/s, 6.1879s/100 iter), loss = 0.488602
I0122 19:58:38.173502 70718 solver.cpp:285]     Train net output #0: loss = 0.488602 (* 1 = 0.488602 loss)
I0122 19:58:38.173507 70718 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 19:58:44.377544 70718 solver.cpp:266] Iteration 1400 (16.1191 iter/s, 6.2038s/100 iter), loss = 0.643387
I0122 19:58:44.377573 70718 solver.cpp:285]     Train net output #0: loss = 0.643387 (* 1 = 0.643387 loss)
I0122 19:58:44.377578 70718 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 19:58:50.587370 70718 solver.cpp:266] Iteration 1500 (16.1042 iter/s, 6.20956s/100 iter), loss = 0.516658
I0122 19:58:50.587471 70718 solver.cpp:285]     Train net output #0: loss = 0.516658 (* 1 = 0.516658 loss)
I0122 19:58:50.587478 70718 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 19:58:56.779511 70718 solver.cpp:266] Iteration 1600 (16.1504 iter/s, 6.1918s/100 iter), loss = 0.666034
I0122 19:58:56.779541 70718 solver.cpp:285]     Train net output #0: loss = 0.666034 (* 1 = 0.666034 loss)
I0122 19:58:56.779546 70718 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 19:59:02.983443 70718 solver.cpp:266] Iteration 1700 (16.1195 iter/s, 6.20367s/100 iter), loss = 0.503105
I0122 19:59:02.983471 70718 solver.cpp:285]     Train net output #0: loss = 0.503105 (* 1 = 0.503105 loss)
I0122 19:59:02.983477 70718 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 19:59:09.191874 70718 solver.cpp:266] Iteration 1800 (16.1078 iter/s, 6.20817s/100 iter), loss = 0.43784
I0122 19:59:09.191900 70718 solver.cpp:285]     Train net output #0: loss = 0.43784 (* 1 = 0.43784 loss)
I0122 19:59:09.191905 70718 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 19:59:15.396297 70718 solver.cpp:266] Iteration 1900 (16.1182 iter/s, 6.20416s/100 iter), loss = 0.491468
I0122 19:59:15.396325 70718 solver.cpp:285]     Train net output #0: loss = 0.491468 (* 1 = 0.491468 loss)
I0122 19:59:15.396332 70718 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 19:59:21.530323 70718 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 19:59:22.986248 70718 solver.cpp:517]     Test net output #0: accuracy = 0.582889
I0122 19:59:22.986274 70718 solver.cpp:517]     Test net output #1: loss = 1.60058 (* 1 = 1.60058 loss)
I0122 19:59:22.986279 70718 solver.cpp:517]     Test net output #2: top-1 = 0.582889
I0122 19:59:22.986282 70718 solver.cpp:517]     Test net output #3: top-5 = 0.939778
I0122 19:59:23.048117 70718 solver.cpp:266] Iteration 2000 (13.0693 iter/s, 7.6515s/100 iter), loss = 0.396029
I0122 19:59:23.048138 70718 solver.cpp:285]     Train net output #0: loss = 0.396029 (* 1 = 0.396029 loss)
I0122 19:59:23.048146 70718 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 19:59:29.251765 70718 solver.cpp:266] Iteration 2100 (16.1202 iter/s, 6.20339s/100 iter), loss = 0.607879
I0122 19:59:29.251791 70718 solver.cpp:285]     Train net output #0: loss = 0.607879 (* 1 = 0.607879 loss)
I0122 19:59:29.251797 70718 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 19:59:35.464603 70718 solver.cpp:266] Iteration 2200 (16.0964 iter/s, 6.21257s/100 iter), loss = 0.376225
I0122 19:59:35.464643 70718 solver.cpp:285]     Train net output #0: loss = 0.376225 (* 1 = 0.376225 loss)
I0122 19:59:35.464651 70718 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 19:59:41.670804 70718 solver.cpp:266] Iteration 2300 (16.1136 iter/s, 6.20593s/100 iter), loss = 0.473856
I0122 19:59:41.670831 70718 solver.cpp:285]     Train net output #0: loss = 0.473856 (* 1 = 0.473856 loss)
I0122 19:59:41.670848 70718 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 19:59:47.865725 70718 solver.cpp:266] Iteration 2400 (16.1429 iter/s, 6.19466s/100 iter), loss = 0.428299
I0122 19:59:47.865761 70718 solver.cpp:285]     Train net output #0: loss = 0.428299 (* 1 = 0.428299 loss)
I0122 19:59:47.865767 70718 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 19:59:54.056520 70718 solver.cpp:266] Iteration 2500 (16.1537 iter/s, 6.19052s/100 iter), loss = 0.423682
I0122 19:59:54.056601 70718 solver.cpp:285]     Train net output #0: loss = 0.423682 (* 1 = 0.423682 loss)
I0122 19:59:54.056607 70718 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 20:00:00.264242 70718 solver.cpp:266] Iteration 2600 (16.1098 iter/s, 6.20741s/100 iter), loss = 0.464466
I0122 20:00:00.264269 70718 solver.cpp:285]     Train net output #0: loss = 0.464466 (* 1 = 0.464466 loss)
I0122 20:00:00.264276 70718 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 20:00:06.467967 70718 solver.cpp:266] Iteration 2700 (16.12 iter/s, 6.20346s/100 iter), loss = 0.730639
I0122 20:00:06.467993 70718 solver.cpp:285]     Train net output #0: loss = 0.730639 (* 1 = 0.730639 loss)
I0122 20:00:06.468000 70718 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 20:00:12.660615 70718 solver.cpp:266] Iteration 2800 (16.1489 iter/s, 6.19238s/100 iter), loss = 0.576423
I0122 20:00:12.660645 70718 solver.cpp:285]     Train net output #0: loss = 0.576423 (* 1 = 0.576423 loss)
I0122 20:00:12.660650 70718 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 20:00:18.869730 70718 solver.cpp:266] Iteration 2900 (16.106 iter/s, 6.20885s/100 iter), loss = 0.49941
I0122 20:00:18.869768 70718 solver.cpp:285]     Train net output #0: loss = 0.49941 (* 1 = 0.49941 loss)
I0122 20:00:18.869776 70718 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 20:00:25.014103 70718 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 20:00:26.463665 70718 solver.cpp:517]     Test net output #0: accuracy = 0.546333
I0122 20:00:26.463690 70718 solver.cpp:517]     Test net output #1: loss = 1.52578 (* 1 = 1.52578 loss)
I0122 20:00:26.463694 70718 solver.cpp:517]     Test net output #2: top-1 = 0.546333
I0122 20:00:26.463697 70718 solver.cpp:517]     Test net output #3: top-5 = 0.945889
I0122 20:00:26.525640 70718 solver.cpp:266] Iteration 3000 (13.0623 iter/s, 7.65559s/100 iter), loss = 0.394277
I0122 20:00:26.525660 70718 solver.cpp:285]     Train net output #0: loss = 0.394277 (* 1 = 0.394277 loss)
I0122 20:00:26.525666 70718 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 20:00:32.731998 70718 solver.cpp:266] Iteration 3100 (16.1132 iter/s, 6.2061s/100 iter), loss = 0.475582
I0122 20:00:32.732026 70718 solver.cpp:285]     Train net output #0: loss = 0.475582 (* 1 = 0.475582 loss)
I0122 20:00:32.732033 70718 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 20:00:38.936556 70718 solver.cpp:266] Iteration 3200 (16.1179 iter/s, 6.20429s/100 iter), loss = 0.523642
I0122 20:00:38.936585 70718 solver.cpp:285]     Train net output #0: loss = 0.523642 (* 1 = 0.523642 loss)
I0122 20:00:38.936591 70718 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 20:00:45.153081 70718 solver.cpp:266] Iteration 3300 (16.0868 iter/s, 6.21626s/100 iter), loss = 0.357407
I0122 20:00:45.153120 70718 solver.cpp:285]     Train net output #0: loss = 0.357407 (* 1 = 0.357407 loss)
I0122 20:00:45.153126 70718 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 20:00:51.358381 70718 solver.cpp:266] Iteration 3400 (16.116 iter/s, 6.20502s/100 iter), loss = 0.640476
I0122 20:00:51.358409 70718 solver.cpp:285]     Train net output #0: loss = 0.640476 (* 1 = 0.640476 loss)
I0122 20:00:51.358415 70718 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 20:00:57.545017 70718 solver.cpp:266] Iteration 3500 (16.1646 iter/s, 6.18637s/100 iter), loss = 0.51945
I0122 20:00:57.545111 70718 solver.cpp:285]     Train net output #0: loss = 0.51945 (* 1 = 0.51945 loss)
I0122 20:00:57.545119 70718 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 20:01:03.762450 70718 solver.cpp:266] Iteration 3600 (16.0847 iter/s, 6.2171s/100 iter), loss = 0.532824
I0122 20:01:03.762491 70718 solver.cpp:285]     Train net output #0: loss = 0.532824 (* 1 = 0.532824 loss)
I0122 20:01:03.762498 70718 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 20:01:09.961258 70718 solver.cpp:266] Iteration 3700 (16.1329 iter/s, 6.19853s/100 iter), loss = 0.436289
I0122 20:01:09.961285 70718 solver.cpp:285]     Train net output #0: loss = 0.436289 (* 1 = 0.436289 loss)
I0122 20:01:09.961292 70718 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 20:01:16.174474 70718 solver.cpp:266] Iteration 3800 (16.0954 iter/s, 6.21295s/100 iter), loss = 0.509245
I0122 20:01:16.174501 70718 solver.cpp:285]     Train net output #0: loss = 0.509245 (* 1 = 0.509245 loss)
I0122 20:01:16.174507 70718 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 20:01:22.378450 70718 solver.cpp:266] Iteration 3900 (16.1194 iter/s, 6.20371s/100 iter), loss = 0.442305
I0122 20:01:22.378480 70718 solver.cpp:285]     Train net output #0: loss = 0.442305 (* 1 = 0.442305 loss)
I0122 20:01:22.378486 70718 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 20:01:28.523691 70718 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 20:01:29.971530 70718 solver.cpp:517]     Test net output #0: accuracy = 0.344111
I0122 20:01:29.971555 70718 solver.cpp:517]     Test net output #1: loss = 1.88703 (* 1 = 1.88703 loss)
I0122 20:01:29.971560 70718 solver.cpp:517]     Test net output #2: top-1 = 0.344111
I0122 20:01:29.971563 70718 solver.cpp:517]     Test net output #3: top-5 = 0.829555
I0122 20:01:30.032670 70718 solver.cpp:266] Iteration 4000 (13.0652 iter/s, 7.6539s/100 iter), loss = 0.467795
I0122 20:01:30.032691 70718 solver.cpp:285]     Train net output #0: loss = 0.467795 (* 1 = 0.467795 loss)
I0122 20:01:30.032697 70718 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 20:01:36.231251 70718 solver.cpp:266] Iteration 4100 (16.1334 iter/s, 6.19832s/100 iter), loss = 0.377432
I0122 20:01:36.231288 70718 solver.cpp:285]     Train net output #0: loss = 0.377432 (* 1 = 0.377432 loss)
I0122 20:01:36.231295 70718 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 20:01:42.453809 70718 solver.cpp:266] Iteration 4200 (16.0713 iter/s, 6.22228s/100 iter), loss = 0.399696
I0122 20:01:42.453848 70718 solver.cpp:285]     Train net output #0: loss = 0.399696 (* 1 = 0.399696 loss)
I0122 20:01:42.453855 70718 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 20:01:48.664057 70718 solver.cpp:266] Iteration 4300 (16.1031 iter/s, 6.20997s/100 iter), loss = 0.562433
I0122 20:01:48.664095 70718 solver.cpp:285]     Train net output #0: loss = 0.562433 (* 1 = 0.562433 loss)
I0122 20:01:48.664103 70718 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 20:01:54.879918 70718 solver.cpp:266] Iteration 4400 (16.0886 iter/s, 6.2156s/100 iter), loss = 0.639381
I0122 20:01:54.879957 70718 solver.cpp:285]     Train net output #0: loss = 0.639381 (* 1 = 0.639381 loss)
I0122 20:01:54.879963 70718 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 20:02:01.094172 70718 solver.cpp:266] Iteration 4500 (16.0927 iter/s, 6.21399s/100 iter), loss = 0.427303
I0122 20:02:01.094249 70718 solver.cpp:285]     Train net output #0: loss = 0.427303 (* 1 = 0.427303 loss)
I0122 20:02:01.094256 70718 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 20:02:07.297348 70718 solver.cpp:266] Iteration 4600 (16.1216 iter/s, 6.20286s/100 iter), loss = 0.604064
I0122 20:02:07.297387 70718 solver.cpp:285]     Train net output #0: loss = 0.604064 (* 1 = 0.604064 loss)
I0122 20:02:07.297394 70718 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 20:02:13.498052 70718 solver.cpp:266] Iteration 4700 (16.1279 iter/s, 6.20043s/100 iter), loss = 0.595444
I0122 20:02:13.498080 70718 solver.cpp:285]     Train net output #0: loss = 0.595444 (* 1 = 0.595444 loss)
I0122 20:02:13.498086 70718 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 20:02:19.715428 70718 solver.cpp:266] Iteration 4800 (16.0846 iter/s, 6.21711s/100 iter), loss = 0.492715
I0122 20:02:19.715457 70718 solver.cpp:285]     Train net output #0: loss = 0.492715 (* 1 = 0.492715 loss)
I0122 20:02:19.715462 70718 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 20:02:25.919868 70718 solver.cpp:266] Iteration 4900 (16.1182 iter/s, 6.20418s/100 iter), loss = 0.629915
I0122 20:02:25.919905 70718 solver.cpp:285]     Train net output #0: loss = 0.629915 (* 1 = 0.629915 loss)
I0122 20:02:25.919912 70718 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 20:02:32.054193 70718 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 20:02:33.509234 70718 solver.cpp:517]     Test net output #0: accuracy = 0.587223
I0122 20:02:33.509260 70718 solver.cpp:517]     Test net output #1: loss = 1.1665 (* 1 = 1.1665 loss)
I0122 20:02:33.509266 70718 solver.cpp:517]     Test net output #2: top-1 = 0.587223
I0122 20:02:33.509269 70718 solver.cpp:517]     Test net output #3: top-5 = 0.945
I0122 20:02:33.570116 70718 solver.cpp:266] Iteration 5000 (13.072 iter/s, 7.64993s/100 iter), loss = 0.539379
I0122 20:02:33.570137 70718 solver.cpp:285]     Train net output #0: loss = 0.539379 (* 1 = 0.539379 loss)
I0122 20:02:33.570144 70718 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 20:02:39.758805 70718 solver.cpp:266] Iteration 5100 (16.1592 iter/s, 6.18843s/100 iter), loss = 0.370682
I0122 20:02:39.758834 70718 solver.cpp:285]     Train net output #0: loss = 0.370682 (* 1 = 0.370682 loss)
I0122 20:02:39.758841 70718 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 20:02:45.964638 70718 solver.cpp:266] Iteration 5200 (16.1146 iter/s, 6.20557s/100 iter), loss = 0.58287
I0122 20:02:45.964668 70718 solver.cpp:285]     Train net output #0: loss = 0.58287 (* 1 = 0.58287 loss)
I0122 20:02:45.964674 70718 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 20:02:52.172088 70718 solver.cpp:266] Iteration 5300 (16.1104 iter/s, 6.20718s/100 iter), loss = 0.506658
I0122 20:02:52.172117 70718 solver.cpp:285]     Train net output #0: loss = 0.506658 (* 1 = 0.506658 loss)
I0122 20:02:52.172122 70718 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 20:02:58.395488 70718 solver.cpp:266] Iteration 5400 (16.0691 iter/s, 6.22313s/100 iter), loss = 0.423528
I0122 20:02:58.395517 70718 solver.cpp:285]     Train net output #0: loss = 0.423528 (* 1 = 0.423528 loss)
I0122 20:02:58.395524 70718 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 20:03:04.598695 70718 solver.cpp:266] Iteration 5500 (16.1214 iter/s, 6.20294s/100 iter), loss = 0.540767
I0122 20:03:04.598822 70718 solver.cpp:285]     Train net output #0: loss = 0.540767 (* 1 = 0.540767 loss)
I0122 20:03:04.598829 70718 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 20:03:10.795501 70718 solver.cpp:266] Iteration 5600 (16.1383 iter/s, 6.19644s/100 iter), loss = 0.536797
I0122 20:03:10.795528 70718 solver.cpp:285]     Train net output #0: loss = 0.536797 (* 1 = 0.536797 loss)
I0122 20:03:10.795534 70718 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 20:03:16.989522 70718 solver.cpp:266] Iteration 5700 (16.1453 iter/s, 6.19376s/100 iter), loss = 0.387972
I0122 20:03:16.989549 70718 solver.cpp:285]     Train net output #0: loss = 0.387972 (* 1 = 0.387972 loss)
I0122 20:03:16.989554 70718 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 20:03:23.184337 70718 solver.cpp:266] Iteration 5800 (16.1432 iter/s, 6.19455s/100 iter), loss = 0.480485
I0122 20:03:23.184366 70718 solver.cpp:285]     Train net output #0: loss = 0.480485 (* 1 = 0.480485 loss)
I0122 20:03:23.184372 70718 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 20:03:29.380476 70718 solver.cpp:266] Iteration 5900 (16.1398 iter/s, 6.19587s/100 iter), loss = 0.541794
I0122 20:03:29.380503 70718 solver.cpp:285]     Train net output #0: loss = 0.541794 (* 1 = 0.541794 loss)
I0122 20:03:29.380509 70718 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 20:03:35.508208 70718 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 20:03:36.953573 70718 solver.cpp:517]     Test net output #0: accuracy = 0.608889
I0122 20:03:36.953598 70718 solver.cpp:517]     Test net output #1: loss = 1.14369 (* 1 = 1.14369 loss)
I0122 20:03:36.953601 70718 solver.cpp:517]     Test net output #2: top-1 = 0.608889
I0122 20:03:36.953604 70718 solver.cpp:517]     Test net output #3: top-5 = 0.933556
I0122 20:03:37.015830 70718 solver.cpp:266] Iteration 6000 (13.0975 iter/s, 7.63504s/100 iter), loss = 0.599417
I0122 20:03:37.015851 70718 solver.cpp:285]     Train net output #0: loss = 0.599417 (* 1 = 0.599417 loss)
I0122 20:03:37.015857 70718 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 20:03:43.229921 70718 solver.cpp:266] Iteration 6100 (16.0931 iter/s, 6.21383s/100 iter), loss = 0.423725
I0122 20:03:43.229948 70718 solver.cpp:285]     Train net output #0: loss = 0.423725 (* 1 = 0.423725 loss)
I0122 20:03:43.229954 70718 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 20:03:49.431541 70718 solver.cpp:266] Iteration 6200 (16.1255 iter/s, 6.20135s/100 iter), loss = 0.456409
I0122 20:03:49.431569 70718 solver.cpp:285]     Train net output #0: loss = 0.456409 (* 1 = 0.456409 loss)
I0122 20:03:49.431576 70718 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 20:03:55.629691 70718 solver.cpp:266] Iteration 6300 (16.1345 iter/s, 6.19788s/100 iter), loss = 0.473987
I0122 20:03:55.629719 70718 solver.cpp:285]     Train net output #0: loss = 0.473987 (* 1 = 0.473987 loss)
I0122 20:03:55.629724 70718 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 20:04:01.826365 70718 solver.cpp:266] Iteration 6400 (16.1384 iter/s, 6.19641s/100 iter), loss = 0.458477
I0122 20:04:01.826392 70718 solver.cpp:285]     Train net output #0: loss = 0.458477 (* 1 = 0.458477 loss)
I0122 20:04:01.826397 70718 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 20:04:08.026897 70718 solver.cpp:266] Iteration 6500 (16.1283 iter/s, 6.20027s/100 iter), loss = 0.689133
I0122 20:04:08.027000 70718 solver.cpp:285]     Train net output #0: loss = 0.689133 (* 1 = 0.689133 loss)
I0122 20:04:08.027006 70718 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 20:04:14.226850 70718 solver.cpp:266] Iteration 6600 (16.13 iter/s, 6.19961s/100 iter), loss = 0.572168
I0122 20:04:14.226891 70718 solver.cpp:285]     Train net output #0: loss = 0.572168 (* 1 = 0.572168 loss)
I0122 20:04:14.226897 70718 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 20:04:20.435529 70718 solver.cpp:266] Iteration 6700 (16.1072 iter/s, 6.20841s/100 iter), loss = 0.380594
I0122 20:04:20.435567 70718 solver.cpp:285]     Train net output #0: loss = 0.380594 (* 1 = 0.380594 loss)
I0122 20:04:20.435575 70718 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 20:04:26.651610 70718 solver.cpp:266] Iteration 6800 (16.088 iter/s, 6.21581s/100 iter), loss = 0.413607
I0122 20:04:26.651638 70718 solver.cpp:285]     Train net output #0: loss = 0.413607 (* 1 = 0.413607 loss)
I0122 20:04:26.651643 70718 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 20:04:32.859081 70718 solver.cpp:266] Iteration 6900 (16.1103 iter/s, 6.2072s/100 iter), loss = 0.37108
I0122 20:04:32.859120 70718 solver.cpp:285]     Train net output #0: loss = 0.37108 (* 1 = 0.37108 loss)
I0122 20:04:32.859127 70718 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 20:04:39.009910 70718 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 20:04:40.454742 70718 solver.cpp:517]     Test net output #0: accuracy = 0.455778
I0122 20:04:40.454767 70718 solver.cpp:517]     Test net output #1: loss = 1.51304 (* 1 = 1.51304 loss)
I0122 20:04:40.454771 70718 solver.cpp:517]     Test net output #2: top-1 = 0.455778
I0122 20:04:40.454776 70718 solver.cpp:517]     Test net output #3: top-5 = 0.900667
I0122 20:04:40.515669 70718 solver.cpp:266] Iteration 7000 (13.0612 iter/s, 7.65626s/100 iter), loss = 0.386719
I0122 20:04:40.515689 70718 solver.cpp:285]     Train net output #0: loss = 0.386719 (* 1 = 0.386719 loss)
I0122 20:04:40.515696 70718 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 20:04:46.717226 70718 solver.cpp:266] Iteration 7100 (16.1257 iter/s, 6.2013s/100 iter), loss = 0.58528
I0122 20:04:46.717254 70718 solver.cpp:285]     Train net output #0: loss = 0.58528 (* 1 = 0.58528 loss)
I0122 20:04:46.717260 70718 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 20:04:52.927958 70718 solver.cpp:266] Iteration 7200 (16.1019 iter/s, 6.21047s/100 iter), loss = 0.548132
I0122 20:04:52.927995 70718 solver.cpp:285]     Train net output #0: loss = 0.548132 (* 1 = 0.548132 loss)
I0122 20:04:52.928002 70718 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 20:04:59.130491 70718 solver.cpp:266] Iteration 7300 (16.1231 iter/s, 6.20227s/100 iter), loss = 0.558016
I0122 20:04:59.130518 70718 solver.cpp:285]     Train net output #0: loss = 0.558016 (* 1 = 0.558016 loss)
I0122 20:04:59.130524 70718 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 20:05:05.348954 70718 solver.cpp:266] Iteration 7400 (16.0818 iter/s, 6.2182s/100 iter), loss = 0.393111
I0122 20:05:05.348982 70718 solver.cpp:285]     Train net output #0: loss = 0.393111 (* 1 = 0.393111 loss)
I0122 20:05:05.348989 70718 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 20:05:11.553928 70718 solver.cpp:266] Iteration 7500 (16.1168 iter/s, 6.20471s/100 iter), loss = 0.490846
I0122 20:05:11.554044 70718 solver.cpp:285]     Train net output #0: loss = 0.490846 (* 1 = 0.490846 loss)
I0122 20:05:11.554051 70718 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 20:05:17.767599 70718 solver.cpp:266] Iteration 7600 (16.0945 iter/s, 6.21331s/100 iter), loss = 0.421701
I0122 20:05:17.767629 70718 solver.cpp:285]     Train net output #0: loss = 0.421701 (* 1 = 0.421701 loss)
I0122 20:05:17.767637 70718 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 20:05:23.981238 70718 solver.cpp:266] Iteration 7700 (16.0943 iter/s, 6.21337s/100 iter), loss = 0.474478
I0122 20:05:23.981266 70718 solver.cpp:285]     Train net output #0: loss = 0.474478 (* 1 = 0.474478 loss)
I0122 20:05:23.981271 70718 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 20:05:30.185649 70718 solver.cpp:266] Iteration 7800 (16.1183 iter/s, 6.20415s/100 iter), loss = 0.339519
I0122 20:05:30.185678 70718 solver.cpp:285]     Train net output #0: loss = 0.339519 (* 1 = 0.339519 loss)
I0122 20:05:30.185683 70718 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 20:05:36.381450 70718 solver.cpp:266] Iteration 7900 (16.1407 iter/s, 6.19553s/100 iter), loss = 0.424793
I0122 20:05:36.381479 70718 solver.cpp:285]     Train net output #0: loss = 0.424793 (* 1 = 0.424793 loss)
I0122 20:05:36.381484 70718 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 20:05:42.543411 70718 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 20:05:44.004163 70718 solver.cpp:517]     Test net output #0: accuracy = 0.679667
I0122 20:05:44.004189 70718 solver.cpp:517]     Test net output #1: loss = 0.941858 (* 1 = 0.941858 loss)
I0122 20:05:44.004192 70718 solver.cpp:517]     Test net output #2: top-1 = 0.679667
I0122 20:05:44.004196 70718 solver.cpp:517]     Test net output #3: top-5 = 0.962667
I0122 20:05:44.065462 70718 solver.cpp:266] Iteration 8000 (13.0146 iter/s, 7.6837s/100 iter), loss = 0.419778
I0122 20:05:44.065484 70718 solver.cpp:285]     Train net output #0: loss = 0.419778 (* 1 = 0.419778 loss)
I0122 20:05:44.065490 70718 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 20:05:50.248616 70718 solver.cpp:266] Iteration 8100 (16.1737 iter/s, 6.1829s/100 iter), loss = 0.548536
I0122 20:05:50.248644 70718 solver.cpp:285]     Train net output #0: loss = 0.548536 (* 1 = 0.548536 loss)
I0122 20:05:50.248651 70718 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 20:05:56.446229 70718 solver.cpp:266] Iteration 8200 (16.1359 iter/s, 6.19735s/100 iter), loss = 0.513904
I0122 20:05:56.446255 70718 solver.cpp:285]     Train net output #0: loss = 0.513904 (* 1 = 0.513904 loss)
I0122 20:05:56.446260 70718 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 20:06:02.637682 70718 solver.cpp:266] Iteration 8300 (16.152 iter/s, 6.19119s/100 iter), loss = 0.406621
I0122 20:06:02.637711 70718 solver.cpp:285]     Train net output #0: loss = 0.406621 (* 1 = 0.406621 loss)
I0122 20:06:02.637717 70718 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 20:06:08.844125 70718 solver.cpp:266] Iteration 8400 (16.113 iter/s, 6.20618s/100 iter), loss = 0.355183
I0122 20:06:08.844151 70718 solver.cpp:285]     Train net output #0: loss = 0.355183 (* 1 = 0.355183 loss)
I0122 20:06:08.844157 70718 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 20:06:15.065215 70718 solver.cpp:266] Iteration 8500 (16.075 iter/s, 6.22083s/100 iter), loss = 0.553047
I0122 20:06:15.065338 70718 solver.cpp:285]     Train net output #0: loss = 0.553047 (* 1 = 0.553047 loss)
I0122 20:06:15.065358 70718 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 20:06:21.253993 70718 solver.cpp:266] Iteration 8600 (16.1592 iter/s, 6.18842s/100 iter), loss = 0.364745
I0122 20:06:21.254020 70718 solver.cpp:285]     Train net output #0: loss = 0.364745 (* 1 = 0.364745 loss)
I0122 20:06:21.254026 70718 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 20:06:27.461663 70718 solver.cpp:266] Iteration 8700 (16.1098 iter/s, 6.2074s/100 iter), loss = 0.441849
I0122 20:06:27.461701 70718 solver.cpp:285]     Train net output #0: loss = 0.441849 (* 1 = 0.441849 loss)
I0122 20:06:27.461707 70718 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 20:06:33.663388 70718 solver.cpp:266] Iteration 8800 (16.1252 iter/s, 6.20146s/100 iter), loss = 0.559849
I0122 20:06:33.663416 70718 solver.cpp:285]     Train net output #0: loss = 0.559849 (* 1 = 0.559849 loss)
I0122 20:06:33.663422 70718 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 20:06:39.856395 70718 solver.cpp:266] Iteration 8900 (16.1479 iter/s, 6.19274s/100 iter), loss = 0.485911
I0122 20:06:39.856432 70718 solver.cpp:285]     Train net output #0: loss = 0.485911 (* 1 = 0.485911 loss)
I0122 20:06:39.856439 70718 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 20:06:46.003636 70718 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 20:06:47.454390 70718 solver.cpp:517]     Test net output #0: accuracy = 0.482444
I0122 20:06:47.454414 70718 solver.cpp:517]     Test net output #1: loss = 1.6503 (* 1 = 1.6503 loss)
I0122 20:06:47.454419 70718 solver.cpp:517]     Test net output #2: top-1 = 0.482444
I0122 20:06:47.454422 70718 solver.cpp:517]     Test net output #3: top-5 = 0.843555
I0122 20:06:47.515722 70718 solver.cpp:266] Iteration 9000 (13.0565 iter/s, 7.65901s/100 iter), loss = 0.353304
I0122 20:06:47.515743 70718 solver.cpp:285]     Train net output #0: loss = 0.353304 (* 1 = 0.353304 loss)
I0122 20:06:47.515748 70718 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 20:06:53.703563 70718 solver.cpp:266] Iteration 9100 (16.1614 iter/s, 6.18758s/100 iter), loss = 0.308731
I0122 20:06:53.703590 70718 solver.cpp:285]     Train net output #0: loss = 0.308731 (* 1 = 0.308731 loss)
I0122 20:06:53.703596 70718 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 20:06:59.909857 70718 solver.cpp:266] Iteration 9200 (16.1134 iter/s, 6.20603s/100 iter), loss = 0.602015
I0122 20:06:59.909885 70718 solver.cpp:285]     Train net output #0: loss = 0.602015 (* 1 = 0.602015 loss)
I0122 20:06:59.909901 70718 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 20:07:06.105412 70718 solver.cpp:266] Iteration 9300 (16.1413 iter/s, 6.19529s/100 iter), loss = 0.291449
I0122 20:07:06.105439 70718 solver.cpp:285]     Train net output #0: loss = 0.291449 (* 1 = 0.291449 loss)
I0122 20:07:06.105445 70718 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 20:07:12.312242 70718 solver.cpp:266] Iteration 9400 (16.112 iter/s, 6.20657s/100 iter), loss = 0.591797
I0122 20:07:12.312269 70718 solver.cpp:285]     Train net output #0: loss = 0.591797 (* 1 = 0.591797 loss)
I0122 20:07:12.312275 70718 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 20:07:18.517442 70718 solver.cpp:266] Iteration 9500 (16.1162 iter/s, 6.20493s/100 iter), loss = 0.418521
I0122 20:07:18.517570 70718 solver.cpp:285]     Train net output #0: loss = 0.418521 (* 1 = 0.418521 loss)
I0122 20:07:18.517577 70718 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 20:07:24.725688 70718 solver.cpp:266] Iteration 9600 (16.1086 iter/s, 6.20788s/100 iter), loss = 0.523939
I0122 20:07:24.725716 70718 solver.cpp:285]     Train net output #0: loss = 0.523939 (* 1 = 0.523939 loss)
I0122 20:07:24.725723 70718 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 20:07:30.920775 70718 solver.cpp:266] Iteration 9700 (16.1425 iter/s, 6.19482s/100 iter), loss = 0.345824
I0122 20:07:30.920812 70718 solver.cpp:285]     Train net output #0: loss = 0.345824 (* 1 = 0.345824 loss)
I0122 20:07:30.920819 70718 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 20:07:37.130374 70718 solver.cpp:266] Iteration 9800 (16.1048 iter/s, 6.20933s/100 iter), loss = 0.422069
I0122 20:07:37.130401 70718 solver.cpp:285]     Train net output #0: loss = 0.422069 (* 1 = 0.422069 loss)
I0122 20:07:37.130409 70718 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 20:07:43.325747 70718 solver.cpp:266] Iteration 9900 (16.1418 iter/s, 6.19511s/100 iter), loss = 0.736626
I0122 20:07:43.325775 70718 solver.cpp:285]     Train net output #0: loss = 0.736626 (* 1 = 0.736626 loss)
I0122 20:07:43.325798 70718 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 20:07:49.474355 70718 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 20:07:50.929266 70718 solver.cpp:517]     Test net output #0: accuracy = 0.649111
I0122 20:07:50.929291 70718 solver.cpp:517]     Test net output #1: loss = 1.06116 (* 1 = 1.06116 loss)
I0122 20:07:50.929296 70718 solver.cpp:517]     Test net output #2: top-1 = 0.649111
I0122 20:07:50.929299 70718 solver.cpp:517]     Test net output #3: top-5 = 0.954667
I0122 20:07:50.991235 70718 solver.cpp:266] Iteration 10000 (13.046 iter/s, 7.66517s/100 iter), loss = 0.630893
I0122 20:07:50.991256 70718 solver.cpp:285]     Train net output #0: loss = 0.630893 (* 1 = 0.630893 loss)
I0122 20:07:50.991262 70718 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 20:07:57.170753 70718 solver.cpp:266] Iteration 10100 (16.1832 iter/s, 6.17926s/100 iter), loss = 0.39685
I0122 20:07:57.170779 70718 solver.cpp:285]     Train net output #0: loss = 0.39685 (* 1 = 0.39685 loss)
I0122 20:07:57.170785 70718 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 20:08:03.378108 70718 solver.cpp:266] Iteration 10200 (16.1106 iter/s, 6.20709s/100 iter), loss = 0.350924
I0122 20:08:03.378134 70718 solver.cpp:285]     Train net output #0: loss = 0.350924 (* 1 = 0.350924 loss)
I0122 20:08:03.378140 70718 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 20:08:09.578375 70718 solver.cpp:266] Iteration 10300 (16.129 iter/s, 6.2s/100 iter), loss = 0.256052
I0122 20:08:09.578404 70718 solver.cpp:285]     Train net output #0: loss = 0.256052 (* 1 = 0.256052 loss)
I0122 20:08:09.578410 70718 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 20:08:15.777864 70718 solver.cpp:266] Iteration 10400 (16.1311 iter/s, 6.19922s/100 iter), loss = 0.391942
I0122 20:08:15.777891 70718 solver.cpp:285]     Train net output #0: loss = 0.391942 (* 1 = 0.391942 loss)
I0122 20:08:15.777897 70718 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 20:08:21.973567 70718 solver.cpp:266] Iteration 10500 (16.1409 iter/s, 6.19544s/100 iter), loss = 0.261851
I0122 20:08:21.973628 70718 solver.cpp:285]     Train net output #0: loss = 0.261851 (* 1 = 0.261851 loss)
I0122 20:08:21.973634 70718 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 20:08:28.170006 70718 solver.cpp:266] Iteration 10600 (16.1391 iter/s, 6.19614s/100 iter), loss = 0.262397
I0122 20:08:28.170035 70718 solver.cpp:285]     Train net output #0: loss = 0.262397 (* 1 = 0.262397 loss)
I0122 20:08:28.170042 70718 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 20:08:34.376863 70718 solver.cpp:266] Iteration 10700 (16.1119 iter/s, 6.20659s/100 iter), loss = 0.278904
I0122 20:08:34.376889 70718 solver.cpp:285]     Train net output #0: loss = 0.278904 (* 1 = 0.278904 loss)
I0122 20:08:34.376895 70718 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 20:08:40.564771 70718 solver.cpp:266] Iteration 10800 (16.1612 iter/s, 6.18765s/100 iter), loss = 0.178317
I0122 20:08:40.564810 70718 solver.cpp:285]     Train net output #0: loss = 0.178317 (* 1 = 0.178317 loss)
I0122 20:08:40.564816 70718 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 20:08:46.776870 70718 solver.cpp:266] Iteration 10900 (16.0983 iter/s, 6.21183s/100 iter), loss = 0.200183
I0122 20:08:46.776897 70718 solver.cpp:285]     Train net output #0: loss = 0.200183 (* 1 = 0.200183 loss)
I0122 20:08:46.776914 70718 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 20:08:52.920339 70718 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 20:08:54.363567 70718 solver.cpp:517]     Test net output #0: accuracy = 0.811222
I0122 20:08:54.363593 70718 solver.cpp:517]     Test net output #1: loss = 0.593092 (* 1 = 0.593092 loss)
I0122 20:08:54.363597 70718 solver.cpp:517]     Test net output #2: top-1 = 0.811222
I0122 20:08:54.363600 70718 solver.cpp:517]     Test net output #3: top-5 = 0.985001
I0122 20:08:54.425014 70718 solver.cpp:266] Iteration 11000 (13.0756 iter/s, 7.64783s/100 iter), loss = 0.252836
I0122 20:08:54.425034 70718 solver.cpp:285]     Train net output #0: loss = 0.252836 (* 1 = 0.252836 loss)
I0122 20:08:54.425038 70718 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 20:09:00.647500 70718 solver.cpp:266] Iteration 11100 (16.0714 iter/s, 6.22223s/100 iter), loss = 0.159726
I0122 20:09:00.647539 70718 solver.cpp:285]     Train net output #0: loss = 0.159726 (* 1 = 0.159726 loss)
I0122 20:09:00.647545 70718 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 20:09:06.850775 70718 solver.cpp:266] Iteration 11200 (16.1212 iter/s, 6.20301s/100 iter), loss = 0.163452
I0122 20:09:06.850803 70718 solver.cpp:285]     Train net output #0: loss = 0.163452 (* 1 = 0.163452 loss)
I0122 20:09:06.850809 70718 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 20:09:13.054767 70718 solver.cpp:266] Iteration 11300 (16.1193 iter/s, 6.20373s/100 iter), loss = 0.132919
I0122 20:09:13.054795 70718 solver.cpp:285]     Train net output #0: loss = 0.132919 (* 1 = 0.132919 loss)
I0122 20:09:13.054800 70718 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 20:09:19.257699 70718 solver.cpp:266] Iteration 11400 (16.1221 iter/s, 6.20267s/100 iter), loss = 0.13728
I0122 20:09:19.257738 70718 solver.cpp:285]     Train net output #0: loss = 0.13728 (* 1 = 0.13728 loss)
I0122 20:09:19.257745 70718 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 20:09:25.479434 70718 solver.cpp:266] Iteration 11500 (16.0734 iter/s, 6.22147s/100 iter), loss = 0.198154
I0122 20:09:25.479521 70718 solver.cpp:285]     Train net output #0: loss = 0.198154 (* 1 = 0.198154 loss)
I0122 20:09:25.479528 70718 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 20:09:31.665117 70718 solver.cpp:266] Iteration 11600 (16.1672 iter/s, 6.18536s/100 iter), loss = 0.266266
I0122 20:09:31.665143 70718 solver.cpp:285]     Train net output #0: loss = 0.266266 (* 1 = 0.266266 loss)
I0122 20:09:31.665150 70718 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 20:09:37.862514 70718 solver.cpp:266] Iteration 11700 (16.1365 iter/s, 6.19713s/100 iter), loss = 0.171539
I0122 20:09:37.862552 70718 solver.cpp:285]     Train net output #0: loss = 0.171539 (* 1 = 0.171539 loss)
I0122 20:09:37.862573 70718 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 20:09:44.056182 70718 solver.cpp:266] Iteration 11800 (16.1462 iter/s, 6.19339s/100 iter), loss = 0.262956
I0122 20:09:44.056222 70718 solver.cpp:285]     Train net output #0: loss = 0.262956 (* 1 = 0.262956 loss)
I0122 20:09:44.056229 70718 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 20:09:50.259227 70718 solver.cpp:266] Iteration 11900 (16.1218 iter/s, 6.20277s/100 iter), loss = 0.1122
I0122 20:09:50.259255 70718 solver.cpp:285]     Train net output #0: loss = 0.1122 (* 1 = 0.1122 loss)
I0122 20:09:50.259261 70718 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 20:09:56.411448 70718 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 20:09:57.857591 70718 solver.cpp:517]     Test net output #0: accuracy = 0.681667
I0122 20:09:57.857623 70718 solver.cpp:517]     Test net output #1: loss = 0.97773 (* 1 = 0.97773 loss)
I0122 20:09:57.857627 70718 solver.cpp:517]     Test net output #2: top-1 = 0.681667
I0122 20:09:57.857631 70718 solver.cpp:517]     Test net output #3: top-5 = 0.958889
I0122 20:09:57.919075 70718 solver.cpp:266] Iteration 12000 (13.0556 iter/s, 7.65953s/100 iter), loss = 0.0938202
I0122 20:09:57.919096 70718 solver.cpp:285]     Train net output #0: loss = 0.0938202 (* 1 = 0.0938202 loss)
I0122 20:09:57.919102 70718 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 20:10:04.103595 70718 solver.cpp:266] Iteration 12100 (16.1701 iter/s, 6.18426s/100 iter), loss = 0.127468
I0122 20:10:04.103622 70718 solver.cpp:285]     Train net output #0: loss = 0.127468 (* 1 = 0.127468 loss)
I0122 20:10:04.103644 70718 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 20:10:10.317875 70718 solver.cpp:266] Iteration 12200 (16.0927 iter/s, 6.21402s/100 iter), loss = 0.115206
I0122 20:10:10.317906 70718 solver.cpp:285]     Train net output #0: loss = 0.115206 (* 1 = 0.115206 loss)
I0122 20:10:10.317912 70718 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 20:10:16.533383 70718 solver.cpp:266] Iteration 12300 (16.0895 iter/s, 6.21524s/100 iter), loss = 0.121613
I0122 20:10:16.533411 70718 solver.cpp:285]     Train net output #0: loss = 0.121613 (* 1 = 0.121613 loss)
I0122 20:10:16.533416 70718 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 20:10:22.724761 70718 solver.cpp:266] Iteration 12400 (16.1522 iter/s, 6.19111s/100 iter), loss = 0.166166
I0122 20:10:22.724800 70718 solver.cpp:285]     Train net output #0: loss = 0.166166 (* 1 = 0.166166 loss)
I0122 20:10:22.724807 70718 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 20:10:28.935400 70718 solver.cpp:266] Iteration 12500 (16.1021 iter/s, 6.21037s/100 iter), loss = 0.0720637
I0122 20:10:28.935459 70718 solver.cpp:285]     Train net output #0: loss = 0.0720637 (* 1 = 0.0720637 loss)
I0122 20:10:28.935467 70718 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 20:10:35.127230 70718 solver.cpp:266] Iteration 12600 (16.1511 iter/s, 6.19153s/100 iter), loss = 0.185179
I0122 20:10:35.127259 70718 solver.cpp:285]     Train net output #0: loss = 0.185179 (* 1 = 0.185179 loss)
I0122 20:10:35.127264 70718 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 20:10:41.340694 70718 solver.cpp:266] Iteration 12700 (16.0948 iter/s, 6.2132s/100 iter), loss = 0.199481
I0122 20:10:41.340723 70718 solver.cpp:285]     Train net output #0: loss = 0.199481 (* 1 = 0.199481 loss)
I0122 20:10:41.340728 70718 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 20:10:47.551126 70718 solver.cpp:266] Iteration 12800 (16.1026 iter/s, 6.21017s/100 iter), loss = 0.182429
I0122 20:10:47.551167 70718 solver.cpp:285]     Train net output #0: loss = 0.182429 (* 1 = 0.182429 loss)
I0122 20:10:47.551172 70718 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 20:10:53.760568 70718 solver.cpp:266] Iteration 12900 (16.1052 iter/s, 6.20917s/100 iter), loss = 0.127761
I0122 20:10:53.760607 70718 solver.cpp:285]     Train net output #0: loss = 0.127761 (* 1 = 0.127761 loss)
I0122 20:10:53.760614 70718 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 20:10:59.911172 70718 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 20:11:01.359946 70718 solver.cpp:517]     Test net output #0: accuracy = 0.657889
I0122 20:11:01.359971 70718 solver.cpp:517]     Test net output #1: loss = 1.05835 (* 1 = 1.05835 loss)
I0122 20:11:01.359975 70718 solver.cpp:517]     Test net output #2: top-1 = 0.657889
I0122 20:11:01.359979 70718 solver.cpp:517]     Test net output #3: top-5 = 0.941445
I0122 20:11:01.421205 70718 solver.cpp:266] Iteration 13000 (13.0543 iter/s, 7.66031s/100 iter), loss = 0.0740421
I0122 20:11:01.421226 70718 solver.cpp:285]     Train net output #0: loss = 0.0740421 (* 1 = 0.0740421 loss)
I0122 20:11:01.421232 70718 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 20:11:07.622895 70718 solver.cpp:266] Iteration 13100 (16.1253 iter/s, 6.20143s/100 iter), loss = 0.130862
I0122 20:11:07.622923 70718 solver.cpp:285]     Train net output #0: loss = 0.130862 (* 1 = 0.130862 loss)
I0122 20:11:07.622929 70718 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 20:11:13.828912 70718 solver.cpp:266] Iteration 13200 (16.1141 iter/s, 6.20575s/100 iter), loss = 0.175835
I0122 20:11:13.828951 70718 solver.cpp:285]     Train net output #0: loss = 0.175835 (* 1 = 0.175835 loss)
I0122 20:11:13.828958 70718 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 20:11:20.027099 70718 solver.cpp:266] Iteration 13300 (16.1344 iter/s, 6.19792s/100 iter), loss = 0.142658
I0122 20:11:20.027138 70718 solver.cpp:285]     Train net output #0: loss = 0.142658 (* 1 = 0.142658 loss)
I0122 20:11:20.027145 70718 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 20:11:26.237934 70718 solver.cpp:266] Iteration 13400 (16.1016 iter/s, 6.21057s/100 iter), loss = 0.106303
I0122 20:11:26.237962 70718 solver.cpp:285]     Train net output #0: loss = 0.106303 (* 1 = 0.106303 loss)
I0122 20:11:26.237969 70718 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 20:11:32.453891 70718 solver.cpp:266] Iteration 13500 (16.0883 iter/s, 6.21569s/100 iter), loss = 0.0956133
I0122 20:11:32.453985 70718 solver.cpp:285]     Train net output #0: loss = 0.0956133 (* 1 = 0.0956133 loss)
I0122 20:11:32.453994 70718 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 20:11:38.654394 70718 solver.cpp:266] Iteration 13600 (16.1286 iter/s, 6.20017s/100 iter), loss = 0.0776256
I0122 20:11:38.654431 70718 solver.cpp:285]     Train net output #0: loss = 0.0776256 (* 1 = 0.0776256 loss)
I0122 20:11:38.654438 70718 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 20:11:44.856567 70718 solver.cpp:266] Iteration 13700 (16.1241 iter/s, 6.20191s/100 iter), loss = 0.0814026
I0122 20:11:44.856606 70718 solver.cpp:285]     Train net output #0: loss = 0.0814026 (* 1 = 0.0814026 loss)
I0122 20:11:44.856613 70718 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 20:11:51.054651 70718 solver.cpp:266] Iteration 13800 (16.1347 iter/s, 6.19782s/100 iter), loss = 0.0694383
I0122 20:11:51.054690 70718 solver.cpp:285]     Train net output #0: loss = 0.0694383 (* 1 = 0.0694383 loss)
I0122 20:11:51.054697 70718 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 20:11:57.254189 70718 solver.cpp:266] Iteration 13900 (16.131 iter/s, 6.19926s/100 iter), loss = 0.0789684
I0122 20:11:57.254230 70718 solver.cpp:285]     Train net output #0: loss = 0.0789684 (* 1 = 0.0789684 loss)
I0122 20:11:57.254235 70718 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 20:12:03.415987 70718 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 20:12:04.859568 70718 solver.cpp:517]     Test net output #0: accuracy = 0.724444
I0122 20:12:04.859593 70718 solver.cpp:517]     Test net output #1: loss = 0.849222 (* 1 = 0.849222 loss)
I0122 20:12:04.859597 70718 solver.cpp:517]     Test net output #2: top-1 = 0.724444
I0122 20:12:04.859601 70718 solver.cpp:517]     Test net output #3: top-5 = 0.966445
I0122 20:12:04.921526 70718 solver.cpp:266] Iteration 14000 (13.0429 iter/s, 7.66701s/100 iter), loss = 0.0450811
I0122 20:12:04.921546 70718 solver.cpp:285]     Train net output #0: loss = 0.0450811 (* 1 = 0.0450811 loss)
I0122 20:12:04.921551 70718 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 20:12:11.114883 70718 solver.cpp:266] Iteration 14100 (16.147 iter/s, 6.1931s/100 iter), loss = 0.150055
I0122 20:12:11.114912 70718 solver.cpp:285]     Train net output #0: loss = 0.150055 (* 1 = 0.150055 loss)
I0122 20:12:11.114917 70718 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 20:12:17.317785 70718 solver.cpp:266] Iteration 14200 (16.1222 iter/s, 6.20264s/100 iter), loss = 0.113769
I0122 20:12:17.317813 70718 solver.cpp:285]     Train net output #0: loss = 0.113769 (* 1 = 0.113769 loss)
I0122 20:12:17.317819 70718 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 20:12:23.527369 70718 solver.cpp:266] Iteration 14300 (16.1048 iter/s, 6.20932s/100 iter), loss = 0.0940524
I0122 20:12:23.527398 70718 solver.cpp:285]     Train net output #0: loss = 0.0940524 (* 1 = 0.0940524 loss)
I0122 20:12:23.527405 70718 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 20:12:29.723393 70718 solver.cpp:266] Iteration 14400 (16.1401 iter/s, 6.19576s/100 iter), loss = 0.0769485
I0122 20:12:29.723423 70718 solver.cpp:285]     Train net output #0: loss = 0.0769485 (* 1 = 0.0769485 loss)
I0122 20:12:29.723428 70718 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 20:12:35.929334 70718 solver.cpp:266] Iteration 14500 (16.1143 iter/s, 6.20567s/100 iter), loss = 0.0707368
I0122 20:12:35.929414 70718 solver.cpp:285]     Train net output #0: loss = 0.0707368 (* 1 = 0.0707368 loss)
I0122 20:12:35.929421 70718 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 20:12:42.132915 70718 solver.cpp:266] Iteration 14600 (16.1205 iter/s, 6.20327s/100 iter), loss = 0.117741
I0122 20:12:42.132957 70718 solver.cpp:285]     Train net output #0: loss = 0.117741 (* 1 = 0.117741 loss)
I0122 20:12:42.132964 70718 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 20:12:48.344372 70718 solver.cpp:266] Iteration 14700 (16.1 iter/s, 6.21118s/100 iter), loss = 0.0428568
I0122 20:12:48.344401 70718 solver.cpp:285]     Train net output #0: loss = 0.0428568 (* 1 = 0.0428568 loss)
I0122 20:12:48.344408 70718 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 20:12:54.535229 70718 solver.cpp:266] Iteration 14800 (16.1535 iter/s, 6.19059s/100 iter), loss = 0.0801891
I0122 20:12:54.535269 70718 solver.cpp:285]     Train net output #0: loss = 0.0801891 (* 1 = 0.0801891 loss)
I0122 20:12:54.535275 70718 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 20:13:00.746349 70718 solver.cpp:266] Iteration 14900 (16.1009 iter/s, 6.21084s/100 iter), loss = 0.0910393
I0122 20:13:00.746394 70718 solver.cpp:285]     Train net output #0: loss = 0.0910392 (* 1 = 0.0910392 loss)
I0122 20:13:00.746400 70718 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 20:13:06.886782 70718 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 20:13:08.332245 70718 solver.cpp:517]     Test net output #0: accuracy = 0.753222
I0122 20:13:08.332269 70718 solver.cpp:517]     Test net output #1: loss = 0.776205 (* 1 = 0.776205 loss)
I0122 20:13:08.332273 70718 solver.cpp:517]     Test net output #2: top-1 = 0.753222
I0122 20:13:08.332278 70718 solver.cpp:517]     Test net output #3: top-5 = 0.972111
I0122 20:13:08.394227 70718 solver.cpp:266] Iteration 15000 (13.0761 iter/s, 7.64755s/100 iter), loss = 0.0693504
I0122 20:13:08.394248 70718 solver.cpp:285]     Train net output #0: loss = 0.0693504 (* 1 = 0.0693504 loss)
I0122 20:13:08.394253 70718 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 20:13:14.584893 70718 solver.cpp:266] Iteration 15100 (16.154 iter/s, 6.19041s/100 iter), loss = 0.0426243
I0122 20:13:14.584923 70718 solver.cpp:285]     Train net output #0: loss = 0.0426243 (* 1 = 0.0426243 loss)
I0122 20:13:14.584928 70718 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 20:13:20.768533 70718 solver.cpp:266] Iteration 15200 (16.1724 iter/s, 6.18337s/100 iter), loss = 0.0734822
I0122 20:13:20.768561 70718 solver.cpp:285]     Train net output #0: loss = 0.0734822 (* 1 = 0.0734822 loss)
I0122 20:13:20.768568 70718 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 20:13:26.994580 70718 solver.cpp:266] Iteration 15300 (16.0622 iter/s, 6.22578s/100 iter), loss = 0.0921456
I0122 20:13:26.994618 70718 solver.cpp:285]     Train net output #0: loss = 0.0921456 (* 1 = 0.0921456 loss)
I0122 20:13:26.994624 70718 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 20:13:33.204540 70718 solver.cpp:266] Iteration 15400 (16.1039 iter/s, 6.20969s/100 iter), loss = 0.0844483
I0122 20:13:33.204568 70718 solver.cpp:285]     Train net output #0: loss = 0.0844482 (* 1 = 0.0844482 loss)
I0122 20:13:33.204574 70718 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 20:13:39.408125 70718 solver.cpp:266] Iteration 15500 (16.1204 iter/s, 6.20332s/100 iter), loss = 0.0810893
I0122 20:13:39.408241 70718 solver.cpp:285]     Train net output #0: loss = 0.0810893 (* 1 = 0.0810893 loss)
I0122 20:13:39.408247 70718 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 20:13:45.604563 70718 solver.cpp:266] Iteration 15600 (16.1392 iter/s, 6.19609s/100 iter), loss = 0.0780126
I0122 20:13:45.604589 70718 solver.cpp:285]     Train net output #0: loss = 0.0780125 (* 1 = 0.0780125 loss)
I0122 20:13:45.604595 70718 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 20:13:51.829144 70718 solver.cpp:266] Iteration 15700 (16.066 iter/s, 6.22432s/100 iter), loss = 0.0993893
I0122 20:13:51.829172 70718 solver.cpp:285]     Train net output #0: loss = 0.0993893 (* 1 = 0.0993893 loss)
I0122 20:13:51.829179 70718 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 20:13:58.032552 70718 solver.cpp:266] Iteration 15800 (16.1209 iter/s, 6.20314s/100 iter), loss = 0.0664111
I0122 20:13:58.032590 70718 solver.cpp:285]     Train net output #0: loss = 0.066411 (* 1 = 0.066411 loss)
I0122 20:13:58.032598 70718 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 20:14:04.237918 70718 solver.cpp:266] Iteration 15900 (16.1158 iter/s, 6.2051s/100 iter), loss = 0.0656008
I0122 20:14:04.237948 70718 solver.cpp:285]     Train net output #0: loss = 0.0656008 (* 1 = 0.0656008 loss)
I0122 20:14:04.237954 70718 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 20:14:10.379120 70718 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 20:14:11.828549 70718 solver.cpp:517]     Test net output #0: accuracy = 0.799
I0122 20:14:11.828574 70718 solver.cpp:517]     Test net output #1: loss = 0.619807 (* 1 = 0.619807 loss)
I0122 20:14:11.828579 70718 solver.cpp:517]     Test net output #2: top-1 = 0.799
I0122 20:14:11.828583 70718 solver.cpp:517]     Test net output #3: top-5 = 0.985334
I0122 20:14:11.890174 70718 solver.cpp:266] Iteration 16000 (13.0686 iter/s, 7.65194s/100 iter), loss = 0.0443127
I0122 20:14:11.890194 70718 solver.cpp:285]     Train net output #0: loss = 0.0443127 (* 1 = 0.0443127 loss)
I0122 20:14:11.890200 70718 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 20:14:18.091868 70718 solver.cpp:266] Iteration 16100 (16.1253 iter/s, 6.20144s/100 iter), loss = 0.193857
I0122 20:14:18.091897 70718 solver.cpp:285]     Train net output #0: loss = 0.193857 (* 1 = 0.193857 loss)
I0122 20:14:18.091903 70718 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 20:14:24.292721 70718 solver.cpp:266] Iteration 16200 (16.1275 iter/s, 6.20059s/100 iter), loss = 0.0644307
I0122 20:14:24.292748 70718 solver.cpp:285]     Train net output #0: loss = 0.0644306 (* 1 = 0.0644306 loss)
I0122 20:14:24.292753 70718 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 20:14:30.498344 70718 solver.cpp:266] Iteration 16300 (16.1151 iter/s, 6.20536s/100 iter), loss = 0.082988
I0122 20:14:30.498383 70718 solver.cpp:285]     Train net output #0: loss = 0.082988 (* 1 = 0.082988 loss)
I0122 20:14:30.498389 70718 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 20:14:36.707455 70718 solver.cpp:266] Iteration 16400 (16.1061 iter/s, 6.20885s/100 iter), loss = 0.0620904
I0122 20:14:36.707496 70718 solver.cpp:285]     Train net output #0: loss = 0.0620904 (* 1 = 0.0620904 loss)
I0122 20:14:36.707504 70718 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 20:14:42.914018 70718 solver.cpp:266] Iteration 16500 (16.1127 iter/s, 6.20628s/100 iter), loss = 0.0534329
I0122 20:14:42.914090 70718 solver.cpp:285]     Train net output #0: loss = 0.0534329 (* 1 = 0.0534329 loss)
I0122 20:14:42.914098 70718 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 20:14:49.108438 70718 solver.cpp:266] Iteration 16600 (16.1444 iter/s, 6.19411s/100 iter), loss = 0.0370192
I0122 20:14:49.108465 70718 solver.cpp:285]     Train net output #0: loss = 0.0370192 (* 1 = 0.0370192 loss)
I0122 20:14:49.108487 70718 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 20:14:55.317934 70718 solver.cpp:266] Iteration 16700 (16.1051 iter/s, 6.20923s/100 iter), loss = 0.047355
I0122 20:14:55.317961 70718 solver.cpp:285]     Train net output #0: loss = 0.047355 (* 1 = 0.047355 loss)
I0122 20:14:55.317967 70718 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 20:15:01.521723 70718 solver.cpp:266] Iteration 16800 (16.1199 iter/s, 6.20352s/100 iter), loss = 0.0688652
I0122 20:15:01.521759 70718 solver.cpp:285]     Train net output #0: loss = 0.0688651 (* 1 = 0.0688651 loss)
I0122 20:15:01.521766 70718 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 20:15:07.725560 70718 solver.cpp:266] Iteration 16900 (16.1197 iter/s, 6.20357s/100 iter), loss = 0.137951
I0122 20:15:07.725597 70718 solver.cpp:285]     Train net output #0: loss = 0.137951 (* 1 = 0.137951 loss)
I0122 20:15:07.725605 70718 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 20:15:13.870177 70718 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 20:15:15.315157 70718 solver.cpp:517]     Test net output #0: accuracy = 0.781778
I0122 20:15:15.315181 70718 solver.cpp:517]     Test net output #1: loss = 0.666969 (* 1 = 0.666969 loss)
I0122 20:15:15.315184 70718 solver.cpp:517]     Test net output #2: top-1 = 0.781778
I0122 20:15:15.315187 70718 solver.cpp:517]     Test net output #3: top-5 = 0.977223
I0122 20:15:15.377307 70718 solver.cpp:266] Iteration 17000 (13.0695 iter/s, 7.65143s/100 iter), loss = 0.0419673
I0122 20:15:15.377328 70718 solver.cpp:285]     Train net output #0: loss = 0.0419672 (* 1 = 0.0419672 loss)
I0122 20:15:15.377336 70718 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 20:15:21.584848 70718 solver.cpp:266] Iteration 17100 (16.1101 iter/s, 6.20728s/100 iter), loss = 0.148361
I0122 20:15:21.584877 70718 solver.cpp:285]     Train net output #0: loss = 0.148361 (* 1 = 0.148361 loss)
I0122 20:15:21.584883 70718 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 20:15:27.789620 70718 solver.cpp:266] Iteration 17200 (16.1173 iter/s, 6.20451s/100 iter), loss = 0.0920349
I0122 20:15:27.789649 70718 solver.cpp:285]     Train net output #0: loss = 0.0920348 (* 1 = 0.0920348 loss)
I0122 20:15:27.789654 70718 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 20:15:33.989686 70718 solver.cpp:266] Iteration 17300 (16.1296 iter/s, 6.1998s/100 iter), loss = 0.080277
I0122 20:15:33.989727 70718 solver.cpp:285]     Train net output #0: loss = 0.080277 (* 1 = 0.080277 loss)
I0122 20:15:33.989732 70718 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 20:15:40.199496 70718 solver.cpp:266] Iteration 17400 (16.1042 iter/s, 6.20954s/100 iter), loss = 0.158945
I0122 20:15:40.199532 70718 solver.cpp:285]     Train net output #0: loss = 0.158945 (* 1 = 0.158945 loss)
I0122 20:15:40.199539 70718 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 20:15:46.394492 70718 solver.cpp:266] Iteration 17500 (16.1427 iter/s, 6.19473s/100 iter), loss = 0.137852
I0122 20:15:46.394554 70718 solver.cpp:285]     Train net output #0: loss = 0.137852 (* 1 = 0.137852 loss)
I0122 20:15:46.394560 70718 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 20:15:52.600054 70718 solver.cpp:266] Iteration 17600 (16.1154 iter/s, 6.20526s/100 iter), loss = 0.0545917
I0122 20:15:52.600091 70718 solver.cpp:285]     Train net output #0: loss = 0.0545916 (* 1 = 0.0545916 loss)
I0122 20:15:52.600097 70718 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 20:15:58.828835 70718 solver.cpp:266] Iteration 17700 (16.0552 iter/s, 6.22852s/100 iter), loss = 0.137945
I0122 20:15:58.828862 70718 solver.cpp:285]     Train net output #0: loss = 0.137945 (* 1 = 0.137945 loss)
I0122 20:15:58.828868 70718 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 20:16:05.054673 70718 solver.cpp:266] Iteration 17800 (16.0628 iter/s, 6.22557s/100 iter), loss = 0.106974
I0122 20:16:05.054713 70718 solver.cpp:285]     Train net output #0: loss = 0.106974 (* 1 = 0.106974 loss)
I0122 20:16:05.054720 70718 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 20:16:11.248587 70718 solver.cpp:266] Iteration 17900 (16.1456 iter/s, 6.19365s/100 iter), loss = 0.0965851
I0122 20:16:11.248625 70718 solver.cpp:285]     Train net output #0: loss = 0.0965851 (* 1 = 0.0965851 loss)
I0122 20:16:11.248632 70718 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 20:16:17.395083 70718 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 20:16:18.840544 70718 solver.cpp:517]     Test net output #0: accuracy = 0.806667
I0122 20:16:18.840569 70718 solver.cpp:517]     Test net output #1: loss = 0.613429 (* 1 = 0.613429 loss)
I0122 20:16:18.840574 70718 solver.cpp:517]     Test net output #2: top-1 = 0.806667
I0122 20:16:18.840577 70718 solver.cpp:517]     Test net output #3: top-5 = 0.986778
I0122 20:16:18.902223 70718 solver.cpp:266] Iteration 18000 (13.0662 iter/s, 7.65332s/100 iter), loss = 0.107945
I0122 20:16:18.902242 70718 solver.cpp:285]     Train net output #0: loss = 0.107945 (* 1 = 0.107945 loss)
I0122 20:16:18.902248 70718 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 20:16:25.100718 70718 solver.cpp:266] Iteration 18100 (16.1336 iter/s, 6.19824s/100 iter), loss = 0.0887526
I0122 20:16:25.100744 70718 solver.cpp:285]     Train net output #0: loss = 0.0887526 (* 1 = 0.0887526 loss)
I0122 20:16:25.100749 70718 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 20:16:31.306490 70718 solver.cpp:266] Iteration 18200 (16.1147 iter/s, 6.20551s/100 iter), loss = 0.0962536
I0122 20:16:31.306517 70718 solver.cpp:285]     Train net output #0: loss = 0.0962535 (* 1 = 0.0962535 loss)
I0122 20:16:31.306524 70718 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 20:16:37.494400 70718 solver.cpp:266] Iteration 18300 (16.1612 iter/s, 6.18764s/100 iter), loss = 0.0941099
I0122 20:16:37.494427 70718 solver.cpp:285]     Train net output #0: loss = 0.0941098 (* 1 = 0.0941098 loss)
I0122 20:16:37.494433 70718 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 20:16:43.711138 70718 solver.cpp:266] Iteration 18400 (16.0863 iter/s, 6.21647s/100 iter), loss = 0.0831456
I0122 20:16:43.711164 70718 solver.cpp:285]     Train net output #0: loss = 0.0831456 (* 1 = 0.0831456 loss)
I0122 20:16:43.711170 70718 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 20:16:49.916252 70718 solver.cpp:266] Iteration 18500 (16.1164 iter/s, 6.20485s/100 iter), loss = 0.103909
I0122 20:16:49.916301 70718 solver.cpp:285]     Train net output #0: loss = 0.103909 (* 1 = 0.103909 loss)
I0122 20:16:49.916307 70718 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 20:16:56.116654 70718 solver.cpp:266] Iteration 18600 (16.1287 iter/s, 6.20012s/100 iter), loss = 0.0556992
I0122 20:16:56.116694 70718 solver.cpp:285]     Train net output #0: loss = 0.0556991 (* 1 = 0.0556991 loss)
I0122 20:16:56.116701 70718 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 20:17:02.317914 70718 solver.cpp:266] Iteration 18700 (16.1264 iter/s, 6.20099s/100 iter), loss = 0.0588313
I0122 20:17:02.317941 70718 solver.cpp:285]     Train net output #0: loss = 0.0588313 (* 1 = 0.0588313 loss)
I0122 20:17:02.317947 70718 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 20:17:08.510263 70718 solver.cpp:266] Iteration 18800 (16.1497 iter/s, 6.19208s/100 iter), loss = 0.0670613
I0122 20:17:08.510293 70718 solver.cpp:285]     Train net output #0: loss = 0.0670612 (* 1 = 0.0670612 loss)
I0122 20:17:08.510298 70718 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 20:17:14.715518 70718 solver.cpp:266] Iteration 18900 (16.1161 iter/s, 6.20499s/100 iter), loss = 0.123926
I0122 20:17:14.715548 70718 solver.cpp:285]     Train net output #0: loss = 0.123926 (* 1 = 0.123926 loss)
I0122 20:17:14.715553 70718 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 20:17:20.852237 70718 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 20:17:22.299631 70718 solver.cpp:517]     Test net output #0: accuracy = 0.805778
I0122 20:17:22.299657 70718 solver.cpp:517]     Test net output #1: loss = 0.681567 (* 1 = 0.681567 loss)
I0122 20:17:22.299661 70718 solver.cpp:517]     Test net output #2: top-1 = 0.805778
I0122 20:17:22.299664 70718 solver.cpp:517]     Test net output #3: top-5 = 0.987444
I0122 20:17:22.361131 70718 solver.cpp:266] Iteration 19000 (13.0799 iter/s, 7.6453s/100 iter), loss = 0.151295
I0122 20:17:22.361151 70718 solver.cpp:285]     Train net output #0: loss = 0.151295 (* 1 = 0.151295 loss)
I0122 20:17:22.361157 70718 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 20:17:28.554616 70718 solver.cpp:266] Iteration 19100 (16.1467 iter/s, 6.19323s/100 iter), loss = 0.0319603
I0122 20:17:28.554643 70718 solver.cpp:285]     Train net output #0: loss = 0.0319602 (* 1 = 0.0319602 loss)
I0122 20:17:28.554649 70718 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 20:17:34.755566 70718 solver.cpp:266] Iteration 19200 (16.1272 iter/s, 6.20069s/100 iter), loss = 0.0523434
I0122 20:17:34.755594 70718 solver.cpp:285]     Train net output #0: loss = 0.0523434 (* 1 = 0.0523434 loss)
I0122 20:17:34.755600 70718 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 20:17:40.947449 70718 solver.cpp:266] Iteration 19300 (16.1509 iter/s, 6.19162s/100 iter), loss = 0.0852471
I0122 20:17:40.947476 70718 solver.cpp:285]     Train net output #0: loss = 0.085247 (* 1 = 0.085247 loss)
I0122 20:17:40.947482 70718 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 20:17:47.159497 70718 solver.cpp:266] Iteration 19400 (16.0984 iter/s, 6.21178s/100 iter), loss = 0.11108
I0122 20:17:47.159525 70718 solver.cpp:285]     Train net output #0: loss = 0.11108 (* 1 = 0.11108 loss)
I0122 20:17:47.159530 70718 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 20:17:53.357780 70718 solver.cpp:266] Iteration 19500 (16.1342 iter/s, 6.19802s/100 iter), loss = 0.0783336
I0122 20:17:53.357859 70718 solver.cpp:285]     Train net output #0: loss = 0.0783336 (* 1 = 0.0783336 loss)
I0122 20:17:53.357867 70718 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 20:17:59.544704 70718 solver.cpp:266] Iteration 19600 (16.1639 iter/s, 6.18661s/100 iter), loss = 0.0704193
I0122 20:17:59.544744 70718 solver.cpp:285]     Train net output #0: loss = 0.0704193 (* 1 = 0.0704193 loss)
I0122 20:17:59.544751 70718 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 20:18:05.765976 70718 solver.cpp:266] Iteration 19700 (16.0746 iter/s, 6.221s/100 iter), loss = 0.0638372
I0122 20:18:05.766005 70718 solver.cpp:285]     Train net output #0: loss = 0.0638372 (* 1 = 0.0638372 loss)
I0122 20:18:05.766011 70718 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 20:18:11.976516 70718 solver.cpp:266] Iteration 19800 (16.1024 iter/s, 6.21027s/100 iter), loss = 0.0856983
I0122 20:18:11.976546 70718 solver.cpp:285]     Train net output #0: loss = 0.0856983 (* 1 = 0.0856983 loss)
I0122 20:18:11.976552 70718 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 20:18:18.174692 70718 solver.cpp:266] Iteration 19900 (16.1345 iter/s, 6.19791s/100 iter), loss = 0.0602519
I0122 20:18:18.174721 70718 solver.cpp:285]     Train net output #0: loss = 0.0602519 (* 1 = 0.0602519 loss)
I0122 20:18:18.174726 70718 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 20:18:24.335024 70718 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_20000.caffemodel
I0122 20:18:24.385376 70718 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_20000.solverstate
I0122 20:18:24.392966 70718 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 20:18:25.838289 70718 solver.cpp:517]     Test net output #0: accuracy = 0.823555
I0122 20:18:25.838313 70718 solver.cpp:517]     Test net output #1: loss = 0.544263 (* 1 = 0.544263 loss)
I0122 20:18:25.838318 70718 solver.cpp:517]     Test net output #2: top-1 = 0.823555
I0122 20:18:25.838322 70718 solver.cpp:517]     Test net output #3: top-5 = 0.990333
I0122 20:18:25.899863 70718 solver.cpp:266] Iteration 20000 (12.9452 iter/s, 7.72485s/100 iter), loss = 0.0978462
I0122 20:18:25.899881 70718 solver.cpp:285]     Train net output #0: loss = 0.0978461 (* 1 = 0.0978461 loss)
I0122 20:18:25.899888 70718 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 20:18:32.097497 70718 solver.cpp:266] Iteration 20100 (16.1359 iter/s, 6.19738s/100 iter), loss = 0.0647567
I0122 20:18:32.097527 70718 solver.cpp:285]     Train net output #0: loss = 0.0647566 (* 1 = 0.0647566 loss)
I0122 20:18:32.097532 70718 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 20:18:38.305946 70718 solver.cpp:266] Iteration 20200 (16.1078 iter/s, 6.20818s/100 iter), loss = 0.0732051
I0122 20:18:38.305976 70718 solver.cpp:285]     Train net output #0: loss = 0.073205 (* 1 = 0.073205 loss)
I0122 20:18:38.305981 70718 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 20:18:44.493160 70718 solver.cpp:266] Iteration 20300 (16.1631 iter/s, 6.18695s/100 iter), loss = 0.0240059
I0122 20:18:44.493189 70718 solver.cpp:285]     Train net output #0: loss = 0.0240059 (* 1 = 0.0240059 loss)
I0122 20:18:44.493196 70718 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 20:18:50.698110 70718 solver.cpp:266] Iteration 20400 (16.1169 iter/s, 6.20468s/100 iter), loss = 0.0634191
I0122 20:18:50.698140 70718 solver.cpp:285]     Train net output #0: loss = 0.0634191 (* 1 = 0.0634191 loss)
I0122 20:18:50.698146 70718 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 20:18:56.884109 70718 solver.cpp:266] Iteration 20500 (16.1662 iter/s, 6.18573s/100 iter), loss = 0.047717
I0122 20:18:56.884203 70718 solver.cpp:285]     Train net output #0: loss = 0.0477169 (* 1 = 0.0477169 loss)
I0122 20:18:56.884212 70718 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 20:19:03.082566 70718 solver.cpp:266] Iteration 20600 (16.1339 iter/s, 6.19813s/100 iter), loss = 0.0383876
I0122 20:19:03.082594 70718 solver.cpp:285]     Train net output #0: loss = 0.0383875 (* 1 = 0.0383875 loss)
I0122 20:19:03.082617 70718 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 20:19:09.291399 70718 solver.cpp:266] Iteration 20700 (16.1068 iter/s, 6.20857s/100 iter), loss = 0.0283104
I0122 20:19:09.291427 70718 solver.cpp:285]     Train net output #0: loss = 0.0283103 (* 1 = 0.0283103 loss)
I0122 20:19:09.291433 70718 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 20:19:15.492718 70718 solver.cpp:266] Iteration 20800 (16.1263 iter/s, 6.20105s/100 iter), loss = 0.0182067
I0122 20:19:15.492748 70718 solver.cpp:285]     Train net output #0: loss = 0.0182066 (* 1 = 0.0182066 loss)
I0122 20:19:15.492769 70718 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 20:19:21.708766 70718 solver.cpp:266] Iteration 20900 (16.0881 iter/s, 6.21578s/100 iter), loss = 0.0105558
I0122 20:19:21.708796 70718 solver.cpp:285]     Train net output #0: loss = 0.0105557 (* 1 = 0.0105557 loss)
I0122 20:19:21.708802 70718 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 20:19:27.856003 70718 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 20:19:29.303911 70718 solver.cpp:517]     Test net output #0: accuracy = 0.895111
I0122 20:19:29.303936 70718 solver.cpp:517]     Test net output #1: loss = 0.348441 (* 1 = 0.348441 loss)
I0122 20:19:29.303941 70718 solver.cpp:517]     Test net output #2: top-1 = 0.895111
I0122 20:19:29.303944 70718 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 20:19:29.365517 70718 solver.cpp:266] Iteration 21000 (13.0609 iter/s, 7.65643s/100 iter), loss = 0.0414593
I0122 20:19:29.365537 70718 solver.cpp:285]     Train net output #0: loss = 0.0414592 (* 1 = 0.0414592 loss)
I0122 20:19:29.365543 70718 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 20:19:35.564282 70718 solver.cpp:266] Iteration 21100 (16.1329 iter/s, 6.19851s/100 iter), loss = 0.0120907
I0122 20:19:35.564311 70718 solver.cpp:285]     Train net output #0: loss = 0.0120906 (* 1 = 0.0120906 loss)
I0122 20:19:35.564317 70718 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 20:19:41.765588 70718 solver.cpp:266] Iteration 21200 (16.1263 iter/s, 6.20104s/100 iter), loss = 0.0477159
I0122 20:19:41.765628 70718 solver.cpp:285]     Train net output #0: loss = 0.0477158 (* 1 = 0.0477158 loss)
I0122 20:19:41.765635 70718 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 20:19:47.966717 70718 solver.cpp:266] Iteration 21300 (16.1268 iter/s, 6.20085s/100 iter), loss = 0.0174922
I0122 20:19:47.966744 70718 solver.cpp:285]     Train net output #0: loss = 0.0174921 (* 1 = 0.0174921 loss)
I0122 20:19:47.966749 70718 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 20:19:54.162137 70718 solver.cpp:266] Iteration 21400 (16.1416 iter/s, 6.19516s/100 iter), loss = 0.0219383
I0122 20:19:54.162168 70718 solver.cpp:285]     Train net output #0: loss = 0.0219382 (* 1 = 0.0219382 loss)
I0122 20:19:54.162173 70718 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 20:20:00.372910 70718 solver.cpp:266] Iteration 21500 (16.1017 iter/s, 6.21051s/100 iter), loss = 0.0207228
I0122 20:20:00.373039 70718 solver.cpp:285]     Train net output #0: loss = 0.0207227 (* 1 = 0.0207227 loss)
I0122 20:20:00.373045 70718 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 20:20:06.567795 70718 solver.cpp:266] Iteration 21600 (16.1433 iter/s, 6.19452s/100 iter), loss = 0.0288106
I0122 20:20:06.567823 70718 solver.cpp:285]     Train net output #0: loss = 0.0288105 (* 1 = 0.0288105 loss)
I0122 20:20:06.567829 70718 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 20:20:12.786218 70718 solver.cpp:266] Iteration 21700 (16.0819 iter/s, 6.21816s/100 iter), loss = 0.0245898
I0122 20:20:12.786247 70718 solver.cpp:285]     Train net output #0: loss = 0.0245897 (* 1 = 0.0245897 loss)
I0122 20:20:12.786253 70718 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 20:20:19.000622 70718 solver.cpp:266] Iteration 21800 (16.0923 iter/s, 6.21414s/100 iter), loss = 0.00656261
I0122 20:20:19.000649 70718 solver.cpp:285]     Train net output #0: loss = 0.00656252 (* 1 = 0.00656252 loss)
I0122 20:20:19.000655 70718 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 20:20:25.204378 70718 solver.cpp:266] Iteration 21900 (16.12 iter/s, 6.20349s/100 iter), loss = 0.0260553
I0122 20:20:25.204407 70718 solver.cpp:285]     Train net output #0: loss = 0.0260552 (* 1 = 0.0260552 loss)
I0122 20:20:25.204412 70718 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 20:20:31.321990 70718 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 20:20:32.767171 70718 solver.cpp:517]     Test net output #0: accuracy = 0.897555
I0122 20:20:32.767196 70718 solver.cpp:517]     Test net output #1: loss = 0.349665 (* 1 = 0.349665 loss)
I0122 20:20:32.767201 70718 solver.cpp:517]     Test net output #2: top-1 = 0.897555
I0122 20:20:32.767204 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996667
I0122 20:20:32.828428 70718 solver.cpp:266] Iteration 22000 (13.1169 iter/s, 7.62373s/100 iter), loss = 0.0100802
I0122 20:20:32.828449 70718 solver.cpp:285]     Train net output #0: loss = 0.0100801 (* 1 = 0.0100801 loss)
I0122 20:20:32.828454 70718 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 20:20:39.045101 70718 solver.cpp:266] Iteration 22100 (16.0864 iter/s, 6.21641s/100 iter), loss = 0.0292658
I0122 20:20:39.045130 70718 solver.cpp:285]     Train net output #0: loss = 0.0292657 (* 1 = 0.0292657 loss)
I0122 20:20:39.045136 70718 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 20:20:45.240491 70718 solver.cpp:266] Iteration 22200 (16.1417 iter/s, 6.19512s/100 iter), loss = 0.0127999
I0122 20:20:45.240520 70718 solver.cpp:285]     Train net output #0: loss = 0.0127998 (* 1 = 0.0127998 loss)
I0122 20:20:45.240526 70718 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 20:20:51.436843 70718 solver.cpp:266] Iteration 22300 (16.1392 iter/s, 6.19609s/100 iter), loss = 0.00666936
I0122 20:20:51.436872 70718 solver.cpp:285]     Train net output #0: loss = 0.00666927 (* 1 = 0.00666927 loss)
I0122 20:20:51.436877 70718 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 20:20:57.642958 70718 solver.cpp:266] Iteration 22400 (16.1138 iter/s, 6.20585s/100 iter), loss = 0.0187491
I0122 20:20:57.643000 70718 solver.cpp:285]     Train net output #0: loss = 0.018749 (* 1 = 0.018749 loss)
I0122 20:20:57.643007 70718 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 20:21:03.851944 70718 solver.cpp:266] Iteration 22500 (16.1064 iter/s, 6.20871s/100 iter), loss = 0.0138719
I0122 20:21:03.852100 70718 solver.cpp:285]     Train net output #0: loss = 0.0138718 (* 1 = 0.0138718 loss)
I0122 20:21:03.852123 70718 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 20:21:10.052994 70718 solver.cpp:266] Iteration 22600 (16.1273 iter/s, 6.20067s/100 iter), loss = 0.0132217
I0122 20:21:10.053025 70718 solver.cpp:285]     Train net output #0: loss = 0.0132216 (* 1 = 0.0132216 loss)
I0122 20:21:10.053031 70718 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 20:21:16.278553 70718 solver.cpp:266] Iteration 22700 (16.0635 iter/s, 6.22529s/100 iter), loss = 0.010282
I0122 20:21:16.278584 70718 solver.cpp:285]     Train net output #0: loss = 0.0102819 (* 1 = 0.0102819 loss)
I0122 20:21:16.278589 70718 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 20:21:22.477470 70718 solver.cpp:266] Iteration 22800 (16.1325 iter/s, 6.19865s/100 iter), loss = 0.014787
I0122 20:21:22.477509 70718 solver.cpp:285]     Train net output #0: loss = 0.0147869 (* 1 = 0.0147869 loss)
I0122 20:21:22.477516 70718 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 20:21:28.676484 70718 solver.cpp:266] Iteration 22900 (16.1323 iter/s, 6.19875s/100 iter), loss = 0.0183866
I0122 20:21:28.676512 70718 solver.cpp:285]     Train net output #0: loss = 0.0183865 (* 1 = 0.0183865 loss)
I0122 20:21:28.676519 70718 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 20:21:34.818292 70718 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 20:21:36.280228 70718 solver.cpp:517]     Test net output #0: accuracy = 0.898555
I0122 20:21:36.280253 70718 solver.cpp:517]     Test net output #1: loss = 0.347008 (* 1 = 0.347008 loss)
I0122 20:21:36.280258 70718 solver.cpp:517]     Test net output #2: top-1 = 0.898555
I0122 20:21:36.280261 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996667
I0122 20:21:36.343817 70718 solver.cpp:266] Iteration 23000 (13.0429 iter/s, 7.66702s/100 iter), loss = 0.013857
I0122 20:21:36.343837 70718 solver.cpp:285]     Train net output #0: loss = 0.0138569 (* 1 = 0.0138569 loss)
I0122 20:21:36.343844 70718 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 20:21:42.544041 70718 solver.cpp:266] Iteration 23100 (16.1291 iter/s, 6.19997s/100 iter), loss = 0.00920291
I0122 20:21:42.544070 70718 solver.cpp:285]     Train net output #0: loss = 0.00920282 (* 1 = 0.00920282 loss)
I0122 20:21:42.544076 70718 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 20:21:48.728729 70718 solver.cpp:266] Iteration 23200 (16.1697 iter/s, 6.18442s/100 iter), loss = 0.0252366
I0122 20:21:48.728757 70718 solver.cpp:285]     Train net output #0: loss = 0.0252365 (* 1 = 0.0252365 loss)
I0122 20:21:48.728762 70718 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 20:21:54.944994 70718 solver.cpp:266] Iteration 23300 (16.0875 iter/s, 6.216s/100 iter), loss = 0.019173
I0122 20:21:54.945024 70718 solver.cpp:285]     Train net output #0: loss = 0.019173 (* 1 = 0.019173 loss)
I0122 20:21:54.945029 70718 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 20:22:01.139719 70718 solver.cpp:266] Iteration 23400 (16.1435 iter/s, 6.19446s/100 iter), loss = 0.0137355
I0122 20:22:01.139748 70718 solver.cpp:285]     Train net output #0: loss = 0.0137354 (* 1 = 0.0137354 loss)
I0122 20:22:01.139755 70718 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 20:22:07.338595 70718 solver.cpp:266] Iteration 23500 (16.1327 iter/s, 6.19861s/100 iter), loss = 0.0139024
I0122 20:22:07.338724 70718 solver.cpp:285]     Train net output #0: loss = 0.0139023 (* 1 = 0.0139023 loss)
I0122 20:22:07.338732 70718 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 20:22:13.546540 70718 solver.cpp:266] Iteration 23600 (16.1093 iter/s, 6.20758s/100 iter), loss = 0.0106322
I0122 20:22:13.546569 70718 solver.cpp:285]     Train net output #0: loss = 0.0106321 (* 1 = 0.0106321 loss)
I0122 20:22:13.546576 70718 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 20:22:19.734153 70718 solver.cpp:266] Iteration 23700 (16.162 iter/s, 6.18735s/100 iter), loss = 0.0205203
I0122 20:22:19.734182 70718 solver.cpp:285]     Train net output #0: loss = 0.0205202 (* 1 = 0.0205202 loss)
I0122 20:22:19.734187 70718 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 20:22:25.933367 70718 solver.cpp:266] Iteration 23800 (16.1318 iter/s, 6.19895s/100 iter), loss = 0.0174627
I0122 20:22:25.933395 70718 solver.cpp:285]     Train net output #0: loss = 0.0174626 (* 1 = 0.0174626 loss)
I0122 20:22:25.933401 70718 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 20:22:32.145059 70718 solver.cpp:266] Iteration 23900 (16.0994 iter/s, 6.21143s/100 iter), loss = 0.00601303
I0122 20:22:32.145088 70718 solver.cpp:285]     Train net output #0: loss = 0.00601295 (* 1 = 0.00601295 loss)
I0122 20:22:32.145093 70718 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 20:22:38.300473 70718 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 20:22:39.751407 70718 solver.cpp:517]     Test net output #0: accuracy = 0.897444
I0122 20:22:39.751432 70718 solver.cpp:517]     Test net output #1: loss = 0.35527 (* 1 = 0.35527 loss)
I0122 20:22:39.751436 70718 solver.cpp:517]     Test net output #2: top-1 = 0.897444
I0122 20:22:39.751441 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 20:22:39.814177 70718 solver.cpp:266] Iteration 24000 (13.0398 iter/s, 7.6688s/100 iter), loss = 0.0111231
I0122 20:22:39.814198 70718 solver.cpp:285]     Train net output #0: loss = 0.011123 (* 1 = 0.011123 loss)
I0122 20:22:39.814204 70718 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 20:22:46.002313 70718 solver.cpp:266] Iteration 24100 (16.1606 iter/s, 6.18788s/100 iter), loss = 0.00880879
I0122 20:22:46.002342 70718 solver.cpp:285]     Train net output #0: loss = 0.00880872 (* 1 = 0.00880872 loss)
I0122 20:22:46.002348 70718 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 20:22:52.190340 70718 solver.cpp:266] Iteration 24200 (16.1609 iter/s, 6.18776s/100 iter), loss = 0.00561981
I0122 20:22:52.190368 70718 solver.cpp:285]     Train net output #0: loss = 0.00561973 (* 1 = 0.00561973 loss)
I0122 20:22:52.190374 70718 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 20:22:58.396522 70718 solver.cpp:266] Iteration 24300 (16.1137 iter/s, 6.20591s/100 iter), loss = 0.0192083
I0122 20:22:58.396550 70718 solver.cpp:285]     Train net output #0: loss = 0.0192082 (* 1 = 0.0192082 loss)
I0122 20:22:58.396556 70718 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 20:23:04.597750 70718 solver.cpp:266] Iteration 24400 (16.1265 iter/s, 6.20096s/100 iter), loss = 0.00976159
I0122 20:23:04.597779 70718 solver.cpp:285]     Train net output #0: loss = 0.00976151 (* 1 = 0.00976151 loss)
I0122 20:23:04.597785 70718 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 20:23:10.800704 70718 solver.cpp:266] Iteration 24500 (16.122 iter/s, 6.20269s/100 iter), loss = 0.015664
I0122 20:23:10.800782 70718 solver.cpp:285]     Train net output #0: loss = 0.0156639 (* 1 = 0.0156639 loss)
I0122 20:23:10.800791 70718 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 20:23:17.006361 70718 solver.cpp:266] Iteration 24600 (16.1151 iter/s, 6.20534s/100 iter), loss = 0.00844654
I0122 20:23:17.006388 70718 solver.cpp:285]     Train net output #0: loss = 0.00844647 (* 1 = 0.00844647 loss)
I0122 20:23:17.006393 70718 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 20:23:23.209816 70718 solver.cpp:266] Iteration 24700 (16.1207 iter/s, 6.20319s/100 iter), loss = 0.0130988
I0122 20:23:23.209844 70718 solver.cpp:285]     Train net output #0: loss = 0.0130987 (* 1 = 0.0130987 loss)
I0122 20:23:23.209851 70718 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 20:23:29.415608 70718 solver.cpp:266] Iteration 24800 (16.1147 iter/s, 6.20553s/100 iter), loss = 0.0110313
I0122 20:23:29.415637 70718 solver.cpp:285]     Train net output #0: loss = 0.0110312 (* 1 = 0.0110312 loss)
I0122 20:23:29.415643 70718 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 20:23:35.616375 70718 solver.cpp:266] Iteration 24900 (16.1277 iter/s, 6.2005s/100 iter), loss = 0.00900748
I0122 20:23:35.616415 70718 solver.cpp:285]     Train net output #0: loss = 0.0090074 (* 1 = 0.0090074 loss)
I0122 20:23:35.616421 70718 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 20:23:41.755497 70718 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 20:23:43.205276 70718 solver.cpp:517]     Test net output #0: accuracy = 0.9
I0122 20:23:43.205301 70718 solver.cpp:517]     Test net output #1: loss = 0.352507 (* 1 = 0.352507 loss)
I0122 20:23:43.205305 70718 solver.cpp:517]     Test net output #2: top-1 = 0.9
I0122 20:23:43.205308 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996667
I0122 20:23:43.266924 70718 solver.cpp:266] Iteration 25000 (13.0715 iter/s, 7.65022s/100 iter), loss = 0.00758248
I0122 20:23:43.266945 70718 solver.cpp:285]     Train net output #0: loss = 0.0075824 (* 1 = 0.0075824 loss)
I0122 20:23:43.266952 70718 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 20:23:49.455862 70718 solver.cpp:266] Iteration 25100 (16.1585 iter/s, 6.18868s/100 iter), loss = 0.00711895
I0122 20:23:49.455890 70718 solver.cpp:285]     Train net output #0: loss = 0.00711887 (* 1 = 0.00711887 loss)
I0122 20:23:49.455896 70718 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 20:23:55.659425 70718 solver.cpp:266] Iteration 25200 (16.1205 iter/s, 6.20329s/100 iter), loss = 0.0143573
I0122 20:23:55.659453 70718 solver.cpp:285]     Train net output #0: loss = 0.0143572 (* 1 = 0.0143572 loss)
I0122 20:23:55.659459 70718 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 20:24:01.868959 70718 solver.cpp:266] Iteration 25300 (16.105 iter/s, 6.20927s/100 iter), loss = 0.00880235
I0122 20:24:01.868988 70718 solver.cpp:285]     Train net output #0: loss = 0.00880228 (* 1 = 0.00880228 loss)
I0122 20:24:01.868994 70718 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 20:24:08.059651 70718 solver.cpp:266] Iteration 25400 (16.154 iter/s, 6.19043s/100 iter), loss = 0.00936099
I0122 20:24:08.059680 70718 solver.cpp:285]     Train net output #0: loss = 0.00936091 (* 1 = 0.00936091 loss)
I0122 20:24:08.059685 70718 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 20:24:14.280766 70718 solver.cpp:266] Iteration 25500 (16.075 iter/s, 6.22085s/100 iter), loss = 0.0123087
I0122 20:24:14.280867 70718 solver.cpp:285]     Train net output #0: loss = 0.0123086 (* 1 = 0.0123086 loss)
I0122 20:24:14.280874 70718 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 20:24:20.463898 70718 solver.cpp:266] Iteration 25600 (16.1739 iter/s, 6.18279s/100 iter), loss = 0.00873857
I0122 20:24:20.463927 70718 solver.cpp:285]     Train net output #0: loss = 0.00873849 (* 1 = 0.00873849 loss)
I0122 20:24:20.463932 70718 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 20:24:26.658819 70718 solver.cpp:266] Iteration 25700 (16.1429 iter/s, 6.19466s/100 iter), loss = 0.0100264
I0122 20:24:26.658845 70718 solver.cpp:285]     Train net output #0: loss = 0.0100263 (* 1 = 0.0100263 loss)
I0122 20:24:26.658850 70718 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 20:24:32.864439 70718 solver.cpp:266] Iteration 25800 (16.1151 iter/s, 6.20536s/100 iter), loss = 0.00945067
I0122 20:24:32.864468 70718 solver.cpp:285]     Train net output #0: loss = 0.0094506 (* 1 = 0.0094506 loss)
I0122 20:24:32.864475 70718 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 20:24:39.061453 70718 solver.cpp:266] Iteration 25900 (16.1375 iter/s, 6.19675s/100 iter), loss = 0.0119605
I0122 20:24:39.061483 70718 solver.cpp:285]     Train net output #0: loss = 0.0119604 (* 1 = 0.0119604 loss)
I0122 20:24:39.061489 70718 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 20:24:45.203155 70718 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 20:24:46.650770 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899666
I0122 20:24:46.650796 70718 solver.cpp:517]     Test net output #1: loss = 0.357994 (* 1 = 0.357994 loss)
I0122 20:24:46.650801 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899666
I0122 20:24:46.650804 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996778
I0122 20:24:46.712870 70718 solver.cpp:266] Iteration 26000 (13.07 iter/s, 7.6511s/100 iter), loss = 0.0101272
I0122 20:24:46.712890 70718 solver.cpp:285]     Train net output #0: loss = 0.0101271 (* 1 = 0.0101271 loss)
I0122 20:24:46.712898 70718 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 20:24:52.913715 70718 solver.cpp:266] Iteration 26100 (16.1275 iter/s, 6.20059s/100 iter), loss = 0.00681618
I0122 20:24:52.913756 70718 solver.cpp:285]     Train net output #0: loss = 0.0068161 (* 1 = 0.0068161 loss)
I0122 20:24:52.913764 70718 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 20:24:59.112232 70718 solver.cpp:266] Iteration 26200 (16.1336 iter/s, 6.19824s/100 iter), loss = 0.0023983
I0122 20:24:59.112272 70718 solver.cpp:285]     Train net output #0: loss = 0.00239822 (* 1 = 0.00239822 loss)
I0122 20:24:59.112293 70718 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 20:25:05.316318 70718 solver.cpp:266] Iteration 26300 (16.1191 iter/s, 6.20381s/100 iter), loss = 0.00913252
I0122 20:25:05.316347 70718 solver.cpp:285]     Train net output #0: loss = 0.00913244 (* 1 = 0.00913244 loss)
I0122 20:25:05.316352 70718 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 20:25:11.513371 70718 solver.cpp:266] Iteration 26400 (16.1374 iter/s, 6.19679s/100 iter), loss = 0.0137025
I0122 20:25:11.513401 70718 solver.cpp:285]     Train net output #0: loss = 0.0137025 (* 1 = 0.0137025 loss)
I0122 20:25:11.513407 70718 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 20:25:17.712505 70718 solver.cpp:266] Iteration 26500 (16.132 iter/s, 6.19887s/100 iter), loss = 0.0038352
I0122 20:25:17.712625 70718 solver.cpp:285]     Train net output #0: loss = 0.00383512 (* 1 = 0.00383512 loss)
I0122 20:25:17.712632 70718 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 20:25:23.903621 70718 solver.cpp:266] Iteration 26600 (16.1531 iter/s, 6.19076s/100 iter), loss = 0.0140946
I0122 20:25:23.903650 70718 solver.cpp:285]     Train net output #0: loss = 0.0140945 (* 1 = 0.0140945 loss)
I0122 20:25:23.903656 70718 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 20:25:30.113137 70718 solver.cpp:266] Iteration 26700 (16.105 iter/s, 6.20925s/100 iter), loss = 0.00752431
I0122 20:25:30.113164 70718 solver.cpp:285]     Train net output #0: loss = 0.00752422 (* 1 = 0.00752422 loss)
I0122 20:25:30.113170 70718 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 20:25:36.304330 70718 solver.cpp:266] Iteration 26800 (16.1527 iter/s, 6.19093s/100 iter), loss = 0.00832125
I0122 20:25:36.304359 70718 solver.cpp:285]     Train net output #0: loss = 0.00832117 (* 1 = 0.00832117 loss)
I0122 20:25:36.304364 70718 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 20:25:42.503196 70718 solver.cpp:266] Iteration 26900 (16.1327 iter/s, 6.1986s/100 iter), loss = 0.00949964
I0122 20:25:42.503224 70718 solver.cpp:285]     Train net output #0: loss = 0.00949956 (* 1 = 0.00949956 loss)
I0122 20:25:42.503231 70718 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 20:25:48.630139 70718 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 20:25:50.077003 70718 solver.cpp:517]     Test net output #0: accuracy = 0.898667
I0122 20:25:50.077028 70718 solver.cpp:517]     Test net output #1: loss = 0.361246 (* 1 = 0.361246 loss)
I0122 20:25:50.077033 70718 solver.cpp:517]     Test net output #2: top-1 = 0.898667
I0122 20:25:50.077035 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:25:50.138839 70718 solver.cpp:266] Iteration 27000 (13.097 iter/s, 7.63533s/100 iter), loss = 0.00374075
I0122 20:25:50.138860 70718 solver.cpp:285]     Train net output #0: loss = 0.00374067 (* 1 = 0.00374067 loss)
I0122 20:25:50.138867 70718 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 20:25:56.345070 70718 solver.cpp:266] Iteration 27100 (16.1135 iter/s, 6.20597s/100 iter), loss = 0.011796
I0122 20:25:56.345100 70718 solver.cpp:285]     Train net output #0: loss = 0.0117959 (* 1 = 0.0117959 loss)
I0122 20:25:56.345105 70718 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 20:26:02.542425 70718 solver.cpp:266] Iteration 27200 (16.1366 iter/s, 6.19709s/100 iter), loss = 0.00469637
I0122 20:26:02.542454 70718 solver.cpp:285]     Train net output #0: loss = 0.0046963 (* 1 = 0.0046963 loss)
I0122 20:26:02.542459 70718 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 20:26:08.721525 70718 solver.cpp:266] Iteration 27300 (16.1843 iter/s, 6.17884s/100 iter), loss = 0.00460201
I0122 20:26:08.721554 70718 solver.cpp:285]     Train net output #0: loss = 0.00460194 (* 1 = 0.00460194 loss)
I0122 20:26:08.721560 70718 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 20:26:14.917357 70718 solver.cpp:266] Iteration 27400 (16.1406 iter/s, 6.19557s/100 iter), loss = 0.00514257
I0122 20:26:14.917387 70718 solver.cpp:285]     Train net output #0: loss = 0.00514249 (* 1 = 0.00514249 loss)
I0122 20:26:14.917392 70718 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 20:26:21.120872 70718 solver.cpp:266] Iteration 27500 (16.1206 iter/s, 6.20325s/100 iter), loss = 0.00566148
I0122 20:26:21.120950 70718 solver.cpp:285]     Train net output #0: loss = 0.0056614 (* 1 = 0.0056614 loss)
I0122 20:26:21.120957 70718 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 20:26:27.316151 70718 solver.cpp:266] Iteration 27600 (16.1421 iter/s, 6.19497s/100 iter), loss = 0.00593666
I0122 20:26:27.316179 70718 solver.cpp:285]     Train net output #0: loss = 0.00593658 (* 1 = 0.00593658 loss)
I0122 20:26:27.316185 70718 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 20:26:33.530978 70718 solver.cpp:266] Iteration 27700 (16.0912 iter/s, 6.21456s/100 iter), loss = 0.00332879
I0122 20:26:33.531008 70718 solver.cpp:285]     Train net output #0: loss = 0.00332871 (* 1 = 0.00332871 loss)
I0122 20:26:33.531013 70718 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 20:26:39.732965 70718 solver.cpp:266] Iteration 27800 (16.1246 iter/s, 6.20172s/100 iter), loss = 0.0124262
I0122 20:26:39.732995 70718 solver.cpp:285]     Train net output #0: loss = 0.0124261 (* 1 = 0.0124261 loss)
I0122 20:26:39.733000 70718 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 20:26:45.924360 70718 solver.cpp:266] Iteration 27900 (16.1521 iter/s, 6.19113s/100 iter), loss = 0.00406756
I0122 20:26:45.924388 70718 solver.cpp:285]     Train net output #0: loss = 0.00406748 (* 1 = 0.00406748 loss)
I0122 20:26:45.924394 70718 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 20:26:52.078770 70718 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 20:26:53.533629 70718 solver.cpp:517]     Test net output #0: accuracy = 0.900889
I0122 20:26:53.533655 70718 solver.cpp:517]     Test net output #1: loss = 0.360952 (* 1 = 0.360952 loss)
I0122 20:26:53.533659 70718 solver.cpp:517]     Test net output #2: top-1 = 0.900889
I0122 20:26:53.533663 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 20:26:53.595118 70718 solver.cpp:266] Iteration 28000 (13.0371 iter/s, 7.67044s/100 iter), loss = 0.00584294
I0122 20:26:53.595139 70718 solver.cpp:285]     Train net output #0: loss = 0.00584286 (* 1 = 0.00584286 loss)
I0122 20:26:53.595144 70718 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 20:26:59.802543 70718 solver.cpp:266] Iteration 28100 (16.1104 iter/s, 6.20717s/100 iter), loss = 0.00397279
I0122 20:26:59.802572 70718 solver.cpp:285]     Train net output #0: loss = 0.00397272 (* 1 = 0.00397272 loss)
I0122 20:26:59.802578 70718 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 20:27:06.003203 70718 solver.cpp:266] Iteration 28200 (16.128 iter/s, 6.20039s/100 iter), loss = 0.00622059
I0122 20:27:06.003232 70718 solver.cpp:285]     Train net output #0: loss = 0.00622051 (* 1 = 0.00622051 loss)
I0122 20:27:06.003238 70718 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 20:27:12.196523 70718 solver.cpp:266] Iteration 28300 (16.1471 iter/s, 6.19305s/100 iter), loss = 0.00555125
I0122 20:27:12.196552 70718 solver.cpp:285]     Train net output #0: loss = 0.00555117 (* 1 = 0.00555117 loss)
I0122 20:27:12.196558 70718 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 20:27:18.402312 70718 solver.cpp:266] Iteration 28400 (16.1147 iter/s, 6.20552s/100 iter), loss = 0.00682436
I0122 20:27:18.402340 70718 solver.cpp:285]     Train net output #0: loss = 0.00682428 (* 1 = 0.00682428 loss)
I0122 20:27:18.402346 70718 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 20:27:24.619565 70718 solver.cpp:266] Iteration 28500 (16.085 iter/s, 6.21699s/100 iter), loss = 0.0035756
I0122 20:27:24.619647 70718 solver.cpp:285]     Train net output #0: loss = 0.00357552 (* 1 = 0.00357552 loss)
I0122 20:27:24.619653 70718 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 20:27:30.828804 70718 solver.cpp:266] Iteration 28600 (16.1059 iter/s, 6.20892s/100 iter), loss = 0.0232265
I0122 20:27:30.828845 70718 solver.cpp:285]     Train net output #0: loss = 0.0232264 (* 1 = 0.0232264 loss)
I0122 20:27:30.828851 70718 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 20:27:37.044334 70718 solver.cpp:266] Iteration 28700 (16.0895 iter/s, 6.21525s/100 iter), loss = 0.00687387
I0122 20:27:37.044375 70718 solver.cpp:285]     Train net output #0: loss = 0.00687379 (* 1 = 0.00687379 loss)
I0122 20:27:37.044384 70718 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 20:27:43.259141 70718 solver.cpp:266] Iteration 28800 (16.0913 iter/s, 6.21453s/100 iter), loss = 0.00812762
I0122 20:27:43.259169 70718 solver.cpp:285]     Train net output #0: loss = 0.00812754 (* 1 = 0.00812754 loss)
I0122 20:27:43.259174 70718 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 20:27:49.467222 70718 solver.cpp:266] Iteration 28900 (16.1087 iter/s, 6.20781s/100 iter), loss = 0.0142634
I0122 20:27:49.467264 70718 solver.cpp:285]     Train net output #0: loss = 0.0142634 (* 1 = 0.0142634 loss)
I0122 20:27:49.467272 70718 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 20:27:55.622332 70718 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 20:27:57.069805 70718 solver.cpp:517]     Test net output #0: accuracy = 0.901889
I0122 20:27:57.069829 70718 solver.cpp:517]     Test net output #1: loss = 0.363654 (* 1 = 0.363654 loss)
I0122 20:27:57.069833 70718 solver.cpp:517]     Test net output #2: top-1 = 0.901889
I0122 20:27:57.069836 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 20:27:57.131084 70718 solver.cpp:266] Iteration 29000 (13.0488 iter/s, 7.66353s/100 iter), loss = 0.00567331
I0122 20:27:57.131104 70718 solver.cpp:285]     Train net output #0: loss = 0.00567323 (* 1 = 0.00567323 loss)
I0122 20:27:57.131110 70718 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 20:28:03.326337 70718 solver.cpp:266] Iteration 29100 (16.1421 iter/s, 6.19499s/100 iter), loss = 0.0041811
I0122 20:28:03.326377 70718 solver.cpp:285]     Train net output #0: loss = 0.00418102 (* 1 = 0.00418102 loss)
I0122 20:28:03.326383 70718 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 20:28:09.530923 70718 solver.cpp:266] Iteration 29200 (16.1178 iter/s, 6.20431s/100 iter), loss = 0.00975759
I0122 20:28:09.530952 70718 solver.cpp:285]     Train net output #0: loss = 0.00975751 (* 1 = 0.00975751 loss)
I0122 20:28:09.530958 70718 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 20:28:15.732195 70718 solver.cpp:266] Iteration 29300 (16.1264 iter/s, 6.20101s/100 iter), loss = 0.0138762
I0122 20:28:15.732223 70718 solver.cpp:285]     Train net output #0: loss = 0.0138761 (* 1 = 0.0138761 loss)
I0122 20:28:15.732228 70718 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 20:28:21.936951 70718 solver.cpp:266] Iteration 29400 (16.1174 iter/s, 6.20449s/100 iter), loss = 0.00695865
I0122 20:28:21.936980 70718 solver.cpp:285]     Train net output #0: loss = 0.00695857 (* 1 = 0.00695857 loss)
I0122 20:28:21.936986 70718 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 20:28:28.147964 70718 solver.cpp:266] Iteration 29500 (16.1011 iter/s, 6.21075s/100 iter), loss = 0.00339745
I0122 20:28:28.148026 70718 solver.cpp:285]     Train net output #0: loss = 0.00339736 (* 1 = 0.00339736 loss)
I0122 20:28:28.148032 70718 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 20:28:34.357475 70718 solver.cpp:266] Iteration 29600 (16.1051 iter/s, 6.20921s/100 iter), loss = 0.00881534
I0122 20:28:34.357503 70718 solver.cpp:285]     Train net output #0: loss = 0.00881526 (* 1 = 0.00881526 loss)
I0122 20:28:34.357511 70718 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 20:28:40.564875 70718 solver.cpp:266] Iteration 29700 (16.1105 iter/s, 6.20714s/100 iter), loss = 0.00716699
I0122 20:28:40.564916 70718 solver.cpp:285]     Train net output #0: loss = 0.0071669 (* 1 = 0.0071669 loss)
I0122 20:28:40.564923 70718 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 20:28:46.767171 70718 solver.cpp:266] Iteration 29800 (16.1238 iter/s, 6.20202s/100 iter), loss = 0.00469171
I0122 20:28:46.767211 70718 solver.cpp:285]     Train net output #0: loss = 0.00469163 (* 1 = 0.00469163 loss)
I0122 20:28:46.767218 70718 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 20:28:52.972595 70718 solver.cpp:266] Iteration 29900 (16.1157 iter/s, 6.20515s/100 iter), loss = 0.00532881
I0122 20:28:52.972625 70718 solver.cpp:285]     Train net output #0: loss = 0.00532872 (* 1 = 0.00532872 loss)
I0122 20:28:52.972631 70718 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 20:28:59.108914 70718 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 20:29:00.567732 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899778
I0122 20:29:00.567755 70718 solver.cpp:517]     Test net output #1: loss = 0.365968 (* 1 = 0.365968 loss)
I0122 20:29:00.567759 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899778
I0122 20:29:00.567762 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 20:29:00.630275 70718 solver.cpp:266] Iteration 30000 (13.0593 iter/s, 7.65736s/100 iter), loss = 0.00552254
I0122 20:29:00.630295 70718 solver.cpp:285]     Train net output #0: loss = 0.00552246 (* 1 = 0.00552246 loss)
I0122 20:29:00.630302 70718 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 20:29:06.829299 70718 solver.cpp:266] Iteration 30100 (16.1322 iter/s, 6.19877s/100 iter), loss = 0.00611626
I0122 20:29:06.829329 70718 solver.cpp:285]     Train net output #0: loss = 0.00611618 (* 1 = 0.00611618 loss)
I0122 20:29:06.829334 70718 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 20:29:13.037106 70718 solver.cpp:266] Iteration 30200 (16.1094 iter/s, 6.20754s/100 iter), loss = 0.0123182
I0122 20:29:13.037134 70718 solver.cpp:285]     Train net output #0: loss = 0.0123181 (* 1 = 0.0123181 loss)
I0122 20:29:13.037140 70718 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 20:29:19.234654 70718 solver.cpp:266] Iteration 30300 (16.1361 iter/s, 6.19728s/100 iter), loss = 0.00561252
I0122 20:29:19.234695 70718 solver.cpp:285]     Train net output #0: loss = 0.00561244 (* 1 = 0.00561244 loss)
I0122 20:29:19.234702 70718 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 20:29:25.445528 70718 solver.cpp:266] Iteration 30400 (16.1015 iter/s, 6.21059s/100 iter), loss = 0.00333682
I0122 20:29:25.445555 70718 solver.cpp:285]     Train net output #0: loss = 0.00333674 (* 1 = 0.00333674 loss)
I0122 20:29:25.445561 70718 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 20:29:31.650308 70718 solver.cpp:266] Iteration 30500 (16.1173 iter/s, 6.20451s/100 iter), loss = 0.00641494
I0122 20:29:31.650384 70718 solver.cpp:285]     Train net output #0: loss = 0.00641485 (* 1 = 0.00641485 loss)
I0122 20:29:31.650393 70718 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 20:29:37.840692 70718 solver.cpp:266] Iteration 30600 (16.1549 iter/s, 6.19007s/100 iter), loss = 0.00667516
I0122 20:29:37.840719 70718 solver.cpp:285]     Train net output #0: loss = 0.00667507 (* 1 = 0.00667507 loss)
I0122 20:29:37.840725 70718 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 20:29:44.038494 70718 solver.cpp:266] Iteration 30700 (16.1354 iter/s, 6.19754s/100 iter), loss = 0.00302001
I0122 20:29:44.038524 70718 solver.cpp:285]     Train net output #0: loss = 0.00301992 (* 1 = 0.00301992 loss)
I0122 20:29:44.038530 70718 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 20:29:50.244926 70718 solver.cpp:266] Iteration 30800 (16.113 iter/s, 6.20616s/100 iter), loss = 0.00745495
I0122 20:29:50.244953 70718 solver.cpp:285]     Train net output #0: loss = 0.00745486 (* 1 = 0.00745486 loss)
I0122 20:29:50.244961 70718 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 20:29:56.443433 70718 solver.cpp:266] Iteration 30900 (16.1336 iter/s, 6.19824s/100 iter), loss = 0.00525521
I0122 20:29:56.443461 70718 solver.cpp:285]     Train net output #0: loss = 0.00525513 (* 1 = 0.00525513 loss)
I0122 20:29:56.443480 70718 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 20:30:02.579411 70718 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 20:30:04.030552 70718 solver.cpp:517]     Test net output #0: accuracy = 0.9
I0122 20:30:04.030575 70718 solver.cpp:517]     Test net output #1: loss = 0.370193 (* 1 = 0.370193 loss)
I0122 20:30:04.030580 70718 solver.cpp:517]     Test net output #2: top-1 = 0.9
I0122 20:30:04.030583 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996444
I0122 20:30:04.092964 70718 solver.cpp:266] Iteration 31000 (13.0732 iter/s, 7.64921s/100 iter), loss = 0.00794866
I0122 20:30:04.092985 70718 solver.cpp:285]     Train net output #0: loss = 0.00794857 (* 1 = 0.00794857 loss)
I0122 20:30:04.092993 70718 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 20:30:10.292094 70718 solver.cpp:266] Iteration 31100 (16.132 iter/s, 6.19887s/100 iter), loss = 0.0066325
I0122 20:30:10.292124 70718 solver.cpp:285]     Train net output #0: loss = 0.00663241 (* 1 = 0.00663241 loss)
I0122 20:30:10.292129 70718 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 20:30:16.485491 70718 solver.cpp:266] Iteration 31200 (16.1469 iter/s, 6.19313s/100 iter), loss = 0.00355822
I0122 20:30:16.485530 70718 solver.cpp:285]     Train net output #0: loss = 0.00355814 (* 1 = 0.00355814 loss)
I0122 20:30:16.485538 70718 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 20:30:22.691915 70718 solver.cpp:266] Iteration 31300 (16.1131 iter/s, 6.20615s/100 iter), loss = 0.00330803
I0122 20:30:22.691946 70718 solver.cpp:285]     Train net output #0: loss = 0.00330795 (* 1 = 0.00330795 loss)
I0122 20:30:22.691951 70718 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 20:30:28.902386 70718 solver.cpp:266] Iteration 31400 (16.1025 iter/s, 6.2102s/100 iter), loss = 0.00743019
I0122 20:30:28.902426 70718 solver.cpp:285]     Train net output #0: loss = 0.00743011 (* 1 = 0.00743011 loss)
I0122 20:30:28.902434 70718 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 20:30:35.109926 70718 solver.cpp:266] Iteration 31500 (16.1102 iter/s, 6.20726s/100 iter), loss = 0.00481854
I0122 20:30:35.109987 70718 solver.cpp:285]     Train net output #0: loss = 0.00481846 (* 1 = 0.00481846 loss)
I0122 20:30:35.109993 70718 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 20:30:41.317920 70718 solver.cpp:266] Iteration 31600 (16.109 iter/s, 6.2077s/100 iter), loss = 0.00606318
I0122 20:30:41.317948 70718 solver.cpp:285]     Train net output #0: loss = 0.0060631 (* 1 = 0.0060631 loss)
I0122 20:30:41.317955 70718 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 20:30:47.522336 70718 solver.cpp:266] Iteration 31700 (16.1182 iter/s, 6.20415s/100 iter), loss = 0.00496643
I0122 20:30:47.522366 70718 solver.cpp:285]     Train net output #0: loss = 0.00496635 (* 1 = 0.00496635 loss)
I0122 20:30:47.522387 70718 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 20:30:53.727798 70718 solver.cpp:266] Iteration 31800 (16.1155 iter/s, 6.2052s/100 iter), loss = 0.00943733
I0122 20:30:53.727826 70718 solver.cpp:285]     Train net output #0: loss = 0.00943725 (* 1 = 0.00943725 loss)
I0122 20:30:53.727833 70718 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 20:30:59.923460 70718 solver.cpp:266] Iteration 31900 (16.141 iter/s, 6.1954s/100 iter), loss = 0.00501113
I0122 20:30:59.923488 70718 solver.cpp:285]     Train net output #0: loss = 0.00501105 (* 1 = 0.00501105 loss)
I0122 20:30:59.923496 70718 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 20:31:06.059522 70718 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 20:31:07.511231 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899444
I0122 20:31:07.511255 70718 solver.cpp:517]     Test net output #1: loss = 0.372118 (* 1 = 0.372118 loss)
I0122 20:31:07.511260 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899444
I0122 20:31:07.511265 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 20:31:07.572461 70718 solver.cpp:266] Iteration 32000 (13.0741 iter/s, 7.64868s/100 iter), loss = 0.00361351
I0122 20:31:07.572482 70718 solver.cpp:285]     Train net output #0: loss = 0.00361343 (* 1 = 0.00361343 loss)
I0122 20:31:07.572489 70718 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 20:31:13.765342 70718 solver.cpp:266] Iteration 32100 (16.1482 iter/s, 6.19262s/100 iter), loss = 0.00753389
I0122 20:31:13.765369 70718 solver.cpp:285]     Train net output #0: loss = 0.0075338 (* 1 = 0.0075338 loss)
I0122 20:31:13.765375 70718 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 20:31:19.968930 70718 solver.cpp:266] Iteration 32200 (16.1204 iter/s, 6.20332s/100 iter), loss = 0.00415799
I0122 20:31:19.968957 70718 solver.cpp:285]     Train net output #0: loss = 0.00415791 (* 1 = 0.00415791 loss)
I0122 20:31:19.968963 70718 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 20:31:26.171748 70718 solver.cpp:266] Iteration 32300 (16.1224 iter/s, 6.20255s/100 iter), loss = 0.018667
I0122 20:31:26.171777 70718 solver.cpp:285]     Train net output #0: loss = 0.0186669 (* 1 = 0.0186669 loss)
I0122 20:31:26.171783 70718 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 20:31:32.377636 70718 solver.cpp:266] Iteration 32400 (16.1144 iter/s, 6.20562s/100 iter), loss = 0.00612738
I0122 20:31:32.377665 70718 solver.cpp:285]     Train net output #0: loss = 0.0061273 (* 1 = 0.0061273 loss)
I0122 20:31:32.377671 70718 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 20:31:38.588007 70718 solver.cpp:266] Iteration 32500 (16.1028 iter/s, 6.2101s/100 iter), loss = 0.00531083
I0122 20:31:38.588104 70718 solver.cpp:285]     Train net output #0: loss = 0.00531075 (* 1 = 0.00531075 loss)
I0122 20:31:38.588112 70718 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 20:31:44.793982 70718 solver.cpp:266] Iteration 32600 (16.1144 iter/s, 6.20564s/100 iter), loss = 0.0066058
I0122 20:31:44.794011 70718 solver.cpp:285]     Train net output #0: loss = 0.00660572 (* 1 = 0.00660572 loss)
I0122 20:31:44.794018 70718 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 20:31:50.993175 70718 solver.cpp:266] Iteration 32700 (16.1318 iter/s, 6.19893s/100 iter), loss = 0.00472253
I0122 20:31:50.993202 70718 solver.cpp:285]     Train net output #0: loss = 0.00472245 (* 1 = 0.00472245 loss)
I0122 20:31:50.993208 70718 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 20:31:57.176762 70718 solver.cpp:266] Iteration 32800 (16.1725 iter/s, 6.18332s/100 iter), loss = 0.00654015
I0122 20:31:57.176801 70718 solver.cpp:285]     Train net output #0: loss = 0.00654006 (* 1 = 0.00654006 loss)
I0122 20:31:57.176808 70718 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 20:32:03.382206 70718 solver.cpp:266] Iteration 32900 (16.1156 iter/s, 6.20517s/100 iter), loss = 0.00735087
I0122 20:32:03.382233 70718 solver.cpp:285]     Train net output #0: loss = 0.00735079 (* 1 = 0.00735079 loss)
I0122 20:32:03.382239 70718 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 20:32:09.546061 70718 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 20:32:10.994668 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 20:32:10.994694 70718 solver.cpp:517]     Test net output #1: loss = 0.372893 (* 1 = 0.372893 loss)
I0122 20:32:10.994699 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 20:32:10.994702 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 20:32:11.055877 70718 solver.cpp:266] Iteration 33000 (13.0321 iter/s, 7.67336s/100 iter), loss = 0.00590706
I0122 20:32:11.055908 70718 solver.cpp:285]     Train net output #0: loss = 0.00590698 (* 1 = 0.00590698 loss)
I0122 20:32:11.055917 70718 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 20:32:17.264212 70718 solver.cpp:266] Iteration 33100 (16.1081 iter/s, 6.20807s/100 iter), loss = 0.00435368
I0122 20:32:17.264252 70718 solver.cpp:285]     Train net output #0: loss = 0.0043536 (* 1 = 0.0043536 loss)
I0122 20:32:17.264259 70718 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 20:32:23.472419 70718 solver.cpp:266] Iteration 33200 (16.1084 iter/s, 6.20794s/100 iter), loss = 0.00287423
I0122 20:32:23.472460 70718 solver.cpp:285]     Train net output #0: loss = 0.00287415 (* 1 = 0.00287415 loss)
I0122 20:32:23.472466 70718 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 20:32:29.676168 70718 solver.cpp:266] Iteration 33300 (16.12 iter/s, 6.20347s/100 iter), loss = 0.00423889
I0122 20:32:29.676196 70718 solver.cpp:285]     Train net output #0: loss = 0.00423881 (* 1 = 0.00423881 loss)
I0122 20:32:29.676203 70718 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 20:32:35.874743 70718 solver.cpp:266] Iteration 33400 (16.1334 iter/s, 6.19831s/100 iter), loss = 0.00327488
I0122 20:32:35.874783 70718 solver.cpp:285]     Train net output #0: loss = 0.00327479 (* 1 = 0.00327479 loss)
I0122 20:32:35.874790 70718 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 20:32:42.091066 70718 solver.cpp:266] Iteration 33500 (16.0874 iter/s, 6.21605s/100 iter), loss = 0.00835461
I0122 20:32:42.091181 70718 solver.cpp:285]     Train net output #0: loss = 0.00835453 (* 1 = 0.00835453 loss)
I0122 20:32:42.091188 70718 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 20:32:48.284765 70718 solver.cpp:266] Iteration 33600 (16.1464 iter/s, 6.19335s/100 iter), loss = 0.00557956
I0122 20:32:48.284792 70718 solver.cpp:285]     Train net output #0: loss = 0.00557948 (* 1 = 0.00557948 loss)
I0122 20:32:48.284799 70718 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 20:32:54.498208 70718 solver.cpp:266] Iteration 33700 (16.0948 iter/s, 6.21318s/100 iter), loss = 0.00878324
I0122 20:32:54.498235 70718 solver.cpp:285]     Train net output #0: loss = 0.00878316 (* 1 = 0.00878316 loss)
I0122 20:32:54.498241 70718 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 20:33:00.685140 70718 solver.cpp:266] Iteration 33800 (16.1638 iter/s, 6.18667s/100 iter), loss = 0.00693649
I0122 20:33:00.685168 70718 solver.cpp:285]     Train net output #0: loss = 0.00693641 (* 1 = 0.00693641 loss)
I0122 20:33:00.685174 70718 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 20:33:06.893698 70718 solver.cpp:266] Iteration 33900 (16.1075 iter/s, 6.20829s/100 iter), loss = 0.00516509
I0122 20:33:06.893739 70718 solver.cpp:285]     Train net output #0: loss = 0.00516501 (* 1 = 0.00516501 loss)
I0122 20:33:06.893762 70718 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 20:33:13.041708 70718 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 20:33:14.494040 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 20:33:14.494065 70718 solver.cpp:517]     Test net output #1: loss = 0.373453 (* 1 = 0.373453 loss)
I0122 20:33:14.494068 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 20:33:14.494071 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:33:14.556102 70718 solver.cpp:266] Iteration 34000 (13.0513 iter/s, 7.66207s/100 iter), loss = 0.00311512
I0122 20:33:14.556133 70718 solver.cpp:285]     Train net output #0: loss = 0.00311504 (* 1 = 0.00311504 loss)
I0122 20:33:14.556140 70718 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 20:33:20.763397 70718 solver.cpp:266] Iteration 34100 (16.1108 iter/s, 6.20703s/100 iter), loss = 0.00635277
I0122 20:33:20.763425 70718 solver.cpp:285]     Train net output #0: loss = 0.00635269 (* 1 = 0.00635269 loss)
I0122 20:33:20.763432 70718 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 20:33:26.974340 70718 solver.cpp:266] Iteration 34200 (16.1013 iter/s, 6.21068s/100 iter), loss = 0.0076815
I0122 20:33:26.974380 70718 solver.cpp:285]     Train net output #0: loss = 0.00768141 (* 1 = 0.00768141 loss)
I0122 20:33:26.974385 70718 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 20:33:33.179988 70718 solver.cpp:266] Iteration 34300 (16.1151 iter/s, 6.20537s/100 iter), loss = 0.00447896
I0122 20:33:33.180016 70718 solver.cpp:285]     Train net output #0: loss = 0.00447888 (* 1 = 0.00447888 loss)
I0122 20:33:33.180022 70718 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 20:33:39.372658 70718 solver.cpp:266] Iteration 34400 (16.1488 iter/s, 6.1924s/100 iter), loss = 0.0172971
I0122 20:33:39.372685 70718 solver.cpp:285]     Train net output #0: loss = 0.017297 (* 1 = 0.017297 loss)
I0122 20:33:39.372691 70718 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 20:33:45.575791 70718 solver.cpp:266] Iteration 34500 (16.1216 iter/s, 6.20287s/100 iter), loss = 0.00612893
I0122 20:33:45.575913 70718 solver.cpp:285]     Train net output #0: loss = 0.00612884 (* 1 = 0.00612884 loss)
I0122 20:33:45.575922 70718 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 20:33:51.775367 70718 solver.cpp:266] Iteration 34600 (16.1311 iter/s, 6.19922s/100 iter), loss = 0.0105193
I0122 20:33:51.775394 70718 solver.cpp:285]     Train net output #0: loss = 0.0105192 (* 1 = 0.0105192 loss)
I0122 20:33:51.775400 70718 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 20:33:57.966023 70718 solver.cpp:266] Iteration 34700 (16.1541 iter/s, 6.19039s/100 iter), loss = 0.00370432
I0122 20:33:57.966063 70718 solver.cpp:285]     Train net output #0: loss = 0.00370424 (* 1 = 0.00370424 loss)
I0122 20:33:57.966069 70718 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 20:34:04.174996 70718 solver.cpp:266] Iteration 34800 (16.1064 iter/s, 6.2087s/100 iter), loss = 0.00295221
I0122 20:34:04.175024 70718 solver.cpp:285]     Train net output #0: loss = 0.00295212 (* 1 = 0.00295212 loss)
I0122 20:34:04.175029 70718 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 20:34:10.372938 70718 solver.cpp:266] Iteration 34900 (16.1351 iter/s, 6.19768s/100 iter), loss = 0.0156529
I0122 20:34:10.372967 70718 solver.cpp:285]     Train net output #0: loss = 0.0156528 (* 1 = 0.0156528 loss)
I0122 20:34:10.372973 70718 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 20:34:16.526171 70718 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 20:34:17.971680 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899
I0122 20:34:17.971705 70718 solver.cpp:517]     Test net output #1: loss = 0.373393 (* 1 = 0.373393 loss)
I0122 20:34:17.971710 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899
I0122 20:34:17.971714 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:34:18.033236 70718 solver.cpp:266] Iteration 35000 (13.0549 iter/s, 7.65998s/100 iter), loss = 0.00689614
I0122 20:34:18.033267 70718 solver.cpp:285]     Train net output #0: loss = 0.00689605 (* 1 = 0.00689605 loss)
I0122 20:34:18.033274 70718 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 20:34:24.237941 70718 solver.cpp:266] Iteration 35100 (16.1175 iter/s, 6.20444s/100 iter), loss = 0.00329959
I0122 20:34:24.237968 70718 solver.cpp:285]     Train net output #0: loss = 0.0032995 (* 1 = 0.0032995 loss)
I0122 20:34:24.237975 70718 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 20:34:30.448900 70718 solver.cpp:266] Iteration 35200 (16.1013 iter/s, 6.21069s/100 iter), loss = 0.00359551
I0122 20:34:30.448930 70718 solver.cpp:285]     Train net output #0: loss = 0.00359543 (* 1 = 0.00359543 loss)
I0122 20:34:30.448935 70718 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 20:34:36.649828 70718 solver.cpp:266] Iteration 35300 (16.1273 iter/s, 6.20066s/100 iter), loss = 0.00708786
I0122 20:34:36.649855 70718 solver.cpp:285]     Train net output #0: loss = 0.00708778 (* 1 = 0.00708778 loss)
I0122 20:34:36.649861 70718 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 20:34:42.836593 70718 solver.cpp:266] Iteration 35400 (16.1642 iter/s, 6.1865s/100 iter), loss = 0.00645593
I0122 20:34:42.836633 70718 solver.cpp:285]     Train net output #0: loss = 0.00645585 (* 1 = 0.00645585 loss)
I0122 20:34:42.836640 70718 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 20:34:49.043642 70718 solver.cpp:266] Iteration 35500 (16.1114 iter/s, 6.20677s/100 iter), loss = 0.00355811
I0122 20:34:49.043735 70718 solver.cpp:285]     Train net output #0: loss = 0.00355803 (* 1 = 0.00355803 loss)
I0122 20:34:49.043743 70718 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 20:34:55.234828 70718 solver.cpp:266] Iteration 35600 (16.1529 iter/s, 6.19086s/100 iter), loss = 0.00365341
I0122 20:34:55.234856 70718 solver.cpp:285]     Train net output #0: loss = 0.00365333 (* 1 = 0.00365333 loss)
I0122 20:34:55.234863 70718 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 20:35:01.434854 70718 solver.cpp:266] Iteration 35700 (16.1297 iter/s, 6.19976s/100 iter), loss = 0.00697216
I0122 20:35:01.434883 70718 solver.cpp:285]     Train net output #0: loss = 0.00697208 (* 1 = 0.00697208 loss)
I0122 20:35:01.434890 70718 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 20:35:07.637023 70718 solver.cpp:266] Iteration 35800 (16.1241 iter/s, 6.2019s/100 iter), loss = 0.0077624
I0122 20:35:07.637050 70718 solver.cpp:285]     Train net output #0: loss = 0.00776232 (* 1 = 0.00776232 loss)
I0122 20:35:07.637058 70718 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 20:35:13.827513 70718 solver.cpp:266] Iteration 35900 (16.1545 iter/s, 6.19023s/100 iter), loss = 0.0125554
I0122 20:35:13.827543 70718 solver.cpp:285]     Train net output #0: loss = 0.0125553 (* 1 = 0.0125553 loss)
I0122 20:35:13.827548 70718 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 20:35:19.979404 70718 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 20:35:21.426430 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 20:35:21.426455 70718 solver.cpp:517]     Test net output #1: loss = 0.37363 (* 1 = 0.37363 loss)
I0122 20:35:21.426460 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 20:35:21.426463 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 20:35:21.489015 70718 solver.cpp:266] Iteration 36000 (13.0528 iter/s, 7.66119s/100 iter), loss = 0.00802551
I0122 20:35:21.489037 70718 solver.cpp:285]     Train net output #0: loss = 0.00802543 (* 1 = 0.00802543 loss)
I0122 20:35:21.489043 70718 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 20:35:27.711336 70718 solver.cpp:266] Iteration 36100 (16.0718 iter/s, 6.22206s/100 iter), loss = 0.00395506
I0122 20:35:27.711364 70718 solver.cpp:285]     Train net output #0: loss = 0.00395498 (* 1 = 0.00395498 loss)
I0122 20:35:27.711369 70718 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 20:35:33.902087 70718 solver.cpp:266] Iteration 36200 (16.1538 iter/s, 6.19049s/100 iter), loss = 0.0034668
I0122 20:35:33.902117 70718 solver.cpp:285]     Train net output #0: loss = 0.00346672 (* 1 = 0.00346672 loss)
I0122 20:35:33.902122 70718 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 20:35:40.110222 70718 solver.cpp:266] Iteration 36300 (16.1086 iter/s, 6.20787s/100 iter), loss = 0.00740461
I0122 20:35:40.110250 70718 solver.cpp:285]     Train net output #0: loss = 0.00740452 (* 1 = 0.00740452 loss)
I0122 20:35:40.110256 70718 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 20:35:46.326431 70718 solver.cpp:266] Iteration 36400 (16.0877 iter/s, 6.21594s/100 iter), loss = 0.00399333
I0122 20:35:46.326458 70718 solver.cpp:285]     Train net output #0: loss = 0.00399325 (* 1 = 0.00399325 loss)
I0122 20:35:46.326463 70718 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 20:35:52.525502 70718 solver.cpp:266] Iteration 36500 (16.1321 iter/s, 6.19881s/100 iter), loss = 0.0047178
I0122 20:35:52.525562 70718 solver.cpp:285]     Train net output #0: loss = 0.00471772 (* 1 = 0.00471772 loss)
I0122 20:35:52.525568 70718 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 20:35:58.735944 70718 solver.cpp:266] Iteration 36600 (16.1027 iter/s, 6.21015s/100 iter), loss = 0.00435263
I0122 20:35:58.735982 70718 solver.cpp:285]     Train net output #0: loss = 0.00435254 (* 1 = 0.00435254 loss)
I0122 20:35:58.735990 70718 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 20:36:04.941591 70718 solver.cpp:266] Iteration 36700 (16.115 iter/s, 6.20538s/100 iter), loss = 0.00391698
I0122 20:36:04.941617 70718 solver.cpp:285]     Train net output #0: loss = 0.0039169 (* 1 = 0.0039169 loss)
I0122 20:36:04.941639 70718 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 20:36:11.143576 70718 solver.cpp:266] Iteration 36800 (16.1246 iter/s, 6.20172s/100 iter), loss = 0.00509807
I0122 20:36:11.143604 70718 solver.cpp:285]     Train net output #0: loss = 0.00509799 (* 1 = 0.00509799 loss)
I0122 20:36:11.143610 70718 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 20:36:17.350001 70718 solver.cpp:266] Iteration 36900 (16.113 iter/s, 6.20616s/100 iter), loss = 0.00422166
I0122 20:36:17.350029 70718 solver.cpp:285]     Train net output #0: loss = 0.00422158 (* 1 = 0.00422158 loss)
I0122 20:36:17.350035 70718 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 20:36:23.495049 70718 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 20:36:24.940136 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899444
I0122 20:36:24.940160 70718 solver.cpp:517]     Test net output #1: loss = 0.373825 (* 1 = 0.373825 loss)
I0122 20:36:24.940165 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899444
I0122 20:36:24.940168 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:36:25.001646 70718 solver.cpp:266] Iteration 37000 (13.0696 iter/s, 7.65133s/100 iter), loss = 0.00622223
I0122 20:36:25.001664 70718 solver.cpp:285]     Train net output #0: loss = 0.00622215 (* 1 = 0.00622215 loss)
I0122 20:36:25.001672 70718 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 20:36:31.179252 70718 solver.cpp:266] Iteration 37100 (16.1882 iter/s, 6.17735s/100 iter), loss = 0.0094263
I0122 20:36:31.179280 70718 solver.cpp:285]     Train net output #0: loss = 0.00942622 (* 1 = 0.00942622 loss)
I0122 20:36:31.179286 70718 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 20:36:37.392138 70718 solver.cpp:266] Iteration 37200 (16.0963 iter/s, 6.21262s/100 iter), loss = 0.00948734
I0122 20:36:37.392179 70718 solver.cpp:285]     Train net output #0: loss = 0.00948726 (* 1 = 0.00948726 loss)
I0122 20:36:37.392185 70718 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 20:36:43.596427 70718 solver.cpp:266] Iteration 37300 (16.1186 iter/s, 6.20401s/100 iter), loss = 0.00576864
I0122 20:36:43.596455 70718 solver.cpp:285]     Train net output #0: loss = 0.00576857 (* 1 = 0.00576857 loss)
I0122 20:36:43.596462 70718 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 20:36:49.798296 70718 solver.cpp:266] Iteration 37400 (16.1249 iter/s, 6.2016s/100 iter), loss = 0.0089949
I0122 20:36:49.798322 70718 solver.cpp:285]     Train net output #0: loss = 0.00899483 (* 1 = 0.00899483 loss)
I0122 20:36:49.798328 70718 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 20:36:56.003279 70718 solver.cpp:266] Iteration 37500 (16.1168 iter/s, 6.20472s/100 iter), loss = 0.00821695
I0122 20:36:56.003341 70718 solver.cpp:285]     Train net output #0: loss = 0.00821687 (* 1 = 0.00821687 loss)
I0122 20:36:56.003348 70718 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 20:37:02.207056 70718 solver.cpp:266] Iteration 37600 (16.12 iter/s, 6.20348s/100 iter), loss = 0.0053546
I0122 20:37:02.207083 70718 solver.cpp:285]     Train net output #0: loss = 0.00535452 (* 1 = 0.00535452 loss)
I0122 20:37:02.207090 70718 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 20:37:08.409735 70718 solver.cpp:266] Iteration 37700 (16.1228 iter/s, 6.20241s/100 iter), loss = 0.00529876
I0122 20:37:08.409765 70718 solver.cpp:285]     Train net output #0: loss = 0.00529868 (* 1 = 0.00529868 loss)
I0122 20:37:08.409771 70718 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 20:37:14.615902 70718 solver.cpp:266] Iteration 37800 (16.1137 iter/s, 6.2059s/100 iter), loss = 0.00997215
I0122 20:37:14.615929 70718 solver.cpp:285]     Train net output #0: loss = 0.00997207 (* 1 = 0.00997207 loss)
I0122 20:37:14.615936 70718 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 20:37:20.794764 70718 solver.cpp:266] Iteration 37900 (16.1849 iter/s, 6.1786s/100 iter), loss = 0.00348177
I0122 20:37:20.794791 70718 solver.cpp:285]     Train net output #0: loss = 0.0034817 (* 1 = 0.0034817 loss)
I0122 20:37:20.794797 70718 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 20:37:26.931969 70718 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 20:37:28.381232 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899111
I0122 20:37:28.381258 70718 solver.cpp:517]     Test net output #1: loss = 0.373755 (* 1 = 0.373755 loss)
I0122 20:37:28.381263 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899111
I0122 20:37:28.381266 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 20:37:28.442404 70718 solver.cpp:266] Iteration 38000 (13.0765 iter/s, 7.64732s/100 iter), loss = 0.00481743
I0122 20:37:28.442425 70718 solver.cpp:285]     Train net output #0: loss = 0.00481735 (* 1 = 0.00481735 loss)
I0122 20:37:28.442431 70718 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 20:37:34.637769 70718 solver.cpp:266] Iteration 38100 (16.1418 iter/s, 6.19511s/100 iter), loss = 0.00355702
I0122 20:37:34.637809 70718 solver.cpp:285]     Train net output #0: loss = 0.00355695 (* 1 = 0.00355695 loss)
I0122 20:37:34.637817 70718 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 20:37:40.854301 70718 solver.cpp:266] Iteration 38200 (16.0869 iter/s, 6.21626s/100 iter), loss = 0.00668491
I0122 20:37:40.854328 70718 solver.cpp:285]     Train net output #0: loss = 0.00668484 (* 1 = 0.00668484 loss)
I0122 20:37:40.854334 70718 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 20:37:47.058743 70718 solver.cpp:266] Iteration 38300 (16.1182 iter/s, 6.20418s/100 iter), loss = 0.00939392
I0122 20:37:47.058782 70718 solver.cpp:285]     Train net output #0: loss = 0.00939385 (* 1 = 0.00939385 loss)
I0122 20:37:47.058789 70718 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 20:37:53.256264 70718 solver.cpp:266] Iteration 38400 (16.1362 iter/s, 6.19725s/100 iter), loss = 0.00667439
I0122 20:37:53.256294 70718 solver.cpp:285]     Train net output #0: loss = 0.00667431 (* 1 = 0.00667431 loss)
I0122 20:37:53.256299 70718 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 20:37:59.456917 70718 solver.cpp:266] Iteration 38500 (16.128 iter/s, 6.20039s/100 iter), loss = 0.00437214
I0122 20:37:59.456980 70718 solver.cpp:285]     Train net output #0: loss = 0.00437207 (* 1 = 0.00437207 loss)
I0122 20:37:59.456997 70718 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 20:38:05.646288 70718 solver.cpp:266] Iteration 38600 (16.1575 iter/s, 6.18907s/100 iter), loss = 0.00452465
I0122 20:38:05.646328 70718 solver.cpp:285]     Train net output #0: loss = 0.00452458 (* 1 = 0.00452458 loss)
I0122 20:38:05.646335 70718 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 20:38:11.871708 70718 solver.cpp:266] Iteration 38700 (16.0639 iter/s, 6.22514s/100 iter), loss = 0.00521805
I0122 20:38:11.871737 70718 solver.cpp:285]     Train net output #0: loss = 0.00521798 (* 1 = 0.00521798 loss)
I0122 20:38:11.871743 70718 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 20:38:18.070106 70718 solver.cpp:266] Iteration 38800 (16.1339 iter/s, 6.19813s/100 iter), loss = 0.00629103
I0122 20:38:18.070144 70718 solver.cpp:285]     Train net output #0: loss = 0.00629096 (* 1 = 0.00629096 loss)
I0122 20:38:18.070152 70718 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 20:38:24.265154 70718 solver.cpp:266] Iteration 38900 (16.1426 iter/s, 6.19477s/100 iter), loss = 0.00887805
I0122 20:38:24.265184 70718 solver.cpp:285]     Train net output #0: loss = 0.00887798 (* 1 = 0.00887798 loss)
I0122 20:38:24.265206 70718 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 20:38:30.411933 70718 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 20:38:31.854773 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899444
I0122 20:38:31.854797 70718 solver.cpp:517]     Test net output #1: loss = 0.373764 (* 1 = 0.373764 loss)
I0122 20:38:31.854802 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899444
I0122 20:38:31.854806 70718 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 20:38:31.917341 70718 solver.cpp:266] Iteration 39000 (13.0687 iter/s, 7.65187s/100 iter), loss = 0.00509599
I0122 20:38:31.917361 70718 solver.cpp:285]     Train net output #0: loss = 0.00509591 (* 1 = 0.00509591 loss)
I0122 20:38:31.917366 70718 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 20:38:38.126869 70718 solver.cpp:266] Iteration 39100 (16.1049 iter/s, 6.20927s/100 iter), loss = 0.00530876
I0122 20:38:38.126907 70718 solver.cpp:285]     Train net output #0: loss = 0.00530869 (* 1 = 0.00530869 loss)
I0122 20:38:38.126914 70718 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 20:38:44.337792 70718 solver.cpp:266] Iteration 39200 (16.1014 iter/s, 6.21066s/100 iter), loss = 0.00299923
I0122 20:38:44.337832 70718 solver.cpp:285]     Train net output #0: loss = 0.00299915 (* 1 = 0.00299915 loss)
I0122 20:38:44.337839 70718 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 20:38:50.535099 70718 solver.cpp:266] Iteration 39300 (16.1368 iter/s, 6.19703s/100 iter), loss = 0.00696637
I0122 20:38:50.535128 70718 solver.cpp:285]     Train net output #0: loss = 0.00696629 (* 1 = 0.00696629 loss)
I0122 20:38:50.535135 70718 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 20:38:56.751660 70718 solver.cpp:266] Iteration 39400 (16.0868 iter/s, 6.2163s/100 iter), loss = 0.00465221
I0122 20:38:56.751688 70718 solver.cpp:285]     Train net output #0: loss = 0.00465213 (* 1 = 0.00465213 loss)
I0122 20:38:56.751710 70718 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 20:39:02.955868 70718 solver.cpp:266] Iteration 39500 (16.1188 iter/s, 6.20394s/100 iter), loss = 0.00470407
I0122 20:39:02.956013 70718 solver.cpp:285]     Train net output #0: loss = 0.00470399 (* 1 = 0.00470399 loss)
I0122 20:39:02.956020 70718 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 20:39:09.160516 70718 solver.cpp:266] Iteration 39600 (16.1179 iter/s, 6.20427s/100 iter), loss = 0.016735
I0122 20:39:09.160557 70718 solver.cpp:285]     Train net output #0: loss = 0.016735 (* 1 = 0.016735 loss)
I0122 20:39:09.160564 70718 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 20:39:15.353826 70718 solver.cpp:266] Iteration 39700 (16.1472 iter/s, 6.19303s/100 iter), loss = 0.00300382
I0122 20:39:15.353854 70718 solver.cpp:285]     Train net output #0: loss = 0.00300374 (* 1 = 0.00300374 loss)
I0122 20:39:15.353860 70718 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 20:39:21.539139 70718 solver.cpp:266] Iteration 39800 (16.168 iter/s, 6.18505s/100 iter), loss = 0.00606758
I0122 20:39:21.539178 70718 solver.cpp:285]     Train net output #0: loss = 0.0060675 (* 1 = 0.0060675 loss)
I0122 20:39:21.539186 70718 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 20:39:27.745748 70718 solver.cpp:266] Iteration 39900 (16.1125 iter/s, 6.20634s/100 iter), loss = 0.00274859
I0122 20:39:27.745776 70718 solver.cpp:285]     Train net output #0: loss = 0.00274851 (* 1 = 0.00274851 loss)
I0122 20:39:27.745782 70718 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 20:39:33.879789 70718 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_40000.caffemodel
I0122 20:39:33.924834 70718 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0.4/snapshots/_iter_40000.solverstate
I0122 20:39:33.954723 70718 solver.cpp:378] Iteration 40000, loss = 0.00169878
I0122 20:39:33.954744 70718 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 20:39:35.412382 70718 solver.cpp:517]     Test net output #0: accuracy = 0.899667
I0122 20:39:35.412406 70718 solver.cpp:517]     Test net output #1: loss = 0.374285 (* 1 = 0.374285 loss)
I0122 20:39:35.412411 70718 solver.cpp:517]     Test net output #2: top-1 = 0.899667
I0122 20:39:35.412415 70718 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 20:39:35.412420 70718 solver.cpp:386] Optimization Done (15.7937 iter/s).
I0122 20:39:35.412425 70718 caffe_interface.cpp:530] Optimization Done.
