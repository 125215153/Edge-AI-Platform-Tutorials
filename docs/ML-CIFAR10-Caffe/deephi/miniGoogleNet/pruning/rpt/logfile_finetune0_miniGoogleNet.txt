I0122 16:59:11.823297 64218 deephi_compress.cpp:236] cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt
I0122 16:59:12.024067 64218 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0122 16:59:12.024616 64218 gpu_memory.cpp:55] Total memory: 25620447232, Free: 22988455936, dev_info[0]: total=25620447232 free=22988455936
I0122 16:59:12.024627 64218 caffe_interface.cpp:493] Using GPUs 0
I0122 16:59:12.024897 64218 caffe_interface.cpp:498] GPU 0: Quadro P6000
I0122 16:59:12.778671 64218 solver.cpp:51] Initializing solver from parameters: 
test_iter: 180
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 20000
snapshot_prefix: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/"
solver_mode: GPU
device_id: 0
net: "cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt"
type: "SGD"
I0122 16:59:12.778793 64218 solver.cpp:99] Creating training net from net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt
I0122 16:59:12.779477 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0122 16:59:12.779520 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0122 16:59:12.779525 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0122 16:59:12.779527 64218 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top5
I0122 16:59:12.780129 64218 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
I0122 16:59:12.780447 64218 layer_factory.hpp:77] Creating layer data
I0122 16:59:12.780546 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.781373 64218 net.cpp:94] Creating Layer data
I0122 16:59:12.781383 64218 net.cpp:409] data -> data
I0122 16:59:12.781394 64218 net.cpp:409] data -> label
I0122 16:59:12.782855 64261 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/train_lmdb
I0122 16:59:12.782902 64261 data_reader.cpp:117] TRAIN: reading data using 1 channel(s)
I0122 16:59:12.783011 64218 data_layer.cpp:78] ReshapePrefetch 128, 3, 32, 32
I0122 16:59:12.783097 64218 data_layer.cpp:83] output data size: 128,3,32,32
I0122 16:59:12.799222 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.799271 64218 net.cpp:144] Setting up data
I0122 16:59:12.799279 64218 net.cpp:151] Top shape: 128 3 32 32 (393216)
I0122 16:59:12.799284 64218 net.cpp:151] Top shape: 128 (128)
I0122 16:59:12.799286 64218 net.cpp:159] Memory required for data: 1573376
I0122 16:59:12.799290 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 16:59:12.799304 64218 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 16:59:12.799307 64218 net.cpp:435] conv1/3x3_s1 <- data
I0122 16:59:12.799322 64218 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 16:59:12.801025 64218 net.cpp:144] Setting up conv1/3x3_s1
I0122 16:59:12.801044 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801048 64218 net.cpp:159] Memory required for data: 51905024
I0122 16:59:12.801064 64218 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 16:59:12.801074 64218 net.cpp:94] Creating Layer conv1/bn1
I0122 16:59:12.801079 64218 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 16:59:12.801085 64218 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.801731 64218 net.cpp:144] Setting up conv1/bn1
I0122 16:59:12.801739 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801743 64218 net.cpp:159] Memory required for data: 102236672
I0122 16:59:12.801754 64218 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 16:59:12.801761 64218 net.cpp:94] Creating Layer conv1/relu1
I0122 16:59:12.801764 64218 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 16:59:12.801769 64218 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.801780 64218 net.cpp:144] Setting up conv1/relu1
I0122 16:59:12.801796 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801800 64218 net.cpp:159] Memory required for data: 152568320
I0122 16:59:12.801802 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.801810 64218 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.801815 64218 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 16:59:12.801820 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.801827 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.801858 64218 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.801863 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801867 64218 net.cpp:151] Top shape: 128 96 32 32 (12582912)
I0122 16:59:12.801870 64218 net.cpp:159] Memory required for data: 253231616
I0122 16:59:12.801873 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 16:59:12.801882 64218 net.cpp:94] Creating Layer inception_2a/1x1
I0122 16:59:12.801887 64218 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.801892 64218 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 16:59:12.802145 64218 net.cpp:144] Setting up inception_2a/1x1
I0122 16:59:12.802152 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.802155 64218 net.cpp:159] Memory required for data: 270008832
I0122 16:59:12.802162 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 16:59:12.802170 64218 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 16:59:12.802173 64218 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 16:59:12.802179 64218 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.803603 64218 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 16:59:12.803611 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.803614 64218 net.cpp:159] Memory required for data: 286786048
I0122 16:59:12.803622 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 16:59:12.803627 64218 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 16:59:12.803632 64218 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 16:59:12.803637 64218 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.803642 64218 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 16:59:12.803647 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.803649 64218 net.cpp:159] Memory required for data: 303563264
I0122 16:59:12.803652 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 16:59:12.803661 64218 net.cpp:94] Creating Layer inception_2a/3x3
I0122 16:59:12.803665 64218 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.803670 64218 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 16:59:12.806650 64218 net.cpp:144] Setting up inception_2a/3x3
I0122 16:59:12.806664 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.806668 64218 net.cpp:159] Memory required for data: 320340480
I0122 16:59:12.806674 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 16:59:12.806695 64218 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 16:59:12.806701 64218 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 16:59:12.806716 64218 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.807451 64218 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 16:59:12.807459 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.807462 64218 net.cpp:159] Memory required for data: 337117696
I0122 16:59:12.807476 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 16:59:12.807482 64218 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 16:59:12.807485 64218 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 16:59:12.807492 64218 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.807512 64218 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 16:59:12.807516 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.807519 64218 net.cpp:159] Memory required for data: 353894912
I0122 16:59:12.807523 64218 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 16:59:12.807528 64218 net.cpp:94] Creating Layer inception_2a/output
I0122 16:59:12.807535 64218 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 16:59:12.807539 64218 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 16:59:12.807546 64218 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 16:59:12.807566 64218 net.cpp:144] Setting up inception_2a/output
I0122 16:59:12.807572 64218 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 16:59:12.807575 64218 net.cpp:159] Memory required for data: 387449344
I0122 16:59:12.807577 64218 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.807584 64218 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.807587 64218 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 16:59:12.807593 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.807601 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.807631 64218 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.807637 64218 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 16:59:12.807642 64218 net.cpp:151] Top shape: 128 64 32 32 (8388608)
I0122 16:59:12.807644 64218 net.cpp:159] Memory required for data: 454558208
I0122 16:59:12.807647 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 16:59:12.807657 64218 net.cpp:94] Creating Layer inception_3a/1x1
I0122 16:59:12.807658 64218 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.807665 64218 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 16:59:12.807904 64218 net.cpp:144] Setting up inception_3a/1x1
I0122 16:59:12.807911 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.807920 64218 net.cpp:159] Memory required for data: 471335424
I0122 16:59:12.807925 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 16:59:12.807934 64218 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 16:59:12.807936 64218 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 16:59:12.807943 64218 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.808595 64218 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 16:59:12.808603 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.808605 64218 net.cpp:159] Memory required for data: 488112640
I0122 16:59:12.808614 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 16:59:12.808620 64218 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 16:59:12.808622 64218 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 16:59:12.808630 64218 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.808636 64218 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 16:59:12.808642 64218 net.cpp:151] Top shape: 128 32 32 32 (4194304)
I0122 16:59:12.808645 64218 net.cpp:159] Memory required for data: 504889856
I0122 16:59:12.808650 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 16:59:12.808660 64218 net.cpp:94] Creating Layer inception_3a/3x3
I0122 16:59:12.808665 64218 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.808670 64218 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 16:59:12.809062 64218 net.cpp:144] Setting up inception_3a/3x3
I0122 16:59:12.809068 64218 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 16:59:12.809072 64218 net.cpp:159] Memory required for data: 530055680
I0122 16:59:12.809077 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 16:59:12.809093 64218 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 16:59:12.809098 64218 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 16:59:12.809103 64218 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.810029 64218 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 16:59:12.810039 64218 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 16:59:12.810041 64218 net.cpp:159] Memory required for data: 555221504
I0122 16:59:12.810055 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 16:59:12.810060 64218 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 16:59:12.810065 64218 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 16:59:12.810072 64218 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.810081 64218 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 16:59:12.810084 64218 net.cpp:151] Top shape: 128 48 32 32 (6291456)
I0122 16:59:12.810087 64218 net.cpp:159] Memory required for data: 580387328
I0122 16:59:12.810091 64218 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 16:59:12.810096 64218 net.cpp:94] Creating Layer inception_3a/output
I0122 16:59:12.810097 64218 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 16:59:12.810108 64218 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 16:59:12.810114 64218 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 16:59:12.810133 64218 net.cpp:144] Setting up inception_3a/output
I0122 16:59:12.810142 64218 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 16:59:12.810147 64218 net.cpp:159] Memory required for data: 622330368
I0122 16:59:12.810148 64218 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.810154 64218 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.810158 64218 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 16:59:12.810164 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.810171 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.810197 64218 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.810206 64218 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 16:59:12.810210 64218 net.cpp:151] Top shape: 128 80 32 32 (10485760)
I0122 16:59:12.810212 64218 net.cpp:159] Memory required for data: 706216448
I0122 16:59:12.810215 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 16:59:12.810225 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 16:59:12.810228 64218 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.810235 64218 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 16:59:12.810788 64218 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 16:59:12.810796 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.810799 64218 net.cpp:159] Memory required for data: 716702208
I0122 16:59:12.810804 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 16:59:12.810814 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 16:59:12.810817 64218 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 16:59:12.810824 64218 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.811467 64218 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 16:59:12.811475 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.811477 64218 net.cpp:159] Memory required for data: 727187968
I0122 16:59:12.811486 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 16:59:12.811491 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 16:59:12.811493 64218 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 16:59:12.811511 64218 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.811519 64218 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 16:59:12.811522 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.811525 64218 net.cpp:159] Memory required for data: 737673728
I0122 16:59:12.811528 64218 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 16:59:12.811535 64218 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 16:59:12.811538 64218 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.811545 64218 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 16:59:12.811585 64218 net.cpp:144] Setting up downsample_4/pool_s2
I0122 16:59:12.811591 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.811595 64218 net.cpp:159] Memory required for data: 748159488
I0122 16:59:12.811599 64218 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 16:59:12.811605 64218 net.cpp:94] Creating Layer downsample_4/output
I0122 16:59:12.811609 64218 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 16:59:12.811612 64218 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 16:59:12.811616 64218 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 16:59:12.811635 64218 net.cpp:144] Setting up downsample_4/output
I0122 16:59:12.811640 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.811643 64218 net.cpp:159] Memory required for data: 769131008
I0122 16:59:12.811645 64218 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.811650 64218 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.811655 64218 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 16:59:12.811659 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.811666 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.811722 64218 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.811729 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.811733 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.811735 64218 net.cpp:159] Memory required for data: 811074048
I0122 16:59:12.811738 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 16:59:12.811748 64218 net.cpp:94] Creating Layer inception_5a/1x1
I0122 16:59:12.811754 64218 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.811759 64218 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 16:59:12.812187 64218 net.cpp:144] Setting up inception_5a/1x1
I0122 16:59:12.812196 64218 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 16:59:12.812198 64218 net.cpp:159] Memory required for data: 825754112
I0122 16:59:12.812203 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 16:59:12.812211 64218 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 16:59:12.812216 64218 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 16:59:12.812222 64218 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.812902 64218 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 16:59:12.812909 64218 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 16:59:12.812913 64218 net.cpp:159] Memory required for data: 840434176
I0122 16:59:12.812921 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 16:59:12.812927 64218 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 16:59:12.812929 64218 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 16:59:12.812934 64218 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.812940 64218 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 16:59:12.812944 64218 net.cpp:151] Top shape: 128 112 16 16 (3670016)
I0122 16:59:12.812955 64218 net.cpp:159] Memory required for data: 855114240
I0122 16:59:12.812959 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 16:59:12.812970 64218 net.cpp:94] Creating Layer inception_5a/3x3
I0122 16:59:12.812975 64218 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.812981 64218 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 16:59:12.813623 64218 net.cpp:144] Setting up inception_5a/3x3
I0122 16:59:12.813632 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.813634 64218 net.cpp:159] Memory required for data: 861405696
I0122 16:59:12.813639 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 16:59:12.813647 64218 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 16:59:12.813650 64218 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 16:59:12.813657 64218 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.814419 64218 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 16:59:12.814426 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.814436 64218 net.cpp:159] Memory required for data: 867697152
I0122 16:59:12.814445 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 16:59:12.814455 64218 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 16:59:12.814461 64218 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 16:59:12.814466 64218 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.814472 64218 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 16:59:12.814476 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.814479 64218 net.cpp:159] Memory required for data: 873988608
I0122 16:59:12.814482 64218 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 16:59:12.814486 64218 net.cpp:94] Creating Layer inception_5a/output
I0122 16:59:12.814489 64218 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 16:59:12.814493 64218 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 16:59:12.814498 64218 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 16:59:12.814620 64218 net.cpp:144] Setting up inception_5a/output
I0122 16:59:12.814626 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.814630 64218 net.cpp:159] Memory required for data: 894960128
I0122 16:59:12.814631 64218 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.814638 64218 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.814641 64218 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 16:59:12.814652 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.814658 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.814695 64218 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.814702 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.814707 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.814709 64218 net.cpp:159] Memory required for data: 936903168
I0122 16:59:12.814713 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 16:59:12.814723 64218 net.cpp:94] Creating Layer inception_6a/1x1
I0122 16:59:12.814734 64218 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.814740 64218 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 16:59:12.815892 64218 net.cpp:144] Setting up inception_6a/1x1
I0122 16:59:12.815904 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.815907 64218 net.cpp:159] Memory required for data: 949486080
I0122 16:59:12.815913 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 16:59:12.815922 64218 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 16:59:12.815937 64218 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 16:59:12.815946 64218 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.816663 64218 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 16:59:12.816670 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.816673 64218 net.cpp:159] Memory required for data: 962068992
I0122 16:59:12.816681 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 16:59:12.816686 64218 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 16:59:12.816689 64218 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 16:59:12.816695 64218 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.816704 64218 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 16:59:12.816709 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.816711 64218 net.cpp:159] Memory required for data: 974651904
I0122 16:59:12.816715 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 16:59:12.816725 64218 net.cpp:94] Creating Layer inception_6a/3x3
I0122 16:59:12.816730 64218 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.816736 64218 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 16:59:12.817507 64218 net.cpp:144] Setting up inception_6a/3x3
I0122 16:59:12.817517 64218 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:59:12.817520 64218 net.cpp:159] Memory required for data: 983040512
I0122 16:59:12.817533 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 16:59:12.817543 64218 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 16:59:12.817549 64218 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 16:59:12.817556 64218 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.818243 64218 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 16:59:12.818250 64218 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:59:12.818254 64218 net.cpp:159] Memory required for data: 991429120
I0122 16:59:12.818262 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 16:59:12.818267 64218 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 16:59:12.818270 64218 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 16:59:12.818276 64218 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.818282 64218 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 16:59:12.818285 64218 net.cpp:151] Top shape: 128 64 16 16 (2097152)
I0122 16:59:12.818289 64218 net.cpp:159] Memory required for data: 999817728
I0122 16:59:12.818292 64218 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 16:59:12.818297 64218 net.cpp:94] Creating Layer inception_6a/output
I0122 16:59:12.818301 64218 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 16:59:12.818305 64218 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 16:59:12.818310 64218 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 16:59:12.818329 64218 net.cpp:144] Setting up inception_6a/output
I0122 16:59:12.818336 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.818339 64218 net.cpp:159] Memory required for data: 1020789248
I0122 16:59:12.818342 64218 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.818349 64218 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.818354 64218 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 16:59:12.818361 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.818367 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.818394 64218 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.818401 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.818418 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.818420 64218 net.cpp:159] Memory required for data: 1062732288
I0122 16:59:12.818423 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 16:59:12.818433 64218 net.cpp:94] Creating Layer inception_7a/1x1
I0122 16:59:12.818439 64218 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.818445 64218 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 16:59:12.818769 64218 net.cpp:144] Setting up inception_7a/1x1
I0122 16:59:12.818775 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.818778 64218 net.cpp:159] Memory required for data: 1073218048
I0122 16:59:12.818784 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 16:59:12.818791 64218 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 16:59:12.818794 64218 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 16:59:12.818800 64218 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.819571 64218 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 16:59:12.819577 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.819581 64218 net.cpp:159] Memory required for data: 1083703808
I0122 16:59:12.819587 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 16:59:12.819595 64218 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 16:59:12.819598 64218 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 16:59:12.819603 64218 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.819614 64218 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 16:59:12.819620 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.819622 64218 net.cpp:159] Memory required for data: 1094189568
I0122 16:59:12.819627 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 16:59:12.819636 64218 net.cpp:94] Creating Layer inception_7a/3x3
I0122 16:59:12.819641 64218 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.819648 64218 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 16:59:12.820673 64218 net.cpp:144] Setting up inception_7a/3x3
I0122 16:59:12.820683 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.820686 64218 net.cpp:159] Memory required for data: 1104675328
I0122 16:59:12.820693 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 16:59:12.820701 64218 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 16:59:12.820704 64218 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 16:59:12.820713 64218 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.821383 64218 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 16:59:12.821390 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.821394 64218 net.cpp:159] Memory required for data: 1115161088
I0122 16:59:12.821403 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 16:59:12.821408 64218 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 16:59:12.821410 64218 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 16:59:12.821416 64218 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.821424 64218 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 16:59:12.821430 64218 net.cpp:151] Top shape: 128 80 16 16 (2621440)
I0122 16:59:12.821434 64218 net.cpp:159] Memory required for data: 1125646848
I0122 16:59:12.821435 64218 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 16:59:12.821441 64218 net.cpp:94] Creating Layer inception_7a/output
I0122 16:59:12.821444 64218 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 16:59:12.821447 64218 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 16:59:12.821454 64218 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 16:59:12.821475 64218 net.cpp:144] Setting up inception_7a/output
I0122 16:59:12.821482 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.821494 64218 net.cpp:159] Memory required for data: 1146618368
I0122 16:59:12.821496 64218 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.821503 64218 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.821506 64218 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 16:59:12.821512 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.821518 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.821555 64218 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.821560 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.821563 64218 net.cpp:151] Top shape: 128 160 16 16 (5242880)
I0122 16:59:12.821566 64218 net.cpp:159] Memory required for data: 1188561408
I0122 16:59:12.821569 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 16:59:12.821578 64218 net.cpp:94] Creating Layer inception_8a/1x1
I0122 16:59:12.821581 64218 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.821588 64218 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 16:59:12.822021 64218 net.cpp:144] Setting up inception_8a/1x1
I0122 16:59:12.822027 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.822031 64218 net.cpp:159] Memory required for data: 1194852864
I0122 16:59:12.822036 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 16:59:12.822043 64218 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 16:59:12.822048 64218 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 16:59:12.822054 64218 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.822726 64218 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 16:59:12.822733 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.822736 64218 net.cpp:159] Memory required for data: 1201144320
I0122 16:59:12.822743 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 16:59:12.822748 64218 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 16:59:12.822751 64218 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 16:59:12.822757 64218 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.822765 64218 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 16:59:12.822768 64218 net.cpp:151] Top shape: 128 48 16 16 (1572864)
I0122 16:59:12.822772 64218 net.cpp:159] Memory required for data: 1207435776
I0122 16:59:12.822774 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 16:59:12.822782 64218 net.cpp:94] Creating Layer inception_8a/3x3
I0122 16:59:12.822788 64218 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.822794 64218 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 16:59:12.824553 64218 net.cpp:144] Setting up inception_8a/3x3
I0122 16:59:12.824566 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.824569 64218 net.cpp:159] Memory required for data: 1220018688
I0122 16:59:12.824586 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 16:59:12.824599 64218 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 16:59:12.824604 64218 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 16:59:12.824609 64218 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.825291 64218 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 16:59:12.825297 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.825300 64218 net.cpp:159] Memory required for data: 1232601600
I0122 16:59:12.825309 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 16:59:12.825315 64218 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 16:59:12.825320 64218 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 16:59:12.825340 64218 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.825346 64218 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 16:59:12.825350 64218 net.cpp:151] Top shape: 128 96 16 16 (3145728)
I0122 16:59:12.825353 64218 net.cpp:159] Memory required for data: 1245184512
I0122 16:59:12.825356 64218 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 16:59:12.825362 64218 net.cpp:94] Creating Layer inception_8a/output
I0122 16:59:12.825368 64218 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 16:59:12.825371 64218 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 16:59:12.825376 64218 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 16:59:12.825397 64218 net.cpp:144] Setting up inception_8a/output
I0122 16:59:12.825402 64218 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 16:59:12.825405 64218 net.cpp:159] Memory required for data: 1264058880
I0122 16:59:12.825407 64218 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.825413 64218 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.825418 64218 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 16:59:12.825423 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.825429 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.825459 64218 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.825465 64218 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 16:59:12.825469 64218 net.cpp:151] Top shape: 128 144 16 16 (4718592)
I0122 16:59:12.825471 64218 net.cpp:159] Memory required for data: 1301807616
I0122 16:59:12.825475 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 16:59:12.825485 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 16:59:12.825490 64218 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.825496 64218 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 16:59:12.826444 64218 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 16:59:12.826455 64218 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 16:59:12.826457 64218 net.cpp:159] Memory required for data: 1304953344
I0122 16:59:12.826463 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 16:59:12.826470 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 16:59:12.826476 64218 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 16:59:12.826484 64218 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.827173 64218 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 16:59:12.827180 64218 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 16:59:12.827183 64218 net.cpp:159] Memory required for data: 1308099072
I0122 16:59:12.827191 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 16:59:12.827198 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 16:59:12.827200 64218 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 16:59:12.827209 64218 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.827215 64218 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 16:59:12.827221 64218 net.cpp:151] Top shape: 128 96 8 8 (786432)
I0122 16:59:12.827224 64218 net.cpp:159] Memory required for data: 1311244800
I0122 16:59:12.827226 64218 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 16:59:12.827234 64218 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 16:59:12.827239 64218 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.827244 64218 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 16:59:12.827275 64218 net.cpp:144] Setting up downsample_9/pool_s2
I0122 16:59:12.827291 64218 net.cpp:151] Top shape: 128 144 8 8 (1179648)
I0122 16:59:12.827293 64218 net.cpp:159] Memory required for data: 1315963392
I0122 16:59:12.827296 64218 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 16:59:12.827301 64218 net.cpp:94] Creating Layer downsample_9/output
I0122 16:59:12.827304 64218 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 16:59:12.827307 64218 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 16:59:12.827314 64218 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 16:59:12.827333 64218 net.cpp:144] Setting up downsample_9/output
I0122 16:59:12.827338 64218 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 16:59:12.827342 64218 net.cpp:159] Memory required for data: 1323827712
I0122 16:59:12.827343 64218 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.827353 64218 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.827358 64218 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 16:59:12.827363 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.827368 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.827397 64218 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.827402 64218 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 16:59:12.827406 64218 net.cpp:151] Top shape: 128 240 8 8 (1966080)
I0122 16:59:12.827409 64218 net.cpp:159] Memory required for data: 1339556352
I0122 16:59:12.827412 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 16:59:12.827421 64218 net.cpp:94] Creating Layer inception_10a/1x1
I0122 16:59:12.827425 64218 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.827432 64218 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 16:59:12.827898 64218 net.cpp:144] Setting up inception_10a/1x1
I0122 16:59:12.827904 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.827908 64218 net.cpp:159] Memory required for data: 1345323520
I0122 16:59:12.827913 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 16:59:12.827920 64218 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 16:59:12.827925 64218 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 16:59:12.827931 64218 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.828604 64218 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 16:59:12.828611 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.828614 64218 net.cpp:159] Memory required for data: 1351090688
I0122 16:59:12.828622 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 16:59:12.828641 64218 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 16:59:12.828647 64218 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 16:59:12.828652 64218 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.828658 64218 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 16:59:12.828662 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.828665 64218 net.cpp:159] Memory required for data: 1356857856
I0122 16:59:12.828667 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 16:59:12.828678 64218 net.cpp:94] Creating Layer inception_10a/3x3
I0122 16:59:12.828683 64218 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.828689 64218 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 16:59:12.831926 64218 net.cpp:144] Setting up inception_10a/3x3
I0122 16:59:12.831938 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.831941 64218 net.cpp:159] Memory required for data: 1362100736
I0122 16:59:12.831948 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 16:59:12.831982 64218 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 16:59:12.831987 64218 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 16:59:12.831995 64218 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.832643 64218 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 16:59:12.832650 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.832653 64218 net.cpp:159] Memory required for data: 1367343616
I0122 16:59:12.832660 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 16:59:12.832669 64218 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 16:59:12.832671 64218 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 16:59:12.832675 64218 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.832684 64218 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 16:59:12.832691 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.832693 64218 net.cpp:159] Memory required for data: 1372586496
I0122 16:59:12.832696 64218 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 16:59:12.832700 64218 net.cpp:94] Creating Layer inception_10a/output
I0122 16:59:12.832705 64218 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 16:59:12.832708 64218 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 16:59:12.832715 64218 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 16:59:12.832734 64218 net.cpp:144] Setting up inception_10a/output
I0122 16:59:12.832741 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.832743 64218 net.cpp:159] Memory required for data: 1383596544
I0122 16:59:12.832746 64218 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.832751 64218 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.832756 64218 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 16:59:12.832762 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.832768 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.832796 64218 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.832803 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.832806 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.832809 64218 net.cpp:159] Memory required for data: 1405616640
I0122 16:59:12.832811 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 16:59:12.832820 64218 net.cpp:94] Creating Layer inception_11a/1x1
I0122 16:59:12.832824 64218 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.832830 64218 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 16:59:12.833395 64218 net.cpp:144] Setting up inception_11a/1x1
I0122 16:59:12.833403 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.833406 64218 net.cpp:159] Memory required for data: 1411383808
I0122 16:59:12.833411 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 16:59:12.833418 64218 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 16:59:12.833425 64218 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 16:59:12.833431 64218 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.834120 64218 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 16:59:12.834128 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.834132 64218 net.cpp:159] Memory required for data: 1417150976
I0122 16:59:12.834139 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 16:59:12.834146 64218 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 16:59:12.834149 64218 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 16:59:12.834154 64218 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.834172 64218 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 16:59:12.834177 64218 net.cpp:151] Top shape: 128 176 8 8 (1441792)
I0122 16:59:12.834179 64218 net.cpp:159] Memory required for data: 1422918144
I0122 16:59:12.834183 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 16:59:12.834193 64218 net.cpp:94] Creating Layer inception_11a/3x3
I0122 16:59:12.834197 64218 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.834203 64218 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 16:59:12.837958 64218 net.cpp:144] Setting up inception_11a/3x3
I0122 16:59:12.837970 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.837973 64218 net.cpp:159] Memory required for data: 1428161024
I0122 16:59:12.837978 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 16:59:12.837988 64218 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 16:59:12.837991 64218 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 16:59:12.837997 64218 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.838650 64218 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 16:59:12.838659 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.838661 64218 net.cpp:159] Memory required for data: 1433403904
I0122 16:59:12.838680 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 16:59:12.838686 64218 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 16:59:12.838690 64218 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 16:59:12.838696 64218 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.838702 64218 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 16:59:12.838708 64218 net.cpp:151] Top shape: 128 160 8 8 (1310720)
I0122 16:59:12.838711 64218 net.cpp:159] Memory required for data: 1438646784
I0122 16:59:12.838714 64218 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 16:59:12.838718 64218 net.cpp:94] Creating Layer inception_11a/output
I0122 16:59:12.838721 64218 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 16:59:12.838726 64218 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 16:59:12.838730 64218 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 16:59:12.838747 64218 net.cpp:144] Setting up inception_11a/output
I0122 16:59:12.838753 64218 net.cpp:151] Top shape: 128 336 8 8 (2752512)
I0122 16:59:12.838757 64218 net.cpp:159] Memory required for data: 1449656832
I0122 16:59:12.838759 64218 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 16:59:12.838764 64218 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 16:59:12.838768 64218 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 16:59:12.838773 64218 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 16:59:12.838798 64218 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 16:59:12.838804 64218 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 16:59:12.838806 64218 net.cpp:159] Memory required for data: 1449828864
I0122 16:59:12.838809 64218 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 16:59:12.838814 64218 net.cpp:94] Creating Layer drop_8x8_s1
I0122 16:59:12.838816 64218 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 16:59:12.838821 64218 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 16:59:12.838840 64218 net.cpp:144] Setting up drop_8x8_s1
I0122 16:59:12.838845 64218 net.cpp:151] Top shape: 128 336 1 1 (43008)
I0122 16:59:12.838846 64218 net.cpp:159] Memory required for data: 1450000896
I0122 16:59:12.838848 64218 layer_factory.hpp:77] Creating layer loss/classifier
I0122 16:59:12.838856 64218 net.cpp:94] Creating Layer loss/classifier
I0122 16:59:12.838860 64218 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 16:59:12.838865 64218 net.cpp:409] loss/classifier -> loss/classifier
I0122 16:59:12.839001 64218 net.cpp:144] Setting up loss/classifier
I0122 16:59:12.839016 64218 net.cpp:151] Top shape: 128 10 (1280)
I0122 16:59:12.839020 64218 net.cpp:159] Memory required for data: 1450006016
I0122 16:59:12.839025 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.839030 64218 net.cpp:94] Creating Layer loss
I0122 16:59:12.839032 64218 net.cpp:435] loss <- loss/classifier
I0122 16:59:12.839036 64218 net.cpp:435] loss <- label
I0122 16:59:12.839040 64218 net.cpp:409] loss -> loss
I0122 16:59:12.839049 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.839125 64218 net.cpp:144] Setting up loss
I0122 16:59:12.839130 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.839133 64218 net.cpp:154]     with loss weight 1
I0122 16:59:12.839143 64218 net.cpp:159] Memory required for data: 1450006020
I0122 16:59:12.839145 64218 net.cpp:220] loss needs backward computation.
I0122 16:59:12.839154 64218 net.cpp:220] loss/classifier needs backward computation.
I0122 16:59:12.839157 64218 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 16:59:12.839159 64218 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 16:59:12.839164 64218 net.cpp:220] inception_11a/output needs backward computation.
I0122 16:59:12.839167 64218 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 16:59:12.839169 64218 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 16:59:12.839172 64218 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 16:59:12.839175 64218 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 16:59:12.839179 64218 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 16:59:12.839181 64218 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 16:59:12.839184 64218 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 16:59:12.839190 64218 net.cpp:220] inception_10a/output needs backward computation.
I0122 16:59:12.839192 64218 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 16:59:12.839195 64218 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 16:59:12.839197 64218 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 16:59:12.839201 64218 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 16:59:12.839203 64218 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 16:59:12.839206 64218 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 16:59:12.839210 64218 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 16:59:12.839213 64218 net.cpp:220] downsample_9/output needs backward computation.
I0122 16:59:12.839216 64218 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 16:59:12.839220 64218 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.839222 64218 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.839226 64218 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 16:59:12.839229 64218 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 16:59:12.839232 64218 net.cpp:220] inception_8a/output needs backward computation.
I0122 16:59:12.839236 64218 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 16:59:12.839239 64218 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 16:59:12.839242 64218 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 16:59:12.839246 64218 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 16:59:12.839248 64218 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 16:59:12.839251 64218 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 16:59:12.839256 64218 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 16:59:12.839259 64218 net.cpp:220] inception_7a/output needs backward computation.
I0122 16:59:12.839262 64218 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 16:59:12.839272 64218 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 16:59:12.839274 64218 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 16:59:12.839277 64218 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 16:59:12.839280 64218 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 16:59:12.839284 64218 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 16:59:12.839287 64218 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 16:59:12.839291 64218 net.cpp:220] inception_6a/output needs backward computation.
I0122 16:59:12.839294 64218 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 16:59:12.839298 64218 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 16:59:12.839301 64218 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 16:59:12.839304 64218 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 16:59:12.839306 64218 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 16:59:12.839310 64218 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 16:59:12.839313 64218 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 16:59:12.839316 64218 net.cpp:220] inception_5a/output needs backward computation.
I0122 16:59:12.839319 64218 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 16:59:12.839323 64218 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 16:59:12.839326 64218 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 16:59:12.839329 64218 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 16:59:12.839332 64218 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 16:59:12.839335 64218 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 16:59:12.839339 64218 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 16:59:12.839342 64218 net.cpp:220] downsample_4/output needs backward computation.
I0122 16:59:12.839346 64218 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 16:59:12.839351 64218 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.839354 64218 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.839357 64218 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 16:59:12.839360 64218 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 16:59:12.839365 64218 net.cpp:220] inception_3a/output needs backward computation.
I0122 16:59:12.839368 64218 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 16:59:12.839371 64218 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 16:59:12.839375 64218 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 16:59:12.839378 64218 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 16:59:12.839381 64218 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 16:59:12.839383 64218 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 16:59:12.839386 64218 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 16:59:12.839390 64218 net.cpp:220] inception_2a/output needs backward computation.
I0122 16:59:12.839395 64218 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 16:59:12.839396 64218 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 16:59:12.839399 64218 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 16:59:12.839403 64218 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 16:59:12.839406 64218 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 16:59:12.839408 64218 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 16:59:12.839411 64218 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 16:59:12.839421 64218 net.cpp:220] conv1/relu1 needs backward computation.
I0122 16:59:12.839423 64218 net.cpp:220] conv1/bn1 needs backward computation.
I0122 16:59:12.839426 64218 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 16:59:12.839429 64218 net.cpp:222] data does not need backward computation.
I0122 16:59:12.839433 64218 net.cpp:264] This network produces output loss
I0122 16:59:12.839498 64218 net.cpp:284] Network initialization done.
I0122 16:59:12.840369 64218 solver.cpp:189] Creating test net (#0) specified by net file: cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/net_finetune.prototxt
I0122 16:59:12.840448 64218 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0122 16:59:12.841073 64218 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "cifar10/input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1/3x3_s1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn1"
  type: "BatchNorm"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/relu1"
  type: "ReLU"
  bottom: "conv1/3x3_s1"
  top: "conv1/3x3_s1"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "conv1/3x3_s1"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1"
  bottom: "inception_2a/3x3"
  top: "inception_2a/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1"
  bottom: "inception_3a/3x3"
  top: "inception_3a/output"
}
layer {
  name: "downsample_4/3x3_s2"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_4/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_4/3x3_s2"
  top: "downsample_4/3x3_s2"
}
layer {
  name: "downsample_4/pool_s2"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "downsample_4/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_4/output"
  type: "Concat"
  bottom: "downsample_4/3x3_s2"
  bottom: "downsample_4/pool_s2"
  top: "downsample_4/output"
}
layer {
  name: "inception_5a/1x1"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_5a/1x1"
  top: "inception_5a/1x1"
}
layer {
  name: "inception_5a/3x3"
  type: "Convolution"
  bottom: "downsample_4/output"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_5a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_5a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_5a/3x3"
  top: "inception_5a/3x3"
}
layer {
  name: "inception_5a/output"
  type: "Concat"
  bottom: "inception_5a/1x1"
  bottom: "inception_5a/3x3"
  top: "inception_5a/output"
}
layer {
  name: "inception_6a/1x1"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_6a/1x1"
  top: "inception_6a/1x1"
}
layer {
  name: "inception_6a/3x3"
  type: "Convolution"
  bottom: "inception_5a/output"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_6a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_6a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_6a/3x3"
  top: "inception_6a/3x3"
}
layer {
  name: "inception_6a/output"
  type: "Concat"
  bottom: "inception_6a/1x1"
  bottom: "inception_6a/3x3"
  top: "inception_6a/output"
}
layer {
  name: "inception_7a/1x1"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_7a/1x1"
  top: "inception_7a/1x1"
}
layer {
  name: "inception_7a/3x3"
  type: "Convolution"
  bottom: "inception_6a/output"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 80
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_7a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_7a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_7a/3x3"
  top: "inception_7a/3x3"
}
layer {
  name: "inception_7a/output"
  type: "Concat"
  bottom: "inception_7a/1x1"
  bottom: "inception_7a/3x3"
  top: "inception_7a/output"
}
layer {
  name: "inception_8a/1x1"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_8a/1x1"
  top: "inception_8a/1x1"
}
layer {
  name: "inception_8a/3x3"
  type: "Convolution"
  bottom: "inception_7a/output"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_8a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_8a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_8a/3x3"
  top: "inception_8a/3x3"
}
layer {
  name: "inception_8a/output"
  type: "Concat"
  bottom: "inception_8a/1x1"
  bottom: "inception_8a/3x3"
  top: "inception_8a/output"
}
layer {
  name: "downsample_9/3x3_s2"
  type: "Convolution"
  bottom: "inception_8a/output"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/bn1"
  type: "BatchNorm"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "downsample_9/3x3_s2/relu1"
  type: "ReLU"
  bottom: "downsample_9/3x3_s2"
  top: "downsample_9/3x3_s2"
}
layer {
  name: "downsample_9/pool_s2"
  type: "Pooling"
  bottom: "inception_8a/output"
  top: "downsample_9/pool_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "downsample_9/output"
  type: "Concat"
  bottom: "downsample_9/3x3_s2"
  bottom: "downsample_9/pool_s2"
  top: "downsample_9/output"
}
layer {
  name: "inception_10a/1x1"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_10a/1x1"
  top: "inception_10a/1x1"
}
layer {
  name: "inception_10a/3x3"
  type: "Convolution"
  bottom: "downsample_9/output"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_10a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_10a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_10a/3x3"
  top: "inception_10a/3x3"
}
layer {
  name: "inception_10a/output"
  type: "Concat"
  bottom: "inception_10a/1x1"
  bottom: "inception_10a/3x3"
  top: "inception_10a/output"
}
layer {
  name: "inception_11a/1x1"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 176
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/1x1/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/1x1/relu1"
  type: "ReLU"
  bottom: "inception_11a/1x1"
  top: "inception_11a/1x1"
}
layer {
  name: "inception_11a/3x3"
  type: "Convolution"
  bottom: "inception_10a/output"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_11a/3x3/bn1"
  type: "BatchNorm"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 1
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    decay_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_11a/3x3/relu1"
  type: "ReLU"
  bottom: "inception_11a/3x3"
  top: "inception_11a/3x3"
}
layer {
  name: "inception_11a/output"
  type: "Concat"
  bottom: "inception_11a/1x1"
  bottom: "inception_11a/3x3"
  top: "inception_11a/output"
}
layer {
  name: "avg_pool_12/8x8_s1"
  type: "Pooling"
  bottom: "inception_11a/output"
  top: "avg_pool_12/8x8_s1"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "drop_8x8_s1"
  type: "Dropout"
  bottom: "avg_pool_12/8x8_s1"
  top: "avg_pool_12/8x8_s1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss/classifier"
  type: "InnerProduct"
  bottom: "avg_pool_12/8x8_s1"
  top: "loss/classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "loss/classifier"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy-top5"
  type: "Accuracy"
  bottom: "loss/classifier"
  bottom: "label"
  top: "top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0122 16:59:12.841380 64218 layer_factory.hpp:77] Creating layer data
I0122 16:59:12.841423 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.842232 64218 net.cpp:94] Creating Layer data
I0122 16:59:12.842248 64218 net.cpp:409] data -> data
I0122 16:59:12.842257 64218 net.cpp:409] data -> label
I0122 16:59:12.843333 64291 db_lmdb.cpp:35] Opened lmdb cifar10/input/lmdb/valid_lmdb
I0122 16:59:12.843369 64291 data_reader.cpp:117] TEST: reading data using 1 channel(s)
I0122 16:59:12.843453 64218 data_layer.cpp:78] ReshapePrefetch 50, 3, 32, 32
I0122 16:59:12.843559 64218 data_layer.cpp:83] output data size: 50,3,32,32
I0122 16:59:12.846608 64218 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0122 16:59:12.846649 64218 net.cpp:144] Setting up data
I0122 16:59:12.846658 64218 net.cpp:151] Top shape: 50 3 32 32 (153600)
I0122 16:59:12.846662 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846665 64218 net.cpp:159] Memory required for data: 614600
I0122 16:59:12.846670 64218 layer_factory.hpp:77] Creating layer label_data_1_split
I0122 16:59:12.846679 64218 net.cpp:94] Creating Layer label_data_1_split
I0122 16:59:12.846685 64218 net.cpp:435] label_data_1_split <- label
I0122 16:59:12.846691 64218 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0122 16:59:12.846698 64218 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0122 16:59:12.846707 64218 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0122 16:59:12.846714 64218 net.cpp:409] label_data_1_split -> label_data_1_split_3
I0122 16:59:12.846832 64218 net.cpp:144] Setting up label_data_1_split
I0122 16:59:12.846838 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846843 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846845 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846848 64218 net.cpp:151] Top shape: 50 (50)
I0122 16:59:12.846851 64218 net.cpp:159] Memory required for data: 615400
I0122 16:59:12.846854 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1
I0122 16:59:12.846864 64218 net.cpp:94] Creating Layer conv1/3x3_s1
I0122 16:59:12.846868 64218 net.cpp:435] conv1/3x3_s1 <- data
I0122 16:59:12.846875 64218 net.cpp:409] conv1/3x3_s1 -> conv1/3x3_s1
I0122 16:59:12.847229 64218 net.cpp:144] Setting up conv1/3x3_s1
I0122 16:59:12.847236 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.847239 64218 net.cpp:159] Memory required for data: 20276200
I0122 16:59:12.847247 64218 layer_factory.hpp:77] Creating layer conv1/bn1
I0122 16:59:12.847256 64218 net.cpp:94] Creating Layer conv1/bn1
I0122 16:59:12.847259 64218 net.cpp:435] conv1/bn1 <- conv1/3x3_s1
I0122 16:59:12.847275 64218 net.cpp:396] conv1/bn1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.847965 64218 net.cpp:144] Setting up conv1/bn1
I0122 16:59:12.847971 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.847975 64218 net.cpp:159] Memory required for data: 39937000
I0122 16:59:12.847985 64218 layer_factory.hpp:77] Creating layer conv1/relu1
I0122 16:59:12.847992 64218 net.cpp:94] Creating Layer conv1/relu1
I0122 16:59:12.847996 64218 net.cpp:435] conv1/relu1 <- conv1/3x3_s1
I0122 16:59:12.848001 64218 net.cpp:396] conv1/relu1 -> conv1/3x3_s1 (in-place)
I0122 16:59:12.848006 64218 net.cpp:144] Setting up conv1/relu1
I0122 16:59:12.848011 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.848013 64218 net.cpp:159] Memory required for data: 59597800
I0122 16:59:12.848016 64218 layer_factory.hpp:77] Creating layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.848021 64218 net.cpp:94] Creating Layer conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.848023 64218 net.cpp:435] conv1/3x3_s1_conv1/relu1_0_split <- conv1/3x3_s1
I0122 16:59:12.848029 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.848035 64218 net.cpp:409] conv1/3x3_s1_conv1/relu1_0_split -> conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.848067 64218 net.cpp:144] Setting up conv1/3x3_s1_conv1/relu1_0_split
I0122 16:59:12.848071 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.848076 64218 net.cpp:151] Top shape: 50 96 32 32 (4915200)
I0122 16:59:12.848078 64218 net.cpp:159] Memory required for data: 98919400
I0122 16:59:12.848080 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1
I0122 16:59:12.848088 64218 net.cpp:94] Creating Layer inception_2a/1x1
I0122 16:59:12.848093 64218 net.cpp:435] inception_2a/1x1 <- conv1/3x3_s1_conv1/relu1_0_split_0
I0122 16:59:12.848100 64218 net.cpp:409] inception_2a/1x1 -> inception_2a/1x1
I0122 16:59:12.848708 64218 net.cpp:144] Setting up inception_2a/1x1
I0122 16:59:12.848714 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.848717 64218 net.cpp:159] Memory required for data: 105473000
I0122 16:59:12.848724 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/bn1
I0122 16:59:12.848734 64218 net.cpp:94] Creating Layer inception_2a/1x1/bn1
I0122 16:59:12.848738 64218 net.cpp:435] inception_2a/1x1/bn1 <- inception_2a/1x1
I0122 16:59:12.848745 64218 net.cpp:396] inception_2a/1x1/bn1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.849553 64218 net.cpp:144] Setting up inception_2a/1x1/bn1
I0122 16:59:12.849560 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.849562 64218 net.cpp:159] Memory required for data: 112026600
I0122 16:59:12.849570 64218 layer_factory.hpp:77] Creating layer inception_2a/1x1/relu1
I0122 16:59:12.849577 64218 net.cpp:94] Creating Layer inception_2a/1x1/relu1
I0122 16:59:12.849581 64218 net.cpp:435] inception_2a/1x1/relu1 <- inception_2a/1x1
I0122 16:59:12.849587 64218 net.cpp:396] inception_2a/1x1/relu1 -> inception_2a/1x1 (in-place)
I0122 16:59:12.849593 64218 net.cpp:144] Setting up inception_2a/1x1/relu1
I0122 16:59:12.849596 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.849599 64218 net.cpp:159] Memory required for data: 118580200
I0122 16:59:12.849602 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3
I0122 16:59:12.849611 64218 net.cpp:94] Creating Layer inception_2a/3x3
I0122 16:59:12.849617 64218 net.cpp:435] inception_2a/3x3 <- conv1/3x3_s1_conv1/relu1_0_split_1
I0122 16:59:12.849622 64218 net.cpp:409] inception_2a/3x3 -> inception_2a/3x3
I0122 16:59:12.850091 64218 net.cpp:144] Setting up inception_2a/3x3
I0122 16:59:12.850113 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.850116 64218 net.cpp:159] Memory required for data: 125133800
I0122 16:59:12.850121 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/bn1
I0122 16:59:12.850127 64218 net.cpp:94] Creating Layer inception_2a/3x3/bn1
I0122 16:59:12.850134 64218 net.cpp:435] inception_2a/3x3/bn1 <- inception_2a/3x3
I0122 16:59:12.850152 64218 net.cpp:396] inception_2a/3x3/bn1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.850898 64218 net.cpp:144] Setting up inception_2a/3x3/bn1
I0122 16:59:12.850904 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.850908 64218 net.cpp:159] Memory required for data: 131687400
I0122 16:59:12.850919 64218 layer_factory.hpp:77] Creating layer inception_2a/3x3/relu1
I0122 16:59:12.850927 64218 net.cpp:94] Creating Layer inception_2a/3x3/relu1
I0122 16:59:12.850930 64218 net.cpp:435] inception_2a/3x3/relu1 <- inception_2a/3x3
I0122 16:59:12.850935 64218 net.cpp:396] inception_2a/3x3/relu1 -> inception_2a/3x3 (in-place)
I0122 16:59:12.850942 64218 net.cpp:144] Setting up inception_2a/3x3/relu1
I0122 16:59:12.850946 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.850949 64218 net.cpp:159] Memory required for data: 138241000
I0122 16:59:12.850952 64218 layer_factory.hpp:77] Creating layer inception_2a/output
I0122 16:59:12.850957 64218 net.cpp:94] Creating Layer inception_2a/output
I0122 16:59:12.850962 64218 net.cpp:435] inception_2a/output <- inception_2a/1x1
I0122 16:59:12.850965 64218 net.cpp:435] inception_2a/output <- inception_2a/3x3
I0122 16:59:12.850971 64218 net.cpp:409] inception_2a/output -> inception_2a/output
I0122 16:59:12.851008 64218 net.cpp:144] Setting up inception_2a/output
I0122 16:59:12.851016 64218 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:12.851018 64218 net.cpp:159] Memory required for data: 151348200
I0122 16:59:12.851022 64218 layer_factory.hpp:77] Creating layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.851027 64218 net.cpp:94] Creating Layer inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.851029 64218 net.cpp:435] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0122 16:59:12.851035 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.851042 64218 net.cpp:409] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.851076 64218 net.cpp:144] Setting up inception_2a/output_inception_2a/output_0_split
I0122 16:59:12.851083 64218 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:12.851085 64218 net.cpp:151] Top shape: 50 64 32 32 (3276800)
I0122 16:59:12.851089 64218 net.cpp:159] Memory required for data: 177562600
I0122 16:59:12.851091 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1
I0122 16:59:12.851099 64218 net.cpp:94] Creating Layer inception_3a/1x1
I0122 16:59:12.851104 64218 net.cpp:435] inception_3a/1x1 <- inception_2a/output_inception_2a/output_0_split_0
I0122 16:59:12.851110 64218 net.cpp:409] inception_3a/1x1 -> inception_3a/1x1
I0122 16:59:12.851418 64218 net.cpp:144] Setting up inception_3a/1x1
I0122 16:59:12.851425 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.851428 64218 net.cpp:159] Memory required for data: 184116200
I0122 16:59:12.851433 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/bn1
I0122 16:59:12.851441 64218 net.cpp:94] Creating Layer inception_3a/1x1/bn1
I0122 16:59:12.851444 64218 net.cpp:435] inception_3a/1x1/bn1 <- inception_3a/1x1
I0122 16:59:12.851451 64218 net.cpp:396] inception_3a/1x1/bn1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.852210 64218 net.cpp:144] Setting up inception_3a/1x1/bn1
I0122 16:59:12.852216 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.852219 64218 net.cpp:159] Memory required for data: 190669800
I0122 16:59:12.852226 64218 layer_factory.hpp:77] Creating layer inception_3a/1x1/relu1
I0122 16:59:12.852234 64218 net.cpp:94] Creating Layer inception_3a/1x1/relu1
I0122 16:59:12.852237 64218 net.cpp:435] inception_3a/1x1/relu1 <- inception_3a/1x1
I0122 16:59:12.852242 64218 net.cpp:396] inception_3a/1x1/relu1 -> inception_3a/1x1 (in-place)
I0122 16:59:12.852249 64218 net.cpp:144] Setting up inception_3a/1x1/relu1
I0122 16:59:12.852253 64218 net.cpp:151] Top shape: 50 32 32 32 (1638400)
I0122 16:59:12.852255 64218 net.cpp:159] Memory required for data: 197223400
I0122 16:59:12.852267 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3
I0122 16:59:12.852278 64218 net.cpp:94] Creating Layer inception_3a/3x3
I0122 16:59:12.852283 64218 net.cpp:435] inception_3a/3x3 <- inception_2a/output_inception_2a/output_0_split_1
I0122 16:59:12.852289 64218 net.cpp:409] inception_3a/3x3 -> inception_3a/3x3
I0122 16:59:12.853443 64218 net.cpp:144] Setting up inception_3a/3x3
I0122 16:59:12.853456 64218 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:12.853459 64218 net.cpp:159] Memory required for data: 207053800
I0122 16:59:12.853466 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/bn1
I0122 16:59:12.853474 64218 net.cpp:94] Creating Layer inception_3a/3x3/bn1
I0122 16:59:12.853480 64218 net.cpp:435] inception_3a/3x3/bn1 <- inception_3a/3x3
I0122 16:59:12.853490 64218 net.cpp:396] inception_3a/3x3/bn1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.854287 64218 net.cpp:144] Setting up inception_3a/3x3/bn1
I0122 16:59:12.854295 64218 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:12.854297 64218 net.cpp:159] Memory required for data: 216884200
I0122 16:59:12.854311 64218 layer_factory.hpp:77] Creating layer inception_3a/3x3/relu1
I0122 16:59:12.854319 64218 net.cpp:94] Creating Layer inception_3a/3x3/relu1
I0122 16:59:12.854323 64218 net.cpp:435] inception_3a/3x3/relu1 <- inception_3a/3x3
I0122 16:59:12.854329 64218 net.cpp:396] inception_3a/3x3/relu1 -> inception_3a/3x3 (in-place)
I0122 16:59:12.854338 64218 net.cpp:144] Setting up inception_3a/3x3/relu1
I0122 16:59:12.854342 64218 net.cpp:151] Top shape: 50 48 32 32 (2457600)
I0122 16:59:12.854346 64218 net.cpp:159] Memory required for data: 226714600
I0122 16:59:12.854348 64218 layer_factory.hpp:77] Creating layer inception_3a/output
I0122 16:59:12.854353 64218 net.cpp:94] Creating Layer inception_3a/output
I0122 16:59:12.854357 64218 net.cpp:435] inception_3a/output <- inception_3a/1x1
I0122 16:59:12.854360 64218 net.cpp:435] inception_3a/output <- inception_3a/3x3
I0122 16:59:12.854365 64218 net.cpp:409] inception_3a/output -> inception_3a/output
I0122 16:59:12.854449 64218 net.cpp:144] Setting up inception_3a/output
I0122 16:59:12.854454 64218 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:12.854456 64218 net.cpp:159] Memory required for data: 243098600
I0122 16:59:12.854460 64218 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.854465 64218 net.cpp:94] Creating Layer inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.854470 64218 net.cpp:435] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0122 16:59:12.854475 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.854482 64218 net.cpp:409] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.854521 64218 net.cpp:144] Setting up inception_3a/output_inception_3a/output_0_split
I0122 16:59:12.854527 64218 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:12.854530 64218 net.cpp:151] Top shape: 50 80 32 32 (4096000)
I0122 16:59:12.854533 64218 net.cpp:159] Memory required for data: 275866600
I0122 16:59:12.854537 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2
I0122 16:59:12.854545 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2
I0122 16:59:12.854548 64218 net.cpp:435] downsample_4/3x3_s2 <- inception_3a/output_inception_3a/output_0_split_0
I0122 16:59:12.854557 64218 net.cpp:409] downsample_4/3x3_s2 -> downsample_4/3x3_s2
I0122 16:59:12.855120 64218 net.cpp:144] Setting up downsample_4/3x3_s2
I0122 16:59:12.855129 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.855131 64218 net.cpp:159] Memory required for data: 279962600
I0122 16:59:12.855136 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/bn1
I0122 16:59:12.855147 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/bn1
I0122 16:59:12.855150 64218 net.cpp:435] downsample_4/3x3_s2/bn1 <- downsample_4/3x3_s2
I0122 16:59:12.855167 64218 net.cpp:396] downsample_4/3x3_s2/bn1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.855990 64218 net.cpp:144] Setting up downsample_4/3x3_s2/bn1
I0122 16:59:12.855998 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.856000 64218 net.cpp:159] Memory required for data: 284058600
I0122 16:59:12.856009 64218 layer_factory.hpp:77] Creating layer downsample_4/3x3_s2/relu1
I0122 16:59:12.856015 64218 net.cpp:94] Creating Layer downsample_4/3x3_s2/relu1
I0122 16:59:12.856019 64218 net.cpp:435] downsample_4/3x3_s2/relu1 <- downsample_4/3x3_s2
I0122 16:59:12.856024 64218 net.cpp:396] downsample_4/3x3_s2/relu1 -> downsample_4/3x3_s2 (in-place)
I0122 16:59:12.856031 64218 net.cpp:144] Setting up downsample_4/3x3_s2/relu1
I0122 16:59:12.856036 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.856040 64218 net.cpp:159] Memory required for data: 288154600
I0122 16:59:12.856042 64218 layer_factory.hpp:77] Creating layer downsample_4/pool_s2
I0122 16:59:12.856050 64218 net.cpp:94] Creating Layer downsample_4/pool_s2
I0122 16:59:12.856053 64218 net.cpp:435] downsample_4/pool_s2 <- inception_3a/output_inception_3a/output_0_split_1
I0122 16:59:12.856060 64218 net.cpp:409] downsample_4/pool_s2 -> downsample_4/pool_s2
I0122 16:59:12.856096 64218 net.cpp:144] Setting up downsample_4/pool_s2
I0122 16:59:12.856101 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.856103 64218 net.cpp:159] Memory required for data: 292250600
I0122 16:59:12.856107 64218 layer_factory.hpp:77] Creating layer downsample_4/output
I0122 16:59:12.856113 64218 net.cpp:94] Creating Layer downsample_4/output
I0122 16:59:12.856117 64218 net.cpp:435] downsample_4/output <- downsample_4/3x3_s2
I0122 16:59:12.856120 64218 net.cpp:435] downsample_4/output <- downsample_4/pool_s2
I0122 16:59:12.856127 64218 net.cpp:409] downsample_4/output -> downsample_4/output
I0122 16:59:12.856199 64218 net.cpp:144] Setting up downsample_4/output
I0122 16:59:12.856204 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.856207 64218 net.cpp:159] Memory required for data: 300442600
I0122 16:59:12.856210 64218 layer_factory.hpp:77] Creating layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.856217 64218 net.cpp:94] Creating Layer downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.856221 64218 net.cpp:435] downsample_4/output_downsample_4/output_0_split <- downsample_4/output
I0122 16:59:12.856225 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.856233 64218 net.cpp:409] downsample_4/output_downsample_4/output_0_split -> downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.856276 64218 net.cpp:144] Setting up downsample_4/output_downsample_4/output_0_split
I0122 16:59:12.856283 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.856288 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.856292 64218 net.cpp:159] Memory required for data: 316826600
I0122 16:59:12.856294 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1
I0122 16:59:12.856304 64218 net.cpp:94] Creating Layer inception_5a/1x1
I0122 16:59:12.856312 64218 net.cpp:435] inception_5a/1x1 <- downsample_4/output_downsample_4/output_0_split_0
I0122 16:59:12.856328 64218 net.cpp:409] inception_5a/1x1 -> inception_5a/1x1
I0122 16:59:12.856690 64218 net.cpp:144] Setting up inception_5a/1x1
I0122 16:59:12.856696 64218 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:12.856699 64218 net.cpp:159] Memory required for data: 322561000
I0122 16:59:12.856705 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/bn1
I0122 16:59:12.856714 64218 net.cpp:94] Creating Layer inception_5a/1x1/bn1
I0122 16:59:12.856716 64218 net.cpp:435] inception_5a/1x1/bn1 <- inception_5a/1x1
I0122 16:59:12.856722 64218 net.cpp:396] inception_5a/1x1/bn1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.857506 64218 net.cpp:144] Setting up inception_5a/1x1/bn1
I0122 16:59:12.857522 64218 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:12.857524 64218 net.cpp:159] Memory required for data: 328295400
I0122 16:59:12.857532 64218 layer_factory.hpp:77] Creating layer inception_5a/1x1/relu1
I0122 16:59:12.857542 64218 net.cpp:94] Creating Layer inception_5a/1x1/relu1
I0122 16:59:12.857545 64218 net.cpp:435] inception_5a/1x1/relu1 <- inception_5a/1x1
I0122 16:59:12.857551 64218 net.cpp:396] inception_5a/1x1/relu1 -> inception_5a/1x1 (in-place)
I0122 16:59:12.857561 64218 net.cpp:144] Setting up inception_5a/1x1/relu1
I0122 16:59:12.857574 64218 net.cpp:151] Top shape: 50 112 16 16 (1433600)
I0122 16:59:12.857578 64218 net.cpp:159] Memory required for data: 334029800
I0122 16:59:12.857580 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3
I0122 16:59:12.857595 64218 net.cpp:94] Creating Layer inception_5a/3x3
I0122 16:59:12.857601 64218 net.cpp:435] inception_5a/3x3 <- downsample_4/output_downsample_4/output_0_split_1
I0122 16:59:12.857609 64218 net.cpp:409] inception_5a/3x3 -> inception_5a/3x3
I0122 16:59:12.858289 64218 net.cpp:144] Setting up inception_5a/3x3
I0122 16:59:12.858297 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.858301 64218 net.cpp:159] Memory required for data: 336487400
I0122 16:59:12.858306 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/bn1
I0122 16:59:12.858319 64218 net.cpp:94] Creating Layer inception_5a/3x3/bn1
I0122 16:59:12.858323 64218 net.cpp:435] inception_5a/3x3/bn1 <- inception_5a/3x3
I0122 16:59:12.858330 64218 net.cpp:396] inception_5a/3x3/bn1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.859122 64218 net.cpp:144] Setting up inception_5a/3x3/bn1
I0122 16:59:12.859129 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.859133 64218 net.cpp:159] Memory required for data: 338945000
I0122 16:59:12.859141 64218 layer_factory.hpp:77] Creating layer inception_5a/3x3/relu1
I0122 16:59:12.859146 64218 net.cpp:94] Creating Layer inception_5a/3x3/relu1
I0122 16:59:12.859149 64218 net.cpp:435] inception_5a/3x3/relu1 <- inception_5a/3x3
I0122 16:59:12.859163 64218 net.cpp:396] inception_5a/3x3/relu1 -> inception_5a/3x3 (in-place)
I0122 16:59:12.859170 64218 net.cpp:144] Setting up inception_5a/3x3/relu1
I0122 16:59:12.859179 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.859182 64218 net.cpp:159] Memory required for data: 341402600
I0122 16:59:12.859184 64218 layer_factory.hpp:77] Creating layer inception_5a/output
I0122 16:59:12.859189 64218 net.cpp:94] Creating Layer inception_5a/output
I0122 16:59:12.859195 64218 net.cpp:435] inception_5a/output <- inception_5a/1x1
I0122 16:59:12.859199 64218 net.cpp:435] inception_5a/output <- inception_5a/3x3
I0122 16:59:12.859203 64218 net.cpp:409] inception_5a/output -> inception_5a/output
I0122 16:59:12.859227 64218 net.cpp:144] Setting up inception_5a/output
I0122 16:59:12.859232 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.859236 64218 net.cpp:159] Memory required for data: 349594600
I0122 16:59:12.859237 64218 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.859243 64218 net.cpp:94] Creating Layer inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.859246 64218 net.cpp:435] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0122 16:59:12.859252 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.859258 64218 net.cpp:409] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.859328 64218 net.cpp:144] Setting up inception_5a/output_inception_5a/output_0_split
I0122 16:59:12.859334 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.859338 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.859340 64218 net.cpp:159] Memory required for data: 365978600
I0122 16:59:12.859344 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1
I0122 16:59:12.859351 64218 net.cpp:94] Creating Layer inception_6a/1x1
I0122 16:59:12.859375 64218 net.cpp:435] inception_6a/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0122 16:59:12.859381 64218 net.cpp:409] inception_6a/1x1 -> inception_6a/1x1
I0122 16:59:12.859725 64218 net.cpp:144] Setting up inception_6a/1x1
I0122 16:59:12.859733 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.859736 64218 net.cpp:159] Memory required for data: 370893800
I0122 16:59:12.859741 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/bn1
I0122 16:59:12.859750 64218 net.cpp:94] Creating Layer inception_6a/1x1/bn1
I0122 16:59:12.859755 64218 net.cpp:435] inception_6a/1x1/bn1 <- inception_6a/1x1
I0122 16:59:12.859760 64218 net.cpp:396] inception_6a/1x1/bn1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.860559 64218 net.cpp:144] Setting up inception_6a/1x1/bn1
I0122 16:59:12.860568 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.860570 64218 net.cpp:159] Memory required for data: 375809000
I0122 16:59:12.860579 64218 layer_factory.hpp:77] Creating layer inception_6a/1x1/relu1
I0122 16:59:12.860590 64218 net.cpp:94] Creating Layer inception_6a/1x1/relu1
I0122 16:59:12.860594 64218 net.cpp:435] inception_6a/1x1/relu1 <- inception_6a/1x1
I0122 16:59:12.860599 64218 net.cpp:396] inception_6a/1x1/relu1 -> inception_6a/1x1 (in-place)
I0122 16:59:12.860611 64218 net.cpp:144] Setting up inception_6a/1x1/relu1
I0122 16:59:12.860615 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.860620 64218 net.cpp:159] Memory required for data: 380724200
I0122 16:59:12.860622 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3
I0122 16:59:12.860632 64218 net.cpp:94] Creating Layer inception_6a/3x3
I0122 16:59:12.860636 64218 net.cpp:435] inception_6a/3x3 <- inception_5a/output_inception_5a/output_0_split_1
I0122 16:59:12.860642 64218 net.cpp:409] inception_6a/3x3 -> inception_6a/3x3
I0122 16:59:12.862144 64218 net.cpp:144] Setting up inception_6a/3x3
I0122 16:59:12.862157 64218 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:12.862160 64218 net.cpp:159] Memory required for data: 384001000
I0122 16:59:12.862175 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/bn1
I0122 16:59:12.862187 64218 net.cpp:94] Creating Layer inception_6a/3x3/bn1
I0122 16:59:12.862191 64218 net.cpp:435] inception_6a/3x3/bn1 <- inception_6a/3x3
I0122 16:59:12.862198 64218 net.cpp:396] inception_6a/3x3/bn1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.863029 64218 net.cpp:144] Setting up inception_6a/3x3/bn1
I0122 16:59:12.863035 64218 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:12.863039 64218 net.cpp:159] Memory required for data: 387277800
I0122 16:59:12.863046 64218 layer_factory.hpp:77] Creating layer inception_6a/3x3/relu1
I0122 16:59:12.863054 64218 net.cpp:94] Creating Layer inception_6a/3x3/relu1
I0122 16:59:12.863057 64218 net.cpp:435] inception_6a/3x3/relu1 <- inception_6a/3x3
I0122 16:59:12.863063 64218 net.cpp:396] inception_6a/3x3/relu1 -> inception_6a/3x3 (in-place)
I0122 16:59:12.863070 64218 net.cpp:144] Setting up inception_6a/3x3/relu1
I0122 16:59:12.863075 64218 net.cpp:151] Top shape: 50 64 16 16 (819200)
I0122 16:59:12.863078 64218 net.cpp:159] Memory required for data: 390554600
I0122 16:59:12.863081 64218 layer_factory.hpp:77] Creating layer inception_6a/output
I0122 16:59:12.863086 64218 net.cpp:94] Creating Layer inception_6a/output
I0122 16:59:12.863090 64218 net.cpp:435] inception_6a/output <- inception_6a/1x1
I0122 16:59:12.863093 64218 net.cpp:435] inception_6a/output <- inception_6a/3x3
I0122 16:59:12.863101 64218 net.cpp:409] inception_6a/output -> inception_6a/output
I0122 16:59:12.863121 64218 net.cpp:144] Setting up inception_6a/output
I0122 16:59:12.863127 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.863129 64218 net.cpp:159] Memory required for data: 398746600
I0122 16:59:12.863132 64218 layer_factory.hpp:77] Creating layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.863138 64218 net.cpp:94] Creating Layer inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.863153 64218 net.cpp:435] inception_6a/output_inception_6a/output_0_split <- inception_6a/output
I0122 16:59:12.863159 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.863168 64218 net.cpp:409] inception_6a/output_inception_6a/output_0_split -> inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.863199 64218 net.cpp:144] Setting up inception_6a/output_inception_6a/output_0_split
I0122 16:59:12.863206 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.863209 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.863211 64218 net.cpp:159] Memory required for data: 415130600
I0122 16:59:12.863215 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1
I0122 16:59:12.863225 64218 net.cpp:94] Creating Layer inception_7a/1x1
I0122 16:59:12.863230 64218 net.cpp:435] inception_7a/1x1 <- inception_6a/output_inception_6a/output_0_split_0
I0122 16:59:12.863236 64218 net.cpp:409] inception_7a/1x1 -> inception_7a/1x1
I0122 16:59:12.863554 64218 net.cpp:144] Setting up inception_7a/1x1
I0122 16:59:12.863561 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.863564 64218 net.cpp:159] Memory required for data: 419226600
I0122 16:59:12.863569 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/bn1
I0122 16:59:12.863575 64218 net.cpp:94] Creating Layer inception_7a/1x1/bn1
I0122 16:59:12.863579 64218 net.cpp:435] inception_7a/1x1/bn1 <- inception_7a/1x1
I0122 16:59:12.863585 64218 net.cpp:396] inception_7a/1x1/bn1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.864289 64218 net.cpp:144] Setting up inception_7a/1x1/bn1
I0122 16:59:12.864296 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.864300 64218 net.cpp:159] Memory required for data: 423322600
I0122 16:59:12.864306 64218 layer_factory.hpp:77] Creating layer inception_7a/1x1/relu1
I0122 16:59:12.864315 64218 net.cpp:94] Creating Layer inception_7a/1x1/relu1
I0122 16:59:12.864317 64218 net.cpp:435] inception_7a/1x1/relu1 <- inception_7a/1x1
I0122 16:59:12.864322 64218 net.cpp:396] inception_7a/1x1/relu1 -> inception_7a/1x1 (in-place)
I0122 16:59:12.864328 64218 net.cpp:144] Setting up inception_7a/1x1/relu1
I0122 16:59:12.864332 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.864334 64218 net.cpp:159] Memory required for data: 427418600
I0122 16:59:12.864338 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3
I0122 16:59:12.864346 64218 net.cpp:94] Creating Layer inception_7a/3x3
I0122 16:59:12.864351 64218 net.cpp:435] inception_7a/3x3 <- inception_6a/output_inception_6a/output_0_split_1
I0122 16:59:12.864358 64218 net.cpp:409] inception_7a/3x3 -> inception_7a/3x3
I0122 16:59:12.865245 64218 net.cpp:144] Setting up inception_7a/3x3
I0122 16:59:12.865255 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.865258 64218 net.cpp:159] Memory required for data: 431514600
I0122 16:59:12.865263 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/bn1
I0122 16:59:12.865272 64218 net.cpp:94] Creating Layer inception_7a/3x3/bn1
I0122 16:59:12.865278 64218 net.cpp:435] inception_7a/3x3/bn1 <- inception_7a/3x3
I0122 16:59:12.865283 64218 net.cpp:396] inception_7a/3x3/bn1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.865990 64218 net.cpp:144] Setting up inception_7a/3x3/bn1
I0122 16:59:12.865998 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.866000 64218 net.cpp:159] Memory required for data: 435610600
I0122 16:59:12.866008 64218 layer_factory.hpp:77] Creating layer inception_7a/3x3/relu1
I0122 16:59:12.866014 64218 net.cpp:94] Creating Layer inception_7a/3x3/relu1
I0122 16:59:12.866019 64218 net.cpp:435] inception_7a/3x3/relu1 <- inception_7a/3x3
I0122 16:59:12.866024 64218 net.cpp:396] inception_7a/3x3/relu1 -> inception_7a/3x3 (in-place)
I0122 16:59:12.866031 64218 net.cpp:144] Setting up inception_7a/3x3/relu1
I0122 16:59:12.866036 64218 net.cpp:151] Top shape: 50 80 16 16 (1024000)
I0122 16:59:12.866040 64218 net.cpp:159] Memory required for data: 439706600
I0122 16:59:12.866052 64218 layer_factory.hpp:77] Creating layer inception_7a/output
I0122 16:59:12.866057 64218 net.cpp:94] Creating Layer inception_7a/output
I0122 16:59:12.866060 64218 net.cpp:435] inception_7a/output <- inception_7a/1x1
I0122 16:59:12.866065 64218 net.cpp:435] inception_7a/output <- inception_7a/3x3
I0122 16:59:12.866070 64218 net.cpp:409] inception_7a/output -> inception_7a/output
I0122 16:59:12.866089 64218 net.cpp:144] Setting up inception_7a/output
I0122 16:59:12.866096 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.866098 64218 net.cpp:159] Memory required for data: 447898600
I0122 16:59:12.866101 64218 layer_factory.hpp:77] Creating layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.866107 64218 net.cpp:94] Creating Layer inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.866111 64218 net.cpp:435] inception_7a/output_inception_7a/output_0_split <- inception_7a/output
I0122 16:59:12.866116 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.866122 64218 net.cpp:409] inception_7a/output_inception_7a/output_0_split -> inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.866154 64218 net.cpp:144] Setting up inception_7a/output_inception_7a/output_0_split
I0122 16:59:12.866159 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.866163 64218 net.cpp:151] Top shape: 50 160 16 16 (2048000)
I0122 16:59:12.866166 64218 net.cpp:159] Memory required for data: 464282600
I0122 16:59:12.866168 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1
I0122 16:59:12.866178 64218 net.cpp:94] Creating Layer inception_8a/1x1
I0122 16:59:12.866183 64218 net.cpp:435] inception_8a/1x1 <- inception_7a/output_inception_7a/output_0_split_0
I0122 16:59:12.866189 64218 net.cpp:409] inception_8a/1x1 -> inception_8a/1x1
I0122 16:59:12.866474 64218 net.cpp:144] Setting up inception_8a/1x1
I0122 16:59:12.866482 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.866484 64218 net.cpp:159] Memory required for data: 466740200
I0122 16:59:12.866489 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/bn1
I0122 16:59:12.866497 64218 net.cpp:94] Creating Layer inception_8a/1x1/bn1
I0122 16:59:12.866499 64218 net.cpp:435] inception_8a/1x1/bn1 <- inception_8a/1x1
I0122 16:59:12.866506 64218 net.cpp:396] inception_8a/1x1/bn1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.867208 64218 net.cpp:144] Setting up inception_8a/1x1/bn1
I0122 16:59:12.867214 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.867218 64218 net.cpp:159] Memory required for data: 469197800
I0122 16:59:12.867225 64218 layer_factory.hpp:77] Creating layer inception_8a/1x1/relu1
I0122 16:59:12.867230 64218 net.cpp:94] Creating Layer inception_8a/1x1/relu1
I0122 16:59:12.867233 64218 net.cpp:435] inception_8a/1x1/relu1 <- inception_8a/1x1
I0122 16:59:12.867239 64218 net.cpp:396] inception_8a/1x1/relu1 -> inception_8a/1x1 (in-place)
I0122 16:59:12.867245 64218 net.cpp:144] Setting up inception_8a/1x1/relu1
I0122 16:59:12.867251 64218 net.cpp:151] Top shape: 50 48 16 16 (614400)
I0122 16:59:12.867254 64218 net.cpp:159] Memory required for data: 471655400
I0122 16:59:12.867256 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3
I0122 16:59:12.867265 64218 net.cpp:94] Creating Layer inception_8a/3x3
I0122 16:59:12.867269 64218 net.cpp:435] inception_8a/3x3 <- inception_7a/output_inception_7a/output_0_split_1
I0122 16:59:12.867275 64218 net.cpp:409] inception_8a/3x3 -> inception_8a/3x3
I0122 16:59:12.868919 64218 net.cpp:144] Setting up inception_8a/3x3
I0122 16:59:12.868933 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.868935 64218 net.cpp:159] Memory required for data: 476570600
I0122 16:59:12.868942 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/bn1
I0122 16:59:12.868968 64218 net.cpp:94] Creating Layer inception_8a/3x3/bn1
I0122 16:59:12.868973 64218 net.cpp:435] inception_8a/3x3/bn1 <- inception_8a/3x3
I0122 16:59:12.868988 64218 net.cpp:396] inception_8a/3x3/bn1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.869699 64218 net.cpp:144] Setting up inception_8a/3x3/bn1
I0122 16:59:12.869715 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.869719 64218 net.cpp:159] Memory required for data: 481485800
I0122 16:59:12.869727 64218 layer_factory.hpp:77] Creating layer inception_8a/3x3/relu1
I0122 16:59:12.869732 64218 net.cpp:94] Creating Layer inception_8a/3x3/relu1
I0122 16:59:12.869735 64218 net.cpp:435] inception_8a/3x3/relu1 <- inception_8a/3x3
I0122 16:59:12.869741 64218 net.cpp:396] inception_8a/3x3/relu1 -> inception_8a/3x3 (in-place)
I0122 16:59:12.869748 64218 net.cpp:144] Setting up inception_8a/3x3/relu1
I0122 16:59:12.869755 64218 net.cpp:151] Top shape: 50 96 16 16 (1228800)
I0122 16:59:12.869757 64218 net.cpp:159] Memory required for data: 486401000
I0122 16:59:12.869761 64218 layer_factory.hpp:77] Creating layer inception_8a/output
I0122 16:59:12.869765 64218 net.cpp:94] Creating Layer inception_8a/output
I0122 16:59:12.869768 64218 net.cpp:435] inception_8a/output <- inception_8a/1x1
I0122 16:59:12.869771 64218 net.cpp:435] inception_8a/output <- inception_8a/3x3
I0122 16:59:12.869778 64218 net.cpp:409] inception_8a/output -> inception_8a/output
I0122 16:59:12.869797 64218 net.cpp:144] Setting up inception_8a/output
I0122 16:59:12.869802 64218 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:12.869805 64218 net.cpp:159] Memory required for data: 493773800
I0122 16:59:12.869808 64218 layer_factory.hpp:77] Creating layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.869814 64218 net.cpp:94] Creating Layer inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.869817 64218 net.cpp:435] inception_8a/output_inception_8a/output_0_split <- inception_8a/output
I0122 16:59:12.869823 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.869830 64218 net.cpp:409] inception_8a/output_inception_8a/output_0_split -> inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.869861 64218 net.cpp:144] Setting up inception_8a/output_inception_8a/output_0_split
I0122 16:59:12.869866 64218 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:12.869870 64218 net.cpp:151] Top shape: 50 144 16 16 (1843200)
I0122 16:59:12.869874 64218 net.cpp:159] Memory required for data: 508519400
I0122 16:59:12.869876 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2
I0122 16:59:12.869885 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2
I0122 16:59:12.869889 64218 net.cpp:435] downsample_9/3x3_s2 <- inception_8a/output_inception_8a/output_0_split_0
I0122 16:59:12.869897 64218 net.cpp:409] downsample_9/3x3_s2 -> downsample_9/3x3_s2
I0122 16:59:12.871490 64218 net.cpp:144] Setting up downsample_9/3x3_s2
I0122 16:59:12.871501 64218 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:12.871505 64218 net.cpp:159] Memory required for data: 509748200
I0122 16:59:12.871510 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/bn1
I0122 16:59:12.871520 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/bn1
I0122 16:59:12.871523 64218 net.cpp:435] downsample_9/3x3_s2/bn1 <- downsample_9/3x3_s2
I0122 16:59:12.871529 64218 net.cpp:396] downsample_9/3x3_s2/bn1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.872220 64218 net.cpp:144] Setting up downsample_9/3x3_s2/bn1
I0122 16:59:12.872227 64218 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:12.872231 64218 net.cpp:159] Memory required for data: 510977000
I0122 16:59:12.872237 64218 layer_factory.hpp:77] Creating layer downsample_9/3x3_s2/relu1
I0122 16:59:12.872244 64218 net.cpp:94] Creating Layer downsample_9/3x3_s2/relu1
I0122 16:59:12.872247 64218 net.cpp:435] downsample_9/3x3_s2/relu1 <- downsample_9/3x3_s2
I0122 16:59:12.872252 64218 net.cpp:396] downsample_9/3x3_s2/relu1 -> downsample_9/3x3_s2 (in-place)
I0122 16:59:12.872258 64218 net.cpp:144] Setting up downsample_9/3x3_s2/relu1
I0122 16:59:12.872262 64218 net.cpp:151] Top shape: 50 96 8 8 (307200)
I0122 16:59:12.872275 64218 net.cpp:159] Memory required for data: 512205800
I0122 16:59:12.872278 64218 layer_factory.hpp:77] Creating layer downsample_9/pool_s2
I0122 16:59:12.872283 64218 net.cpp:94] Creating Layer downsample_9/pool_s2
I0122 16:59:12.872290 64218 net.cpp:435] downsample_9/pool_s2 <- inception_8a/output_inception_8a/output_0_split_1
I0122 16:59:12.872297 64218 net.cpp:409] downsample_9/pool_s2 -> downsample_9/pool_s2
I0122 16:59:12.872329 64218 net.cpp:144] Setting up downsample_9/pool_s2
I0122 16:59:12.872335 64218 net.cpp:151] Top shape: 50 144 8 8 (460800)
I0122 16:59:12.872339 64218 net.cpp:159] Memory required for data: 514049000
I0122 16:59:12.872341 64218 layer_factory.hpp:77] Creating layer downsample_9/output
I0122 16:59:12.872350 64218 net.cpp:94] Creating Layer downsample_9/output
I0122 16:59:12.872355 64218 net.cpp:435] downsample_9/output <- downsample_9/3x3_s2
I0122 16:59:12.872359 64218 net.cpp:435] downsample_9/output <- downsample_9/pool_s2
I0122 16:59:12.872364 64218 net.cpp:409] downsample_9/output -> downsample_9/output
I0122 16:59:12.872381 64218 net.cpp:144] Setting up downsample_9/output
I0122 16:59:12.872386 64218 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:12.872390 64218 net.cpp:159] Memory required for data: 517121000
I0122 16:59:12.872392 64218 layer_factory.hpp:77] Creating layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.872400 64218 net.cpp:94] Creating Layer downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.872406 64218 net.cpp:435] downsample_9/output_downsample_9/output_0_split <- downsample_9/output
I0122 16:59:12.872411 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.872418 64218 net.cpp:409] downsample_9/output_downsample_9/output_0_split -> downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.872447 64218 net.cpp:144] Setting up downsample_9/output_downsample_9/output_0_split
I0122 16:59:12.872452 64218 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:12.872457 64218 net.cpp:151] Top shape: 50 240 8 8 (768000)
I0122 16:59:12.872459 64218 net.cpp:159] Memory required for data: 523265000
I0122 16:59:12.872462 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1
I0122 16:59:12.872470 64218 net.cpp:94] Creating Layer inception_10a/1x1
I0122 16:59:12.872475 64218 net.cpp:435] inception_10a/1x1 <- downsample_9/output_downsample_9/output_0_split_0
I0122 16:59:12.872481 64218 net.cpp:409] inception_10a/1x1 -> inception_10a/1x1
I0122 16:59:12.872944 64218 net.cpp:144] Setting up inception_10a/1x1
I0122 16:59:12.872951 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.872954 64218 net.cpp:159] Memory required for data: 525517800
I0122 16:59:12.872959 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/bn1
I0122 16:59:12.872967 64218 net.cpp:94] Creating Layer inception_10a/1x1/bn1
I0122 16:59:12.872972 64218 net.cpp:435] inception_10a/1x1/bn1 <- inception_10a/1x1
I0122 16:59:12.872978 64218 net.cpp:396] inception_10a/1x1/bn1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.873661 64218 net.cpp:144] Setting up inception_10a/1x1/bn1
I0122 16:59:12.873667 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.873672 64218 net.cpp:159] Memory required for data: 527770600
I0122 16:59:12.873678 64218 layer_factory.hpp:77] Creating layer inception_10a/1x1/relu1
I0122 16:59:12.873683 64218 net.cpp:94] Creating Layer inception_10a/1x1/relu1
I0122 16:59:12.873687 64218 net.cpp:435] inception_10a/1x1/relu1 <- inception_10a/1x1
I0122 16:59:12.873690 64218 net.cpp:396] inception_10a/1x1/relu1 -> inception_10a/1x1 (in-place)
I0122 16:59:12.873697 64218 net.cpp:144] Setting up inception_10a/1x1/relu1
I0122 16:59:12.873700 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.873703 64218 net.cpp:159] Memory required for data: 530023400
I0122 16:59:12.873705 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3
I0122 16:59:12.873716 64218 net.cpp:94] Creating Layer inception_10a/3x3
I0122 16:59:12.873729 64218 net.cpp:435] inception_10a/3x3 <- downsample_9/output_downsample_9/output_0_split_1
I0122 16:59:12.873734 64218 net.cpp:409] inception_10a/3x3 -> inception_10a/3x3
I0122 16:59:12.876235 64218 net.cpp:144] Setting up inception_10a/3x3
I0122 16:59:12.876248 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.876250 64218 net.cpp:159] Memory required for data: 532071400
I0122 16:59:12.876255 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/bn1
I0122 16:59:12.876263 64218 net.cpp:94] Creating Layer inception_10a/3x3/bn1
I0122 16:59:12.876267 64218 net.cpp:435] inception_10a/3x3/bn1 <- inception_10a/3x3
I0122 16:59:12.876272 64218 net.cpp:396] inception_10a/3x3/bn1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.876888 64218 net.cpp:144] Setting up inception_10a/3x3/bn1
I0122 16:59:12.876895 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.876899 64218 net.cpp:159] Memory required for data: 534119400
I0122 16:59:12.876905 64218 layer_factory.hpp:77] Creating layer inception_10a/3x3/relu1
I0122 16:59:12.876910 64218 net.cpp:94] Creating Layer inception_10a/3x3/relu1
I0122 16:59:12.876914 64218 net.cpp:435] inception_10a/3x3/relu1 <- inception_10a/3x3
I0122 16:59:12.876920 64218 net.cpp:396] inception_10a/3x3/relu1 -> inception_10a/3x3 (in-place)
I0122 16:59:12.876926 64218 net.cpp:144] Setting up inception_10a/3x3/relu1
I0122 16:59:12.876932 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.876935 64218 net.cpp:159] Memory required for data: 536167400
I0122 16:59:12.876937 64218 layer_factory.hpp:77] Creating layer inception_10a/output
I0122 16:59:12.876941 64218 net.cpp:94] Creating Layer inception_10a/output
I0122 16:59:12.876945 64218 net.cpp:435] inception_10a/output <- inception_10a/1x1
I0122 16:59:12.876948 64218 net.cpp:435] inception_10a/output <- inception_10a/3x3
I0122 16:59:12.876955 64218 net.cpp:409] inception_10a/output -> inception_10a/output
I0122 16:59:12.876972 64218 net.cpp:144] Setting up inception_10a/output
I0122 16:59:12.876978 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.876981 64218 net.cpp:159] Memory required for data: 540468200
I0122 16:59:12.876983 64218 layer_factory.hpp:77] Creating layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.876989 64218 net.cpp:94] Creating Layer inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.876992 64218 net.cpp:435] inception_10a/output_inception_10a/output_0_split <- inception_10a/output
I0122 16:59:12.876998 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.877004 64218 net.cpp:409] inception_10a/output_inception_10a/output_0_split -> inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.877035 64218 net.cpp:144] Setting up inception_10a/output_inception_10a/output_0_split
I0122 16:59:12.877040 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.877043 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.877046 64218 net.cpp:159] Memory required for data: 549069800
I0122 16:59:12.877049 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1
I0122 16:59:12.877058 64218 net.cpp:94] Creating Layer inception_11a/1x1
I0122 16:59:12.877060 64218 net.cpp:435] inception_11a/1x1 <- inception_10a/output_inception_10a/output_0_split_0
I0122 16:59:12.877068 64218 net.cpp:409] inception_11a/1x1 -> inception_11a/1x1
I0122 16:59:12.877626 64218 net.cpp:144] Setting up inception_11a/1x1
I0122 16:59:12.877634 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.877637 64218 net.cpp:159] Memory required for data: 551322600
I0122 16:59:12.877642 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/bn1
I0122 16:59:12.877650 64218 net.cpp:94] Creating Layer inception_11a/1x1/bn1
I0122 16:59:12.877653 64218 net.cpp:435] inception_11a/1x1/bn1 <- inception_11a/1x1
I0122 16:59:12.877660 64218 net.cpp:396] inception_11a/1x1/bn1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.878376 64218 net.cpp:144] Setting up inception_11a/1x1/bn1
I0122 16:59:12.878384 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.878387 64218 net.cpp:159] Memory required for data: 553575400
I0122 16:59:12.878394 64218 layer_factory.hpp:77] Creating layer inception_11a/1x1/relu1
I0122 16:59:12.878401 64218 net.cpp:94] Creating Layer inception_11a/1x1/relu1
I0122 16:59:12.878403 64218 net.cpp:435] inception_11a/1x1/relu1 <- inception_11a/1x1
I0122 16:59:12.878408 64218 net.cpp:396] inception_11a/1x1/relu1 -> inception_11a/1x1 (in-place)
I0122 16:59:12.878414 64218 net.cpp:144] Setting up inception_11a/1x1/relu1
I0122 16:59:12.878419 64218 net.cpp:151] Top shape: 50 176 8 8 (563200)
I0122 16:59:12.878422 64218 net.cpp:159] Memory required for data: 555828200
I0122 16:59:12.878424 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3
I0122 16:59:12.878433 64218 net.cpp:94] Creating Layer inception_11a/3x3
I0122 16:59:12.878438 64218 net.cpp:435] inception_11a/3x3 <- inception_10a/output_inception_10a/output_0_split_1
I0122 16:59:12.878444 64218 net.cpp:409] inception_11a/3x3 -> inception_11a/3x3
I0122 16:59:12.882194 64218 net.cpp:144] Setting up inception_11a/3x3
I0122 16:59:12.882205 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.882207 64218 net.cpp:159] Memory required for data: 557876200
I0122 16:59:12.882212 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/bn1
I0122 16:59:12.882221 64218 net.cpp:94] Creating Layer inception_11a/3x3/bn1
I0122 16:59:12.882225 64218 net.cpp:435] inception_11a/3x3/bn1 <- inception_11a/3x3
I0122 16:59:12.882231 64218 net.cpp:396] inception_11a/3x3/bn1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.882923 64218 net.cpp:144] Setting up inception_11a/3x3/bn1
I0122 16:59:12.882931 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.882935 64218 net.cpp:159] Memory required for data: 559924200
I0122 16:59:12.882953 64218 layer_factory.hpp:77] Creating layer inception_11a/3x3/relu1
I0122 16:59:12.882961 64218 net.cpp:94] Creating Layer inception_11a/3x3/relu1
I0122 16:59:12.882964 64218 net.cpp:435] inception_11a/3x3/relu1 <- inception_11a/3x3
I0122 16:59:12.882969 64218 net.cpp:396] inception_11a/3x3/relu1 -> inception_11a/3x3 (in-place)
I0122 16:59:12.882977 64218 net.cpp:144] Setting up inception_11a/3x3/relu1
I0122 16:59:12.882982 64218 net.cpp:151] Top shape: 50 160 8 8 (512000)
I0122 16:59:12.882985 64218 net.cpp:159] Memory required for data: 561972200
I0122 16:59:12.882987 64218 layer_factory.hpp:77] Creating layer inception_11a/output
I0122 16:59:12.882993 64218 net.cpp:94] Creating Layer inception_11a/output
I0122 16:59:12.882997 64218 net.cpp:435] inception_11a/output <- inception_11a/1x1
I0122 16:59:12.882999 64218 net.cpp:435] inception_11a/output <- inception_11a/3x3
I0122 16:59:12.883004 64218 net.cpp:409] inception_11a/output -> inception_11a/output
I0122 16:59:12.883024 64218 net.cpp:144] Setting up inception_11a/output
I0122 16:59:12.883029 64218 net.cpp:151] Top shape: 50 336 8 8 (1075200)
I0122 16:59:12.883033 64218 net.cpp:159] Memory required for data: 566273000
I0122 16:59:12.883034 64218 layer_factory.hpp:77] Creating layer avg_pool_12/8x8_s1
I0122 16:59:12.883041 64218 net.cpp:94] Creating Layer avg_pool_12/8x8_s1
I0122 16:59:12.883044 64218 net.cpp:435] avg_pool_12/8x8_s1 <- inception_11a/output
I0122 16:59:12.883049 64218 net.cpp:409] avg_pool_12/8x8_s1 -> avg_pool_12/8x8_s1
I0122 16:59:12.883071 64218 net.cpp:144] Setting up avg_pool_12/8x8_s1
I0122 16:59:12.883076 64218 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 16:59:12.883080 64218 net.cpp:159] Memory required for data: 566340200
I0122 16:59:12.883081 64218 layer_factory.hpp:77] Creating layer drop_8x8_s1
I0122 16:59:12.883086 64218 net.cpp:94] Creating Layer drop_8x8_s1
I0122 16:59:12.883090 64218 net.cpp:435] drop_8x8_s1 <- avg_pool_12/8x8_s1
I0122 16:59:12.883095 64218 net.cpp:396] drop_8x8_s1 -> avg_pool_12/8x8_s1 (in-place)
I0122 16:59:12.883113 64218 net.cpp:144] Setting up drop_8x8_s1
I0122 16:59:12.883119 64218 net.cpp:151] Top shape: 50 336 1 1 (16800)
I0122 16:59:12.883133 64218 net.cpp:159] Memory required for data: 566407400
I0122 16:59:12.883136 64218 layer_factory.hpp:77] Creating layer loss/classifier
I0122 16:59:12.883143 64218 net.cpp:94] Creating Layer loss/classifier
I0122 16:59:12.883146 64218 net.cpp:435] loss/classifier <- avg_pool_12/8x8_s1
I0122 16:59:12.883152 64218 net.cpp:409] loss/classifier -> loss/classifier
I0122 16:59:12.883302 64218 net.cpp:144] Setting up loss/classifier
I0122 16:59:12.883307 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883311 64218 net.cpp:159] Memory required for data: 566409400
I0122 16:59:12.883316 64218 layer_factory.hpp:77] Creating layer loss/classifier_loss/classifier_0_split
I0122 16:59:12.883322 64218 net.cpp:94] Creating Layer loss/classifier_loss/classifier_0_split
I0122 16:59:12.883325 64218 net.cpp:435] loss/classifier_loss/classifier_0_split <- loss/classifier
I0122 16:59:12.883330 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_0
I0122 16:59:12.883337 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_1
I0122 16:59:12.883342 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_2
I0122 16:59:12.883347 64218 net.cpp:409] loss/classifier_loss/classifier_0_split -> loss/classifier_loss/classifier_0_split_3
I0122 16:59:12.883399 64218 net.cpp:144] Setting up loss/classifier_loss/classifier_0_split
I0122 16:59:12.883404 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883407 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883410 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883414 64218 net.cpp:151] Top shape: 50 10 (500)
I0122 16:59:12.883416 64218 net.cpp:159] Memory required for data: 566417400
I0122 16:59:12.883419 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.883424 64218 net.cpp:94] Creating Layer loss
I0122 16:59:12.883426 64218 net.cpp:435] loss <- loss/classifier_loss/classifier_0_split_0
I0122 16:59:12.883430 64218 net.cpp:435] loss <- label_data_1_split_0
I0122 16:59:12.883436 64218 net.cpp:409] loss -> loss
I0122 16:59:12.883445 64218 layer_factory.hpp:77] Creating layer loss
I0122 16:59:12.883524 64218 net.cpp:144] Setting up loss
I0122 16:59:12.883530 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883533 64218 net.cpp:154]     with loss weight 1
I0122 16:59:12.883543 64218 net.cpp:159] Memory required for data: 566417404
I0122 16:59:12.883545 64218 layer_factory.hpp:77] Creating layer accuracy
I0122 16:59:12.883551 64218 net.cpp:94] Creating Layer accuracy
I0122 16:59:12.883554 64218 net.cpp:435] accuracy <- loss/classifier_loss/classifier_0_split_1
I0122 16:59:12.883558 64218 net.cpp:435] accuracy <- label_data_1_split_1
I0122 16:59:12.883563 64218 net.cpp:409] accuracy -> accuracy
I0122 16:59:12.883574 64218 net.cpp:144] Setting up accuracy
I0122 16:59:12.883579 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883581 64218 net.cpp:159] Memory required for data: 566417408
I0122 16:59:12.883584 64218 layer_factory.hpp:77] Creating layer accuracy-top1
I0122 16:59:12.883589 64218 net.cpp:94] Creating Layer accuracy-top1
I0122 16:59:12.883591 64218 net.cpp:435] accuracy-top1 <- loss/classifier_loss/classifier_0_split_2
I0122 16:59:12.883594 64218 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0122 16:59:12.883599 64218 net.cpp:409] accuracy-top1 -> top-1
I0122 16:59:12.883605 64218 net.cpp:144] Setting up accuracy-top1
I0122 16:59:12.883608 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883610 64218 net.cpp:159] Memory required for data: 566417412
I0122 16:59:12.883612 64218 layer_factory.hpp:77] Creating layer accuracy-top5
I0122 16:59:12.883620 64218 net.cpp:94] Creating Layer accuracy-top5
I0122 16:59:12.883622 64218 net.cpp:435] accuracy-top5 <- loss/classifier_loss/classifier_0_split_3
I0122 16:59:12.883626 64218 net.cpp:435] accuracy-top5 <- label_data_1_split_3
I0122 16:59:12.883630 64218 net.cpp:409] accuracy-top5 -> top-5
I0122 16:59:12.883636 64218 net.cpp:144] Setting up accuracy-top5
I0122 16:59:12.883647 64218 net.cpp:151] Top shape: (1)
I0122 16:59:12.883651 64218 net.cpp:159] Memory required for data: 566417416
I0122 16:59:12.883652 64218 net.cpp:222] accuracy-top5 does not need backward computation.
I0122 16:59:12.883657 64218 net.cpp:222] accuracy-top1 does not need backward computation.
I0122 16:59:12.883661 64218 net.cpp:222] accuracy does not need backward computation.
I0122 16:59:12.883663 64218 net.cpp:220] loss needs backward computation.
I0122 16:59:12.883667 64218 net.cpp:220] loss/classifier_loss/classifier_0_split needs backward computation.
I0122 16:59:12.883671 64218 net.cpp:220] loss/classifier needs backward computation.
I0122 16:59:12.883674 64218 net.cpp:220] drop_8x8_s1 needs backward computation.
I0122 16:59:12.883677 64218 net.cpp:220] avg_pool_12/8x8_s1 needs backward computation.
I0122 16:59:12.883679 64218 net.cpp:220] inception_11a/output needs backward computation.
I0122 16:59:12.883684 64218 net.cpp:220] inception_11a/3x3/relu1 needs backward computation.
I0122 16:59:12.883687 64218 net.cpp:220] inception_11a/3x3/bn1 needs backward computation.
I0122 16:59:12.883689 64218 net.cpp:220] inception_11a/3x3 needs backward computation.
I0122 16:59:12.883692 64218 net.cpp:220] inception_11a/1x1/relu1 needs backward computation.
I0122 16:59:12.883695 64218 net.cpp:220] inception_11a/1x1/bn1 needs backward computation.
I0122 16:59:12.883698 64218 net.cpp:220] inception_11a/1x1 needs backward computation.
I0122 16:59:12.883702 64218 net.cpp:220] inception_10a/output_inception_10a/output_0_split needs backward computation.
I0122 16:59:12.883705 64218 net.cpp:220] inception_10a/output needs backward computation.
I0122 16:59:12.883709 64218 net.cpp:220] inception_10a/3x3/relu1 needs backward computation.
I0122 16:59:12.883718 64218 net.cpp:220] inception_10a/3x3/bn1 needs backward computation.
I0122 16:59:12.883720 64218 net.cpp:220] inception_10a/3x3 needs backward computation.
I0122 16:59:12.883723 64218 net.cpp:220] inception_10a/1x1/relu1 needs backward computation.
I0122 16:59:12.883726 64218 net.cpp:220] inception_10a/1x1/bn1 needs backward computation.
I0122 16:59:12.883729 64218 net.cpp:220] inception_10a/1x1 needs backward computation.
I0122 16:59:12.883731 64218 net.cpp:220] downsample_9/output_downsample_9/output_0_split needs backward computation.
I0122 16:59:12.883734 64218 net.cpp:220] downsample_9/output needs backward computation.
I0122 16:59:12.883739 64218 net.cpp:220] downsample_9/pool_s2 needs backward computation.
I0122 16:59:12.883743 64218 net.cpp:220] downsample_9/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.883744 64218 net.cpp:220] downsample_9/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.883747 64218 net.cpp:220] downsample_9/3x3_s2 needs backward computation.
I0122 16:59:12.883751 64218 net.cpp:220] inception_8a/output_inception_8a/output_0_split needs backward computation.
I0122 16:59:12.883754 64218 net.cpp:220] inception_8a/output needs backward computation.
I0122 16:59:12.883759 64218 net.cpp:220] inception_8a/3x3/relu1 needs backward computation.
I0122 16:59:12.883761 64218 net.cpp:220] inception_8a/3x3/bn1 needs backward computation.
I0122 16:59:12.883764 64218 net.cpp:220] inception_8a/3x3 needs backward computation.
I0122 16:59:12.883769 64218 net.cpp:220] inception_8a/1x1/relu1 needs backward computation.
I0122 16:59:12.883771 64218 net.cpp:220] inception_8a/1x1/bn1 needs backward computation.
I0122 16:59:12.883774 64218 net.cpp:220] inception_8a/1x1 needs backward computation.
I0122 16:59:12.883777 64218 net.cpp:220] inception_7a/output_inception_7a/output_0_split needs backward computation.
I0122 16:59:12.883780 64218 net.cpp:220] inception_7a/output needs backward computation.
I0122 16:59:12.883783 64218 net.cpp:220] inception_7a/3x3/relu1 needs backward computation.
I0122 16:59:12.883786 64218 net.cpp:220] inception_7a/3x3/bn1 needs backward computation.
I0122 16:59:12.883790 64218 net.cpp:220] inception_7a/3x3 needs backward computation.
I0122 16:59:12.883792 64218 net.cpp:220] inception_7a/1x1/relu1 needs backward computation.
I0122 16:59:12.883800 64218 net.cpp:220] inception_7a/1x1/bn1 needs backward computation.
I0122 16:59:12.883803 64218 net.cpp:220] inception_7a/1x1 needs backward computation.
I0122 16:59:12.883807 64218 net.cpp:220] inception_6a/output_inception_6a/output_0_split needs backward computation.
I0122 16:59:12.883810 64218 net.cpp:220] inception_6a/output needs backward computation.
I0122 16:59:12.883813 64218 net.cpp:220] inception_6a/3x3/relu1 needs backward computation.
I0122 16:59:12.883816 64218 net.cpp:220] inception_6a/3x3/bn1 needs backward computation.
I0122 16:59:12.883821 64218 net.cpp:220] inception_6a/3x3 needs backward computation.
I0122 16:59:12.883823 64218 net.cpp:220] inception_6a/1x1/relu1 needs backward computation.
I0122 16:59:12.883826 64218 net.cpp:220] inception_6a/1x1/bn1 needs backward computation.
I0122 16:59:12.883828 64218 net.cpp:220] inception_6a/1x1 needs backward computation.
I0122 16:59:12.883832 64218 net.cpp:220] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0122 16:59:12.883836 64218 net.cpp:220] inception_5a/output needs backward computation.
I0122 16:59:12.883838 64218 net.cpp:220] inception_5a/3x3/relu1 needs backward computation.
I0122 16:59:12.883841 64218 net.cpp:220] inception_5a/3x3/bn1 needs backward computation.
I0122 16:59:12.883844 64218 net.cpp:220] inception_5a/3x3 needs backward computation.
I0122 16:59:12.883847 64218 net.cpp:220] inception_5a/1x1/relu1 needs backward computation.
I0122 16:59:12.883850 64218 net.cpp:220] inception_5a/1x1/bn1 needs backward computation.
I0122 16:59:12.883853 64218 net.cpp:220] inception_5a/1x1 needs backward computation.
I0122 16:59:12.883857 64218 net.cpp:220] downsample_4/output_downsample_4/output_0_split needs backward computation.
I0122 16:59:12.883859 64218 net.cpp:220] downsample_4/output needs backward computation.
I0122 16:59:12.883863 64218 net.cpp:220] downsample_4/pool_s2 needs backward computation.
I0122 16:59:12.883867 64218 net.cpp:220] downsample_4/3x3_s2/relu1 needs backward computation.
I0122 16:59:12.883872 64218 net.cpp:220] downsample_4/3x3_s2/bn1 needs backward computation.
I0122 16:59:12.883874 64218 net.cpp:220] downsample_4/3x3_s2 needs backward computation.
I0122 16:59:12.883877 64218 net.cpp:220] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0122 16:59:12.883880 64218 net.cpp:220] inception_3a/output needs backward computation.
I0122 16:59:12.883884 64218 net.cpp:220] inception_3a/3x3/relu1 needs backward computation.
I0122 16:59:12.883888 64218 net.cpp:220] inception_3a/3x3/bn1 needs backward computation.
I0122 16:59:12.883890 64218 net.cpp:220] inception_3a/3x3 needs backward computation.
I0122 16:59:12.883893 64218 net.cpp:220] inception_3a/1x1/relu1 needs backward computation.
I0122 16:59:12.883896 64218 net.cpp:220] inception_3a/1x1/bn1 needs backward computation.
I0122 16:59:12.883899 64218 net.cpp:220] inception_3a/1x1 needs backward computation.
I0122 16:59:12.883903 64218 net.cpp:220] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0122 16:59:12.883905 64218 net.cpp:220] inception_2a/output needs backward computation.
I0122 16:59:12.883909 64218 net.cpp:220] inception_2a/3x3/relu1 needs backward computation.
I0122 16:59:12.883913 64218 net.cpp:220] inception_2a/3x3/bn1 needs backward computation.
I0122 16:59:12.883915 64218 net.cpp:220] inception_2a/3x3 needs backward computation.
I0122 16:59:12.883919 64218 net.cpp:220] inception_2a/1x1/relu1 needs backward computation.
I0122 16:59:12.883922 64218 net.cpp:220] inception_2a/1x1/bn1 needs backward computation.
I0122 16:59:12.883924 64218 net.cpp:220] inception_2a/1x1 needs backward computation.
I0122 16:59:12.883929 64218 net.cpp:220] conv1/3x3_s1_conv1/relu1_0_split needs backward computation.
I0122 16:59:12.883931 64218 net.cpp:220] conv1/relu1 needs backward computation.
I0122 16:59:12.883934 64218 net.cpp:220] conv1/bn1 needs backward computation.
I0122 16:59:12.883937 64218 net.cpp:220] conv1/3x3_s1 needs backward computation.
I0122 16:59:12.883946 64218 net.cpp:222] label_data_1_split does not need backward computation.
I0122 16:59:12.883950 64218 net.cpp:222] data does not need backward computation.
I0122 16:59:12.883955 64218 net.cpp:264] This network produces output accuracy
I0122 16:59:12.883957 64218 net.cpp:264] This network produces output loss
I0122 16:59:12.883960 64218 net.cpp:264] This network produces output top-1
I0122 16:59:12.883963 64218 net.cpp:264] This network produces output top-5
I0122 16:59:12.884032 64218 net.cpp:284] Network initialization done.
I0122 16:59:12.884367 64218 solver.cpp:63] Solver scaffolding done.
I0122 16:59:12.888835 64218 caffe_interface.cpp:93] Finetuning from cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/sparse.caffemodel
W0122 16:59:12.919659 64218 net.cpp:860] Force copying param 4 weights from layer 'conv1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.931596 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.931886 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932065 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932283 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932576 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_4/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.932781 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933123 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933321 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933655 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.933851 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.934523 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.934718 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.935132 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.935515 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_9/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.935765 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.936470 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.936755 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.937646 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.954486 64218 net.cpp:860] Force copying param 4 weights from layer 'conv1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.954666 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.954879 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_2a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955204 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955425 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_3a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955710 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_4/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.955924 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956250 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_5a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956452 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956777 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_6a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.956976 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.957329 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_7a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.957525 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.957923 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_8a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.958315 64218 net.cpp:860] Force copying param 4 weights from layer 'downsample_9/3x3_s2/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.958562 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.959252 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_10a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.959530 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/1x1/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0122 16:59:12.960383 64218 net.cpp:860] Force copying param 4 weights from layer 'inception_11a/3x3/bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
I0122 16:59:12.960599 64218 caffe_interface.cpp:527] Starting Optimization
I0122 16:59:12.960605 64218 solver.cpp:335] Solving 
I0122 16:59:12.960608 64218 solver.cpp:336] Learning Rate Policy: step
I0122 16:59:12.963109 64218 solver.cpp:418] Iteration 0, Testing net (#0)
I0122 16:59:15.289312 64218 solver.cpp:517]     Test net output #0: accuracy = 0.897778
I0122 16:59:15.289362 64218 solver.cpp:517]     Test net output #1: loss = 0.337907 (* 1 = 0.337907 loss)
I0122 16:59:15.289367 64218 solver.cpp:517]     Test net output #2: top-1 = 0.897778
I0122 16:59:15.289372 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 16:59:15.411653 64218 solver.cpp:266] Iteration 0 (0 iter/s, 2.45092s/100 iter), loss = 0.00980846
I0122 16:59:15.411685 64218 solver.cpp:285]     Train net output #0: loss = 0.00980846 (* 1 = 0.00980846 loss)
I0122 16:59:15.411697 64218 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0122 16:59:25.321040 64218 solver.cpp:266] Iteration 100 (10.0919 iter/s, 9.90898s/100 iter), loss = 1.23095
I0122 16:59:25.321074 64218 solver.cpp:285]     Train net output #0: loss = 1.23095 (* 1 = 1.23095 loss)
I0122 16:59:25.321080 64218 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0122 16:59:35.237478 64218 solver.cpp:266] Iteration 200 (10.0847 iter/s, 9.91603s/100 iter), loss = 1.18834
I0122 16:59:35.237511 64218 solver.cpp:285]     Train net output #0: loss = 1.18834 (* 1 = 1.18834 loss)
I0122 16:59:35.237519 64218 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0122 16:59:45.009392 64218 solver.cpp:266] Iteration 300 (10.2338 iter/s, 9.77151s/100 iter), loss = 0.978324
I0122 16:59:45.009469 64218 solver.cpp:285]     Train net output #0: loss = 0.978324 (* 1 = 0.978324 loss)
I0122 16:59:45.009476 64218 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0122 16:59:54.900861 64218 solver.cpp:266] Iteration 400 (10.1102 iter/s, 9.89102s/100 iter), loss = 0.781388
I0122 16:59:54.900907 64218 solver.cpp:285]     Train net output #0: loss = 0.781388 (* 1 = 0.781388 loss)
I0122 16:59:54.900914 64218 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0122 17:00:04.796079 64218 solver.cpp:266] Iteration 500 (10.1063 iter/s, 9.8948s/100 iter), loss = 0.834341
I0122 17:00:04.796113 64218 solver.cpp:285]     Train net output #0: loss = 0.834341 (* 1 = 0.834341 loss)
I0122 17:00:04.796120 64218 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0122 17:00:14.710749 64218 solver.cpp:266] Iteration 600 (10.0865 iter/s, 9.91426s/100 iter), loss = 0.737883
I0122 17:00:14.710781 64218 solver.cpp:285]     Train net output #0: loss = 0.737883 (* 1 = 0.737883 loss)
I0122 17:00:14.710788 64218 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0122 17:00:24.607306 64218 solver.cpp:266] Iteration 700 (10.1049 iter/s, 9.89615s/100 iter), loss = 0.84515
I0122 17:00:24.607372 64218 solver.cpp:285]     Train net output #0: loss = 0.84515 (* 1 = 0.84515 loss)
I0122 17:00:24.607380 64218 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0122 17:00:34.522425 64218 solver.cpp:266] Iteration 800 (10.0861 iter/s, 9.91467s/100 iter), loss = 0.905017
I0122 17:00:34.522459 64218 solver.cpp:285]     Train net output #0: loss = 0.905017 (* 1 = 0.905017 loss)
I0122 17:00:34.522465 64218 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0122 17:00:43.987553 64218 solver.cpp:266] Iteration 900 (10.5655 iter/s, 9.46473s/100 iter), loss = 0.618011
I0122 17:00:43.987586 64218 solver.cpp:285]     Train net output #0: loss = 0.618011 (* 1 = 0.618011 loss)
I0122 17:00:43.987591 64218 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0122 17:00:53.803179 64218 solver.cpp:418] Iteration 1000, Testing net (#0)
I0122 17:00:56.098443 64218 solver.cpp:517]     Test net output #0: accuracy = 0.198
I0122 17:00:56.098508 64218 solver.cpp:517]     Test net output #1: loss = 21.9294 (* 1 = 21.9294 loss)
I0122 17:00:56.098513 64218 solver.cpp:517]     Test net output #2: top-1 = 0.198
I0122 17:00:56.098517 64218 solver.cpp:517]     Test net output #3: top-5 = 0.665444
I0122 17:00:56.172874 64218 solver.cpp:266] Iteration 1000 (8.20694 iter/s, 12.1848s/100 iter), loss = 0.763146
I0122 17:00:56.172900 64218 solver.cpp:285]     Train net output #0: loss = 0.763146 (* 1 = 0.763146 loss)
I0122 17:00:56.172947 64218 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0122 17:01:06.090226 64218 solver.cpp:266] Iteration 1100 (10.0838 iter/s, 9.91689s/100 iter), loss = 0.701044
I0122 17:01:06.090270 64218 solver.cpp:285]     Train net output #0: loss = 0.701044 (* 1 = 0.701044 loss)
I0122 17:01:06.090276 64218 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0122 17:01:15.985049 64218 solver.cpp:266] Iteration 1200 (10.1067 iter/s, 9.89439s/100 iter), loss = 0.64415
I0122 17:01:15.985080 64218 solver.cpp:285]     Train net output #0: loss = 0.64415 (* 1 = 0.64415 loss)
I0122 17:01:15.985087 64218 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0122 17:01:25.924335 64218 solver.cpp:266] Iteration 1300 (10.0615 iter/s, 9.93887s/100 iter), loss = 0.63659
I0122 17:01:25.924368 64218 solver.cpp:285]     Train net output #0: loss = 0.63659 (* 1 = 0.63659 loss)
I0122 17:01:25.924376 64218 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0122 17:01:35.885099 64218 solver.cpp:266] Iteration 1400 (10.0398 iter/s, 9.96034s/100 iter), loss = 0.680251
I0122 17:01:35.885226 64218 solver.cpp:285]     Train net output #0: loss = 0.680251 (* 1 = 0.680251 loss)
I0122 17:01:35.885233 64218 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0122 17:01:45.788204 64218 solver.cpp:266] Iteration 1500 (10.0984 iter/s, 9.90259s/100 iter), loss = 0.648688
I0122 17:01:45.788239 64218 solver.cpp:285]     Train net output #0: loss = 0.648688 (* 1 = 0.648688 loss)
I0122 17:01:45.788244 64218 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0122 17:01:55.711263 64218 solver.cpp:266] Iteration 1600 (10.078 iter/s, 9.92264s/100 iter), loss = 0.707135
I0122 17:01:55.711297 64218 solver.cpp:285]     Train net output #0: loss = 0.707135 (* 1 = 0.707135 loss)
I0122 17:01:55.711303 64218 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0122 17:02:05.646179 64218 solver.cpp:266] Iteration 1700 (10.0659 iter/s, 9.93449s/100 iter), loss = 0.59069
I0122 17:02:05.646214 64218 solver.cpp:285]     Train net output #0: loss = 0.59069 (* 1 = 0.59069 loss)
I0122 17:02:05.646219 64218 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0122 17:02:15.599395 64218 solver.cpp:266] Iteration 1800 (10.0474 iter/s, 9.95279s/100 iter), loss = 0.63409
I0122 17:02:15.599452 64218 solver.cpp:285]     Train net output #0: loss = 0.63409 (* 1 = 0.63409 loss)
I0122 17:02:15.599474 64218 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0122 17:02:24.155696 64218 solver.cpp:266] Iteration 1900 (11.6878 iter/s, 8.55591s/100 iter), loss = 0.58959
I0122 17:02:24.155738 64218 solver.cpp:285]     Train net output #0: loss = 0.58959 (* 1 = 0.58959 loss)
I0122 17:02:24.155745 64218 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0122 17:02:30.852553 64218 solver.cpp:418] Iteration 2000, Testing net (#0)
I0122 17:02:32.325647 64218 solver.cpp:517]     Test net output #0: accuracy = 0.419889
I0122 17:02:32.325677 64218 solver.cpp:517]     Test net output #1: loss = 3.0678 (* 1 = 3.0678 loss)
I0122 17:02:32.325681 64218 solver.cpp:517]     Test net output #2: top-1 = 0.419889
I0122 17:02:32.325685 64218 solver.cpp:517]     Test net output #3: top-5 = 0.871777
I0122 17:02:32.389144 64218 solver.cpp:266] Iteration 2000 (12.1461 iter/s, 8.23309s/100 iter), loss = 0.543379
I0122 17:02:32.389176 64218 solver.cpp:285]     Train net output #0: loss = 0.543379 (* 1 = 0.543379 loss)
I0122 17:02:32.389183 64218 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0122 17:02:38.669178 64218 solver.cpp:266] Iteration 2100 (15.9242 iter/s, 6.27976s/100 iter), loss = 0.59188
I0122 17:02:38.669206 64218 solver.cpp:285]     Train net output #0: loss = 0.59188 (* 1 = 0.59188 loss)
I0122 17:02:38.669212 64218 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0122 17:02:44.957744 64218 solver.cpp:266] Iteration 2200 (15.9026 iter/s, 6.28829s/100 iter), loss = 0.44329
I0122 17:02:44.957774 64218 solver.cpp:285]     Train net output #0: loss = 0.44329 (* 1 = 0.44329 loss)
I0122 17:02:44.957780 64218 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0122 17:02:51.248493 64218 solver.cpp:266] Iteration 2300 (15.8971 iter/s, 6.29047s/100 iter), loss = 0.588783
I0122 17:02:51.248602 64218 solver.cpp:285]     Train net output #0: loss = 0.588783 (* 1 = 0.588783 loss)
I0122 17:02:51.248610 64218 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0122 17:02:57.532135 64218 solver.cpp:266] Iteration 2400 (15.9152 iter/s, 6.28329s/100 iter), loss = 0.443405
I0122 17:02:57.532166 64218 solver.cpp:285]     Train net output #0: loss = 0.443405 (* 1 = 0.443405 loss)
I0122 17:02:57.532171 64218 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0122 17:03:03.833413 64218 solver.cpp:266] Iteration 2500 (15.8705 iter/s, 6.301s/100 iter), loss = 0.500547
I0122 17:03:03.833442 64218 solver.cpp:285]     Train net output #0: loss = 0.500547 (* 1 = 0.500547 loss)
I0122 17:03:03.833448 64218 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0122 17:03:10.119339 64218 solver.cpp:266] Iteration 2600 (15.9093 iter/s, 6.28565s/100 iter), loss = 0.473666
I0122 17:03:10.119380 64218 solver.cpp:285]     Train net output #0: loss = 0.473666 (* 1 = 0.473666 loss)
I0122 17:03:10.119386 64218 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0122 17:03:16.400467 64218 solver.cpp:266] Iteration 2700 (15.9214 iter/s, 6.28084s/100 iter), loss = 0.65002
I0122 17:03:16.400497 64218 solver.cpp:285]     Train net output #0: loss = 0.65002 (* 1 = 0.65002 loss)
I0122 17:03:16.400502 64218 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0122 17:03:22.709966 64218 solver.cpp:266] Iteration 2800 (15.8498 iter/s, 6.30922s/100 iter), loss = 0.634212
I0122 17:03:22.710072 64218 solver.cpp:285]     Train net output #0: loss = 0.634212 (* 1 = 0.634212 loss)
I0122 17:03:22.710078 64218 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0122 17:03:28.970549 64218 solver.cpp:266] Iteration 2900 (15.9738 iter/s, 6.26023s/100 iter), loss = 0.535999
I0122 17:03:28.970579 64218 solver.cpp:285]     Train net output #0: loss = 0.535999 (* 1 = 0.535999 loss)
I0122 17:03:28.970585 64218 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0122 17:03:35.200136 64218 solver.cpp:418] Iteration 3000, Testing net (#0)
I0122 17:03:36.670575 64218 solver.cpp:517]     Test net output #0: accuracy = 0.531222
I0122 17:03:36.670600 64218 solver.cpp:517]     Test net output #1: loss = 2.16988 (* 1 = 2.16988 loss)
I0122 17:03:36.670604 64218 solver.cpp:517]     Test net output #2: top-1 = 0.531222
I0122 17:03:36.670608 64218 solver.cpp:517]     Test net output #3: top-5 = 0.914444
I0122 17:03:36.733899 64218 solver.cpp:266] Iteration 3000 (12.8816 iter/s, 7.76302s/100 iter), loss = 0.499563
I0122 17:03:36.733920 64218 solver.cpp:285]     Train net output #0: loss = 0.499563 (* 1 = 0.499563 loss)
I0122 17:03:36.733927 64218 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0122 17:03:43.005512 64218 solver.cpp:266] Iteration 3100 (15.9455 iter/s, 6.27135s/100 iter), loss = 0.508736
I0122 17:03:43.005553 64218 solver.cpp:285]     Train net output #0: loss = 0.508736 (* 1 = 0.508736 loss)
I0122 17:03:43.005558 64218 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0122 17:03:49.288455 64218 solver.cpp:266] Iteration 3200 (15.9168 iter/s, 6.28266s/100 iter), loss = 0.49204
I0122 17:03:49.288483 64218 solver.cpp:285]     Train net output #0: loss = 0.49204 (* 1 = 0.49204 loss)
I0122 17:03:49.288489 64218 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0122 17:03:55.554626 64218 solver.cpp:266] Iteration 3300 (15.9594 iter/s, 6.2659s/100 iter), loss = 0.458151
I0122 17:03:55.554697 64218 solver.cpp:285]     Train net output #0: loss = 0.458151 (* 1 = 0.458151 loss)
I0122 17:03:55.554703 64218 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0122 17:04:01.838019 64218 solver.cpp:266] Iteration 3400 (15.9158 iter/s, 6.28308s/100 iter), loss = 0.625705
I0122 17:04:01.838057 64218 solver.cpp:285]     Train net output #0: loss = 0.625705 (* 1 = 0.625705 loss)
I0122 17:04:01.838064 64218 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0122 17:04:08.147706 64218 solver.cpp:266] Iteration 3500 (15.8494 iter/s, 6.3094s/100 iter), loss = 0.435966
I0122 17:04:08.147733 64218 solver.cpp:285]     Train net output #0: loss = 0.435966 (* 1 = 0.435966 loss)
I0122 17:04:08.147738 64218 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0122 17:04:14.680032 64218 solver.cpp:266] Iteration 3600 (15.3091 iter/s, 6.53204s/100 iter), loss = 0.608255
I0122 17:04:14.680060 64218 solver.cpp:285]     Train net output #0: loss = 0.608255 (* 1 = 0.608255 loss)
I0122 17:04:14.680083 64218 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0122 17:04:21.159417 64218 solver.cpp:266] Iteration 3700 (15.4342 iter/s, 6.4791s/100 iter), loss = 0.48724
I0122 17:04:21.159447 64218 solver.cpp:285]     Train net output #0: loss = 0.48724 (* 1 = 0.48724 loss)
I0122 17:04:21.159452 64218 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0122 17:04:27.429881 64218 solver.cpp:266] Iteration 3800 (15.9485 iter/s, 6.27019s/100 iter), loss = 0.463679
I0122 17:04:27.430027 64218 solver.cpp:285]     Train net output #0: loss = 0.463679 (* 1 = 0.463679 loss)
I0122 17:04:27.430035 64218 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0122 17:04:33.688761 64218 solver.cpp:266] Iteration 3900 (15.9783 iter/s, 6.25849s/100 iter), loss = 0.561816
I0122 17:04:33.688791 64218 solver.cpp:285]     Train net output #0: loss = 0.561816 (* 1 = 0.561816 loss)
I0122 17:04:33.688796 64218 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0122 17:04:39.918716 64218 solver.cpp:418] Iteration 4000, Testing net (#0)
I0122 17:04:41.389219 64218 solver.cpp:517]     Test net output #0: accuracy = 0.497444
I0122 17:04:41.389245 64218 solver.cpp:517]     Test net output #1: loss = 2.14562 (* 1 = 2.14562 loss)
I0122 17:04:41.389250 64218 solver.cpp:517]     Test net output #2: top-1 = 0.497444
I0122 17:04:41.389255 64218 solver.cpp:517]     Test net output #3: top-5 = 0.860555
I0122 17:04:41.451529 64218 solver.cpp:266] Iteration 4000 (12.8825 iter/s, 7.76244s/100 iter), loss = 0.524706
I0122 17:04:41.451550 64218 solver.cpp:285]     Train net output #0: loss = 0.524706 (* 1 = 0.524706 loss)
I0122 17:04:41.451555 64218 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0122 17:04:47.719166 64218 solver.cpp:266] Iteration 4100 (15.9557 iter/s, 6.26737s/100 iter), loss = 0.524054
I0122 17:04:47.719195 64218 solver.cpp:285]     Train net output #0: loss = 0.524054 (* 1 = 0.524054 loss)
I0122 17:04:47.719202 64218 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0122 17:04:53.989893 64218 solver.cpp:266] Iteration 4200 (15.9478 iter/s, 6.27045s/100 iter), loss = 0.561482
I0122 17:04:53.989926 64218 solver.cpp:285]     Train net output #0: loss = 0.561482 (* 1 = 0.561482 loss)
I0122 17:04:53.989931 64218 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0122 17:05:00.281675 64218 solver.cpp:266] Iteration 4300 (15.8945 iter/s, 6.2915s/100 iter), loss = 0.572603
I0122 17:05:00.281738 64218 solver.cpp:285]     Train net output #0: loss = 0.572603 (* 1 = 0.572603 loss)
I0122 17:05:00.281745 64218 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0122 17:05:06.569659 64218 solver.cpp:266] Iteration 4400 (15.9041 iter/s, 6.28768s/100 iter), loss = 0.681291
I0122 17:05:06.569689 64218 solver.cpp:285]     Train net output #0: loss = 0.681291 (* 1 = 0.681291 loss)
I0122 17:05:06.569694 64218 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0122 17:05:12.853040 64218 solver.cpp:266] Iteration 4500 (15.9157 iter/s, 6.28311s/100 iter), loss = 0.416642
I0122 17:05:12.853082 64218 solver.cpp:285]     Train net output #0: loss = 0.416642 (* 1 = 0.416642 loss)
I0122 17:05:12.853090 64218 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0122 17:05:19.119536 64218 solver.cpp:266] Iteration 4600 (15.9586 iter/s, 6.26621s/100 iter), loss = 0.657684
I0122 17:05:19.119567 64218 solver.cpp:285]     Train net output #0: loss = 0.657684 (* 1 = 0.657684 loss)
I0122 17:05:19.119573 64218 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0122 17:05:25.405055 64218 solver.cpp:266] Iteration 4700 (15.9103 iter/s, 6.28524s/100 iter), loss = 0.687578
I0122 17:05:25.405083 64218 solver.cpp:285]     Train net output #0: loss = 0.687578 (* 1 = 0.687578 loss)
I0122 17:05:25.405089 64218 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0122 17:05:31.699404 64218 solver.cpp:266] Iteration 4800 (15.888 iter/s, 6.29407s/100 iter), loss = 0.528002
I0122 17:05:31.699499 64218 solver.cpp:285]     Train net output #0: loss = 0.528002 (* 1 = 0.528002 loss)
I0122 17:05:31.699507 64218 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0122 17:05:37.971904 64218 solver.cpp:266] Iteration 4900 (15.9435 iter/s, 6.27216s/100 iter), loss = 0.491155
I0122 17:05:37.971943 64218 solver.cpp:285]     Train net output #0: loss = 0.491155 (* 1 = 0.491155 loss)
I0122 17:05:37.971951 64218 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0122 17:05:44.179024 64218 solver.cpp:418] Iteration 5000, Testing net (#0)
I0122 17:05:45.643517 64218 solver.cpp:517]     Test net output #0: accuracy = 0.353889
I0122 17:05:45.643543 64218 solver.cpp:517]     Test net output #1: loss = 3.19469 (* 1 = 3.19469 loss)
I0122 17:05:45.643548 64218 solver.cpp:517]     Test net output #2: top-1 = 0.353889
I0122 17:05:45.643550 64218 solver.cpp:517]     Test net output #3: top-5 = 0.821444
I0122 17:05:45.706207 64218 solver.cpp:266] Iteration 5000 (12.93 iter/s, 7.73397s/100 iter), loss = 0.630112
I0122 17:05:45.706226 64218 solver.cpp:285]     Train net output #0: loss = 0.630112 (* 1 = 0.630112 loss)
I0122 17:05:45.706231 64218 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0122 17:05:51.968252 64218 solver.cpp:266] Iteration 5100 (15.9699 iter/s, 6.26178s/100 iter), loss = 0.430784
I0122 17:05:51.968281 64218 solver.cpp:285]     Train net output #0: loss = 0.430784 (* 1 = 0.430784 loss)
I0122 17:05:51.968286 64218 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0122 17:05:58.235421 64218 solver.cpp:266] Iteration 5200 (15.9569 iter/s, 6.2669s/100 iter), loss = 0.563418
I0122 17:05:58.235460 64218 solver.cpp:285]     Train net output #0: loss = 0.563418 (* 1 = 0.563418 loss)
I0122 17:05:58.235466 64218 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0122 17:06:04.501829 64218 solver.cpp:266] Iteration 5300 (15.9588 iter/s, 6.26613s/100 iter), loss = 0.600417
I0122 17:06:04.501895 64218 solver.cpp:285]     Train net output #0: loss = 0.600417 (* 1 = 0.600417 loss)
I0122 17:06:04.501901 64218 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0122 17:06:10.796906 64218 solver.cpp:266] Iteration 5400 (15.8862 iter/s, 6.29477s/100 iter), loss = 0.52509
I0122 17:06:10.796937 64218 solver.cpp:285]     Train net output #0: loss = 0.52509 (* 1 = 0.52509 loss)
I0122 17:06:10.796943 64218 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0122 17:06:17.070438 64218 solver.cpp:266] Iteration 5500 (15.9407 iter/s, 6.27326s/100 iter), loss = 0.575375
I0122 17:06:17.070480 64218 solver.cpp:285]     Train net output #0: loss = 0.575375 (* 1 = 0.575375 loss)
I0122 17:06:17.070487 64218 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0122 17:06:23.333393 64218 solver.cpp:266] Iteration 5600 (15.9676 iter/s, 6.26267s/100 iter), loss = 0.570814
I0122 17:06:23.333423 64218 solver.cpp:285]     Train net output #0: loss = 0.570814 (* 1 = 0.570814 loss)
I0122 17:06:23.333429 64218 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0122 17:06:29.616194 64218 solver.cpp:266] Iteration 5700 (15.9172 iter/s, 6.28253s/100 iter), loss = 0.446092
I0122 17:06:29.616225 64218 solver.cpp:285]     Train net output #0: loss = 0.446092 (* 1 = 0.446092 loss)
I0122 17:06:29.616230 64218 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0122 17:06:35.897192 64218 solver.cpp:266] Iteration 5800 (15.9217 iter/s, 6.28072s/100 iter), loss = 0.636296
I0122 17:06:35.897291 64218 solver.cpp:285]     Train net output #0: loss = 0.636296 (* 1 = 0.636296 loss)
I0122 17:06:35.897297 64218 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0122 17:06:42.162334 64218 solver.cpp:266] Iteration 5900 (15.9622 iter/s, 6.2648s/100 iter), loss = 0.723793
I0122 17:06:42.162364 64218 solver.cpp:285]     Train net output #0: loss = 0.723793 (* 1 = 0.723793 loss)
I0122 17:06:42.162369 64218 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0122 17:06:48.369484 64218 solver.cpp:418] Iteration 6000, Testing net (#0)
I0122 17:06:49.839665 64218 solver.cpp:517]     Test net output #0: accuracy = 0.681778
I0122 17:06:49.839691 64218 solver.cpp:517]     Test net output #1: loss = 0.998328 (* 1 = 0.998328 loss)
I0122 17:06:49.839695 64218 solver.cpp:517]     Test net output #2: top-1 = 0.681778
I0122 17:06:49.839699 64218 solver.cpp:517]     Test net output #3: top-5 = 0.962778
I0122 17:06:49.901908 64218 solver.cpp:266] Iteration 6000 (12.9212 iter/s, 7.73924s/100 iter), loss = 0.477444
I0122 17:06:49.901940 64218 solver.cpp:285]     Train net output #0: loss = 0.477444 (* 1 = 0.477444 loss)
I0122 17:06:49.901947 64218 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0122 17:06:56.164144 64218 solver.cpp:266] Iteration 6100 (15.9694 iter/s, 6.26197s/100 iter), loss = 0.396846
I0122 17:06:56.164175 64218 solver.cpp:285]     Train net output #0: loss = 0.396846 (* 1 = 0.396846 loss)
I0122 17:06:56.164180 64218 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0122 17:07:02.450959 64218 solver.cpp:266] Iteration 6200 (15.907 iter/s, 6.28654s/100 iter), loss = 0.484741
I0122 17:07:02.450999 64218 solver.cpp:285]     Train net output #0: loss = 0.484741 (* 1 = 0.484741 loss)
I0122 17:07:02.451004 64218 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0122 17:07:08.733575 64218 solver.cpp:266] Iteration 6300 (15.9177 iter/s, 6.28233s/100 iter), loss = 0.512145
I0122 17:07:08.733700 64218 solver.cpp:285]     Train net output #0: loss = 0.512145 (* 1 = 0.512145 loss)
I0122 17:07:08.733706 64218 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0122 17:07:14.993646 64218 solver.cpp:266] Iteration 6400 (15.9752 iter/s, 6.2597s/100 iter), loss = 0.474107
I0122 17:07:14.993675 64218 solver.cpp:285]     Train net output #0: loss = 0.474107 (* 1 = 0.474107 loss)
I0122 17:07:14.993681 64218 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0122 17:07:21.272835 64218 solver.cpp:266] Iteration 6500 (15.9263 iter/s, 6.27892s/100 iter), loss = 0.702613
I0122 17:07:21.272864 64218 solver.cpp:285]     Train net output #0: loss = 0.702613 (* 1 = 0.702613 loss)
I0122 17:07:21.272871 64218 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0122 17:07:27.534328 64218 solver.cpp:266] Iteration 6600 (15.9713 iter/s, 6.26122s/100 iter), loss = 0.538209
I0122 17:07:27.534358 64218 solver.cpp:285]     Train net output #0: loss = 0.538209 (* 1 = 0.538209 loss)
I0122 17:07:27.534363 64218 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0122 17:07:33.786643 64218 solver.cpp:266] Iteration 6700 (15.9948 iter/s, 6.25204s/100 iter), loss = 0.454453
I0122 17:07:33.786672 64218 solver.cpp:285]     Train net output #0: loss = 0.454453 (* 1 = 0.454453 loss)
I0122 17:07:33.786677 64218 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0122 17:07:40.071804 64218 solver.cpp:266] Iteration 6800 (15.9112 iter/s, 6.28489s/100 iter), loss = 0.475208
I0122 17:07:40.071909 64218 solver.cpp:285]     Train net output #0: loss = 0.475208 (* 1 = 0.475208 loss)
I0122 17:07:40.071915 64218 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0122 17:07:46.348884 64218 solver.cpp:266] Iteration 6900 (15.9319 iter/s, 6.27673s/100 iter), loss = 0.488271
I0122 17:07:46.348923 64218 solver.cpp:285]     Train net output #0: loss = 0.488271 (* 1 = 0.488271 loss)
I0122 17:07:46.348930 64218 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0122 17:07:52.562785 64218 solver.cpp:418] Iteration 7000, Testing net (#0)
I0122 17:07:54.038436 64218 solver.cpp:517]     Test net output #0: accuracy = 0.603555
I0122 17:07:54.038462 64218 solver.cpp:517]     Test net output #1: loss = 1.4267 (* 1 = 1.4267 loss)
I0122 17:07:54.038468 64218 solver.cpp:517]     Test net output #2: top-1 = 0.603555
I0122 17:07:54.038471 64218 solver.cpp:517]     Test net output #3: top-5 = 0.964111
I0122 17:07:54.101159 64218 solver.cpp:266] Iteration 7000 (12.9 iter/s, 7.75194s/100 iter), loss = 0.379201
I0122 17:07:54.101179 64218 solver.cpp:285]     Train net output #0: loss = 0.379201 (* 1 = 0.379201 loss)
I0122 17:07:54.101186 64218 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0122 17:08:00.345324 64218 solver.cpp:266] Iteration 7100 (16.0156 iter/s, 6.2439s/100 iter), loss = 0.720759
I0122 17:08:00.345351 64218 solver.cpp:285]     Train net output #0: loss = 0.720759 (* 1 = 0.720759 loss)
I0122 17:08:00.345357 64218 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0122 17:08:06.631608 64218 solver.cpp:266] Iteration 7200 (15.9083 iter/s, 6.28601s/100 iter), loss = 0.498259
I0122 17:08:06.631635 64218 solver.cpp:285]     Train net output #0: loss = 0.498259 (* 1 = 0.498259 loss)
I0122 17:08:06.631641 64218 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0122 17:08:12.893939 64218 solver.cpp:266] Iteration 7300 (15.9692 iter/s, 6.26206s/100 iter), loss = 0.556979
I0122 17:08:12.894022 64218 solver.cpp:285]     Train net output #0: loss = 0.556979 (* 1 = 0.556979 loss)
I0122 17:08:12.894029 64218 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0122 17:08:19.174314 64218 solver.cpp:266] Iteration 7400 (15.9234 iter/s, 6.28005s/100 iter), loss = 0.409164
I0122 17:08:19.174343 64218 solver.cpp:285]     Train net output #0: loss = 0.409164 (* 1 = 0.409164 loss)
I0122 17:08:19.174365 64218 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0122 17:08:25.454099 64218 solver.cpp:266] Iteration 7500 (15.9248 iter/s, 6.27951s/100 iter), loss = 0.518081
I0122 17:08:25.454128 64218 solver.cpp:285]     Train net output #0: loss = 0.518081 (* 1 = 0.518081 loss)
I0122 17:08:25.454134 64218 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0122 17:08:31.719002 64218 solver.cpp:266] Iteration 7600 (15.9626 iter/s, 6.26463s/100 iter), loss = 0.415282
I0122 17:08:31.719029 64218 solver.cpp:285]     Train net output #0: loss = 0.415282 (* 1 = 0.415282 loss)
I0122 17:08:31.719035 64218 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0122 17:08:37.986205 64218 solver.cpp:266] Iteration 7700 (15.9568 iter/s, 6.26693s/100 iter), loss = 0.434642
I0122 17:08:37.986235 64218 solver.cpp:285]     Train net output #0: loss = 0.434642 (* 1 = 0.434642 loss)
I0122 17:08:37.986240 64218 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0122 17:08:44.258890 64218 solver.cpp:266] Iteration 7800 (15.9428 iter/s, 6.27241s/100 iter), loss = 0.482292
I0122 17:08:44.258965 64218 solver.cpp:285]     Train net output #0: loss = 0.482292 (* 1 = 0.482292 loss)
I0122 17:08:44.258972 64218 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0122 17:08:50.503784 64218 solver.cpp:266] Iteration 7900 (16.0139 iter/s, 6.24458s/100 iter), loss = 0.458533
I0122 17:08:50.503814 64218 solver.cpp:285]     Train net output #0: loss = 0.458533 (* 1 = 0.458533 loss)
I0122 17:08:50.503819 64218 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0122 17:08:56.738329 64218 solver.cpp:418] Iteration 8000, Testing net (#0)
I0122 17:08:58.206267 64218 solver.cpp:517]     Test net output #0: accuracy = 0.457555
I0122 17:08:58.206295 64218 solver.cpp:517]     Test net output #1: loss = 2.35416 (* 1 = 2.35416 loss)
I0122 17:08:58.206300 64218 solver.cpp:517]     Test net output #2: top-1 = 0.457555
I0122 17:08:58.206303 64218 solver.cpp:517]     Test net output #3: top-5 = 0.902111
I0122 17:08:58.269250 64218 solver.cpp:266] Iteration 8000 (12.8781 iter/s, 7.76514s/100 iter), loss = 0.352352
I0122 17:08:58.269281 64218 solver.cpp:285]     Train net output #0: loss = 0.352352 (* 1 = 0.352352 loss)
I0122 17:08:58.269287 64218 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0122 17:09:04.540339 64218 solver.cpp:266] Iteration 8100 (15.9469 iter/s, 6.27081s/100 iter), loss = 0.564125
I0122 17:09:04.540367 64218 solver.cpp:285]     Train net output #0: loss = 0.564125 (* 1 = 0.564125 loss)
I0122 17:09:04.540374 64218 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0122 17:09:10.808583 64218 solver.cpp:266] Iteration 8200 (15.9541 iter/s, 6.26797s/100 iter), loss = 0.602894
I0122 17:09:10.808624 64218 solver.cpp:285]     Train net output #0: loss = 0.602894 (* 1 = 0.602894 loss)
I0122 17:09:10.808629 64218 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0122 17:09:17.070731 64218 solver.cpp:266] Iteration 8300 (15.9697 iter/s, 6.26187s/100 iter), loss = 0.451101
I0122 17:09:17.070806 64218 solver.cpp:285]     Train net output #0: loss = 0.451101 (* 1 = 0.451101 loss)
I0122 17:09:17.070812 64218 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0122 17:09:23.333205 64218 solver.cpp:266] Iteration 8400 (15.9689 iter/s, 6.26216s/100 iter), loss = 0.322735
I0122 17:09:23.333235 64218 solver.cpp:285]     Train net output #0: loss = 0.322735 (* 1 = 0.322735 loss)
I0122 17:09:23.333240 64218 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0122 17:09:29.612231 64218 solver.cpp:266] Iteration 8500 (15.9267 iter/s, 6.27875s/100 iter), loss = 0.602343
I0122 17:09:29.612270 64218 solver.cpp:285]     Train net output #0: loss = 0.602343 (* 1 = 0.602343 loss)
I0122 17:09:29.612277 64218 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0122 17:09:35.885840 64218 solver.cpp:266] Iteration 8600 (15.9405 iter/s, 6.27333s/100 iter), loss = 0.392096
I0122 17:09:35.885871 64218 solver.cpp:285]     Train net output #0: loss = 0.392096 (* 1 = 0.392096 loss)
I0122 17:09:35.885876 64218 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0122 17:09:42.152009 64218 solver.cpp:266] Iteration 8700 (15.9594 iter/s, 6.26589s/100 iter), loss = 0.410024
I0122 17:09:42.152040 64218 solver.cpp:285]     Train net output #0: loss = 0.410024 (* 1 = 0.410024 loss)
I0122 17:09:42.152046 64218 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0122 17:09:48.428818 64218 solver.cpp:266] Iteration 8800 (15.9324 iter/s, 6.27654s/100 iter), loss = 0.533433
I0122 17:09:48.428933 64218 solver.cpp:285]     Train net output #0: loss = 0.533433 (* 1 = 0.533433 loss)
I0122 17:09:48.428939 64218 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0122 17:09:54.685359 64218 solver.cpp:266] Iteration 8900 (15.9842 iter/s, 6.25618s/100 iter), loss = 0.531568
I0122 17:09:54.685387 64218 solver.cpp:285]     Train net output #0: loss = 0.531568 (* 1 = 0.531568 loss)
I0122 17:09:54.685392 64218 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0122 17:10:00.898070 64218 solver.cpp:418] Iteration 9000, Testing net (#0)
I0122 17:10:02.367183 64218 solver.cpp:517]     Test net output #0: accuracy = 0.638
I0122 17:10:02.367210 64218 solver.cpp:517]     Test net output #1: loss = 1.12431 (* 1 = 1.12431 loss)
I0122 17:10:02.367214 64218 solver.cpp:517]     Test net output #2: top-1 = 0.638
I0122 17:10:02.367218 64218 solver.cpp:517]     Test net output #3: top-5 = 0.964223
I0122 17:10:02.429210 64218 solver.cpp:266] Iteration 9000 (12.914 iter/s, 7.74353s/100 iter), loss = 0.478374
I0122 17:10:02.429230 64218 solver.cpp:285]     Train net output #0: loss = 0.478374 (* 1 = 0.478374 loss)
I0122 17:10:02.429235 64218 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0122 17:10:08.689282 64218 solver.cpp:266] Iteration 9100 (15.9749 iter/s, 6.25981s/100 iter), loss = 0.371375
I0122 17:10:08.689322 64218 solver.cpp:285]     Train net output #0: loss = 0.371375 (* 1 = 0.371375 loss)
I0122 17:10:08.689329 64218 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0122 17:10:14.971745 64218 solver.cpp:266] Iteration 9200 (15.918 iter/s, 6.28218s/100 iter), loss = 0.569353
I0122 17:10:14.971774 64218 solver.cpp:285]     Train net output #0: loss = 0.569353 (* 1 = 0.569353 loss)
I0122 17:10:14.971781 64218 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0122 17:10:21.248735 64218 solver.cpp:266] Iteration 9300 (15.9319 iter/s, 6.27672s/100 iter), loss = 0.426938
I0122 17:10:21.248837 64218 solver.cpp:285]     Train net output #0: loss = 0.426938 (* 1 = 0.426938 loss)
I0122 17:10:21.248843 64218 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0122 17:10:27.514166 64218 solver.cpp:266] Iteration 9400 (15.9615 iter/s, 6.26509s/100 iter), loss = 0.495651
I0122 17:10:27.514196 64218 solver.cpp:285]     Train net output #0: loss = 0.495651 (* 1 = 0.495651 loss)
I0122 17:10:27.514202 64218 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0122 17:10:33.766245 64218 solver.cpp:266] Iteration 9500 (15.9954 iter/s, 6.25181s/100 iter), loss = 0.30908
I0122 17:10:33.766285 64218 solver.cpp:285]     Train net output #0: loss = 0.30908 (* 1 = 0.30908 loss)
I0122 17:10:33.766291 64218 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0122 17:10:40.021956 64218 solver.cpp:266] Iteration 9600 (15.9861 iter/s, 6.25543s/100 iter), loss = 0.477014
I0122 17:10:40.021984 64218 solver.cpp:285]     Train net output #0: loss = 0.477014 (* 1 = 0.477014 loss)
I0122 17:10:40.021991 64218 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0122 17:10:46.275190 64218 solver.cpp:266] Iteration 9700 (15.9924 iter/s, 6.25296s/100 iter), loss = 0.475628
I0122 17:10:46.275218 64218 solver.cpp:285]     Train net output #0: loss = 0.475628 (* 1 = 0.475628 loss)
I0122 17:10:46.275224 64218 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0122 17:10:52.543401 64218 solver.cpp:266] Iteration 9800 (15.9542 iter/s, 6.26794s/100 iter), loss = 0.381351
I0122 17:10:52.543524 64218 solver.cpp:285]     Train net output #0: loss = 0.381351 (* 1 = 0.381351 loss)
I0122 17:10:52.543529 64218 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0122 17:10:58.805583 64218 solver.cpp:266] Iteration 9900 (15.9698 iter/s, 6.26182s/100 iter), loss = 0.471862
I0122 17:10:58.805613 64218 solver.cpp:285]     Train net output #0: loss = 0.471862 (* 1 = 0.471862 loss)
I0122 17:10:58.805619 64218 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0122 17:11:05.014190 64218 solver.cpp:418] Iteration 10000, Testing net (#0)
I0122 17:11:06.496549 64218 solver.cpp:517]     Test net output #0: accuracy = 0.582889
I0122 17:11:06.496577 64218 solver.cpp:517]     Test net output #1: loss = 1.29166 (* 1 = 1.29166 loss)
I0122 17:11:06.496582 64218 solver.cpp:517]     Test net output #2: top-1 = 0.582889
I0122 17:11:06.496585 64218 solver.cpp:517]     Test net output #3: top-5 = 0.957334
I0122 17:11:06.559161 64218 solver.cpp:266] Iteration 10000 (12.8978 iter/s, 7.75325s/100 iter), loss = 0.566057
I0122 17:11:06.559181 64218 solver.cpp:285]     Train net output #0: loss = 0.566057 (* 1 = 0.566057 loss)
I0122 17:11:06.559188 64218 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0122 17:11:12.812595 64218 solver.cpp:266] Iteration 10100 (15.9919 iter/s, 6.25317s/100 iter), loss = 0.383686
I0122 17:11:12.812635 64218 solver.cpp:285]     Train net output #0: loss = 0.383686 (* 1 = 0.383686 loss)
I0122 17:11:12.812642 64218 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0122 17:11:19.095630 64218 solver.cpp:266] Iteration 10200 (15.9166 iter/s, 6.28275s/100 iter), loss = 0.271836
I0122 17:11:19.095659 64218 solver.cpp:285]     Train net output #0: loss = 0.271836 (* 1 = 0.271836 loss)
I0122 17:11:19.095665 64218 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0122 17:11:25.367106 64218 solver.cpp:266] Iteration 10300 (15.9459 iter/s, 6.2712s/100 iter), loss = 0.234522
I0122 17:11:25.367182 64218 solver.cpp:285]     Train net output #0: loss = 0.234522 (* 1 = 0.234522 loss)
I0122 17:11:25.367189 64218 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0122 17:11:31.630383 64218 solver.cpp:266] Iteration 10400 (15.9669 iter/s, 6.26296s/100 iter), loss = 0.322251
I0122 17:11:31.630412 64218 solver.cpp:285]     Train net output #0: loss = 0.322251 (* 1 = 0.322251 loss)
I0122 17:11:31.630419 64218 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0122 17:11:37.900972 64218 solver.cpp:266] Iteration 10500 (15.9482 iter/s, 6.27032s/100 iter), loss = 0.26901
I0122 17:11:37.901000 64218 solver.cpp:285]     Train net output #0: loss = 0.26901 (* 1 = 0.26901 loss)
I0122 17:11:37.901006 64218 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0122 17:11:44.170627 64218 solver.cpp:266] Iteration 10600 (15.9505 iter/s, 6.26938s/100 iter), loss = 0.27378
I0122 17:11:44.170668 64218 solver.cpp:285]     Train net output #0: loss = 0.27378 (* 1 = 0.27378 loss)
I0122 17:11:44.170675 64218 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0122 17:11:50.442492 64218 solver.cpp:266] Iteration 10700 (15.9449 iter/s, 6.27158s/100 iter), loss = 0.278576
I0122 17:11:50.442522 64218 solver.cpp:285]     Train net output #0: loss = 0.278576 (* 1 = 0.278576 loss)
I0122 17:11:50.442528 64218 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0122 17:11:56.723294 64218 solver.cpp:266] Iteration 10800 (15.9222 iter/s, 6.28053s/100 iter), loss = 0.236032
I0122 17:11:56.723390 64218 solver.cpp:285]     Train net output #0: loss = 0.236032 (* 1 = 0.236032 loss)
I0122 17:11:56.723397 64218 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0122 17:12:02.989523 64218 solver.cpp:266] Iteration 10900 (15.9594 iter/s, 6.26589s/100 iter), loss = 0.220214
I0122 17:12:02.989552 64218 solver.cpp:285]     Train net output #0: loss = 0.220214 (* 1 = 0.220214 loss)
I0122 17:12:02.989558 64218 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0122 17:12:09.187188 64218 solver.cpp:418] Iteration 11000, Testing net (#0)
I0122 17:12:10.658397 64218 solver.cpp:517]     Test net output #0: accuracy = 0.804777
I0122 17:12:10.658423 64218 solver.cpp:517]     Test net output #1: loss = 0.655865 (* 1 = 0.655865 loss)
I0122 17:12:10.658427 64218 solver.cpp:517]     Test net output #2: top-1 = 0.804777
I0122 17:12:10.658432 64218 solver.cpp:517]     Test net output #3: top-5 = 0.976445
I0122 17:12:10.721186 64218 solver.cpp:266] Iteration 11000 (12.9344 iter/s, 7.73134s/100 iter), loss = 0.271104
I0122 17:12:10.721217 64218 solver.cpp:285]     Train net output #0: loss = 0.271104 (* 1 = 0.271104 loss)
I0122 17:12:10.721225 64218 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0122 17:12:16.980860 64218 solver.cpp:266] Iteration 11100 (15.9759 iter/s, 6.25941s/100 iter), loss = 0.228013
I0122 17:12:16.980890 64218 solver.cpp:285]     Train net output #0: loss = 0.228013 (* 1 = 0.228013 loss)
I0122 17:12:16.980895 64218 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0122 17:12:23.239878 64218 solver.cpp:266] Iteration 11200 (15.9776 iter/s, 6.25875s/100 iter), loss = 0.14163
I0122 17:12:23.239907 64218 solver.cpp:285]     Train net output #0: loss = 0.14163 (* 1 = 0.14163 loss)
I0122 17:12:23.239912 64218 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0122 17:12:29.511394 64218 solver.cpp:266] Iteration 11300 (15.9458 iter/s, 6.27124s/100 iter), loss = 0.157528
I0122 17:12:29.511478 64218 solver.cpp:285]     Train net output #0: loss = 0.157528 (* 1 = 0.157528 loss)
I0122 17:12:29.511485 64218 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0122 17:12:35.767679 64218 solver.cpp:266] Iteration 11400 (15.9848 iter/s, 6.25596s/100 iter), loss = 0.128527
I0122 17:12:35.767707 64218 solver.cpp:285]     Train net output #0: loss = 0.128527 (* 1 = 0.128527 loss)
I0122 17:12:35.767714 64218 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0122 17:12:42.042912 64218 solver.cpp:266] Iteration 11500 (15.9363 iter/s, 6.27496s/100 iter), loss = 0.20788
I0122 17:12:42.042940 64218 solver.cpp:285]     Train net output #0: loss = 0.20788 (* 1 = 0.20788 loss)
I0122 17:12:42.042946 64218 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0122 17:12:48.322382 64218 solver.cpp:266] Iteration 11600 (15.9256 iter/s, 6.2792s/100 iter), loss = 0.139032
I0122 17:12:48.322412 64218 solver.cpp:285]     Train net output #0: loss = 0.139032 (* 1 = 0.139032 loss)
I0122 17:12:48.322417 64218 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0122 17:12:54.571236 64218 solver.cpp:266] Iteration 11700 (16.0036 iter/s, 6.24858s/100 iter), loss = 0.170852
I0122 17:12:54.571266 64218 solver.cpp:285]     Train net output #0: loss = 0.170852 (* 1 = 0.170852 loss)
I0122 17:12:54.571272 64218 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0122 17:13:00.829313 64218 solver.cpp:266] Iteration 11800 (15.98 iter/s, 6.2578s/100 iter), loss = 0.178797
I0122 17:13:00.829377 64218 solver.cpp:285]     Train net output #0: loss = 0.178797 (* 1 = 0.178797 loss)
I0122 17:13:00.829383 64218 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0122 17:13:07.088456 64218 solver.cpp:266] Iteration 11900 (15.9774 iter/s, 6.25884s/100 iter), loss = 0.155719
I0122 17:13:07.088495 64218 solver.cpp:285]     Train net output #0: loss = 0.155719 (* 1 = 0.155719 loss)
I0122 17:13:07.088501 64218 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0122 17:13:13.300796 64218 solver.cpp:418] Iteration 12000, Testing net (#0)
I0122 17:13:14.756661 64218 solver.cpp:517]     Test net output #0: accuracy = 0.667
I0122 17:13:14.756690 64218 solver.cpp:517]     Test net output #1: loss = 1.04871 (* 1 = 1.04871 loss)
I0122 17:13:14.756693 64218 solver.cpp:517]     Test net output #2: top-1 = 0.667
I0122 17:13:14.756697 64218 solver.cpp:517]     Test net output #3: top-5 = 0.933889
I0122 17:13:14.819502 64218 solver.cpp:266] Iteration 12000 (12.9354 iter/s, 7.73071s/100 iter), loss = 0.110507
I0122 17:13:14.819533 64218 solver.cpp:285]     Train net output #0: loss = 0.110507 (* 1 = 0.110507 loss)
I0122 17:13:14.819540 64218 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0122 17:13:21.069730 64218 solver.cpp:266] Iteration 12100 (16.0001 iter/s, 6.24996s/100 iter), loss = 0.0896993
I0122 17:13:21.069759 64218 solver.cpp:285]     Train net output #0: loss = 0.0896993 (* 1 = 0.0896993 loss)
I0122 17:13:21.069764 64218 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0122 17:13:27.348721 64218 solver.cpp:266] Iteration 12200 (15.9268 iter/s, 6.27872s/100 iter), loss = 0.147041
I0122 17:13:27.348749 64218 solver.cpp:285]     Train net output #0: loss = 0.147041 (* 1 = 0.147041 loss)
I0122 17:13:27.348755 64218 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0122 17:13:33.629935 64218 solver.cpp:266] Iteration 12300 (15.9212 iter/s, 6.28094s/100 iter), loss = 0.124082
I0122 17:13:33.630017 64218 solver.cpp:285]     Train net output #0: loss = 0.124082 (* 1 = 0.124082 loss)
I0122 17:13:33.630024 64218 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0122 17:13:39.893853 64218 solver.cpp:266] Iteration 12400 (15.9653 iter/s, 6.2636s/100 iter), loss = 0.1989
I0122 17:13:39.893896 64218 solver.cpp:285]     Train net output #0: loss = 0.1989 (* 1 = 0.1989 loss)
I0122 17:13:39.893906 64218 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0122 17:13:46.149581 64218 solver.cpp:266] Iteration 12500 (15.9861 iter/s, 6.25544s/100 iter), loss = 0.137989
I0122 17:13:46.149612 64218 solver.cpp:285]     Train net output #0: loss = 0.137989 (* 1 = 0.137989 loss)
I0122 17:13:46.149618 64218 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0122 17:13:52.403448 64218 solver.cpp:266] Iteration 12600 (15.9908 iter/s, 6.25359s/100 iter), loss = 0.1242
I0122 17:13:52.403479 64218 solver.cpp:285]     Train net output #0: loss = 0.124199 (* 1 = 0.124199 loss)
I0122 17:13:52.403486 64218 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0122 17:13:58.671766 64218 solver.cpp:266] Iteration 12700 (15.9539 iter/s, 6.26804s/100 iter), loss = 0.131932
I0122 17:13:58.671797 64218 solver.cpp:285]     Train net output #0: loss = 0.131932 (* 1 = 0.131932 loss)
I0122 17:13:58.671802 64218 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0122 17:14:04.960724 64218 solver.cpp:266] Iteration 12800 (15.9016 iter/s, 6.28868s/100 iter), loss = 0.201801
I0122 17:14:04.960789 64218 solver.cpp:285]     Train net output #0: loss = 0.201801 (* 1 = 0.201801 loss)
I0122 17:14:04.960796 64218 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0122 17:14:11.208737 64218 solver.cpp:266] Iteration 12900 (16.0059 iter/s, 6.24771s/100 iter), loss = 0.0404426
I0122 17:14:11.208770 64218 solver.cpp:285]     Train net output #0: loss = 0.0404426 (* 1 = 0.0404426 loss)
I0122 17:14:11.208775 64218 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0122 17:14:17.400668 64218 solver.cpp:418] Iteration 13000, Testing net (#0)
I0122 17:14:18.855540 64218 solver.cpp:517]     Test net output #0: accuracy = 0.599556
I0122 17:14:18.855567 64218 solver.cpp:517]     Test net output #1: loss = 1.22786 (* 1 = 1.22786 loss)
I0122 17:14:18.855571 64218 solver.cpp:517]     Test net output #2: top-1 = 0.599556
I0122 17:14:18.855576 64218 solver.cpp:517]     Test net output #3: top-5 = 0.927667
I0122 17:14:18.917548 64218 solver.cpp:266] Iteration 13000 (12.9727 iter/s, 7.70849s/100 iter), loss = 0.0955092
I0122 17:14:18.917569 64218 solver.cpp:285]     Train net output #0: loss = 0.0955092 (* 1 = 0.0955092 loss)
I0122 17:14:18.917575 64218 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0122 17:14:25.176697 64218 solver.cpp:266] Iteration 13100 (15.9773 iter/s, 6.25889s/100 iter), loss = 0.124461
I0122 17:14:25.176726 64218 solver.cpp:285]     Train net output #0: loss = 0.124461 (* 1 = 0.124461 loss)
I0122 17:14:25.176731 64218 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0122 17:14:31.460906 64218 solver.cpp:266] Iteration 13200 (15.9136 iter/s, 6.28394s/100 iter), loss = 0.13432
I0122 17:14:31.460935 64218 solver.cpp:285]     Train net output #0: loss = 0.13432 (* 1 = 0.13432 loss)
I0122 17:14:31.460942 64218 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0122 17:14:37.743028 64218 solver.cpp:266] Iteration 13300 (15.9189 iter/s, 6.28185s/100 iter), loss = 0.15012
I0122 17:14:37.743203 64218 solver.cpp:285]     Train net output #0: loss = 0.15012 (* 1 = 0.15012 loss)
I0122 17:14:37.743224 64218 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0122 17:14:44.026334 64218 solver.cpp:266] Iteration 13400 (15.9162 iter/s, 6.2829s/100 iter), loss = 0.128189
I0122 17:14:44.026374 64218 solver.cpp:285]     Train net output #0: loss = 0.128189 (* 1 = 0.128189 loss)
I0122 17:14:44.026381 64218 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0122 17:14:50.306200 64218 solver.cpp:266] Iteration 13500 (15.9246 iter/s, 6.27958s/100 iter), loss = 0.0957963
I0122 17:14:50.306227 64218 solver.cpp:285]     Train net output #0: loss = 0.0957963 (* 1 = 0.0957963 loss)
I0122 17:14:50.306232 64218 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0122 17:14:56.560322 64218 solver.cpp:266] Iteration 13600 (15.9901 iter/s, 6.25385s/100 iter), loss = 0.0520561
I0122 17:14:56.560353 64218 solver.cpp:285]     Train net output #0: loss = 0.0520561 (* 1 = 0.0520561 loss)
I0122 17:14:56.560359 64218 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0122 17:15:02.838423 64218 solver.cpp:266] Iteration 13700 (15.9291 iter/s, 6.27783s/100 iter), loss = 0.0683967
I0122 17:15:02.838454 64218 solver.cpp:285]     Train net output #0: loss = 0.0683966 (* 1 = 0.0683966 loss)
I0122 17:15:02.838459 64218 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0122 17:15:09.123982 64218 solver.cpp:266] Iteration 13800 (15.9102 iter/s, 6.28529s/100 iter), loss = 0.114632
I0122 17:15:09.124049 64218 solver.cpp:285]     Train net output #0: loss = 0.114632 (* 1 = 0.114632 loss)
I0122 17:15:09.124056 64218 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0122 17:15:15.386554 64218 solver.cpp:266] Iteration 13900 (15.9687 iter/s, 6.26226s/100 iter), loss = 0.0744611
I0122 17:15:15.386584 64218 solver.cpp:285]     Train net output #0: loss = 0.0744611 (* 1 = 0.0744611 loss)
I0122 17:15:15.386590 64218 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0122 17:15:21.601747 64218 solver.cpp:418] Iteration 14000, Testing net (#0)
I0122 17:15:23.065255 64218 solver.cpp:517]     Test net output #0: accuracy = 0.688444
I0122 17:15:23.065282 64218 solver.cpp:517]     Test net output #1: loss = 0.989285 (* 1 = 0.989285 loss)
I0122 17:15:23.065287 64218 solver.cpp:517]     Test net output #2: top-1 = 0.688444
I0122 17:15:23.065290 64218 solver.cpp:517]     Test net output #3: top-5 = 0.938222
I0122 17:15:23.127012 64218 solver.cpp:266] Iteration 14000 (12.9197 iter/s, 7.74013s/100 iter), loss = 0.0543464
I0122 17:15:23.127043 64218 solver.cpp:285]     Train net output #0: loss = 0.0543464 (* 1 = 0.0543464 loss)
I0122 17:15:23.127050 64218 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0122 17:15:29.396584 64218 solver.cpp:266] Iteration 14100 (15.9507 iter/s, 6.2693s/100 iter), loss = 0.102429
I0122 17:15:29.396615 64218 solver.cpp:285]     Train net output #0: loss = 0.102429 (* 1 = 0.102429 loss)
I0122 17:15:29.396621 64218 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0122 17:15:35.642151 64218 solver.cpp:266] Iteration 14200 (16.0121 iter/s, 6.2453s/100 iter), loss = 0.069733
I0122 17:15:35.642181 64218 solver.cpp:285]     Train net output #0: loss = 0.069733 (* 1 = 0.069733 loss)
I0122 17:15:35.642187 64218 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0122 17:15:41.918179 64218 solver.cpp:266] Iteration 14300 (15.9343 iter/s, 6.27575s/100 iter), loss = 0.0909426
I0122 17:15:41.918282 64218 solver.cpp:285]     Train net output #0: loss = 0.0909426 (* 1 = 0.0909426 loss)
I0122 17:15:41.918288 64218 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0122 17:15:48.176841 64218 solver.cpp:266] Iteration 14400 (15.9787 iter/s, 6.25832s/100 iter), loss = 0.072023
I0122 17:15:48.176872 64218 solver.cpp:285]     Train net output #0: loss = 0.072023 (* 1 = 0.072023 loss)
I0122 17:15:48.176877 64218 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0122 17:15:54.453248 64218 solver.cpp:266] Iteration 14500 (15.9334 iter/s, 6.27613s/100 iter), loss = 0.110764
I0122 17:15:54.453277 64218 solver.cpp:285]     Train net output #0: loss = 0.110764 (* 1 = 0.110764 loss)
I0122 17:15:54.453284 64218 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0122 17:16:00.733183 64218 solver.cpp:266] Iteration 14600 (15.9244 iter/s, 6.27966s/100 iter), loss = 0.140075
I0122 17:16:00.733212 64218 solver.cpp:285]     Train net output #0: loss = 0.140075 (* 1 = 0.140075 loss)
I0122 17:16:00.733217 64218 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0122 17:16:06.995154 64218 solver.cpp:266] Iteration 14700 (15.9701 iter/s, 6.2617s/100 iter), loss = 0.0661887
I0122 17:16:06.995185 64218 solver.cpp:285]     Train net output #0: loss = 0.0661887 (* 1 = 0.0661887 loss)
I0122 17:16:06.995191 64218 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0122 17:16:13.244534 64218 solver.cpp:266] Iteration 14800 (16.0023 iter/s, 6.24911s/100 iter), loss = 0.11678
I0122 17:16:13.244617 64218 solver.cpp:285]     Train net output #0: loss = 0.11678 (* 1 = 0.11678 loss)
I0122 17:16:13.244624 64218 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0122 17:16:19.521631 64218 solver.cpp:266] Iteration 14900 (15.9318 iter/s, 6.27677s/100 iter), loss = 0.0707194
I0122 17:16:19.521670 64218 solver.cpp:285]     Train net output #0: loss = 0.0707193 (* 1 = 0.0707193 loss)
I0122 17:16:19.521677 64218 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0122 17:16:25.718194 64218 solver.cpp:418] Iteration 15000, Testing net (#0)
I0122 17:16:27.185252 64218 solver.cpp:517]     Test net output #0: accuracy = 0.694889
I0122 17:16:27.185289 64218 solver.cpp:517]     Test net output #1: loss = 0.959884 (* 1 = 0.959884 loss)
I0122 17:16:27.185294 64218 solver.cpp:517]     Test net output #2: top-1 = 0.694889
I0122 17:16:27.185297 64218 solver.cpp:517]     Test net output #3: top-5 = 0.971889
I0122 17:16:27.249061 64218 solver.cpp:266] Iteration 15000 (12.9415 iter/s, 7.7271s/100 iter), loss = 0.0406867
I0122 17:16:27.249092 64218 solver.cpp:285]     Train net output #0: loss = 0.0406867 (* 1 = 0.0406867 loss)
I0122 17:16:27.249099 64218 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0122 17:16:33.499583 64218 solver.cpp:266] Iteration 15100 (15.9993 iter/s, 6.25026s/100 iter), loss = 0.0428607
I0122 17:16:33.499613 64218 solver.cpp:285]     Train net output #0: loss = 0.0428607 (* 1 = 0.0428607 loss)
I0122 17:16:33.499617 64218 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0122 17:16:39.771982 64218 solver.cpp:266] Iteration 15200 (15.9436 iter/s, 6.27213s/100 iter), loss = 0.182874
I0122 17:16:39.772012 64218 solver.cpp:285]     Train net output #0: loss = 0.182874 (* 1 = 0.182874 loss)
I0122 17:16:39.772018 64218 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0122 17:16:46.037919 64218 solver.cpp:266] Iteration 15300 (15.96 iter/s, 6.26567s/100 iter), loss = 0.126047
I0122 17:16:46.038020 64218 solver.cpp:285]     Train net output #0: loss = 0.126047 (* 1 = 0.126047 loss)
I0122 17:16:46.038027 64218 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0122 17:16:52.297401 64218 solver.cpp:266] Iteration 15400 (15.9766 iter/s, 6.25914s/100 iter), loss = 0.126433
I0122 17:16:52.297430 64218 solver.cpp:285]     Train net output #0: loss = 0.126433 (* 1 = 0.126433 loss)
I0122 17:16:52.297436 64218 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0122 17:16:58.567685 64218 solver.cpp:266] Iteration 15500 (15.9489 iter/s, 6.27001s/100 iter), loss = 0.093863
I0122 17:16:58.567726 64218 solver.cpp:285]     Train net output #0: loss = 0.093863 (* 1 = 0.093863 loss)
I0122 17:16:58.567732 64218 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0122 17:17:04.817373 64218 solver.cpp:266] Iteration 15600 (16.0015 iter/s, 6.24941s/100 iter), loss = 0.0703308
I0122 17:17:04.817404 64218 solver.cpp:285]     Train net output #0: loss = 0.0703308 (* 1 = 0.0703308 loss)
I0122 17:17:04.817409 64218 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0122 17:17:11.081634 64218 solver.cpp:266] Iteration 15700 (15.9643 iter/s, 6.26399s/100 iter), loss = 0.132121
I0122 17:17:11.081665 64218 solver.cpp:285]     Train net output #0: loss = 0.132121 (* 1 = 0.132121 loss)
I0122 17:17:11.081671 64218 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0122 17:17:17.351608 64218 solver.cpp:266] Iteration 15800 (15.9497 iter/s, 6.2697s/100 iter), loss = 0.0710229
I0122 17:17:17.351732 64218 solver.cpp:285]     Train net output #0: loss = 0.0710229 (* 1 = 0.0710229 loss)
I0122 17:17:17.351740 64218 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0122 17:17:23.613402 64218 solver.cpp:266] Iteration 15900 (15.9708 iter/s, 6.26143s/100 iter), loss = 0.115421
I0122 17:17:23.613443 64218 solver.cpp:285]     Train net output #0: loss = 0.115421 (* 1 = 0.115421 loss)
I0122 17:17:23.613449 64218 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0122 17:17:29.823173 64218 solver.cpp:418] Iteration 16000, Testing net (#0)
I0122 17:17:31.283668 64218 solver.cpp:517]     Test net output #0: accuracy = 0.811333
I0122 17:17:31.283694 64218 solver.cpp:517]     Test net output #1: loss = 0.580165 (* 1 = 0.580165 loss)
I0122 17:17:31.283699 64218 solver.cpp:517]     Test net output #2: top-1 = 0.811333
I0122 17:17:31.283704 64218 solver.cpp:517]     Test net output #3: top-5 = 0.985222
I0122 17:17:31.346287 64218 solver.cpp:266] Iteration 16000 (12.9323 iter/s, 7.73255s/100 iter), loss = 0.0508728
I0122 17:17:31.346307 64218 solver.cpp:285]     Train net output #0: loss = 0.0508728 (* 1 = 0.0508728 loss)
I0122 17:17:31.346313 64218 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0122 17:17:37.584010 64218 solver.cpp:266] Iteration 16100 (16.0322 iter/s, 6.23746s/100 iter), loss = 0.150211
I0122 17:17:37.584040 64218 solver.cpp:285]     Train net output #0: loss = 0.150211 (* 1 = 0.150211 loss)
I0122 17:17:37.584046 64218 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0122 17:17:43.868631 64218 solver.cpp:266] Iteration 16200 (15.9125 iter/s, 6.28435s/100 iter), loss = 0.0640948
I0122 17:17:43.868661 64218 solver.cpp:285]     Train net output #0: loss = 0.0640948 (* 1 = 0.0640948 loss)
I0122 17:17:43.868667 64218 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0122 17:17:50.140395 64218 solver.cpp:266] Iteration 16300 (15.9452 iter/s, 6.27149s/100 iter), loss = 0.170144
I0122 17:17:50.140460 64218 solver.cpp:285]     Train net output #0: loss = 0.170144 (* 1 = 0.170144 loss)
I0122 17:17:50.140466 64218 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0122 17:17:56.392280 64218 solver.cpp:266] Iteration 16400 (15.996 iter/s, 6.25158s/100 iter), loss = 0.0424423
I0122 17:17:56.392320 64218 solver.cpp:285]     Train net output #0: loss = 0.0424423 (* 1 = 0.0424423 loss)
I0122 17:17:56.392328 64218 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0122 17:18:02.642910 64218 solver.cpp:266] Iteration 16500 (15.9991 iter/s, 6.25035s/100 iter), loss = 0.0652235
I0122 17:18:02.642948 64218 solver.cpp:285]     Train net output #0: loss = 0.0652235 (* 1 = 0.0652235 loss)
I0122 17:18:02.642954 64218 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0122 17:18:08.919570 64218 solver.cpp:266] Iteration 16600 (15.9328 iter/s, 6.27638s/100 iter), loss = 0.0652025
I0122 17:18:08.919600 64218 solver.cpp:285]     Train net output #0: loss = 0.0652025 (* 1 = 0.0652025 loss)
I0122 17:18:08.919606 64218 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0122 17:18:15.187209 64218 solver.cpp:266] Iteration 16700 (15.9557 iter/s, 6.26737s/100 iter), loss = 0.126824
I0122 17:18:15.187238 64218 solver.cpp:285]     Train net output #0: loss = 0.126824 (* 1 = 0.126824 loss)
I0122 17:18:15.187245 64218 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0122 17:18:21.437155 64218 solver.cpp:266] Iteration 16800 (16.0008 iter/s, 6.24968s/100 iter), loss = 0.107433
I0122 17:18:21.437227 64218 solver.cpp:285]     Train net output #0: loss = 0.107433 (* 1 = 0.107433 loss)
I0122 17:18:21.437233 64218 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0122 17:18:27.693341 64218 solver.cpp:266] Iteration 16900 (15.985 iter/s, 6.25587s/100 iter), loss = 0.174938
I0122 17:18:27.693382 64218 solver.cpp:285]     Train net output #0: loss = 0.174938 (* 1 = 0.174938 loss)
I0122 17:18:27.693387 64218 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0122 17:18:33.912693 64218 solver.cpp:418] Iteration 17000, Testing net (#0)
I0122 17:18:35.379014 64218 solver.cpp:517]     Test net output #0: accuracy = 0.824555
I0122 17:18:35.379040 64218 solver.cpp:517]     Test net output #1: loss = 0.538081 (* 1 = 0.538081 loss)
I0122 17:18:35.379043 64218 solver.cpp:517]     Test net output #2: top-1 = 0.824555
I0122 17:18:35.379047 64218 solver.cpp:517]     Test net output #3: top-5 = 0.991445
I0122 17:18:35.441232 64218 solver.cpp:266] Iteration 17000 (12.9073 iter/s, 7.74756s/100 iter), loss = 0.0896869
I0122 17:18:35.441252 64218 solver.cpp:285]     Train net output #0: loss = 0.0896869 (* 1 = 0.0896869 loss)
I0122 17:18:35.441258 64218 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0122 17:18:41.717098 64218 solver.cpp:266] Iteration 17100 (15.9347 iter/s, 6.2756s/100 iter), loss = 0.0877546
I0122 17:18:41.717129 64218 solver.cpp:285]     Train net output #0: loss = 0.0877546 (* 1 = 0.0877546 loss)
I0122 17:18:41.717135 64218 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0122 17:18:47.982172 64218 solver.cpp:266] Iteration 17200 (15.9622 iter/s, 6.2648s/100 iter), loss = 0.119453
I0122 17:18:47.982201 64218 solver.cpp:285]     Train net output #0: loss = 0.119453 (* 1 = 0.119453 loss)
I0122 17:18:47.982208 64218 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0122 17:18:54.241348 64218 solver.cpp:266] Iteration 17300 (15.9772 iter/s, 6.25891s/100 iter), loss = 0.13167
I0122 17:18:54.241431 64218 solver.cpp:285]     Train net output #0: loss = 0.13167 (* 1 = 0.13167 loss)
I0122 17:18:54.241438 64218 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0122 17:19:00.503950 64218 solver.cpp:266] Iteration 17400 (15.9686 iter/s, 6.26228s/100 iter), loss = 0.165236
I0122 17:19:00.503989 64218 solver.cpp:285]     Train net output #0: loss = 0.165236 (* 1 = 0.165236 loss)
I0122 17:19:00.503995 64218 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0122 17:19:06.779741 64218 solver.cpp:266] Iteration 17500 (15.935 iter/s, 6.27551s/100 iter), loss = 0.11758
I0122 17:19:06.779772 64218 solver.cpp:285]     Train net output #0: loss = 0.11758 (* 1 = 0.11758 loss)
I0122 17:19:06.779778 64218 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0122 17:19:13.075115 64218 solver.cpp:266] Iteration 17600 (15.8854 iter/s, 6.2951s/100 iter), loss = 0.0586217
I0122 17:19:13.075158 64218 solver.cpp:285]     Train net output #0: loss = 0.0586217 (* 1 = 0.0586217 loss)
I0122 17:19:13.075165 64218 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0122 17:19:19.325656 64218 solver.cpp:266] Iteration 17700 (15.9993 iter/s, 6.25026s/100 iter), loss = 0.140459
I0122 17:19:19.325686 64218 solver.cpp:285]     Train net output #0: loss = 0.140459 (* 1 = 0.140459 loss)
I0122 17:19:19.325691 64218 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0122 17:19:25.576395 64218 solver.cpp:266] Iteration 17800 (15.9988 iter/s, 6.25047s/100 iter), loss = 0.114873
I0122 17:19:25.576459 64218 solver.cpp:285]     Train net output #0: loss = 0.114873 (* 1 = 0.114873 loss)
I0122 17:19:25.576467 64218 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0122 17:19:31.857674 64218 solver.cpp:266] Iteration 17900 (15.9211 iter/s, 6.28097s/100 iter), loss = 0.069155
I0122 17:19:31.857705 64218 solver.cpp:285]     Train net output #0: loss = 0.069155 (* 1 = 0.069155 loss)
I0122 17:19:31.857712 64218 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0122 17:19:38.078428 64218 solver.cpp:418] Iteration 18000, Testing net (#0)
I0122 17:19:39.548941 64218 solver.cpp:517]     Test net output #0: accuracy = 0.820222
I0122 17:19:39.548969 64218 solver.cpp:517]     Test net output #1: loss = 0.607669 (* 1 = 0.607669 loss)
I0122 17:19:39.548972 64218 solver.cpp:517]     Test net output #2: top-1 = 0.820222
I0122 17:19:39.548976 64218 solver.cpp:517]     Test net output #3: top-5 = 0.989667
I0122 17:19:39.612906 64218 solver.cpp:266] Iteration 18000 (12.8951 iter/s, 7.75491s/100 iter), loss = 0.0680041
I0122 17:19:39.612926 64218 solver.cpp:285]     Train net output #0: loss = 0.0680041 (* 1 = 0.0680041 loss)
I0122 17:19:39.612931 64218 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0122 17:19:45.858721 64218 solver.cpp:266] Iteration 18100 (16.0114 iter/s, 6.24556s/100 iter), loss = 0.161474
I0122 17:19:45.858748 64218 solver.cpp:285]     Train net output #0: loss = 0.161474 (* 1 = 0.161474 loss)
I0122 17:19:45.858753 64218 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0122 17:19:52.131618 64218 solver.cpp:266] Iteration 18200 (15.9423 iter/s, 6.27263s/100 iter), loss = 0.0325364
I0122 17:19:52.131647 64218 solver.cpp:285]     Train net output #0: loss = 0.0325364 (* 1 = 0.0325364 loss)
I0122 17:19:52.131654 64218 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0122 17:19:58.400857 64218 solver.cpp:266] Iteration 18300 (15.9516 iter/s, 6.26897s/100 iter), loss = 0.151864
I0122 17:19:58.400951 64218 solver.cpp:285]     Train net output #0: loss = 0.151864 (* 1 = 0.151864 loss)
I0122 17:19:58.400959 64218 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0122 17:20:04.663712 64218 solver.cpp:266] Iteration 18400 (15.968 iter/s, 6.26252s/100 iter), loss = 0.0875673
I0122 17:20:04.663743 64218 solver.cpp:285]     Train net output #0: loss = 0.0875673 (* 1 = 0.0875673 loss)
I0122 17:20:04.663748 64218 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0122 17:20:10.920352 64218 solver.cpp:266] Iteration 18500 (15.9837 iter/s, 6.25637s/100 iter), loss = 0.111194
I0122 17:20:10.920382 64218 solver.cpp:285]     Train net output #0: loss = 0.111194 (* 1 = 0.111194 loss)
I0122 17:20:10.920388 64218 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0122 17:20:17.200429 64218 solver.cpp:266] Iteration 18600 (15.9241 iter/s, 6.27981s/100 iter), loss = 0.131505
I0122 17:20:17.200457 64218 solver.cpp:285]     Train net output #0: loss = 0.131505 (* 1 = 0.131505 loss)
I0122 17:20:17.200464 64218 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0122 17:20:23.470499 64218 solver.cpp:266] Iteration 18700 (15.9495 iter/s, 6.2698s/100 iter), loss = 0.0598872
I0122 17:20:23.470541 64218 solver.cpp:285]     Train net output #0: loss = 0.0598871 (* 1 = 0.0598871 loss)
I0122 17:20:23.470547 64218 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0122 17:20:29.732687 64218 solver.cpp:266] Iteration 18800 (15.9696 iter/s, 6.26191s/100 iter), loss = 0.0793546
I0122 17:20:29.732750 64218 solver.cpp:285]     Train net output #0: loss = 0.0793545 (* 1 = 0.0793545 loss)
I0122 17:20:29.732756 64218 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0122 17:20:36.009912 64218 solver.cpp:266] Iteration 18900 (15.9314 iter/s, 6.27692s/100 iter), loss = 0.0775995
I0122 17:20:36.009943 64218 solver.cpp:285]     Train net output #0: loss = 0.0775995 (* 1 = 0.0775995 loss)
I0122 17:20:36.009949 64218 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0122 17:20:42.210656 64218 solver.cpp:418] Iteration 19000, Testing net (#0)
I0122 17:20:43.673355 64218 solver.cpp:517]     Test net output #0: accuracy = 0.836667
I0122 17:20:43.673380 64218 solver.cpp:517]     Test net output #1: loss = 0.527093 (* 1 = 0.527093 loss)
I0122 17:20:43.673385 64218 solver.cpp:517]     Test net output #2: top-1 = 0.836667
I0122 17:20:43.673389 64218 solver.cpp:517]     Test net output #3: top-5 = 0.992111
I0122 17:20:43.737213 64218 solver.cpp:266] Iteration 19000 (12.9417 iter/s, 7.72698s/100 iter), loss = 0.0936135
I0122 17:20:43.737233 64218 solver.cpp:285]     Train net output #0: loss = 0.0936134 (* 1 = 0.0936134 loss)
I0122 17:20:43.737241 64218 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0122 17:20:50.029285 64218 solver.cpp:266] Iteration 19100 (15.8937 iter/s, 6.29181s/100 iter), loss = 0.134625
I0122 17:20:50.029314 64218 solver.cpp:285]     Train net output #0: loss = 0.134625 (* 1 = 0.134625 loss)
I0122 17:20:50.029320 64218 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0122 17:20:56.304391 64218 solver.cpp:266] Iteration 19200 (15.9367 iter/s, 6.27483s/100 iter), loss = 0.0911594
I0122 17:20:56.304421 64218 solver.cpp:285]     Train net output #0: loss = 0.0911593 (* 1 = 0.0911593 loss)
I0122 17:20:56.304426 64218 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0122 17:21:02.675509 64218 solver.cpp:266] Iteration 19300 (15.6965 iter/s, 6.37084s/100 iter), loss = 0.054451
I0122 17:21:02.675606 64218 solver.cpp:285]     Train net output #0: loss = 0.0544509 (* 1 = 0.0544509 loss)
I0122 17:21:02.675613 64218 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0122 17:21:09.037307 64218 solver.cpp:266] Iteration 19400 (15.7197 iter/s, 6.36146s/100 iter), loss = 0.061913
I0122 17:21:09.037336 64218 solver.cpp:285]     Train net output #0: loss = 0.0619129 (* 1 = 0.0619129 loss)
I0122 17:21:09.037343 64218 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0122 17:21:15.321949 64218 solver.cpp:266] Iteration 19500 (15.9125 iter/s, 6.28437s/100 iter), loss = 0.0533869
I0122 17:21:15.321980 64218 solver.cpp:285]     Train net output #0: loss = 0.0533868 (* 1 = 0.0533868 loss)
I0122 17:21:15.321986 64218 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0122 17:21:21.580121 64218 solver.cpp:266] Iteration 19600 (15.9798 iter/s, 6.2579s/100 iter), loss = 0.131535
I0122 17:21:21.580152 64218 solver.cpp:285]     Train net output #0: loss = 0.131535 (* 1 = 0.131535 loss)
I0122 17:21:21.580157 64218 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0122 17:21:27.895766 64218 solver.cpp:266] Iteration 19700 (15.8344 iter/s, 6.31537s/100 iter), loss = 0.108643
I0122 17:21:27.895808 64218 solver.cpp:285]     Train net output #0: loss = 0.108643 (* 1 = 0.108643 loss)
I0122 17:21:27.895814 64218 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0122 17:21:34.235096 64218 solver.cpp:266] Iteration 19800 (15.7752 iter/s, 6.33905s/100 iter), loss = 0.0936802
I0122 17:21:34.235229 64218 solver.cpp:285]     Train net output #0: loss = 0.0936801 (* 1 = 0.0936801 loss)
I0122 17:21:34.235236 64218 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0122 17:21:40.599962 64218 solver.cpp:266] Iteration 19900 (15.7122 iter/s, 6.36449s/100 iter), loss = 0.110356
I0122 17:21:40.600004 64218 solver.cpp:285]     Train net output #0: loss = 0.110356 (* 1 = 0.110356 loss)
I0122 17:21:40.600010 64218 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0122 17:21:46.858891 64218 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_20000.caffemodel
I0122 17:21:46.912647 64218 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_20000.solverstate
I0122 17:21:46.920990 64218 solver.cpp:418] Iteration 20000, Testing net (#0)
I0122 17:21:48.389123 64218 solver.cpp:517]     Test net output #0: accuracy = 0.783222
I0122 17:21:48.389151 64218 solver.cpp:517]     Test net output #1: loss = 0.810611 (* 1 = 0.810611 loss)
I0122 17:21:48.389155 64218 solver.cpp:517]     Test net output #2: top-1 = 0.783222
I0122 17:21:48.389159 64218 solver.cpp:517]     Test net output #3: top-5 = 0.989889
I0122 17:21:48.453270 64218 solver.cpp:266] Iteration 20000 (12.734 iter/s, 7.85297s/100 iter), loss = 0.0895783
I0122 17:21:48.453292 64218 solver.cpp:285]     Train net output #0: loss = 0.0895782 (* 1 = 0.0895782 loss)
I0122 17:21:48.453299 64218 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0122 17:21:54.766280 64218 solver.cpp:266] Iteration 20100 (15.841 iter/s, 6.31274s/100 iter), loss = 0.0705072
I0122 17:21:54.766310 64218 solver.cpp:285]     Train net output #0: loss = 0.0705071 (* 1 = 0.0705071 loss)
I0122 17:21:54.766316 64218 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0122 17:22:01.048208 64218 solver.cpp:266] Iteration 20200 (15.9194 iter/s, 6.28166s/100 iter), loss = 0.0802972
I0122 17:22:01.048239 64218 solver.cpp:285]     Train net output #0: loss = 0.0802971 (* 1 = 0.0802971 loss)
I0122 17:22:01.048244 64218 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0122 17:22:07.313750 64218 solver.cpp:266] Iteration 20300 (15.961 iter/s, 6.26527s/100 iter), loss = 0.0277703
I0122 17:22:07.313880 64218 solver.cpp:285]     Train net output #0: loss = 0.0277702 (* 1 = 0.0277702 loss)
I0122 17:22:07.313889 64218 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0122 17:22:13.588203 64218 solver.cpp:266] Iteration 20400 (15.9386 iter/s, 6.27408s/100 iter), loss = 0.0723343
I0122 17:22:13.588234 64218 solver.cpp:285]     Train net output #0: loss = 0.0723342 (* 1 = 0.0723342 loss)
I0122 17:22:13.588240 64218 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0122 17:22:22.085868 64218 solver.cpp:266] Iteration 20500 (11.7684 iter/s, 8.49731s/100 iter), loss = 0.026555
I0122 17:22:22.085901 64218 solver.cpp:285]     Train net output #0: loss = 0.0265549 (* 1 = 0.0265549 loss)
I0122 17:22:22.085911 64218 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0122 17:22:31.938289 64218 solver.cpp:266] Iteration 20600 (10.1502 iter/s, 9.85201s/100 iter), loss = 0.0393766
I0122 17:22:31.938321 64218 solver.cpp:285]     Train net output #0: loss = 0.0393765 (* 1 = 0.0393765 loss)
I0122 17:22:31.938328 64218 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0122 17:22:41.809422 64218 solver.cpp:266] Iteration 20700 (10.131 iter/s, 9.87072s/100 iter), loss = 0.0242083
I0122 17:22:41.809568 64218 solver.cpp:285]     Train net output #0: loss = 0.0242083 (* 1 = 0.0242083 loss)
I0122 17:22:41.809576 64218 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0122 17:22:51.739517 64218 solver.cpp:266] Iteration 20800 (10.0709 iter/s, 9.92957s/100 iter), loss = 0.0218761
I0122 17:22:51.739562 64218 solver.cpp:285]     Train net output #0: loss = 0.0218761 (* 1 = 0.0218761 loss)
I0122 17:22:51.739568 64218 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0122 17:23:01.719857 64218 solver.cpp:266] Iteration 20900 (10.0201 iter/s, 9.97991s/100 iter), loss = 0.00860927
I0122 17:23:01.719900 64218 solver.cpp:285]     Train net output #0: loss = 0.00860919 (* 1 = 0.00860919 loss)
I0122 17:23:01.719908 64218 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0122 17:23:11.583801 64218 solver.cpp:418] Iteration 21000, Testing net (#0)
I0122 17:23:13.832592 64218 solver.cpp:517]     Test net output #0: accuracy = 0.893777
I0122 17:23:13.832664 64218 solver.cpp:517]     Test net output #1: loss = 0.350566 (* 1 = 0.350566 loss)
I0122 17:23:13.832669 64218 solver.cpp:517]     Test net output #2: top-1 = 0.893777
I0122 17:23:13.832674 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996333
I0122 17:23:13.926604 64218 solver.cpp:266] Iteration 21000 (8.19253 iter/s, 12.2062s/100 iter), loss = 0.0312746
I0122 17:23:13.926630 64218 solver.cpp:285]     Train net output #0: loss = 0.0312745 (* 1 = 0.0312745 loss)
I0122 17:23:13.926636 64218 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0122 17:23:23.785913 64218 solver.cpp:266] Iteration 21100 (10.1431 iter/s, 9.8589s/100 iter), loss = 0.012168
I0122 17:23:23.785945 64218 solver.cpp:285]     Train net output #0: loss = 0.0121679 (* 1 = 0.0121679 loss)
I0122 17:23:23.785951 64218 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0122 17:23:33.624428 64218 solver.cpp:266] Iteration 21200 (10.1646 iter/s, 9.8381s/100 iter), loss = 0.0209534
I0122 17:23:33.624459 64218 solver.cpp:285]     Train net output #0: loss = 0.0209533 (* 1 = 0.0209533 loss)
I0122 17:23:33.624466 64218 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0122 17:23:43.469619 64218 solver.cpp:266] Iteration 21300 (10.1577 iter/s, 9.84478s/100 iter), loss = 0.0321422
I0122 17:23:43.469650 64218 solver.cpp:285]     Train net output #0: loss = 0.0321422 (* 1 = 0.0321422 loss)
I0122 17:23:43.469656 64218 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0122 17:23:53.403038 64218 solver.cpp:266] Iteration 21400 (10.0674 iter/s, 9.93301s/100 iter), loss = 0.0168502
I0122 17:23:53.403098 64218 solver.cpp:285]     Train net output #0: loss = 0.0168501 (* 1 = 0.0168501 loss)
I0122 17:23:53.403105 64218 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0122 17:24:02.767534 64218 solver.cpp:266] Iteration 21500 (10.6791 iter/s, 9.36407s/100 iter), loss = 0.0153653
I0122 17:24:02.767576 64218 solver.cpp:285]     Train net output #0: loss = 0.0153652 (* 1 = 0.0153652 loss)
I0122 17:24:02.767585 64218 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0122 17:24:12.623286 64218 solver.cpp:266] Iteration 21600 (10.1468 iter/s, 9.85533s/100 iter), loss = 0.0236997
I0122 17:24:12.623319 64218 solver.cpp:285]     Train net output #0: loss = 0.0236996 (* 1 = 0.0236996 loss)
I0122 17:24:12.623327 64218 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0122 17:24:22.523579 64218 solver.cpp:266] Iteration 21700 (10.1011 iter/s, 9.89988s/100 iter), loss = 0.0230963
I0122 17:24:22.523622 64218 solver.cpp:285]     Train net output #0: loss = 0.0230962 (* 1 = 0.0230962 loss)
I0122 17:24:22.523628 64218 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0122 17:24:32.421003 64218 solver.cpp:266] Iteration 21800 (10.1041 iter/s, 9.897s/100 iter), loss = 0.00948939
I0122 17:24:32.421138 64218 solver.cpp:285]     Train net output #0: loss = 0.0094893 (* 1 = 0.0094893 loss)
I0122 17:24:32.421146 64218 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0122 17:24:42.279552 64218 solver.cpp:266] Iteration 21900 (10.144 iter/s, 9.85804s/100 iter), loss = 0.0225419
I0122 17:24:42.279584 64218 solver.cpp:285]     Train net output #0: loss = 0.0225418 (* 1 = 0.0225418 loss)
I0122 17:24:42.279592 64218 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0122 17:24:52.073527 64218 solver.cpp:418] Iteration 22000, Testing net (#0)
I0122 17:24:54.396829 64218 solver.cpp:517]     Test net output #0: accuracy = 0.892778
I0122 17:24:54.396859 64218 solver.cpp:517]     Test net output #1: loss = 0.354708 (* 1 = 0.354708 loss)
I0122 17:24:54.396863 64218 solver.cpp:517]     Test net output #2: top-1 = 0.892778
I0122 17:24:54.396867 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996556
I0122 17:24:54.496299 64218 solver.cpp:266] Iteration 22000 (8.18582 iter/s, 12.2162s/100 iter), loss = 0.0130559
I0122 17:24:54.496325 64218 solver.cpp:285]     Train net output #0: loss = 0.0130558 (* 1 = 0.0130558 loss)
I0122 17:24:54.496331 64218 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0122 17:25:04.336956 64218 solver.cpp:266] Iteration 22100 (10.1623 iter/s, 9.84025s/100 iter), loss = 0.0149498
I0122 17:25:04.337024 64218 solver.cpp:285]     Train net output #0: loss = 0.0149497 (* 1 = 0.0149497 loss)
I0122 17:25:04.337031 64218 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0122 17:25:14.179242 64218 solver.cpp:266] Iteration 22200 (10.1607 iter/s, 9.84184s/100 iter), loss = 0.0103902
I0122 17:25:14.179277 64218 solver.cpp:285]     Train net output #0: loss = 0.0103901 (* 1 = 0.0103901 loss)
I0122 17:25:14.179284 64218 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0122 17:25:24.023208 64218 solver.cpp:266] Iteration 22300 (10.1589 iter/s, 9.84356s/100 iter), loss = 0.00857387
I0122 17:25:24.023241 64218 solver.cpp:285]     Train net output #0: loss = 0.00857379 (* 1 = 0.00857379 loss)
I0122 17:25:24.023247 64218 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0122 17:25:33.936695 64218 solver.cpp:266] Iteration 22400 (10.0877 iter/s, 9.91307s/100 iter), loss = 0.0176951
I0122 17:25:33.936728 64218 solver.cpp:285]     Train net output #0: loss = 0.017695 (* 1 = 0.017695 loss)
I0122 17:25:33.936734 64218 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0122 17:25:43.154533 64218 solver.cpp:266] Iteration 22500 (10.849 iter/s, 9.21745s/100 iter), loss = 0.0152429
I0122 17:25:43.154642 64218 solver.cpp:285]     Train net output #0: loss = 0.0152429 (* 1 = 0.0152429 loss)
I0122 17:25:43.154650 64218 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0122 17:25:52.771865 64218 solver.cpp:266] Iteration 22600 (10.3984 iter/s, 9.61686s/100 iter), loss = 0.0103471
I0122 17:25:52.771908 64218 solver.cpp:285]     Train net output #0: loss = 0.0103471 (* 1 = 0.0103471 loss)
I0122 17:25:52.771915 64218 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0122 17:26:02.242219 64218 solver.cpp:266] Iteration 22700 (10.5597 iter/s, 9.46995s/100 iter), loss = 0.0137601
I0122 17:26:02.242254 64218 solver.cpp:285]     Train net output #0: loss = 0.01376 (* 1 = 0.01376 loss)
I0122 17:26:02.242261 64218 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0122 17:26:11.799558 64218 solver.cpp:266] Iteration 22800 (10.4636 iter/s, 9.55694s/100 iter), loss = 0.0193159
I0122 17:26:11.799589 64218 solver.cpp:285]     Train net output #0: loss = 0.0193158 (* 1 = 0.0193158 loss)
I0122 17:26:11.799595 64218 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0122 17:26:21.275095 64218 solver.cpp:266] Iteration 22900 (10.5539 iter/s, 9.47514s/100 iter), loss = 0.0108496
I0122 17:26:21.275264 64218 solver.cpp:285]     Train net output #0: loss = 0.0108495 (* 1 = 0.0108495 loss)
I0122 17:26:21.277355 64218 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0122 17:26:30.671635 64218 solver.cpp:418] Iteration 23000, Testing net (#0)
I0122 17:26:32.946171 64218 solver.cpp:517]     Test net output #0: accuracy = 0.894
I0122 17:26:32.946200 64218 solver.cpp:517]     Test net output #1: loss = 0.351559 (* 1 = 0.351559 loss)
I0122 17:26:32.946205 64218 solver.cpp:517]     Test net output #2: top-1 = 0.894
I0122 17:26:32.946208 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:26:33.041000 64218 solver.cpp:266] Iteration 23000 (8.50109 iter/s, 11.7632s/100 iter), loss = 0.0136623
I0122 17:26:33.041028 64218 solver.cpp:285]     Train net output #0: loss = 0.0136623 (* 1 = 0.0136623 loss)
I0122 17:26:33.041033 64218 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0122 17:26:42.467784 64218 solver.cpp:266] Iteration 23100 (10.6085 iter/s, 9.4264s/100 iter), loss = 0.00856657
I0122 17:26:42.467816 64218 solver.cpp:285]     Train net output #0: loss = 0.00856648 (* 1 = 0.00856648 loss)
I0122 17:26:42.467823 64218 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0122 17:26:52.026271 64218 solver.cpp:266] Iteration 23200 (10.4623 iter/s, 9.55809s/100 iter), loss = 0.0153593
I0122 17:26:52.027081 64218 solver.cpp:285]     Train net output #0: loss = 0.0153592 (* 1 = 0.0153592 loss)
I0122 17:26:52.028511 64218 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0122 17:27:01.498332 64218 solver.cpp:266] Iteration 23300 (10.5603 iter/s, 9.46946s/100 iter), loss = 0.00725933
I0122 17:27:01.498366 64218 solver.cpp:285]     Train net output #0: loss = 0.00725924 (* 1 = 0.00725924 loss)
I0122 17:27:01.498412 64218 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0122 17:27:11.019632 64218 solver.cpp:266] Iteration 23400 (10.5033 iter/s, 9.52086s/100 iter), loss = 0.0161987
I0122 17:27:11.019665 64218 solver.cpp:285]     Train net output #0: loss = 0.0161986 (* 1 = 0.0161986 loss)
I0122 17:27:11.019671 64218 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0122 17:27:20.109447 64218 solver.cpp:266] Iteration 23500 (11.0018 iter/s, 9.08944s/100 iter), loss = 0.0099356
I0122 17:27:20.109479 64218 solver.cpp:285]     Train net output #0: loss = 0.00993551 (* 1 = 0.00993551 loss)
I0122 17:27:20.109486 64218 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0122 17:27:29.619145 64218 solver.cpp:266] Iteration 23600 (10.516 iter/s, 9.5093s/100 iter), loss = 0.00901636
I0122 17:27:29.619199 64218 solver.cpp:285]     Train net output #0: loss = 0.00901627 (* 1 = 0.00901627 loss)
I0122 17:27:29.621387 64218 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0122 17:27:39.061956 64218 solver.cpp:266] Iteration 23700 (10.593 iter/s, 9.44021s/100 iter), loss = 0.00834609
I0122 17:27:39.061997 64218 solver.cpp:285]     Train net output #0: loss = 0.008346 (* 1 = 0.008346 loss)
I0122 17:27:39.062005 64218 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0122 17:27:48.525399 64218 solver.cpp:266] Iteration 23800 (10.5674 iter/s, 9.46304s/100 iter), loss = 0.00853977
I0122 17:27:48.525432 64218 solver.cpp:285]     Train net output #0: loss = 0.00853968 (* 1 = 0.00853968 loss)
I0122 17:27:48.525439 64218 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0122 17:27:57.995517 64218 solver.cpp:266] Iteration 23900 (10.56 iter/s, 9.46972s/100 iter), loss = 0.00932777
I0122 17:27:57.995549 64218 solver.cpp:285]     Train net output #0: loss = 0.00932767 (* 1 = 0.00932767 loss)
I0122 17:27:57.995555 64218 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0122 17:28:07.356365 64218 solver.cpp:418] Iteration 24000, Testing net (#0)
I0122 17:28:09.620587 64218 solver.cpp:517]     Test net output #0: accuracy = 0.892667
I0122 17:28:09.620620 64218 solver.cpp:517]     Test net output #1: loss = 0.363296 (* 1 = 0.363296 loss)
I0122 17:28:09.620623 64218 solver.cpp:517]     Test net output #2: top-1 = 0.892667
I0122 17:28:09.620627 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:28:09.713033 64218 solver.cpp:266] Iteration 24000 (8.53458 iter/s, 11.717s/100 iter), loss = 0.0185081
I0122 17:28:09.713059 64218 solver.cpp:285]     Train net output #0: loss = 0.018508 (* 1 = 0.018508 loss)
I0122 17:28:09.713066 64218 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0122 17:28:19.223393 64218 solver.cpp:266] Iteration 24100 (10.5153 iter/s, 9.50997s/100 iter), loss = 0.00847753
I0122 17:28:19.223426 64218 solver.cpp:285]     Train net output #0: loss = 0.00847743 (* 1 = 0.00847743 loss)
I0122 17:28:19.223433 64218 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0122 17:28:28.665503 64218 solver.cpp:266] Iteration 24200 (10.5913 iter/s, 9.44172s/100 iter), loss = 0.010031
I0122 17:28:28.665535 64218 solver.cpp:285]     Train net output #0: loss = 0.0100309 (* 1 = 0.0100309 loss)
I0122 17:28:28.665542 64218 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0122 17:28:38.122105 64218 solver.cpp:266] Iteration 24300 (10.5751 iter/s, 9.45621s/100 iter), loss = 0.0182092
I0122 17:28:38.122213 64218 solver.cpp:285]     Train net output #0: loss = 0.0182091 (* 1 = 0.0182091 loss)
I0122 17:28:38.122222 64218 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0122 17:28:48.037245 64218 solver.cpp:266] Iteration 24400 (10.0861 iter/s, 9.91465s/100 iter), loss = 0.0113657
I0122 17:28:48.037276 64218 solver.cpp:285]     Train net output #0: loss = 0.0113656 (* 1 = 0.0113656 loss)
I0122 17:28:48.037281 64218 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0122 17:28:57.905539 64218 solver.cpp:266] Iteration 24500 (10.1339 iter/s, 9.86789s/100 iter), loss = 0.0111817
I0122 17:28:57.905571 64218 solver.cpp:285]     Train net output #0: loss = 0.0111816 (* 1 = 0.0111816 loss)
I0122 17:28:57.905580 64218 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0122 17:29:07.408926 64218 solver.cpp:266] Iteration 24600 (10.523 iter/s, 9.50299s/100 iter), loss = 0.00636365
I0122 17:29:07.408957 64218 solver.cpp:285]     Train net output #0: loss = 0.00636356 (* 1 = 0.00636356 loss)
I0122 17:29:07.408965 64218 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0122 17:29:17.241626 64218 solver.cpp:266] Iteration 24700 (10.1706 iter/s, 9.83229s/100 iter), loss = 0.0294782
I0122 17:29:17.241749 64218 solver.cpp:285]     Train net output #0: loss = 0.0294781 (* 1 = 0.0294781 loss)
I0122 17:29:17.241755 64218 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0122 17:29:27.103489 64218 solver.cpp:266] Iteration 24800 (10.1406 iter/s, 9.86137s/100 iter), loss = 0.0161856
I0122 17:29:27.103523 64218 solver.cpp:285]     Train net output #0: loss = 0.0161855 (* 1 = 0.0161855 loss)
I0122 17:29:27.103529 64218 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0122 17:29:36.983777 64218 solver.cpp:266] Iteration 24900 (10.1216 iter/s, 9.87988s/100 iter), loss = 0.00764838
I0122 17:29:36.983819 64218 solver.cpp:285]     Train net output #0: loss = 0.00764829 (* 1 = 0.00764829 loss)
I0122 17:29:36.983917 64218 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0122 17:29:46.762446 64218 solver.cpp:418] Iteration 25000, Testing net (#0)
I0122 17:29:49.106209 64218 solver.cpp:517]     Test net output #0: accuracy = 0.894556
I0122 17:29:49.106271 64218 solver.cpp:517]     Test net output #1: loss = 0.357556 (* 1 = 0.357556 loss)
I0122 17:29:49.106277 64218 solver.cpp:517]     Test net output #2: top-1 = 0.894556
I0122 17:29:49.106281 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:29:49.198865 64218 solver.cpp:266] Iteration 25000 (8.187 iter/s, 12.2145s/100 iter), loss = 0.00865492
I0122 17:29:49.198890 64218 solver.cpp:285]     Train net output #0: loss = 0.00865483 (* 1 = 0.00865483 loss)
I0122 17:29:49.198897 64218 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0122 17:29:59.072440 64218 solver.cpp:266] Iteration 25100 (10.1285 iter/s, 9.87317s/100 iter), loss = 0.0102705
I0122 17:29:59.072474 64218 solver.cpp:285]     Train net output #0: loss = 0.0102704 (* 1 = 0.0102704 loss)
I0122 17:29:59.072480 64218 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0122 17:30:08.963999 64218 solver.cpp:266] Iteration 25200 (10.1101 iter/s, 9.89114s/100 iter), loss = 0.0291133
I0122 17:30:08.964032 64218 solver.cpp:285]     Train net output #0: loss = 0.0291132 (* 1 = 0.0291132 loss)
I0122 17:30:08.964038 64218 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0122 17:30:18.885812 64218 solver.cpp:266] Iteration 25300 (10.0792 iter/s, 9.9214s/100 iter), loss = 0.0144092
I0122 17:30:18.885845 64218 solver.cpp:285]     Train net output #0: loss = 0.0144091 (* 1 = 0.0144091 loss)
I0122 17:30:18.885851 64218 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0122 17:30:28.800712 64218 solver.cpp:266] Iteration 25400 (10.0863 iter/s, 9.91448s/100 iter), loss = 0.00745859
I0122 17:30:28.800848 64218 solver.cpp:285]     Train net output #0: loss = 0.0074585 (* 1 = 0.0074585 loss)
I0122 17:30:28.800858 64218 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0122 17:30:38.723143 64218 solver.cpp:266] Iteration 25500 (10.0787 iter/s, 9.92192s/100 iter), loss = 0.00797322
I0122 17:30:38.723177 64218 solver.cpp:285]     Train net output #0: loss = 0.00797313 (* 1 = 0.00797313 loss)
I0122 17:30:38.723183 64218 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0122 17:30:48.069788 64218 solver.cpp:266] Iteration 25600 (10.6995 iter/s, 9.34625s/100 iter), loss = 0.0120727
I0122 17:30:48.069833 64218 solver.cpp:285]     Train net output #0: loss = 0.0120726 (* 1 = 0.0120726 loss)
I0122 17:30:48.069839 64218 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0122 17:30:57.901309 64218 solver.cpp:266] Iteration 25700 (10.1718 iter/s, 9.8311s/100 iter), loss = 0.0147665
I0122 17:30:57.901342 64218 solver.cpp:285]     Train net output #0: loss = 0.0147664 (* 1 = 0.0147664 loss)
I0122 17:30:57.901350 64218 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0122 17:31:07.823842 64218 solver.cpp:266] Iteration 25800 (10.0785 iter/s, 9.92212s/100 iter), loss = 0.00874868
I0122 17:31:07.823916 64218 solver.cpp:285]     Train net output #0: loss = 0.00874859 (* 1 = 0.00874859 loss)
I0122 17:31:07.823925 64218 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0122 17:31:17.770407 64218 solver.cpp:266] Iteration 25900 (10.0542 iter/s, 9.94611s/100 iter), loss = 0.0170399
I0122 17:31:17.770439 64218 solver.cpp:285]     Train net output #0: loss = 0.0170398 (* 1 = 0.0170398 loss)
I0122 17:31:17.770445 64218 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0122 17:31:27.523380 64218 solver.cpp:418] Iteration 26000, Testing net (#0)
I0122 17:31:29.858376 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895555
I0122 17:31:29.858404 64218 solver.cpp:517]     Test net output #1: loss = 0.362615 (* 1 = 0.362615 loss)
I0122 17:31:29.858409 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895555
I0122 17:31:29.858413 64218 solver.cpp:517]     Test net output #3: top-5 = 0.995889
I0122 17:31:29.952046 64218 solver.cpp:266] Iteration 26000 (8.20941 iter/s, 12.1811s/100 iter), loss = 0.00747546
I0122 17:31:29.952071 64218 solver.cpp:285]     Train net output #0: loss = 0.00747537 (* 1 = 0.00747537 loss)
I0122 17:31:29.952078 64218 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0122 17:31:39.771251 64218 solver.cpp:266] Iteration 26100 (10.1845 iter/s, 9.8188s/100 iter), loss = 0.00983977
I0122 17:31:39.771358 64218 solver.cpp:285]     Train net output #0: loss = 0.00983968 (* 1 = 0.00983968 loss)
I0122 17:31:39.771366 64218 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0122 17:31:49.683799 64218 solver.cpp:266] Iteration 26200 (10.0887 iter/s, 9.91206s/100 iter), loss = 0.00787884
I0122 17:31:49.683840 64218 solver.cpp:285]     Train net output #0: loss = 0.00787875 (* 1 = 0.00787875 loss)
I0122 17:31:49.683847 64218 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0122 17:31:59.562892 64218 solver.cpp:266] Iteration 26300 (10.1228 iter/s, 9.87867s/100 iter), loss = 0.00685245
I0122 17:31:59.562924 64218 solver.cpp:285]     Train net output #0: loss = 0.00685236 (* 1 = 0.00685236 loss)
I0122 17:31:59.562932 64218 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0122 17:32:09.475682 64218 solver.cpp:266] Iteration 26400 (10.0884 iter/s, 9.91238s/100 iter), loss = 0.015489
I0122 17:32:09.475711 64218 solver.cpp:285]     Train net output #0: loss = 0.0154889 (* 1 = 0.0154889 loss)
I0122 17:32:09.475718 64218 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0122 17:32:19.277266 64218 solver.cpp:266] Iteration 26500 (10.2029 iter/s, 9.80118s/100 iter), loss = 0.00745083
I0122 17:32:19.277349 64218 solver.cpp:285]     Train net output #0: loss = 0.00745074 (* 1 = 0.00745074 loss)
I0122 17:32:19.277385 64218 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0122 17:32:28.738623 64218 solver.cpp:266] Iteration 26600 (10.5698 iter/s, 9.46088s/100 iter), loss = 0.012619
I0122 17:32:28.738656 64218 solver.cpp:285]     Train net output #0: loss = 0.0126189 (* 1 = 0.0126189 loss)
I0122 17:32:28.738677 64218 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0122 17:32:38.542158 64218 solver.cpp:266] Iteration 26700 (10.2008 iter/s, 9.80313s/100 iter), loss = 0.00401938
I0122 17:32:38.542191 64218 solver.cpp:285]     Train net output #0: loss = 0.00401929 (* 1 = 0.00401929 loss)
I0122 17:32:38.542197 64218 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0122 17:32:48.453547 64218 solver.cpp:266] Iteration 26800 (10.0898 iter/s, 9.91097s/100 iter), loss = 0.00643009
I0122 17:32:48.453577 64218 solver.cpp:285]     Train net output #0: loss = 0.00643 (* 1 = 0.00643 loss)
I0122 17:32:48.453599 64218 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0122 17:32:58.305537 64218 solver.cpp:266] Iteration 26900 (10.1507 iter/s, 9.85158s/100 iter), loss = 0.0077434
I0122 17:32:58.305691 64218 solver.cpp:285]     Train net output #0: loss = 0.00774332 (* 1 = 0.00774332 loss)
I0122 17:32:58.305698 64218 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0122 17:33:07.993903 64218 solver.cpp:418] Iteration 27000, Testing net (#0)
I0122 17:33:10.484037 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895111
I0122 17:33:10.484066 64218 solver.cpp:517]     Test net output #1: loss = 0.366317 (* 1 = 0.366317 loss)
I0122 17:33:10.484071 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895111
I0122 17:33:10.484074 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 17:33:10.583617 64218 solver.cpp:266] Iteration 27000 (8.14501 iter/s, 12.2775s/100 iter), loss = 0.00924124
I0122 17:33:10.583643 64218 solver.cpp:285]     Train net output #0: loss = 0.00924116 (* 1 = 0.00924116 loss)
I0122 17:33:10.583650 64218 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0122 17:33:20.446852 64218 solver.cpp:266] Iteration 27100 (10.1391 iter/s, 9.86283s/100 iter), loss = 0.00707752
I0122 17:33:20.446885 64218 solver.cpp:285]     Train net output #0: loss = 0.00707744 (* 1 = 0.00707744 loss)
I0122 17:33:20.446892 64218 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0122 17:33:30.488523 64218 solver.cpp:266] Iteration 27200 (9.95892 iter/s, 10.0413s/100 iter), loss = 0.00428541
I0122 17:33:30.488658 64218 solver.cpp:285]     Train net output #0: loss = 0.00428533 (* 1 = 0.00428533 loss)
I0122 17:33:30.490768 64218 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0122 17:33:40.426187 64218 solver.cpp:266] Iteration 27300 (10.0654 iter/s, 9.93504s/100 iter), loss = 0.00509873
I0122 17:33:40.426218 64218 solver.cpp:285]     Train net output #0: loss = 0.00509865 (* 1 = 0.00509865 loss)
I0122 17:33:40.428225 64218 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0122 17:33:50.332041 64218 solver.cpp:266] Iteration 27400 (10.0975 iter/s, 9.90344s/100 iter), loss = 0.00760954
I0122 17:33:50.332070 64218 solver.cpp:285]     Train net output #0: loss = 0.00760946 (* 1 = 0.00760946 loss)
I0122 17:33:50.332113 64218 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0122 17:33:59.765888 64218 solver.cpp:266] Iteration 27500 (10.6006 iter/s, 9.43342s/100 iter), loss = 0.00616053
I0122 17:33:59.765923 64218 solver.cpp:285]     Train net output #0: loss = 0.00616045 (* 1 = 0.00616045 loss)
I0122 17:33:59.765930 64218 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0122 17:34:09.611433 64218 solver.cpp:266] Iteration 27600 (10.1573 iter/s, 9.84513s/100 iter), loss = 0.006358
I0122 17:34:09.611589 64218 solver.cpp:285]     Train net output #0: loss = 0.00635791 (* 1 = 0.00635791 loss)
I0122 17:34:09.611598 64218 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0122 17:34:19.478410 64218 solver.cpp:266] Iteration 27700 (10.1354 iter/s, 9.86645s/100 iter), loss = 0.00634097
I0122 17:34:19.478440 64218 solver.cpp:285]     Train net output #0: loss = 0.00634088 (* 1 = 0.00634088 loss)
I0122 17:34:19.478444 64218 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0122 17:34:29.318902 64218 solver.cpp:266] Iteration 27800 (10.1625 iter/s, 9.84009s/100 iter), loss = 0.0129647
I0122 17:34:29.318931 64218 solver.cpp:285]     Train net output #0: loss = 0.0129646 (* 1 = 0.0129646 loss)
I0122 17:34:29.318938 64218 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0122 17:34:39.185335 64218 solver.cpp:266] Iteration 27900 (10.1358 iter/s, 9.86603s/100 iter), loss = 0.00761588
I0122 17:34:39.185369 64218 solver.cpp:285]     Train net output #0: loss = 0.0076158 (* 1 = 0.0076158 loss)
I0122 17:34:39.185375 64218 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0122 17:34:48.918845 64218 solver.cpp:418] Iteration 28000, Testing net (#0)
I0122 17:34:51.179358 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895777
I0122 17:34:51.179388 64218 solver.cpp:517]     Test net output #1: loss = 0.367031 (* 1 = 0.367031 loss)
I0122 17:34:51.179392 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895777
I0122 17:34:51.179395 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:34:51.274184 64218 solver.cpp:266] Iteration 28000 (8.27246 iter/s, 12.0883s/100 iter), loss = 0.00489061
I0122 17:34:51.274214 64218 solver.cpp:285]     Train net output #0: loss = 0.00489053 (* 1 = 0.00489053 loss)
I0122 17:34:51.274219 64218 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0122 17:35:01.123569 64218 solver.cpp:266] Iteration 28100 (10.1534 iter/s, 9.84893s/100 iter), loss = 0.00620548
I0122 17:35:01.123602 64218 solver.cpp:285]     Train net output #0: loss = 0.0062054 (* 1 = 0.0062054 loss)
I0122 17:35:01.123610 64218 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0122 17:35:10.988703 64218 solver.cpp:266] Iteration 28200 (10.1372 iter/s, 9.86468s/100 iter), loss = 0.00535825
I0122 17:35:10.988735 64218 solver.cpp:285]     Train net output #0: loss = 0.00535817 (* 1 = 0.00535817 loss)
I0122 17:35:10.988742 64218 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0122 17:35:20.787478 64218 solver.cpp:266] Iteration 28300 (10.2058 iter/s, 9.79833s/100 iter), loss = 0.00614073
I0122 17:35:20.787530 64218 solver.cpp:285]     Train net output #0: loss = 0.00614065 (* 1 = 0.00614065 loss)
I0122 17:35:20.787537 64218 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0122 17:35:30.582304 64218 solver.cpp:266] Iteration 28400 (10.21 iter/s, 9.79436s/100 iter), loss = 0.00995618
I0122 17:35:30.582337 64218 solver.cpp:285]     Train net output #0: loss = 0.0099561 (* 1 = 0.0099561 loss)
I0122 17:35:30.582345 64218 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0122 17:35:39.967053 64218 solver.cpp:266] Iteration 28500 (10.6561 iter/s, 9.38431s/100 iter), loss = 0.00835746
I0122 17:35:39.967084 64218 solver.cpp:285]     Train net output #0: loss = 0.00835738 (* 1 = 0.00835738 loss)
I0122 17:35:39.967092 64218 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0122 17:35:49.843523 64218 solver.cpp:266] Iteration 28600 (10.1255 iter/s, 9.87602s/100 iter), loss = 0.0170534
I0122 17:35:49.843554 64218 solver.cpp:285]     Train net output #0: loss = 0.0170533 (* 1 = 0.0170533 loss)
I0122 17:35:49.843561 64218 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0122 17:35:59.742553 64218 solver.cpp:266] Iteration 28700 (10.1025 iter/s, 9.89858s/100 iter), loss = 0.0063661
I0122 17:35:59.742656 64218 solver.cpp:285]     Train net output #0: loss = 0.00636602 (* 1 = 0.00636602 loss)
I0122 17:35:59.742662 64218 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0122 17:36:09.603875 64218 solver.cpp:266] Iteration 28800 (10.1412 iter/s, 9.86081s/100 iter), loss = 0.00611679
I0122 17:36:09.603907 64218 solver.cpp:285]     Train net output #0: loss = 0.00611671 (* 1 = 0.00611671 loss)
I0122 17:36:09.603915 64218 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0122 17:36:19.472947 64218 solver.cpp:266] Iteration 28900 (10.1331 iter/s, 9.86862s/100 iter), loss = 0.00696091
I0122 17:36:19.472980 64218 solver.cpp:285]     Train net output #0: loss = 0.00696083 (* 1 = 0.00696083 loss)
I0122 17:36:19.472986 64218 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0122 17:36:29.225545 64218 solver.cpp:418] Iteration 29000, Testing net (#0)
I0122 17:36:31.481717 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895222
I0122 17:36:31.481815 64218 solver.cpp:517]     Test net output #1: loss = 0.371315 (* 1 = 0.371315 loss)
I0122 17:36:31.481822 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895222
I0122 17:36:31.481825 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996222
I0122 17:36:31.575024 64218 solver.cpp:266] Iteration 29000 (8.26341 iter/s, 12.1015s/100 iter), loss = 0.00582122
I0122 17:36:31.575062 64218 solver.cpp:285]     Train net output #0: loss = 0.00582113 (* 1 = 0.00582113 loss)
I0122 17:36:31.575085 64218 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0122 17:36:41.416263 64218 solver.cpp:266] Iteration 29100 (10.1618 iter/s, 9.84079s/100 iter), loss = 0.00461417
I0122 17:36:41.416296 64218 solver.cpp:285]     Train net output #0: loss = 0.00461408 (* 1 = 0.00461408 loss)
I0122 17:36:41.416301 64218 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0122 17:36:51.285481 64218 solver.cpp:266] Iteration 29200 (10.133 iter/s, 9.86877s/100 iter), loss = 0.00623521
I0122 17:36:51.285513 64218 solver.cpp:285]     Train net output #0: loss = 0.00623512 (* 1 = 0.00623512 loss)
I0122 17:36:51.285521 64218 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0122 17:37:01.169911 64218 solver.cpp:266] Iteration 29300 (10.1174 iter/s, 9.88398s/100 iter), loss = 0.00430684
I0122 17:37:01.169953 64218 solver.cpp:285]     Train net output #0: loss = 0.00430676 (* 1 = 0.00430676 loss)
I0122 17:37:01.169961 64218 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0122 17:37:11.071982 64218 solver.cpp:266] Iteration 29400 (10.0994 iter/s, 9.90161s/100 iter), loss = 0.0309371
I0122 17:37:11.072124 64218 solver.cpp:285]     Train net output #0: loss = 0.030937 (* 1 = 0.030937 loss)
I0122 17:37:11.072132 64218 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0122 17:37:20.433365 64218 solver.cpp:266] Iteration 29500 (10.6828 iter/s, 9.36085s/100 iter), loss = 0.00673283
I0122 17:37:20.433395 64218 solver.cpp:285]     Train net output #0: loss = 0.00673275 (* 1 = 0.00673275 loss)
I0122 17:37:20.433403 64218 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0122 17:37:30.242866 64218 solver.cpp:266] Iteration 29600 (10.1947 iter/s, 9.80906s/100 iter), loss = 0.00532359
I0122 17:37:30.242898 64218 solver.cpp:285]     Train net output #0: loss = 0.0053235 (* 1 = 0.0053235 loss)
I0122 17:37:30.243162 64218 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0122 17:37:40.149806 64218 solver.cpp:266] Iteration 29700 (10.0947 iter/s, 9.90623s/100 iter), loss = 0.0122378
I0122 17:37:40.149838 64218 solver.cpp:285]     Train net output #0: loss = 0.0122377 (* 1 = 0.0122377 loss)
I0122 17:37:40.149844 64218 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0122 17:37:50.033828 64218 solver.cpp:266] Iteration 29800 (10.1178 iter/s, 9.88358s/100 iter), loss = 0.00477893
I0122 17:37:50.033948 64218 solver.cpp:285]     Train net output #0: loss = 0.00477885 (* 1 = 0.00477885 loss)
I0122 17:37:50.033957 64218 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0122 17:37:59.913045 64218 solver.cpp:266] Iteration 29900 (10.1228 iter/s, 9.87868s/100 iter), loss = 0.00843585
I0122 17:37:59.913086 64218 solver.cpp:285]     Train net output #0: loss = 0.00843576 (* 1 = 0.00843576 loss)
I0122 17:37:59.913094 64218 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0122 17:38:07.113236 64218 solver.cpp:418] Iteration 30000, Testing net (#0)
I0122 17:38:08.624822 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895666
I0122 17:38:08.624848 64218 solver.cpp:517]     Test net output #1: loss = 0.370352 (* 1 = 0.370352 loss)
I0122 17:38:08.624852 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895666
I0122 17:38:08.624856 64218 solver.cpp:517]     Test net output #3: top-5 = 0.995778
I0122 17:38:08.688968 64218 solver.cpp:266] Iteration 30000 (11.3953 iter/s, 8.77553s/100 iter), loss = 0.00580949
I0122 17:38:08.689003 64218 solver.cpp:285]     Train net output #0: loss = 0.0058094 (* 1 = 0.0058094 loss)
I0122 17:38:08.689010 64218 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I0122 17:38:15.089350 64218 solver.cpp:266] Iteration 30100 (15.6248 iter/s, 6.40008s/100 iter), loss = 0.00747158
I0122 17:38:15.089381 64218 solver.cpp:285]     Train net output #0: loss = 0.00747149 (* 1 = 0.00747149 loss)
I0122 17:38:15.089387 64218 sgd_solver.cpp:106] Iteration 30100, lr = 0.0001
I0122 17:38:21.459105 64218 solver.cpp:266] Iteration 30200 (15.6999 iter/s, 6.36946s/100 iter), loss = 0.0156194
I0122 17:38:21.459239 64218 solver.cpp:285]     Train net output #0: loss = 0.0156193 (* 1 = 0.0156193 loss)
I0122 17:38:21.459246 64218 sgd_solver.cpp:106] Iteration 30200, lr = 0.0001
I0122 17:38:27.799275 64218 solver.cpp:266] Iteration 30300 (15.7734 iter/s, 6.33978s/100 iter), loss = 0.00409591
I0122 17:38:27.799305 64218 solver.cpp:285]     Train net output #0: loss = 0.00409583 (* 1 = 0.00409583 loss)
I0122 17:38:27.799311 64218 sgd_solver.cpp:106] Iteration 30300, lr = 0.0001
I0122 17:38:34.124797 64218 solver.cpp:266] Iteration 30400 (15.8097 iter/s, 6.32523s/100 iter), loss = 0.00470565
I0122 17:38:34.124826 64218 solver.cpp:285]     Train net output #0: loss = 0.00470557 (* 1 = 0.00470557 loss)
I0122 17:38:34.124832 64218 sgd_solver.cpp:106] Iteration 30400, lr = 0.0001
I0122 17:38:40.403228 64218 solver.cpp:266] Iteration 30500 (15.9283 iter/s, 6.27814s/100 iter), loss = 0.0073408
I0122 17:38:40.403268 64218 solver.cpp:285]     Train net output #0: loss = 0.00734071 (* 1 = 0.00734071 loss)
I0122 17:38:40.403275 64218 sgd_solver.cpp:106] Iteration 30500, lr = 0.0001
I0122 17:38:46.675881 64218 solver.cpp:266] Iteration 30600 (15.943 iter/s, 6.27235s/100 iter), loss = 0.00427621
I0122 17:38:46.675923 64218 solver.cpp:285]     Train net output #0: loss = 0.00427612 (* 1 = 0.00427612 loss)
I0122 17:38:46.675930 64218 sgd_solver.cpp:106] Iteration 30600, lr = 0.0001
I0122 17:38:52.930784 64218 solver.cpp:266] Iteration 30700 (15.9882 iter/s, 6.2546s/100 iter), loss = 0.0031986
I0122 17:38:52.930908 64218 solver.cpp:285]     Train net output #0: loss = 0.00319851 (* 1 = 0.00319851 loss)
I0122 17:38:52.930917 64218 sgd_solver.cpp:106] Iteration 30700, lr = 0.0001
I0122 17:38:59.242975 64218 solver.cpp:266] Iteration 30800 (15.8433 iter/s, 6.31181s/100 iter), loss = 0.00691445
I0122 17:38:59.243005 64218 solver.cpp:285]     Train net output #0: loss = 0.00691437 (* 1 = 0.00691437 loss)
I0122 17:38:59.243011 64218 sgd_solver.cpp:106] Iteration 30800, lr = 0.0001
I0122 17:39:05.519839 64218 solver.cpp:266] Iteration 30900 (15.9323 iter/s, 6.27657s/100 iter), loss = 0.00589808
I0122 17:39:05.519879 64218 solver.cpp:285]     Train net output #0: loss = 0.005898 (* 1 = 0.005898 loss)
I0122 17:39:05.519886 64218 sgd_solver.cpp:106] Iteration 30900, lr = 0.0001
I0122 17:39:11.761674 64218 solver.cpp:418] Iteration 31000, Testing net (#0)
I0122 17:39:13.231596 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895888
I0122 17:39:13.231627 64218 solver.cpp:517]     Test net output #1: loss = 0.370912 (* 1 = 0.370912 loss)
I0122 17:39:13.231631 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895888
I0122 17:39:13.231636 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:39:13.295687 64218 solver.cpp:266] Iteration 31000 (12.8609 iter/s, 7.77549s/100 iter), loss = 0.00471151
I0122 17:39:13.295722 64218 solver.cpp:285]     Train net output #0: loss = 0.00471143 (* 1 = 0.00471143 loss)
I0122 17:39:13.295729 64218 sgd_solver.cpp:106] Iteration 31000, lr = 0.0001
I0122 17:39:19.625793 64218 solver.cpp:266] Iteration 31100 (15.7983 iter/s, 6.32981s/100 iter), loss = 0.00416513
I0122 17:39:19.625823 64218 solver.cpp:285]     Train net output #0: loss = 0.00416505 (* 1 = 0.00416505 loss)
I0122 17:39:19.625828 64218 sgd_solver.cpp:106] Iteration 31100, lr = 0.0001
I0122 17:39:25.930932 64218 solver.cpp:266] Iteration 31200 (15.8608 iter/s, 6.30485s/100 iter), loss = 0.00646361
I0122 17:39:25.931063 64218 solver.cpp:285]     Train net output #0: loss = 0.00646353 (* 1 = 0.00646353 loss)
I0122 17:39:25.931072 64218 sgd_solver.cpp:106] Iteration 31200, lr = 0.0001
I0122 17:39:32.251461 64218 solver.cpp:266] Iteration 31300 (15.8224 iter/s, 6.32014s/100 iter), loss = 0.00209865
I0122 17:39:32.251502 64218 solver.cpp:285]     Train net output #0: loss = 0.00209857 (* 1 = 0.00209857 loss)
I0122 17:39:32.251508 64218 sgd_solver.cpp:106] Iteration 31300, lr = 0.0001
I0122 17:39:38.586081 64218 solver.cpp:266] Iteration 31400 (15.787 iter/s, 6.33432s/100 iter), loss = 0.0101286
I0122 17:39:38.586123 64218 solver.cpp:285]     Train net output #0: loss = 0.0101286 (* 1 = 0.0101286 loss)
I0122 17:39:38.586130 64218 sgd_solver.cpp:106] Iteration 31400, lr = 0.0001
I0122 17:39:44.929929 64218 solver.cpp:266] Iteration 31500 (15.7641 iter/s, 6.34354s/100 iter), loss = 0.00700731
I0122 17:39:44.929958 64218 solver.cpp:285]     Train net output #0: loss = 0.00700723 (* 1 = 0.00700723 loss)
I0122 17:39:44.929965 64218 sgd_solver.cpp:106] Iteration 31500, lr = 0.0001
I0122 17:39:51.265735 64218 solver.cpp:266] Iteration 31600 (15.784 iter/s, 6.33551s/100 iter), loss = 0.00808502
I0122 17:39:51.265766 64218 solver.cpp:285]     Train net output #0: loss = 0.00808494 (* 1 = 0.00808494 loss)
I0122 17:39:51.265774 64218 sgd_solver.cpp:106] Iteration 31600, lr = 0.0001
I0122 17:39:57.622493 64218 solver.cpp:266] Iteration 31700 (15.732 iter/s, 6.35646s/100 iter), loss = 0.00443353
I0122 17:39:57.622594 64218 solver.cpp:285]     Train net output #0: loss = 0.00443345 (* 1 = 0.00443345 loss)
I0122 17:39:57.622601 64218 sgd_solver.cpp:106] Iteration 31700, lr = 0.0001
I0122 17:40:03.937547 64218 solver.cpp:266] Iteration 31800 (15.8361 iter/s, 6.31469s/100 iter), loss = 0.00486467
I0122 17:40:03.937587 64218 solver.cpp:285]     Train net output #0: loss = 0.00486459 (* 1 = 0.00486459 loss)
I0122 17:40:03.937594 64218 sgd_solver.cpp:106] Iteration 31800, lr = 0.0001
I0122 17:40:10.212348 64218 solver.cpp:266] Iteration 31900 (15.9375 iter/s, 6.2745s/100 iter), loss = 0.00323142
I0122 17:40:10.212378 64218 solver.cpp:285]     Train net output #0: loss = 0.00323134 (* 1 = 0.00323134 loss)
I0122 17:40:10.212383 64218 sgd_solver.cpp:106] Iteration 31900, lr = 0.0001
I0122 17:40:16.434783 64218 solver.cpp:418] Iteration 32000, Testing net (#0)
I0122 17:40:17.916738 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895555
I0122 17:40:17.916765 64218 solver.cpp:517]     Test net output #1: loss = 0.372623 (* 1 = 0.372623 loss)
I0122 17:40:17.916769 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895555
I0122 17:40:17.916774 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:40:17.979749 64218 solver.cpp:266] Iteration 32000 (12.8749 iter/s, 7.76706s/100 iter), loss = 0.00285488
I0122 17:40:17.979770 64218 solver.cpp:285]     Train net output #0: loss = 0.0028548 (* 1 = 0.0028548 loss)
I0122 17:40:17.979776 64218 sgd_solver.cpp:106] Iteration 32000, lr = 0.0001
I0122 17:40:24.238095 64218 solver.cpp:266] Iteration 32100 (15.9794 iter/s, 6.25807s/100 iter), loss = 0.0108251
I0122 17:40:24.238124 64218 solver.cpp:285]     Train net output #0: loss = 0.0108251 (* 1 = 0.0108251 loss)
I0122 17:40:24.238131 64218 sgd_solver.cpp:106] Iteration 32100, lr = 0.0001
I0122 17:40:30.541872 64218 solver.cpp:266] Iteration 32200 (15.8642 iter/s, 6.30349s/100 iter), loss = 0.00331257
I0122 17:40:30.542006 64218 solver.cpp:285]     Train net output #0: loss = 0.00331248 (* 1 = 0.00331248 loss)
I0122 17:40:30.542012 64218 sgd_solver.cpp:106] Iteration 32200, lr = 0.0001
I0122 17:40:36.833050 64218 solver.cpp:266] Iteration 32300 (15.8963 iter/s, 6.29079s/100 iter), loss = 0.00503825
I0122 17:40:36.833078 64218 solver.cpp:285]     Train net output #0: loss = 0.00503817 (* 1 = 0.00503817 loss)
I0122 17:40:36.833084 64218 sgd_solver.cpp:106] Iteration 32300, lr = 0.0001
I0122 17:40:43.124055 64218 solver.cpp:266] Iteration 32400 (15.8964 iter/s, 6.29072s/100 iter), loss = 0.00521051
I0122 17:40:43.124086 64218 solver.cpp:285]     Train net output #0: loss = 0.00521043 (* 1 = 0.00521043 loss)
I0122 17:40:43.124092 64218 sgd_solver.cpp:106] Iteration 32400, lr = 0.0001
I0122 17:40:49.413791 64218 solver.cpp:266] Iteration 32500 (15.8997 iter/s, 6.28945s/100 iter), loss = 0.00716515
I0122 17:40:49.413820 64218 solver.cpp:285]     Train net output #0: loss = 0.00716507 (* 1 = 0.00716507 loss)
I0122 17:40:49.413826 64218 sgd_solver.cpp:106] Iteration 32500, lr = 0.0001
I0122 17:40:55.690212 64218 solver.cpp:266] Iteration 32600 (15.9334 iter/s, 6.27614s/100 iter), loss = 0.00598994
I0122 17:40:55.690239 64218 solver.cpp:285]     Train net output #0: loss = 0.00598985 (* 1 = 0.00598985 loss)
I0122 17:40:55.690245 64218 sgd_solver.cpp:106] Iteration 32600, lr = 0.0001
I0122 17:41:01.976739 64218 solver.cpp:266] Iteration 32700 (15.9078 iter/s, 6.28624s/100 iter), loss = 0.00290997
I0122 17:41:01.976830 64218 solver.cpp:285]     Train net output #0: loss = 0.00290989 (* 1 = 0.00290989 loss)
I0122 17:41:01.976836 64218 sgd_solver.cpp:106] Iteration 32700, lr = 0.0001
I0122 17:41:08.287428 64218 solver.cpp:266] Iteration 32800 (15.847 iter/s, 6.31034s/100 iter), loss = 0.00616393
I0122 17:41:08.287456 64218 solver.cpp:285]     Train net output #0: loss = 0.00616384 (* 1 = 0.00616384 loss)
I0122 17:41:08.287462 64218 sgd_solver.cpp:106] Iteration 32800, lr = 0.0001
I0122 17:41:14.593955 64218 solver.cpp:266] Iteration 32900 (15.8573 iter/s, 6.30624s/100 iter), loss = 0.00322639
I0122 17:41:14.593992 64218 solver.cpp:285]     Train net output #0: loss = 0.0032263 (* 1 = 0.0032263 loss)
I0122 17:41:14.593998 64218 sgd_solver.cpp:106] Iteration 32900, lr = 0.0001
I0122 17:41:20.802704 64218 solver.cpp:418] Iteration 33000, Testing net (#0)
I0122 17:41:22.275285 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895888
I0122 17:41:22.275321 64218 solver.cpp:517]     Test net output #1: loss = 0.373277 (* 1 = 0.373277 loss)
I0122 17:41:22.275326 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895888
I0122 17:41:22.275328 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:41:22.338315 64218 solver.cpp:266] Iteration 33000 (12.9132 iter/s, 7.74401s/100 iter), loss = 0.00726023
I0122 17:41:22.338337 64218 solver.cpp:285]     Train net output #0: loss = 0.00726015 (* 1 = 0.00726015 loss)
I0122 17:41:22.338344 64218 sgd_solver.cpp:106] Iteration 33000, lr = 0.0001
I0122 17:41:28.642271 64218 solver.cpp:266] Iteration 33100 (15.8638 iter/s, 6.30367s/100 iter), loss = 0.0049676
I0122 17:41:28.642300 64218 solver.cpp:285]     Train net output #0: loss = 0.00496751 (* 1 = 0.00496751 loss)
I0122 17:41:28.642307 64218 sgd_solver.cpp:106] Iteration 33100, lr = 0.0001
I0122 17:41:34.941118 64218 solver.cpp:266] Iteration 33200 (15.8766 iter/s, 6.29856s/100 iter), loss = 0.00518801
I0122 17:41:34.941239 64218 solver.cpp:285]     Train net output #0: loss = 0.00518793 (* 1 = 0.00518793 loss)
I0122 17:41:34.941246 64218 sgd_solver.cpp:106] Iteration 33200, lr = 0.0001
I0122 17:41:41.385727 64218 solver.cpp:266] Iteration 33300 (15.5178 iter/s, 6.44423s/100 iter), loss = 0.00412217
I0122 17:41:41.385759 64218 solver.cpp:285]     Train net output #0: loss = 0.00412208 (* 1 = 0.00412208 loss)
I0122 17:41:41.385764 64218 sgd_solver.cpp:106] Iteration 33300, lr = 0.0001
I0122 17:41:47.823135 64218 solver.cpp:266] Iteration 33400 (15.5349 iter/s, 6.43711s/100 iter), loss = 0.00310175
I0122 17:41:47.823165 64218 solver.cpp:285]     Train net output #0: loss = 0.00310166 (* 1 = 0.00310166 loss)
I0122 17:41:47.823171 64218 sgd_solver.cpp:106] Iteration 33400, lr = 0.0001
I0122 17:41:54.199769 64218 solver.cpp:266] Iteration 33500 (15.683 iter/s, 6.37634s/100 iter), loss = 0.00633338
I0122 17:41:54.199800 64218 solver.cpp:285]     Train net output #0: loss = 0.0063333 (* 1 = 0.0063333 loss)
I0122 17:41:54.199806 64218 sgd_solver.cpp:106] Iteration 33500, lr = 0.0001
I0122 17:42:00.465888 64218 solver.cpp:266] Iteration 33600 (15.9596 iter/s, 6.26583s/100 iter), loss = 0.00363548
I0122 17:42:00.465920 64218 solver.cpp:285]     Train net output #0: loss = 0.0036354 (* 1 = 0.0036354 loss)
I0122 17:42:00.465941 64218 sgd_solver.cpp:106] Iteration 33600, lr = 0.0001
I0122 17:42:06.755487 64218 solver.cpp:266] Iteration 33700 (15.9 iter/s, 6.28931s/100 iter), loss = 0.00639126
I0122 17:42:06.755581 64218 solver.cpp:285]     Train net output #0: loss = 0.00639118 (* 1 = 0.00639118 loss)
I0122 17:42:06.755589 64218 sgd_solver.cpp:106] Iteration 33700, lr = 0.0001
I0122 17:42:13.019476 64218 solver.cpp:266] Iteration 33800 (15.9652 iter/s, 6.26364s/100 iter), loss = 0.00653344
I0122 17:42:13.019505 64218 solver.cpp:285]     Train net output #0: loss = 0.00653335 (* 1 = 0.00653335 loss)
I0122 17:42:13.019511 64218 sgd_solver.cpp:106] Iteration 33800, lr = 0.0001
I0122 17:42:19.304144 64218 solver.cpp:266] Iteration 33900 (15.9125 iter/s, 6.28438s/100 iter), loss = 0.00696642
I0122 17:42:19.304174 64218 solver.cpp:285]     Train net output #0: loss = 0.00696633 (* 1 = 0.00696633 loss)
I0122 17:42:19.304180 64218 sgd_solver.cpp:106] Iteration 33900, lr = 0.0001
I0122 17:42:25.501112 64218 solver.cpp:418] Iteration 34000, Testing net (#0)
I0122 17:42:26.997270 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895222
I0122 17:42:26.997297 64218 solver.cpp:517]     Test net output #1: loss = 0.373709 (* 1 = 0.373709 loss)
I0122 17:42:26.997301 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895222
I0122 17:42:26.997305 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:42:27.066712 64218 solver.cpp:266] Iteration 34000 (12.8829 iter/s, 7.76223s/100 iter), loss = 0.00412645
I0122 17:42:27.066733 64218 solver.cpp:285]     Train net output #0: loss = 0.00412637 (* 1 = 0.00412637 loss)
I0122 17:42:27.066740 64218 sgd_solver.cpp:106] Iteration 34000, lr = 0.0001
I0122 17:42:33.373386 64218 solver.cpp:266] Iteration 34100 (15.8569 iter/s, 6.3064s/100 iter), loss = 0.00405047
I0122 17:42:33.373417 64218 solver.cpp:285]     Train net output #0: loss = 0.00405039 (* 1 = 0.00405039 loss)
I0122 17:42:33.373423 64218 sgd_solver.cpp:106] Iteration 34100, lr = 0.0001
I0122 17:42:39.669921 64218 solver.cpp:266] Iteration 34200 (15.8825 iter/s, 6.29625s/100 iter), loss = 0.00506066
I0122 17:42:39.670006 64218 solver.cpp:285]     Train net output #0: loss = 0.00506057 (* 1 = 0.00506057 loss)
I0122 17:42:39.670013 64218 sgd_solver.cpp:106] Iteration 34200, lr = 0.0001
I0122 17:42:45.953400 64218 solver.cpp:266] Iteration 34300 (15.9156 iter/s, 6.28314s/100 iter), loss = 0.00563428
I0122 17:42:45.953430 64218 solver.cpp:285]     Train net output #0: loss = 0.00563419 (* 1 = 0.00563419 loss)
I0122 17:42:45.953436 64218 sgd_solver.cpp:106] Iteration 34300, lr = 0.0001
I0122 17:42:52.228969 64218 solver.cpp:266] Iteration 34400 (15.9355 iter/s, 6.27528s/100 iter), loss = 0.0107926
I0122 17:42:52.228997 64218 solver.cpp:285]     Train net output #0: loss = 0.0107925 (* 1 = 0.0107925 loss)
I0122 17:42:52.229002 64218 sgd_solver.cpp:106] Iteration 34400, lr = 0.0001
I0122 17:42:58.499763 64218 solver.cpp:266] Iteration 34500 (15.9477 iter/s, 6.27051s/100 iter), loss = 0.00228857
I0122 17:42:58.499804 64218 solver.cpp:285]     Train net output #0: loss = 0.00228848 (* 1 = 0.00228848 loss)
I0122 17:42:58.499810 64218 sgd_solver.cpp:106] Iteration 34500, lr = 0.0001
I0122 17:43:04.745559 64218 solver.cpp:266] Iteration 34600 (16.0115 iter/s, 6.2455s/100 iter), loss = 0.0042284
I0122 17:43:04.745589 64218 solver.cpp:285]     Train net output #0: loss = 0.00422831 (* 1 = 0.00422831 loss)
I0122 17:43:04.745595 64218 sgd_solver.cpp:106] Iteration 34600, lr = 0.0001
I0122 17:43:11.024549 64218 solver.cpp:266] Iteration 34700 (15.9269 iter/s, 6.2787s/100 iter), loss = 0.004485
I0122 17:43:11.024641 64218 solver.cpp:285]     Train net output #0: loss = 0.00448491 (* 1 = 0.00448491 loss)
I0122 17:43:11.024648 64218 sgd_solver.cpp:106] Iteration 34700, lr = 0.0001
I0122 17:43:17.291630 64218 solver.cpp:266] Iteration 34800 (15.9573 iter/s, 6.26674s/100 iter), loss = 0.0034133
I0122 17:43:17.291659 64218 solver.cpp:285]     Train net output #0: loss = 0.00341321 (* 1 = 0.00341321 loss)
I0122 17:43:17.291666 64218 sgd_solver.cpp:106] Iteration 34800, lr = 0.0001
I0122 17:43:23.568832 64218 solver.cpp:266] Iteration 34900 (15.9314 iter/s, 6.27692s/100 iter), loss = 0.0120055
I0122 17:43:23.568861 64218 solver.cpp:285]     Train net output #0: loss = 0.0120054 (* 1 = 0.0120054 loss)
I0122 17:43:23.568867 64218 sgd_solver.cpp:106] Iteration 34900, lr = 0.0001
I0122 17:43:29.815894 64218 solver.cpp:418] Iteration 35000, Testing net (#0)
I0122 17:43:31.286686 64218 solver.cpp:517]     Test net output #0: accuracy = 0.896222
I0122 17:43:31.286713 64218 solver.cpp:517]     Test net output #1: loss = 0.373921 (* 1 = 0.373921 loss)
I0122 17:43:31.286717 64218 solver.cpp:517]     Test net output #2: top-1 = 0.896222
I0122 17:43:31.286721 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:43:31.349565 64218 solver.cpp:266] Iteration 35000 (12.8528 iter/s, 7.78039s/100 iter), loss = 0.00759784
I0122 17:43:31.349586 64218 solver.cpp:285]     Train net output #0: loss = 0.00759775 (* 1 = 0.00759775 loss)
I0122 17:43:31.349592 64218 sgd_solver.cpp:106] Iteration 35000, lr = 0.0001
I0122 17:43:37.622514 64218 solver.cpp:266] Iteration 35100 (15.9422 iter/s, 6.27267s/100 iter), loss = 0.00246872
I0122 17:43:37.622545 64218 solver.cpp:285]     Train net output #0: loss = 0.00246863 (* 1 = 0.00246863 loss)
I0122 17:43:37.622551 64218 sgd_solver.cpp:106] Iteration 35100, lr = 0.0001
I0122 17:43:43.914471 64218 solver.cpp:266] Iteration 35200 (15.894 iter/s, 6.29167s/100 iter), loss = 0.00851007
I0122 17:43:43.914579 64218 solver.cpp:285]     Train net output #0: loss = 0.00850998 (* 1 = 0.00850998 loss)
I0122 17:43:43.914587 64218 sgd_solver.cpp:106] Iteration 35200, lr = 0.0001
I0122 17:43:50.222123 64218 solver.cpp:266] Iteration 35300 (15.8547 iter/s, 6.30729s/100 iter), loss = 0.0067545
I0122 17:43:50.222152 64218 solver.cpp:285]     Train net output #0: loss = 0.00675441 (* 1 = 0.00675441 loss)
I0122 17:43:50.222157 64218 sgd_solver.cpp:106] Iteration 35300, lr = 0.0001
I0122 17:43:56.528334 64218 solver.cpp:266] Iteration 35400 (15.8581 iter/s, 6.30593s/100 iter), loss = 0.00489548
I0122 17:43:56.528363 64218 solver.cpp:285]     Train net output #0: loss = 0.00489539 (* 1 = 0.00489539 loss)
I0122 17:43:56.528368 64218 sgd_solver.cpp:106] Iteration 35400, lr = 0.0001
I0122 17:44:02.795557 64218 solver.cpp:266] Iteration 35500 (15.9567 iter/s, 6.26694s/100 iter), loss = 0.00781946
I0122 17:44:02.795586 64218 solver.cpp:285]     Train net output #0: loss = 0.00781937 (* 1 = 0.00781937 loss)
I0122 17:44:02.795593 64218 sgd_solver.cpp:106] Iteration 35500, lr = 0.0001
I0122 17:44:09.128751 64218 solver.cpp:266] Iteration 35600 (15.7905 iter/s, 6.33291s/100 iter), loss = 0.00565488
I0122 17:44:09.128782 64218 solver.cpp:285]     Train net output #0: loss = 0.00565479 (* 1 = 0.00565479 loss)
I0122 17:44:09.128787 64218 sgd_solver.cpp:106] Iteration 35600, lr = 0.0001
I0122 17:44:15.436264 64218 solver.cpp:266] Iteration 35700 (15.8548 iter/s, 6.30723s/100 iter), loss = 0.00546114
I0122 17:44:15.436390 64218 solver.cpp:285]     Train net output #0: loss = 0.00546105 (* 1 = 0.00546105 loss)
I0122 17:44:15.436396 64218 sgd_solver.cpp:106] Iteration 35700, lr = 0.0001
I0122 17:44:21.721313 64218 solver.cpp:266] Iteration 35800 (15.9117 iter/s, 6.28467s/100 iter), loss = 0.00676943
I0122 17:44:21.721341 64218 solver.cpp:285]     Train net output #0: loss = 0.00676934 (* 1 = 0.00676934 loss)
I0122 17:44:21.721348 64218 sgd_solver.cpp:106] Iteration 35800, lr = 0.0001
I0122 17:44:28.030558 64218 solver.cpp:266] Iteration 35900 (15.8505 iter/s, 6.30896s/100 iter), loss = 0.00272039
I0122 17:44:28.030601 64218 solver.cpp:285]     Train net output #0: loss = 0.0027203 (* 1 = 0.0027203 loss)
I0122 17:44:28.030606 64218 sgd_solver.cpp:106] Iteration 35900, lr = 0.0001
I0122 17:44:34.257710 64218 solver.cpp:418] Iteration 36000, Testing net (#0)
I0122 17:44:35.738508 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895444
I0122 17:44:35.738536 64218 solver.cpp:517]     Test net output #1: loss = 0.374471 (* 1 = 0.374471 loss)
I0122 17:44:35.738541 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895444
I0122 17:44:35.738544 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:44:35.802971 64218 solver.cpp:266] Iteration 36000 (12.8666 iter/s, 7.77206s/100 iter), loss = 0.00586163
I0122 17:44:35.802996 64218 solver.cpp:285]     Train net output #0: loss = 0.00586154 (* 1 = 0.00586154 loss)
I0122 17:44:35.803004 64218 sgd_solver.cpp:106] Iteration 36000, lr = 0.0001
I0122 17:44:42.093845 64218 solver.cpp:266] Iteration 36100 (15.8967 iter/s, 6.2906s/100 iter), loss = 0.00412684
I0122 17:44:42.093875 64218 solver.cpp:285]     Train net output #0: loss = 0.00412675 (* 1 = 0.00412675 loss)
I0122 17:44:42.093883 64218 sgd_solver.cpp:106] Iteration 36100, lr = 0.0001
I0122 17:44:48.406944 64218 solver.cpp:266] Iteration 36200 (15.8408 iter/s, 6.31281s/100 iter), loss = 0.00366496
I0122 17:44:48.407081 64218 solver.cpp:285]     Train net output #0: loss = 0.00366487 (* 1 = 0.00366487 loss)
I0122 17:44:48.407089 64218 sgd_solver.cpp:106] Iteration 36200, lr = 0.0001
I0122 17:44:54.673928 64218 solver.cpp:266] Iteration 36300 (15.9576 iter/s, 6.2666s/100 iter), loss = 0.00700542
I0122 17:44:54.673959 64218 solver.cpp:285]     Train net output #0: loss = 0.00700533 (* 1 = 0.00700533 loss)
I0122 17:44:54.673964 64218 sgd_solver.cpp:106] Iteration 36300, lr = 0.0001
I0122 17:45:00.940153 64218 solver.cpp:266] Iteration 36400 (15.9593 iter/s, 6.26594s/100 iter), loss = 0.00365558
I0122 17:45:00.940184 64218 solver.cpp:285]     Train net output #0: loss = 0.00365549 (* 1 = 0.00365549 loss)
I0122 17:45:00.940189 64218 sgd_solver.cpp:106] Iteration 36400, lr = 0.0001
I0122 17:45:07.192183 64218 solver.cpp:266] Iteration 36500 (15.9955 iter/s, 6.25175s/100 iter), loss = 0.00734094
I0122 17:45:07.192211 64218 solver.cpp:285]     Train net output #0: loss = 0.00734085 (* 1 = 0.00734085 loss)
I0122 17:45:07.192219 64218 sgd_solver.cpp:106] Iteration 36500, lr = 0.0001
I0122 17:45:13.465900 64218 solver.cpp:266] Iteration 36600 (15.9402 iter/s, 6.27344s/100 iter), loss = 0.0029221
I0122 17:45:13.465930 64218 solver.cpp:285]     Train net output #0: loss = 0.00292202 (* 1 = 0.00292202 loss)
I0122 17:45:13.465936 64218 sgd_solver.cpp:106] Iteration 36600, lr = 0.0001
I0122 17:45:19.721101 64218 solver.cpp:266] Iteration 36700 (15.9874 iter/s, 6.25492s/100 iter), loss = 0.00404088
I0122 17:45:19.721165 64218 solver.cpp:285]     Train net output #0: loss = 0.0040408 (* 1 = 0.0040408 loss)
I0122 17:45:19.721173 64218 sgd_solver.cpp:106] Iteration 36700, lr = 0.0001
I0122 17:45:25.976651 64218 solver.cpp:266] Iteration 36800 (15.9866 iter/s, 6.25524s/100 iter), loss = 0.00834045
I0122 17:45:25.976692 64218 solver.cpp:285]     Train net output #0: loss = 0.00834036 (* 1 = 0.00834036 loss)
I0122 17:45:25.976698 64218 sgd_solver.cpp:106] Iteration 36800, lr = 0.0001
I0122 17:45:32.236783 64218 solver.cpp:266] Iteration 36900 (15.9748 iter/s, 6.25984s/100 iter), loss = 0.00480485
I0122 17:45:32.236812 64218 solver.cpp:285]     Train net output #0: loss = 0.00480476 (* 1 = 0.00480476 loss)
I0122 17:45:32.236819 64218 sgd_solver.cpp:106] Iteration 36900, lr = 0.0001
I0122 17:45:38.432915 64218 solver.cpp:418] Iteration 37000, Testing net (#0)
I0122 17:45:39.890501 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895888
I0122 17:45:39.890528 64218 solver.cpp:517]     Test net output #1: loss = 0.373872 (* 1 = 0.373872 loss)
I0122 17:45:39.890533 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895888
I0122 17:45:39.890552 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:45:39.953660 64218 solver.cpp:266] Iteration 37000 (12.9592 iter/s, 7.71654s/100 iter), loss = 0.00989747
I0122 17:45:39.953681 64218 solver.cpp:285]     Train net output #0: loss = 0.00989738 (* 1 = 0.00989738 loss)
I0122 17:45:39.953688 64218 sgd_solver.cpp:106] Iteration 37000, lr = 0.0001
I0122 17:45:46.214447 64218 solver.cpp:266] Iteration 37100 (15.9731 iter/s, 6.26051s/100 iter), loss = 0.00357499
I0122 17:45:46.214488 64218 solver.cpp:285]     Train net output #0: loss = 0.00357491 (* 1 = 0.00357491 loss)
I0122 17:45:46.214494 64218 sgd_solver.cpp:106] Iteration 37100, lr = 0.0001
I0122 17:45:52.437415 64218 solver.cpp:266] Iteration 37200 (16.0702 iter/s, 6.22268s/100 iter), loss = 0.00550309
I0122 17:45:52.437506 64218 solver.cpp:285]     Train net output #0: loss = 0.005503 (* 1 = 0.005503 loss)
I0122 17:45:52.437515 64218 sgd_solver.cpp:106] Iteration 37200, lr = 0.0001
I0122 17:45:58.705982 64218 solver.cpp:266] Iteration 37300 (15.9535 iter/s, 6.26823s/100 iter), loss = 0.00598155
I0122 17:45:58.706010 64218 solver.cpp:285]     Train net output #0: loss = 0.00598146 (* 1 = 0.00598146 loss)
I0122 17:45:58.706017 64218 sgd_solver.cpp:106] Iteration 37300, lr = 0.0001
I0122 17:46:04.955891 64218 solver.cpp:266] Iteration 37400 (16.0009 iter/s, 6.24963s/100 iter), loss = 0.00245948
I0122 17:46:04.955920 64218 solver.cpp:285]     Train net output #0: loss = 0.00245939 (* 1 = 0.00245939 loss)
I0122 17:46:04.955927 64218 sgd_solver.cpp:106] Iteration 37400, lr = 0.0001
I0122 17:46:11.228956 64218 solver.cpp:266] Iteration 37500 (15.9419 iter/s, 6.27278s/100 iter), loss = 0.00690917
I0122 17:46:11.228983 64218 solver.cpp:285]     Train net output #0: loss = 0.00690908 (* 1 = 0.00690908 loss)
I0122 17:46:11.228989 64218 sgd_solver.cpp:106] Iteration 37500, lr = 0.0001
I0122 17:46:17.492491 64218 solver.cpp:266] Iteration 37600 (15.9661 iter/s, 6.26326s/100 iter), loss = 0.00325214
I0122 17:46:17.492521 64218 solver.cpp:285]     Train net output #0: loss = 0.00325205 (* 1 = 0.00325205 loss)
I0122 17:46:17.492527 64218 sgd_solver.cpp:106] Iteration 37600, lr = 0.0001
I0122 17:46:23.743377 64218 solver.cpp:266] Iteration 37700 (15.9984 iter/s, 6.25061s/100 iter), loss = 0.00952537
I0122 17:46:23.743439 64218 solver.cpp:285]     Train net output #0: loss = 0.00952528 (* 1 = 0.00952528 loss)
I0122 17:46:23.743446 64218 sgd_solver.cpp:106] Iteration 37700, lr = 0.0001
I0122 17:46:29.999392 64218 solver.cpp:266] Iteration 37800 (15.9854 iter/s, 6.2557s/100 iter), loss = 0.00570323
I0122 17:46:29.999431 64218 solver.cpp:285]     Train net output #0: loss = 0.00570315 (* 1 = 0.00570315 loss)
I0122 17:46:29.999439 64218 sgd_solver.cpp:106] Iteration 37800, lr = 0.0001
I0122 17:46:36.252794 64218 solver.cpp:266] Iteration 37900 (15.992 iter/s, 6.25311s/100 iter), loss = 0.00677969
I0122 17:46:36.252825 64218 solver.cpp:285]     Train net output #0: loss = 0.0067796 (* 1 = 0.0067796 loss)
I0122 17:46:36.252830 64218 sgd_solver.cpp:106] Iteration 37900, lr = 0.0001
I0122 17:46:42.438366 64218 solver.cpp:418] Iteration 38000, Testing net (#0)
I0122 17:46:43.895489 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895444
I0122 17:46:43.895514 64218 solver.cpp:517]     Test net output #1: loss = 0.373965 (* 1 = 0.373965 loss)
I0122 17:46:43.895517 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895444
I0122 17:46:43.895521 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996
I0122 17:46:43.959228 64218 solver.cpp:266] Iteration 38000 (12.9767 iter/s, 7.7061s/100 iter), loss = 0.00439637
I0122 17:46:43.959246 64218 solver.cpp:285]     Train net output #0: loss = 0.00439628 (* 1 = 0.00439628 loss)
I0122 17:46:43.959254 64218 sgd_solver.cpp:106] Iteration 38000, lr = 0.0001
I0122 17:46:50.212147 64218 solver.cpp:266] Iteration 38100 (15.9932 iter/s, 6.25265s/100 iter), loss = 0.00554695
I0122 17:46:50.212175 64218 solver.cpp:285]     Train net output #0: loss = 0.00554686 (* 1 = 0.00554686 loss)
I0122 17:46:50.212180 64218 sgd_solver.cpp:106] Iteration 38100, lr = 0.0001
I0122 17:46:56.473008 64218 solver.cpp:266] Iteration 38200 (15.973 iter/s, 6.26058s/100 iter), loss = 0.00712834
I0122 17:46:56.473143 64218 solver.cpp:285]     Train net output #0: loss = 0.00712824 (* 1 = 0.00712824 loss)
I0122 17:46:56.473150 64218 sgd_solver.cpp:106] Iteration 38200, lr = 0.0001
I0122 17:47:02.720399 64218 solver.cpp:266] Iteration 38300 (16.0077 iter/s, 6.24701s/100 iter), loss = 0.00674534
I0122 17:47:02.720428 64218 solver.cpp:285]     Train net output #0: loss = 0.00674525 (* 1 = 0.00674525 loss)
I0122 17:47:02.720434 64218 sgd_solver.cpp:106] Iteration 38300, lr = 0.0001
I0122 17:47:09.000645 64218 solver.cpp:266] Iteration 38400 (15.9237 iter/s, 6.27997s/100 iter), loss = 0.0081917
I0122 17:47:09.000674 64218 solver.cpp:285]     Train net output #0: loss = 0.0081916 (* 1 = 0.0081916 loss)
I0122 17:47:09.000679 64218 sgd_solver.cpp:106] Iteration 38400, lr = 0.0001
I0122 17:47:15.267161 64218 solver.cpp:266] Iteration 38500 (15.9585 iter/s, 6.26624s/100 iter), loss = 0.00917292
I0122 17:47:15.267187 64218 solver.cpp:285]     Train net output #0: loss = 0.00917283 (* 1 = 0.00917283 loss)
I0122 17:47:15.267192 64218 sgd_solver.cpp:106] Iteration 38500, lr = 0.0001
I0122 17:47:21.532946 64218 solver.cpp:266] Iteration 38600 (15.9604 iter/s, 6.26551s/100 iter), loss = 0.00277375
I0122 17:47:21.532976 64218 solver.cpp:285]     Train net output #0: loss = 0.00277366 (* 1 = 0.00277366 loss)
I0122 17:47:21.532982 64218 sgd_solver.cpp:106] Iteration 38600, lr = 0.0001
I0122 17:47:27.794373 64218 solver.cpp:266] Iteration 38700 (15.9715 iter/s, 6.26115s/100 iter), loss = 0.00589407
I0122 17:47:27.794432 64218 solver.cpp:285]     Train net output #0: loss = 0.00589398 (* 1 = 0.00589398 loss)
I0122 17:47:27.794440 64218 sgd_solver.cpp:106] Iteration 38700, lr = 0.0001
I0122 17:47:34.050460 64218 solver.cpp:266] Iteration 38800 (15.9852 iter/s, 6.25578s/100 iter), loss = 0.0074406
I0122 17:47:34.050492 64218 solver.cpp:285]     Train net output #0: loss = 0.00744051 (* 1 = 0.00744051 loss)
I0122 17:47:34.050498 64218 sgd_solver.cpp:106] Iteration 38800, lr = 0.0001
I0122 17:47:40.304071 64218 solver.cpp:266] Iteration 38900 (15.9915 iter/s, 6.25333s/100 iter), loss = 0.00596343
I0122 17:47:40.304101 64218 solver.cpp:285]     Train net output #0: loss = 0.00596333 (* 1 = 0.00596333 loss)
I0122 17:47:40.304107 64218 sgd_solver.cpp:106] Iteration 38900, lr = 0.0001
I0122 17:47:46.487993 64218 solver.cpp:418] Iteration 39000, Testing net (#0)
I0122 17:47:47.960788 64218 solver.cpp:517]     Test net output #0: accuracy = 0.896222
I0122 17:47:47.960814 64218 solver.cpp:517]     Test net output #1: loss = 0.373637 (* 1 = 0.373637 loss)
I0122 17:47:47.960819 64218 solver.cpp:517]     Test net output #2: top-1 = 0.896222
I0122 17:47:47.960822 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:47:48.025765 64218 solver.cpp:266] Iteration 39000 (12.9511 iter/s, 7.72136s/100 iter), loss = 0.00453338
I0122 17:47:48.025786 64218 solver.cpp:285]     Train net output #0: loss = 0.00453329 (* 1 = 0.00453329 loss)
I0122 17:47:48.025794 64218 sgd_solver.cpp:106] Iteration 39000, lr = 0.0001
I0122 17:47:54.280653 64218 solver.cpp:266] Iteration 39100 (15.9882 iter/s, 6.25462s/100 iter), loss = 0.0323906
I0122 17:47:54.280683 64218 solver.cpp:285]     Train net output #0: loss = 0.0323905 (* 1 = 0.0323905 loss)
I0122 17:47:54.280689 64218 sgd_solver.cpp:106] Iteration 39100, lr = 0.0001
I0122 17:48:00.533414 64218 solver.cpp:266] Iteration 39200 (15.9936 iter/s, 6.25248s/100 iter), loss = 0.00485437
I0122 17:48:00.533471 64218 solver.cpp:285]     Train net output #0: loss = 0.00485428 (* 1 = 0.00485428 loss)
I0122 17:48:00.533478 64218 sgd_solver.cpp:106] Iteration 39200, lr = 0.0001
I0122 17:48:06.805066 64218 solver.cpp:266] Iteration 39300 (15.9455 iter/s, 6.27135s/100 iter), loss = 0.00626143
I0122 17:48:06.805096 64218 solver.cpp:285]     Train net output #0: loss = 0.00626134 (* 1 = 0.00626134 loss)
I0122 17:48:06.805102 64218 sgd_solver.cpp:106] Iteration 39300, lr = 0.0001
I0122 17:48:13.063447 64218 solver.cpp:266] Iteration 39400 (15.9793 iter/s, 6.2581s/100 iter), loss = 0.00646417
I0122 17:48:13.063477 64218 solver.cpp:285]     Train net output #0: loss = 0.00646408 (* 1 = 0.00646408 loss)
I0122 17:48:13.063482 64218 sgd_solver.cpp:106] Iteration 39400, lr = 0.0001
I0122 17:48:19.307777 64218 solver.cpp:266] Iteration 39500 (16.0152 iter/s, 6.24405s/100 iter), loss = 0.00390461
I0122 17:48:19.307807 64218 solver.cpp:285]     Train net output #0: loss = 0.00390452 (* 1 = 0.00390452 loss)
I0122 17:48:19.307813 64218 sgd_solver.cpp:106] Iteration 39500, lr = 0.0001
I0122 17:48:25.575251 64218 solver.cpp:266] Iteration 39600 (15.9561 iter/s, 6.26719s/100 iter), loss = 0.0205236
I0122 17:48:25.575291 64218 solver.cpp:285]     Train net output #0: loss = 0.0205235 (* 1 = 0.0205235 loss)
I0122 17:48:25.575299 64218 sgd_solver.cpp:106] Iteration 39600, lr = 0.0001
I0122 17:48:31.838977 64218 solver.cpp:266] Iteration 39700 (15.9657 iter/s, 6.26344s/100 iter), loss = 0.00355441
I0122 17:48:31.839056 64218 solver.cpp:285]     Train net output #0: loss = 0.00355432 (* 1 = 0.00355432 loss)
I0122 17:48:31.839063 64218 sgd_solver.cpp:106] Iteration 39700, lr = 0.0001
I0122 17:48:38.089114 64218 solver.cpp:266] Iteration 39800 (16.0005 iter/s, 6.24981s/100 iter), loss = 0.00953196
I0122 17:48:38.089144 64218 solver.cpp:285]     Train net output #0: loss = 0.00953187 (* 1 = 0.00953187 loss)
I0122 17:48:38.089150 64218 sgd_solver.cpp:106] Iteration 39800, lr = 0.0001
I0122 17:48:44.353148 64218 solver.cpp:266] Iteration 39900 (15.9649 iter/s, 6.26375s/100 iter), loss = 0.00342594
I0122 17:48:44.353178 64218 solver.cpp:285]     Train net output #0: loss = 0.00342585 (* 1 = 0.00342585 loss)
I0122 17:48:44.353184 64218 sgd_solver.cpp:106] Iteration 39900, lr = 0.0001
I0122 17:48:50.520723 64218 solver.cpp:929] Snapshotting to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_40000.caffemodel
I0122 17:48:50.564146 64218 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar10/deephi/miniGoogleNet/pruning/regular_rate_0/snapshots/_iter_40000.solverstate
I0122 17:48:50.594069 64218 solver.cpp:378] Iteration 40000, loss = 0.00367317
I0122 17:48:50.594101 64218 solver.cpp:418] Iteration 40000, Testing net (#0)
I0122 17:48:52.069146 64218 solver.cpp:517]     Test net output #0: accuracy = 0.895555
I0122 17:48:52.069173 64218 solver.cpp:517]     Test net output #1: loss = 0.373944 (* 1 = 0.373944 loss)
I0122 17:48:52.069180 64218 solver.cpp:517]     Test net output #2: top-1 = 0.895555
I0122 17:48:52.069182 64218 solver.cpp:517]     Test net output #3: top-5 = 0.996111
I0122 17:48:52.069186 64218 solver.cpp:386] Optimization Done (13.4624 iter/s).
I0122 17:48:52.069191 64218 caffe_interface.cpp:530] Optimization Done.
